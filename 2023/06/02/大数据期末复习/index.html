

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Starmin">
  <meta name="keywords" content="">
  
    <meta name="description" content="大数据期末复习 Ch1 Intruction What is big data? Big data is used to describe a massive volume of both structured and unstructured data that is so large that it&#39;s difficult to process using traditional databa">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据期末复习">
<meta property="og:url" content="https://gstarmin.github.io/2023/06/02/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/">
<meta property="og:site_name" content="私人杂货铺">
<meta property="og:description" content="大数据期末复习 Ch1 Intruction What is big data? Big data is used to describe a massive volume of both structured and unstructured data that is so large that it&#39;s difficult to process using traditional databa">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/4v-features.png">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/KDD-process.png">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/ch2-lossfunction.png">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/ch3-the-big-pic.png">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/ch3-similarity.png">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/ch3-signature计算.png">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/Partion-Into-Bands.png">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/Partion-Into-Bands-例子.png">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/Spectral-Hashing公式.png">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/ch3-Learning-Based-Hashing-步骤.png">
<meta property="og:image" content="https://gstarmin.github.io/img/大数据/ch4-CDF.png">
<meta property="article:published_time" content="2023-06-02T09:38:02.000Z">
<meta property="article:modified_time" content="2023-06-02T09:38:02.000Z">
<meta property="article:author" content="Starmin">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://gstarmin.github.io/img/大数据/4v-features.png">
  
  
  
  <title>大数据期末复习 - 私人杂货铺</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"gstarmin.github.io","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 5.4.2"><style>.mjpage .MJX-monospace {
  font-family: monospace;
}

.mjpage .MJX-sans-serif {
  font-family: sans-serif;
}

.mjpage {
  display: inline;
  font-style: normal;
  font-weight: normal;
  line-height: normal;
  font-size: 100%;
  font-size-adjust: none;
  text-indent: 0;
  text-align: left;
  text-transform: none;
  letter-spacing: normal;
  word-spacing: normal;
  word-wrap: normal;
  white-space: nowrap;
  float: none;
  direction: ltr;
  max-width: none;
  max-height: none;
  min-width: 0;
  min-height: 0;
  border: 0;
  padding: 0;
  margin: 0;
}

.mjpage * {
  transition: none;
  -webkit-transition: none;
  -moz-transition: none;
  -ms-transition: none;
  -o-transition: none;
}

.mjx-svg-href {
  fill: blue;
  stroke: blue;
}

.MathJax_SVG_LineBox {
  display: table !important;
}

.MathJax_SVG_LineBox span {
  display: table-cell !important;
  width: 10000em !important;
  min-width: 0;
  max-width: none;
  padding: 0;
  border: 0;
  margin: 0;
}

.mjpage__block {
  text-align: center;
  margin: 1em 0em;
  position: relative;
  display: block !important;
  text-indent: 0;
  max-width: none;
  max-height: none;
  min-width: 0;
  min-height: 0;
  width: 100%;
}
</style></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Starmin</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="大数据期末复习"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-06-02 17:38" pubdate>
          2023年6月2日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.2k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          63 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">大数据期末复习</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="大数据期末复习">大数据期末复习</h1>
<h2 id="ch1-intruction">Ch1 Intruction</h2>
<h3 id="what-is-big-data">What is big data?</h3>
<p><strong>Big data</strong> is used to describe a massive volume of
both structured and unstructured data that is so large that it's
difficult to process using traditional database and software
techniques.</p>
<p><strong>大数据</strong>用来描述大量的结构化和非结构化的数据，这些数据非常大，难以用传统的数据库和软件技术来处理。</p>
<h3 id="the-4v-features-of-big-data">The 4V Features of big data</h3>
<p><img src="/img/大数据/4v-features.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>Volume (Scale of Data)</li>
<li>Velocity (Data Stream)</li>
<li>Variety (Different types of data)</li>
<li>Veracity (Uncertainty, missing value)</li>
</ul>
<h3 id="what-is-data-mining">What is data mining?</h3>
<p><strong>Data mining</strong> consists of applying data analysis and
discovery algorithms that, under acceptable computational efficiency
limitations, produce a particular enumeration of patterns over the
data.</p>
<p><strong>数据挖掘</strong>包括应用数据分析和发现算法，在可接受的计算效率限制下，在数据上产生特定的模式列举。</p>
<h3 id="the-kdd-processcore-part">The KDD Process(core part)</h3>
<p><img src="/img/大数据/KDD-process.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="the-main-tasks-of-data-mining">The main tasks of Data
mining</h3>
<ul>
<li>Association Rule Mining(关联规则挖掘)</li>
<li>Cluster Analysis(聚类分析)</li>
<li>Classification/Prediction(分类/预测)</li>
<li>Outlier Detection(异常点检测)</li>
</ul>
<h3
id="the-relationship-between-data-minning-and-other-subjectse.g.-database">The
relationship between Data minning and other subjects(e.g. Database)</h3>
<p>Data mining is known as Knowledge Discovery in Database (KDD) in the
field of artificial intelligence, is also considered as a fundamental
step in the process of knowledge discovery in database.</p>
<p>数据挖掘在人工智能领域被称为数据库知识发现（KDD），也被认为是数据库知识发现过程中的一个基本步骤。</p>
<h3 id="the-challenges-of-big-data-mining">The challenges of big data
mining</h3>
<ul>
<li>Curse of dimensionality</li>
<li>Storage cost</li>
<li>Query speed <!-- - Data Quality
- Data Complexity
- Data Privacy and Security
- Scalability
- Ethics(伦理学)
- interpretability --></li>
</ul>
<h2 id="ch2-foundations-of-data-mining">Ch2 Foundations of Data
Mining</h2>
<h3
id="supervised-learningunsupervised-learningsemi-supervised-learning">Supervised
learning/Unsupervised learning/Semi-supervised learning</h3>
<ul>
<li><strong>Supervised learning</strong>: targets to learn the mapping
function or relationship between the features and the labels based on
the labeled data. Namely, <span class="math inline">\(𝑌=𝐹(𝑋|𝜃)\)</span>.
(e.g. Classification, Prediction)</li>
<li><strong>Unsupervised learning</strong>: aims at learning the
intrinsic structure from unlabeled data. (e.g. Clustering, Latent Factor
Learning and Frequent Items Mining)</li>
<li><strong>Semi-supervised learning</strong>: can be regarded as the
unsupervised learning with some constraints on labels, or the supervised
learning with additional information on the distribution of data.</li>
</ul>
<h3 id="loss-function">LOSS FUNCTION</h3>
<p><img src="/img/大数据/ch2-lossfunction.png" srcset="/img/loading.gif" lazyload /></p>
<p><span class="math inline">\(l_1\)</span> norm:</p>
<p><span class="math display">\[L(\beta) =\frac{1}{N}\sum\limits_{i =
1}^{N}L(Y_i, F(X_i | \beta)) + \frac{\lambda}{2} || \beta
||_2\]</span></p>
<p><span class="math inline">\(l_2\)</span> norm:</p>
<p><span class="math display">\[L(\beta) =\frac{1}{N}\sum\limits_{i =
1}^{N}L(Y_i, F(X_i | \beta)) + \frac{\lambda}{2} || \beta
||_1\]</span></p>
<p><span class="math inline">\(||A||_∗\)</span> nuclear norm:</p>
<p><span class="math display">\[||A||∗=∑_i{σ_i}(A).\]</span></p>
<h3 id="overfittingunderfitting-problem">Overfitting/Underfitting
problem</h3>
<p><strong>Reason</strong>?</p>
<p><strong>How to avoid overfitting</strong>?</p>
<h3 id="classfied-algorithms">Classfied Algorithms</h3>
<h4 id="decision-tree">Decision Tree</h4>
<ul>
<li>How to construct DT?</li>
<li>Attribute selection Criteria
<ul>
<li>Information Gain</li>
<li>Information Gain Ratio</li>
<li>Gini index</li>
</ul></li>
</ul>
<h4 id="knn">KNN</h4>
<p><strong>Lazy Learning</strong>: Lazy Learning does not extract rules
or generalizations from a specific model. Instead, it searches for
historical instances that are similar to the testing instance and makes
a prediction based on their output results.(Lazy
Learning并没有从特定的模型中提取基本规则或一般情况，而是在预测时查找与测试实例相似的历史实例，并根据它们的输出结果做出预测)</p>
<p><strong>advantage</strong>:</p>
<ul>
<li>local data distribution（适用本地数据分布）</li>
<li>Incremental/online learning（渐进式/在线学习）</li>
<li>large number of classes（可以对很大的类型数量分类）</li>
</ul>
<p><strong>disvantage</strong>:</p>
<ul>
<li>parameter k(要设置参数k)</li>
<li>imbalanced data（数据不平衡时分类效果差）</li>
<li>slow inference（推理慢）</li>
</ul>
<h4 id="naive-bayse">Naive bayse</h4>
<p><strong>basic idea</strong></p>
<p><strong>advantage</strong></p>
<h4 id="svm">SVM</h4>
<ol type="1">
<li>basic concept</li>
<li>Linear seperation problem
<ol type="1">
<li>Why SVM works well on small size of samples?</li>
<li>Good generalization</li>
</ol></li>
<li>NonLinear problem
<ol type="1">
<li>solution: map data into high dimension space</li>
<li>Trick: kernel Trick <span class="math inline">\(K(X,Y) = \Phi(X)
\Phi(Y)\)</span></li>
<li>Kernel function: Gaussian kernel, polynormial kernel</li>
</ol></li>
</ol>
<h4 id="section"></h4>
<p>损失函数是平方损失加上L1正则化</p>
<p><span class="math display">\[J(\theta) = \frac{1}{2m} \sum_{i=1}^m
(h_\theta(x^{(i)}) - y^{(i)})^2 + \alpha \sum_{j=1}^n
|\theta_j|\]</span></p>
<p>其中，第一项是平方损失，第二项是L1正则化项，<span
class="math inline">\(\alpha\)</span>是正则化参数。</p>
<h4 id="subspace-clustering子空间聚类">Subspace
Clustering(子空间聚类)</h4>
<h2 id="ch3-hashing">Ch3 Hashing</h2>
<h3 id="the-role-of-hashing作用">The role of Hashing(作用)</h3>
<ul>
<li>After using the hash code to represent the data, the required
storage space will be greatly
reduced（使用哈希码表示数据后，所需要的存储空间会被大幅减小）</li>
<li>Can reduce data dimensionality, thereby alleviating the
dimensionality curse
problem(可以降低数据维度，从而减轻维度灾难问题)</li>
<li>Can realize fast neighbor retrieval at constant or sub-linear level,
and provide support for the rapid realization of upper-level learning
tasks(可以实现常数或者次线性级别的快速近邻检索，为上层学习任务的快速实现提供支撑)</li>
</ul>
<h3 id="find-similar-items">Find similar items</h3>
<p>Three Essential Techniques for Similar items:</p>
<ul>
<li><strong>K-Shingling</strong>：convert documents, emails, etc., to
sets.</li>
<li><strong>Minhashing</strong>：convert large sets to short signatures,
while preserving similarity.</li>
<li><strong>Locality-sensitive hashing</strong> : focus on pairs of
signatures likely to be similar.</li>
</ul>
<p><img src="/img/大数据/ch3-the-big-pic.png" srcset="/img/loading.gif" lazyload /></p>
<h4 id="shingles">Shingles</h4>
<p>A k -shingle (or k -gram) for a document is a sequence of k
characters that appears in the document.
一个文件的k-shingle（或k-gram）是一个出现在文件中的k个字符的序列。</p>
<p>Example: <span class="math inline">\(k=2; doc = abcab\)</span>. Set
of 2-shingles = <span class="math inline">\(\{ab, bc, ca\}\)</span>.</p>
<h4 id="min-hashing">min-hashing</h4>
<p>definition:min-hash is an algorithm for text and data similarity
comparison that efficiently extracts the signature of each data from
large-scale data, thus supporting fast comparison of their similarity.
min-hash是一种用于文本和数据相似度比较的算法，它可以高效地从大规模数据中提取每个数据的签名，从而支持快速地比较它们之间的相似程度。</p>
<h4 id="signature-matrix-rightarrow-how-to-compute-similarity">signature
matrix <span class="math inline">\(\Rightarrow\)</span> how to compute
similarity</h4>
<p><img src="/img/大数据/ch3-similarity.png" srcset="/img/loading.gif" lazyload /></p>
<p>Jaccard similarity：不将<span
class="math inline">\((0,0)\)</span>计入分母，相同的行占全部行的比率</p>
<p>matrix similarity：相同的行占全部行的比率</p>
<p><strong>Signature Matrix的计算方法</strong>：</p>
<p><img src="/img/大数据/ch3-signature计算.png" srcset="/img/loading.gif" lazyload /></p>
<p>上图中间矩阵是输入矩阵，左侧的每一列都代表输入矩阵行的一种排列，那么signature
matrix的每一行都对应左侧的一种排列方式，该行的每列数字对应该种排列方式对应列的第一个1的出现行数。</p>
<h4 id="locality-sensitive-hashinglsh">Locality-Sensitive
Hashing（LSH）</h4>
<p>假设我们在主内存中有代表大量对象的数据</p>
<ul>
<li>可能是对象本身</li>
<li>可能是min-hashing中的签名</li>
</ul>
<p>我们要逐一进行比较，找到那些足够相似的pair。但是检查所有的pair是很困难的。</p>
<ul>
<li>一般的想法：
使用一个函数f(x,y)，告诉人们x和y是否是一个候选对：一对元素的相似性必须被评估。</li>
<li>对于min-hash矩阵：
哈希列到许多桶中，并使同一桶中的元素成为候选对。</li>
</ul>
<p>基本思想：Generate from the collection of all elements (signatures in
our example) a small list of candidate pairs: pairs of elements whose
similarity must be evaluated.</p>
<p>简单来说就是从我们Min-hashing得到的标记矩阵生成可能相似的文档对列表。</p>
<p>候选相似文档对 <span class="math inline">\(\Rightarrow\)</span>
这一对的Jaccard相似度必须被准确计算出来</p>
<p>方法：</p>
<ul>
<li>选一个相似度标准 <span class="math inline">\(t\)</span>，并且 <span
class="math inline">\(t&lt;1\)</span>，如果两个文档的相似度大于 <span
class="math inline">\(t\)</span>，则认为这两个文档相似。</li>
<li>如果列<span class="math inline">\(c\)</span>和列<span
class="math inline">\(d\)</span>被视为候选文档对，那么他们一定要满足
<span
class="math inline">\(M(i,c)=M(i,d)&gt;=t\)</span>，其中M是标记矩阵。</li>
</ul>
<h5 id="lsh-for-minhashing-signatures">LSH for Minhashing
Signatures</h5>
<p>总体思想：把标记矩阵里的hash很多遍，只有hash到同一个桶(bucket)里的列才被认为是可能相似的。</p>
<p><strong>Partion Into Bands</strong></p>
<p><img src="/img/大数据/Partion-Into-Bands.png" srcset="/img/loading.gif" lazyload /></p>
<p>如图所示，把标记矩阵(signature matrix)的所有行分成 <span
class="math inline">\(b\)</span> 个带(bands)，每个带有 <span
class="math inline">\(r\)</span>
行。对于每条带，对带里面每列进行hash，分别hash到<span
class="math inline">\(k\)</span>个桶中，并让<span
class="math inline">\(k\)</span>尽可能得大。</p>
<p>只有有<span
class="math inline">\(&gt;=1\)</span>的band哈希到同一个桶中，就把这两列当作候选相似对。</p>
<p><img src="/img/大数据/Partion-Into-Bands-例子.png" srcset="/img/loading.gif" lazyload /></p>
<h5 id="example---bands">Example - Bands</h5>
<p>假设有 100,000 列，每列有100个标记，因此存储标记需要40MB;
我们希望找到所以相似度大于80%的文档对，用上面的方法，把标记分为20个带，每个带里有5个标记。</p>
<p>这样的话，如果文档<span class="math inline">\(C_1\)</span>和<span
class="math inline">\(C_2\)</span>的相似度是<span
class="math inline">\(80\%\)</span>，那么他们的任意一个带的<span
class="math inline">\(5\)</span>个标记都相同的概率是: <span
class="math inline">\((0.8)^5=0.328\)</span>
，看起来好像不大，但是只要有任意一个带都相同就被认为是候选对，所以他们不被选上的概率，即20个带都不相同的概率为：<span
class="math inline">\((1−0.328)^20=0.00035\)</span> ，也就是每<span
class="math inline">\(3000\)</span>个相似度为<span
class="math inline">\(80\%\)</span>的文档对里才会有一对漏选。</p>
<p>我们再考虑文档<span class="math inline">\(C_1\)</span>和<span
class="math inline">\(C_2\)</span>只有<span
class="math inline">\(40\%\)</span>的相似度，那么他们任意一个带的<span
class="math inline">\(5\)</span>个标记都相同的概率为 <span
class="math inline">\((0.4)^5=0.01\)</span>，则文档<span
class="math inline">\(C_1\)</span>和<span
class="math inline">\(C_2\)</span>被选为候选对的概率，即他们中有一个带完全相同的概率为:
<span class="math inline">\(C^1_{20}×0.01=0.2\)</span> ，就是说每<span
class="math inline">\(5\)</span>个<span
class="math inline">\(40\%\)</span>相似度的文档对里就有一对会被误选为候选对。但是相似度小于<span
class="math inline">\(40\%\)</span>的文档对里误选的概率就非常小了。</p>
<h3 id="learn-to-hash">Learn to Hash</h3>
<ol type="1">
<li>Data indenpendent:Random projection</li>
<li>Data dependent:
<ol type="1">
<li>PCA hashing</li>
<li>Spectral Hashing</li>
</ol></li>
</ol>
<h4 id="pca-hashing">PCA hashing</h4>
<p>分为两个阶段</p>
<p><strong>Projection Stage（投影阶段）</strong>:</p>
<p>用一个转换矩阵<span class="math inline">\(W\)</span>,可以将<span
class="math inline">\(x\)</span>投影到一个新的特征平面。</p>
<p><span class="math display">\[Y=W^T X\]</span></p>
<p><strong>Quantization Stage（量化阶段）</strong>:</p>
<p><span class="math display">\[h(x) = sgn(W^T X)\]</span></p>
<p>最小化quantization loss（量化损失）</p>
<p><span class="math display">\[Q(B,Y) = ||B - Y^T R||^2_F\]</span></p>
<p><span class="math inline">\(R\)</span>是正交矩阵. <span
class="math inline">\(B = Sgn(Y^T R)\)</span></p>
<p>基本思想是旋转数据以最小化量化损失。</p>
<p>实现方法：从<span
class="math inline">\(R\)</span>的随机初始化开始，采用类似K-means的迭代算法来优化<span
class="math inline">\(R\)</span>。在每次迭代中，每个数据点首先被分配到最近的聚类中心，然后更新<span
class="math inline">\(R\)</span>以使量化损失最小化。</p>
<h4 id="spectral-hashing谱哈希">Spectral Hashing（谱哈希）</h4>
<p><img src="/img/大数据/Spectral-Hashing公式.png" srcset="/img/loading.gif" lazyload /></p>
<h4
id="general-approach-to-learning-based-hashinglearning-based哈希的一般方法">General
Approach to Learning-Based Hashing(Learning-Based哈希的一般方法)</h4>
<p>将哈希学习问题分解为两个步骤：</p>
<ol type="1">
<li>哈希比特学习</li>
<li>基于所学习的哈希比特的哈希函数学习</li>
</ol>
<p><img src="/img/大数据/ch3-Learning-Based-Hashing-步骤.png" srcset="/img/loading.gif" lazyload /></p>
<h2 id="sampling">Sampling</h2>
<h3 id="inverse-transform-sampling">Inverse Transform Sampling</h3>
<p>基于累积分布函数的逆变换采样</p>
<p>方法：</p>
<p><img src="/img/大数据/ch4-CDF.png" srcset="/img/loading.gif" lazyload /></p>
<p>Advantages:</p>
<p>Disadvantages:</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>大数据期末复习</div>
      <div>https://gstarmin.github.io/2023/06/02/大数据期末复习/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Starmin</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年6月2日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/06/01/%E5%89%8D%E7%BC%80%E5%92%8C%E6%95%B0%E7%BB%84%E4%B8%8E%E5%B7%AE%E5%88%86%E6%95%B0%E7%BB%84/" title="前缀和数组与差分数组">
                        <span class="hidden-mobile">前缀和数组与差分数组</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
