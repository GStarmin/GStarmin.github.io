{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"source/img/多项式规约/3-SAT23-COLOLABLE-1.png","path":"img/多项式规约/3-SAT23-COLOLABLE-1.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/3-SAT23-COLOLABLE-2.png","path":"img/多项式规约/3-SAT23-COLOLABLE-2.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/3-SAT23-COLOLABLE-4.png","path":"img/多项式规约/3-SAT23-COLOLABLE-4.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/3-SAT2IndependentSet.png","path":"img/多项式规约/3-SAT2IndependentSet.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/3-SAT例子.png","path":"img/多项式规约/3-SAT例子.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/3-SAT23-COLOLABLE-3.png","path":"img/多项式规约/3-SAT23-COLOLABLE-3.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/3-SAT2Ham-Cycle构造.png","path":"img/多项式规约/3-SAT2Ham-Cycle构造.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/HamiltonianCycle定义.png","path":"img/多项式规约/HamiltonianCycle定义.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/DIR-HAM-CYC2Ham-Cycle.png","path":"img/多项式规约/DIR-HAM-CYC2Ham-Cycle.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/VertexCover归约到SetCover例子.png","path":"img/多项式规约/VertexCover归约到SetCover例子.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/点覆盖.png","path":"img/多项式规约/点覆盖.png","modified":1,"renderable":0},{"_id":"source/img/动态规划/最短路径.png","path":"img/动态规划/最短路径.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/独立集.png","path":"img/多项式规约/独立集.png","modified":1,"renderable":0},{"_id":"source/img/动态规划/最长上升子序列代码.jpg","path":"img/动态规划/最长上升子序列代码.jpg","modified":1,"renderable":0},{"_id":"source/img/多项式规约/集合覆盖例子.png","path":"img/多项式规约/集合覆盖例子.png","modified":1,"renderable":0},{"_id":"source/img/动态规划/状态转移方程.svg","path":"img/动态规划/状态转移方程.svg","modified":1,"renderable":0},{"_id":"source/img/动态规划/解决方案.jpg","path":"img/动态规划/解决方案.jpg","modified":1,"renderable":0},{"_id":"source/img/矩阵论/Jordan标准型定理2.png","path":"img/矩阵论/Jordan标准型定理2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/Jordan标准型定义.png","path":"img/矩阵论/Jordan标准型定义.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/Rayleigh-Ritz定理.png","path":"img/矩阵论/Rayleigh-Ritz定理.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/shur不等式证明.png","path":"img/矩阵论/shur不等式证明.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/例1-1.png","path":"img/矩阵论/例1-1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/例1-2.png","path":"img/矩阵论/例1-2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/例2-1.png","path":"img/矩阵论/例2-1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/例2-2.png","path":"img/矩阵论/例2-2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/全部广义逆集合定义.png","path":"img/矩阵论/全部广义逆集合定义.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/例2-2.webp","path":"img/矩阵论/例2-2.webp","modified":1,"renderable":0},{"_id":"source/img/矩阵论/单边逆定义.png","path":"img/矩阵论/单边逆定义.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/圆盘定理2.png","path":"img/矩阵论/圆盘定理2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/圆盘定理1.png","path":"img/矩阵论/圆盘定理1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/定理3(v)证明.png","path":"img/矩阵论/定理3(v)证明.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/对角占优矩阵.png","path":"img/矩阵论/对角占优矩阵.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆定义.png","path":"img/矩阵论/广义逆定义.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆定理1.png","path":"img/矩阵论/广义逆定理1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆定理2-2.png","path":"img/矩阵论/广义逆定理2-2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆定理2-1.png","path":"img/矩阵论/广义逆定理2-1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆定理3-1.png","path":"img/矩阵论/广义逆定理3-1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆定理3-2.png","path":"img/矩阵论/广义逆定理3-2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆推论1.png","path":"img/矩阵论/广义逆推论1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/特征值估计-shur不等式.png","path":"img/矩阵论/特征值估计-shur不等式.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/盖尔圆盘.png","path":"img/矩阵论/盖尔圆盘.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/矩阵范数性质-定理1-2.png","path":"img/矩阵论/矩阵范数性质-定理1-2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/矩阵范数性质-定理1.png","path":"img/矩阵论/矩阵范数性质-定理1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/算子范数定义2.png","path":"img/矩阵论/算子范数定义2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/算子范数定义1.png","path":"img/矩阵论/算子范数定义1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/算子范数性质-定理3.png","path":"img/矩阵论/算子范数性质-定理3.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/自反广义逆矩阵定义.png","path":"img/矩阵论/自反广义逆矩阵定义.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/自反广义逆矩阵定理1.png","path":"img/矩阵论/自反广义逆矩阵定理1.png","modified":1,"renderable":0},{"_id":"source/img/胜者树败者树/fig2.jpg","path":"img/胜者树败者树/fig2.jpg","modified":1,"renderable":0},{"_id":"source/img/近似算法/CentrerSelectionProblem.png","path":"img/近似算法/CentrerSelectionProblem.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/CentrerSelectionProblem贪心算法-证明.png","path":"img/近似算法/CentrerSelectionProblem贪心算法-证明.png","modified":1,"renderable":0},{"_id":"source/img/胜者树败者树/fig3.jpg","path":"img/胜者树败者树/fig3.jpg","modified":1,"renderable":0},{"_id":"source/img/胜者树败者树/fig4.jpg","path":"img/胜者树败者树/fig4.jpg","modified":1,"renderable":0},{"_id":"source/img/胜者树败者树/fig1.jpg","path":"img/胜者树败者树/fig1.jpg","modified":1,"renderable":0},{"_id":"source/img/近似算法/CentrerSelectionProblem贪心算法.png","path":"img/近似算法/CentrerSelectionProblem贪心算法.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/LoadBalancingLPT算法.png","path":"img/近似算法/LoadBalancingLPT算法.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/LoadBalancing实例-贪心算法.png","path":"img/近似算法/LoadBalancing实例-贪心算法.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/LoadBalancing实例-最优解.png","path":"img/近似算法/LoadBalancing实例-最优解.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/LoadBalancing贪心算法.png","path":"img/近似算法/LoadBalancing贪心算法.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/LoadBalancing贪心算法证明-1.png","path":"img/近似算法/LoadBalancing贪心算法证明-1.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/WeightedVertexCover-PricingMethod-例子.png","path":"img/近似算法/WeightedVertexCover-PricingMethod-例子.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/WeightedVertexCover-PricingMethod-求解过程.png","path":"img/近似算法/WeightedVertexCover-PricingMethod-求解过程.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/WeightedVertexCover-不等式放缩.png","path":"img/近似算法/WeightedVertexCover-不等式放缩.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子1.png","path":"img/最大流最小割/Ford-Fulkerson例子1.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/证明PricingMethod2倍近似解.png","path":"img/近似算法/证明PricingMethod2倍近似解.png","modified":1,"renderable":0},{"_id":"source/img/近似算法/WeightedVertexCover.png","path":"img/近似算法/WeightedVertexCover.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子2.png","path":"img/最大流最小割/Ford-Fulkerson例子2.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子3.png","path":"img/最大流最小割/Ford-Fulkerson例子3.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子5.png","path":"img/最大流最小割/Ford-Fulkerson例子5.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子4.png","path":"img/最大流最小割/Ford-Fulkerson例子4.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子7.png","path":"img/最大流最小割/Ford-Fulkerson例子7.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子6.png","path":"img/最大流最小割/Ford-Fulkerson例子6.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/iii到i.png","path":"img/最大流最小割/iii到i.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/一个割例子.png","path":"img/最大流最小割/一个割例子.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/最大流.png","path":"img/最大流最小割/最大流.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/最大流最小割定理.png","path":"img/最大流最小割/最大流最小割定理.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/最小割定义.png","path":"img/最大流最小割/最小割定义.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/残余图.png","path":"img/最大流最小割/残余图.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆定理1.png","path":"img/矩阵论/广义逆矩阵/M-P广义逆定理1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆定理3.png","path":"img/矩阵论/广义逆矩阵/M-P广义逆定理3.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆定义.png","path":"img/矩阵论/广义逆矩阵/M-P广义逆定义.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆定理5.png","path":"img/矩阵论/广义逆矩阵/M-P广义逆定理5.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆的计算定理1.png","path":"img/矩阵论/广义逆矩阵/M-P广义逆的计算定理1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-1.png","path":"img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-2.png","path":"img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/图1.png","path":"img/矩阵论/广义逆矩阵/图1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/图2.png","path":"img/矩阵论/广义逆矩阵/图2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/定理2.png","path":"img/矩阵论/广义逆矩阵/定理2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/定理3.png","path":"img/矩阵论/广义逆矩阵/定理3.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/引理1.png","path":"img/矩阵论/广义逆矩阵/引理1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/最大秩分解法例1-1.png","path":"img/矩阵论/广义逆矩阵/最大秩分解法例1-1.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/最大秩分解法例1-2.png","path":"img/矩阵论/广义逆矩阵/最大秩分解法例1-2.png","modified":1,"renderable":0},{"_id":"source/img/矩阵论/广义逆矩阵/最大秩分解法例1-3.png","path":"img/矩阵论/广义逆矩阵/最大秩分解法例1-3.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/5.2.2证明.png","path":"img/随机过程/平稳过程/5.2.2证明.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/严平稳过程定义-2.png","path":"img/随机过程/平稳过程/严平稳过程定义-2.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/严平稳过程定义.png","path":"img/随机过程/平稳过程/严平稳过程定义.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/定理5.2.2.png","path":"img/随机过程/平稳过程/定理5.2.2.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/定理5.2.3.png","path":"img/随机过程/平稳过程/定理5.2.3.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/宽平稳过程定义.png","path":"img/随机过程/平稳过程/宽平稳过程定义.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/平稳过程自相关函数性质-1.png","path":"img/随机过程/平稳过程/平稳过程自相关函数性质-1.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/平稳过程自相关函数性质-2.png","path":"img/随机过程/平稳过程/平稳过程自相关函数性质-2.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/自相关函数推论.png","path":"img/随机过程/平稳过程/自相关函数推论.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/自相关证明1.png","path":"img/随机过程/平稳过程/自相关证明1.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/自相关证明2.png","path":"img/随机过程/平稳过程/自相关证明2.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/自相关证明3.png","path":"img/随机过程/平稳过程/自相关证明3.png","modified":1,"renderable":0},{"_id":"source/img/随机过程/平稳过程/自相关证明4.png","path":"img/随机过程/平稳过程/自相关证明4.png","modified":1,"renderable":0},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","path":"css/highlight-dark.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","path":"css/highlight.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","path":"img/default.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","path":"img/fluid.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","path":"img/loading.gif","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","path":"js/boot.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","path":"js/events.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","path":"js/plugins.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1}],"Cache":[{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1669908961622},{"_id":"source/_posts/Git常用命令.md","hash":"7bb310ecc4d3ede1a0d87821108f9c87e5726a69","modified":1670054969350},{"_id":"source/_posts/动态规划.md","hash":"4c6ee63bddf07404e015cba4966f83b8998f7a6b","modified":1670083911193},{"_id":"source/_posts/Latex常用符号.md","hash":"e6b97a79fb9edf5bd18cbd3f6dea0736a3ce5dba","modified":1670325667195},{"_id":"source/_posts/NP问题.md","hash":"180039d85dc0dcd5111b178dd5ea0182bdd2630e","modified":1670473388632},{"_id":"source/_posts/平稳过程.md","hash":"4a9df96c4de30f0d8f6fe9dccf8c3ebeae6a8a22","modified":1670399145494},{"_id":"source/_posts/广义逆矩阵.md","hash":"d5e5de4176af6ebd4765dfaf49c668ca9e545ecb","modified":1670473313673},{"_id":"source/_posts/Jardon标准型.md","hash":"399395fdee33c95122895d5f7ba5c0cabf6ffaac","modified":1670243076290},{"_id":"source/_posts/多项式规约.md","hash":"57a17b7321c24f8c576a3a6b948581e570aa65a5","modified":1670254245162},{"_id":"source/_posts/最大流最小割.md","hash":"6b6e38ea26605fadbee856a2485fc24e2137ff14","modified":1670251848625},{"_id":"source/_posts/矩阵分解.md","hash":"6d55e9ecf34cc26d97f5e86f54bb1cddf685b314","modified":1670341978786},{"_id":"source/_posts/红黑树.md","hash":"4130f9bea7213a08ba72317646859b570520c3c9","modified":1670251857012},{"_id":"source/_posts/特征值估计.md","hash":"7599281bfbdc836f34b070ffeee8a2b73b94c7e4","modified":1670463349575},{"_id":"source/_posts/近似算法.md","hash":"baa9108949c72161a139b6a7d4f167cd67996897","modified":1670506913495},{"_id":"source/_posts/范数.md","hash":"21fa5a66498fae0f0063707e51d6416c4921b59c","modified":1670473601492},{"_id":"source/img/多项式规约/3-SAT23-COLOLABLE-1.png","hash":"e089ff65920dbdfe299bcbe07b7ed360fef2f900","modified":1670403150031},{"_id":"source/img/多项式规约/3-SAT23-COLOLABLE-2.png","hash":"97a60785bb5ec1fe0501fbdf57c9c088dbb166e2","modified":1670403571481},{"_id":"source/img/多项式规约/3-SAT23-COLOLABLE-4.png","hash":"7d65756bf0c1426c068fb4cbab92e15cc833b988","modified":1670404864299},{"_id":"source/img/多项式规约/3-SAT2IndependentSet.png","hash":"99cc5a082dd54fcc1351ea3f741c4eab2b919d09","modified":1670246584960},{"_id":"source/img/多项式规约/3-SAT23-COLOLABLE-3.png","hash":"f669ea65a9c5b8461c5e52062fe687b070791306","modified":1670404042761},{"_id":"source/img/多项式规约/3-SAT例子.png","hash":"f3efd838662fb8f18b2cb336619be06dca3140b4","modified":1670245622629},{"_id":"source/img/多项式规约/HamiltonianCycle定义.png","hash":"a992de285d802d1856bb4ff85e284d359edf044f","modified":1670325878699},{"_id":"source/img/多项式规约/DIR-HAM-CYC2Ham-Cycle.png","hash":"68a04c1f4d78a55ddced3f22710e72fd6eaabe58","modified":1670326396044},{"_id":"source/img/多项式规约/VertexCover归约到SetCover例子.png","hash":"097b817dd6a6e3c99f94f2e539b5ff8d31945203","modified":1670243021143},{"_id":"source/img/多项式规约/点覆盖.png","hash":"021805ebf776c01cd678d4c26f21f8a0672e1902","modified":1670070318643},{"_id":"source/img/动态规划/最短路径.png","hash":"0ba147ab707a0e36e3051bff42d30cbaa6759c63","modified":1646917567601},{"_id":"source/img/多项式规约/独立集.png","hash":"c41df5652e2b1ec4fc4c0afa8960ca8db7e7f252","modified":1670070305476},{"_id":"source/img/多项式规约/集合覆盖例子.png","hash":"7a362f1b37966dbfeb1f2d0a62f606dcf5a0f7c1","modified":1670241468469},{"_id":"source/img/动态规划/最长上升子序列代码.jpg","hash":"d0c1dbb9c49b2b4264b9e6eca7971f38d06e5455","modified":1646918693344},{"_id":"source/img/动态规划/状态转移方程.svg","hash":"8b5734d7212db7f4d24e95f2d422d7f1c6defb1d","modified":1646918590917},{"_id":"source/img/动态规划/解决方案.jpg","hash":"8500d51aa92b8cf3e1a4faa475de9524d179f978","modified":1646917030251},{"_id":"source/img/矩阵论/Jordan标准型定理2.png","hash":"831a8ebd5f087a8af02f7091a2e98af603e7cd10","modified":1670224593734},{"_id":"source/img/矩阵论/Jordan标准型定义.png","hash":"fd7ab301d4a052294fcf9534a52d5f885bb04afa","modified":1670223618119},{"_id":"source/_posts/胜者树败者树.md","hash":"91285e6a406007db9055cc61b67a870f420ca4ec","modified":1670251852767},{"_id":"source/img/矩阵论/shur不等式证明.png","hash":"598bb2e50b796e085a3b247a5d23138afe2665eb","modified":1670424510442},{"_id":"source/img/矩阵论/例1-1.png","hash":"ce9a8d48eb483edeeb02a69429ed517bce30a157","modified":1670230780459},{"_id":"source/img/矩阵论/例2-1.png","hash":"e924c3bff5df279c2b041f9575a7b1e777544266","modified":1670230826624},{"_id":"source/img/矩阵论/例1-2.png","hash":"94772735e5144392761b8dcc93212182df44de20","modified":1670230787878},{"_id":"source/img/矩阵论/例2-2.webp","hash":"f021ca4e86c1cdd2b9b2e3cdb6bf39841a7d4da9","modified":1670230832607},{"_id":"source/img/矩阵论/例2-2.png","hash":"f021ca4e86c1cdd2b9b2e3cdb6bf39841a7d4da9","modified":1670230847809},{"_id":"source/img/矩阵论/全部广义逆集合定义.png","hash":"9745aa36667cb01985319c2ff500c8904a77bd12","modified":1670231154193},{"_id":"source/img/矩阵论/单边逆定义.png","hash":"63b9c0b8fb1babd332aeb0a9b0655c92e986427f","modified":1670230426271},{"_id":"source/img/矩阵论/定理3(v)证明.png","hash":"5cb563931d15a987ce63aab807fd24b3612282d9","modified":1670231827392},{"_id":"source/img/矩阵论/圆盘定理1.png","hash":"f3fa0425de576cba18a5440d91003ebcf7861b21","modified":1670425461187},{"_id":"source/img/矩阵论/广义逆定义.png","hash":"15320e82be1884fbcfa9376b82ed5059b7891841","modified":1670230978104},{"_id":"source/img/矩阵论/广义逆定理1.png","hash":"9ee64fe21f8c34f28b84fff0502591a6dbd5d07f","modified":1670231027835},{"_id":"source/img/矩阵论/广义逆定理2-2.png","hash":"fd5360153ace174550b2b734b14a9850aa8f273f","modified":1670231218507},{"_id":"source/img/矩阵论/广义逆定理2-1.png","hash":"ba82245e52ea81cb10f25ca11bfb03fa95b256ec","modified":1670231210329},{"_id":"source/img/矩阵论/广义逆定理3-1.png","hash":"6ece2ecee1c2acd17ef563183efc325dc896d602","modified":1670231521061},{"_id":"source/img/矩阵论/广义逆定理3-2.png","hash":"10feec4e6b41efcdf89896b7c70eb6259b086b4f","modified":1670231532050},{"_id":"source/img/矩阵论/广义逆推论1.png","hash":"1cabd42b07c99e5a38c8142344a2e733eb9cc149","modified":1670231087779},{"_id":"source/img/矩阵论/特征值估计-shur不等式.png","hash":"04e221d97b35290d2e3f7c6e04c9bfc798c15cfd","modified":1670424446828},{"_id":"source/img/矩阵论/矩阵范数性质-定理1.png","hash":"932b41c023d8a8e210e23ac91836bf9279210d07","modified":1670423000900},{"_id":"source/img/矩阵论/算子范数定义2.png","hash":"e2eb299b2b17d2a87809b4046d7d766e261b9a42","modified":1670423497139},{"_id":"source/img/矩阵论/自反广义逆矩阵定义.png","hash":"e22b0f9e4ad70bb55c677dc87b0c71795f065f9f","modified":1670232321912},{"_id":"source/img/矩阵论/算子范数性质-定理3.png","hash":"1af57f8acac0c1c7b6933d5d7c718fd5dd9d3038","modified":1670424061815},{"_id":"source/img/矩阵论/算子范数定义1.png","hash":"42e65c6cea212584efb01fa60043a94ab1b9c4c7","modified":1670423381674},{"_id":"source/img/矩阵论/自反广义逆矩阵定理1.png","hash":"c71c853ac1e7ab8e6c4544b8a691c97fb7e10cb8","modified":1670232492131},{"_id":"source/img/胜者树败者树/fig2.jpg","hash":"daaf81658569b19710523c650f4a1c95fa46db4b","modified":1647227127787},{"_id":"source/img/近似算法/CentrerSelectionProblem.png","hash":"0aed6e89774041b4cd29c59ae338a4b2d877879a","modified":1670498474455},{"_id":"source/img/近似算法/CentrerSelectionProblem贪心算法-证明.png","hash":"72a7e740e3ac52cec0a393eda9c6a8bdf38a86f1","modified":1670501398483},{"_id":"source/img/胜者树败者树/fig3.jpg","hash":"f65abc86102943457c2fd7f4de3bc2ca6e9ff8ff","modified":1647227136005},{"_id":"source/img/近似算法/CentrerSelectionProblem贪心算法.png","hash":"5817c70eb2dd3666c7bd96ff528d5fd4ffc56a34","modified":1670501130319},{"_id":"source/img/胜者树败者树/fig4.jpg","hash":"8f104f440e15af2f0fa833339e76b58e1c0fc1ee","modified":1647227141329},{"_id":"source/img/胜者树败者树/fig1.jpg","hash":"97867bf0b5eeedc2a763d42b0ddf3a489ee2a08d","modified":1647227120629},{"_id":"source/img/近似算法/LoadBalancingLPT算法.png","hash":"e69741234fa1bd5aba148ec8da69f0a8a002b66f","modified":1670495361633},{"_id":"source/img/近似算法/LoadBalancing实例-最优解.png","hash":"6cd261c033a45ecb72215908067dd49c7135386f","modified":1670491912702},{"_id":"source/img/近似算法/LoadBalancing实例-贪心算法.png","hash":"bd73a41af05c16f462ddb6ed7870f24bf17721f9","modified":1670491844931},{"_id":"source/img/近似算法/LoadBalancing贪心算法.png","hash":"365af0e750226f27615e5fbf425ad9194a66b460","modified":1670489536113},{"_id":"source/img/近似算法/LoadBalancing贪心算法证明-1.png","hash":"c665d1f6a9b7e1bad5373e48b0973da2dcf62abf","modified":1670490954420},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子1.png","hash":"67e5f7b1db79d46598fe41b1b57fff2c84dc6d32","modified":1670052565578},{"_id":"source/img/近似算法/WeightedVertexCover-不等式放缩.png","hash":"bb7608412df0ecfc1e017426be27102f3f865f77","modified":1670506102689},{"_id":"source/img/近似算法/WeightedVertexCover-PricingMethod-求解过程.png","hash":"193fb21ed9c3a5ac4b96ce97a1d0a0c6ea76013e","modified":1670506198915},{"_id":"source/img/近似算法/WeightedVertexCover.png","hash":"a09667ced16a32117c7070ab27facb6b79324040","modified":1670505871882},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子2.png","hash":"df88bf8af91a2073fbaaba71def9ebebe949b645","modified":1670052706600},{"_id":"source/img/近似算法/证明PricingMethod2倍近似解.png","hash":"9dec755a2bf4e9119b7be6e3cb113cc78c2f50ba","modified":1670506633714},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子3.png","hash":"757c7bb6ff26a30ea9e46deb7777740516f225cc","modified":1670052873685},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子5.png","hash":"19e85b264deafb8926b70ed397a59cd495e224f6","modified":1670052912631},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子4.png","hash":"e08eea19af73ad0bcc8c8c0181173e5db30e19df","modified":1670052896438},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子7.png","hash":"1a935d7a67c1cd2241cdeb2c4a61ca437e65a756","modified":1670052947803},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子6.png","hash":"6a815e321d3abd5d260709d42b921d4cf35f5bf5","modified":1670052929316},{"_id":"source/img/最大流最小割/iii到i.png","hash":"eb6738e99b57447dcd63fdf8aa241fb8f5c2b321","modified":1670053933038},{"_id":"source/img/最大流最小割/一个割例子.png","hash":"79f139ef1f807758efb8dd0614723b008117597d","modified":1670044400309},{"_id":"source/img/最大流最小割/最大流.png","hash":"f4671c1a200b41a3ac6608cd4ad0c03b14da6596","modified":1670049218424},{"_id":"source/img/最大流最小割/最小割定义.png","hash":"f3d62ba163797d84ab99a6113baea85c67152a94","modified":1670044091900},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆定理1.png","hash":"68b5d35faccba9d90d2dc318e504fcff1ae8881b","modified":1670233267103},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆定理3.png","hash":"1322d25010deffde7fc429ef6154b463c8045c0a","modified":1670234358623},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆定义.png","hash":"db60c9834047722dfb0c84c3e09b482b2c89225f","modified":1670233145325},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆的计算定理1.png","hash":"3c9a342f4171ebdc0ff837638e9a596a496291af","modified":1670239466774},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆定理5.png","hash":"45fc109d729de45c444e89736126775a5f0b8122","modified":1670234435531},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-1.png","hash":"9d029526af7af5e2a3908aa283476e5214ddd795","modified":1670240116150},{"_id":"source/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-2.png","hash":"d21aec756ff0373dba5460f061c2933f4185c397","modified":1670240147808},{"_id":"source/img/矩阵论/广义逆矩阵/图1.png","hash":"9ed45a13693724b55b9bb54bbe84763571cb67f5","modified":1670232591473},{"_id":"source/img/矩阵论/广义逆矩阵/定理2.png","hash":"4fe34c0040ed10fd0e0abd580ec22ad76c46e10c","modified":1670232787780},{"_id":"source/img/矩阵论/广义逆矩阵/图2.png","hash":"ce4ffa7ddbc0842c2c0c31d7cf45c2ebd36d7395","modified":1670232632897},{"_id":"source/img/矩阵论/广义逆矩阵/定理3.png","hash":"0e87e3391df3e87a2b6eb0083ecc9f7b9e5186cc","modified":1670232852270},{"_id":"source/img/矩阵论/广义逆矩阵/引理1.png","hash":"b19c4e62d664f276a53d9d4e9112df6854e55434","modified":1670235385866},{"_id":"source/img/矩阵论/广义逆矩阵/最大秩分解法例1-1.png","hash":"652f575341ccd09d3f16f2fa2980454bf7506938","modified":1670240002155},{"_id":"source/img/矩阵论/广义逆矩阵/最大秩分解法例1-2.png","hash":"0757c3939b94137f5854e113ab5c44edc6662a11","modified":1670240012848},{"_id":"source/img/矩阵论/广义逆矩阵/最大秩分解法例1-3.png","hash":"e966d003a7179232a4235cf6053f7ae5ee1e2ca5","modified":1670240021392},{"_id":"source/img/随机过程/平稳过程/5.2.2证明.png","hash":"7d4827ab30a39501daaf423830f5af0d50ff3c36","modified":1670395979373},{"_id":"source/img/随机过程/平稳过程/严平稳过程定义.png","hash":"2c4335e6870993517fb99f132e33b7f8e1536caf","modified":1670380688456},{"_id":"source/about/index.md","hash":"9aefab0ac381b3378b472ea3ff97de5a58274e89","modified":1669955882134},{"_id":"source/img/随机过程/平稳过程/平稳过程自相关函数性质-2.png","hash":"36ba8f248bb8481a4b5ccfafeb2aacee432072e5","modified":1670389391595},{"_id":"source/img/随机过程/平稳过程/自相关证明1.png","hash":"cbd9244966c91b696be1caaa17e157cea133f4fa","modified":1670395599541},{"_id":"source/_posts/矩阵级数和矩阵函数.md","hash":"22e789cdba0dd7b67b9e46fac01dec170ec5f5a0","modified":1670224878690},{"_id":"source/img/随机过程/平稳过程/自相关证明2.png","hash":"97e929ee9ec4961daa05f1d2e344e8d317a4dd9a","modified":1670395699969},{"_id":"source/img/随机过程/平稳过程/自相关证明3.png","hash":"15c2d6b976b12a09e26c5be3198c97e2a7969fc9","modified":1670395741759},{"_id":"node_modules/hexo-theme-fluid/_config.yml","hash":"39baa882da9b0af5178c7767306be14bcf992a55","modified":1669908961627},{"_id":"node_modules/hexo-theme-fluid/package.json","hash":"167c6a0729a9286a7f508c1dd6a9c689e8799008","modified":1669908959661},{"_id":"node_modules/hexo-theme-fluid/languages/de.yml","hash":"0e7d455d9e004ff15d8924b7a0c35cea25ee5b1d","modified":1669908961627},{"_id":"node_modules/hexo-theme-fluid/languages/en.yml","hash":"cb11b39f44ea069652c9647179606b6cecc98d50","modified":1669908961628},{"_id":"node_modules/hexo-theme-fluid/languages/eo.yml","hash":"a556251cc50a5680578c03f1efbf252b1f4ab860","modified":1669908961628},{"_id":"node_modules/hexo-theme-fluid/languages/es.yml","hash":"7112594259c88c04714be152af7fd377687dad40","modified":1669908961628},{"_id":"node_modules/hexo-theme-fluid/languages/ru.yml","hash":"7dc78f22696649a4c68dc65a9b52d9a992fa82a0","modified":1669908961629},{"_id":"node_modules/hexo-theme-fluid/languages/ja.yml","hash":"3dd6d20f8d26585a7c154a8e59fe8d5d902f4c6a","modified":1669908961629},{"_id":"node_modules/hexo-theme-fluid/languages/zh-HK.yml","hash":"80ed400a7adaa92ea54fc7f5d534c9af795bed00","modified":1669908961633},{"_id":"node_modules/hexo-theme-fluid/languages/zh-CN.yml","hash":"f96a22f989897ecddc69d5867a206e1cf6b8f610","modified":1669908961632},{"_id":"node_modules/hexo-theme-fluid/layout/404.ejs","hash":"9569c5c8f67d2783f372f671c57b93a00dc63c2f","modified":1669908959159},{"_id":"node_modules/hexo-theme-fluid/layout/about.ejs","hash":"163bee643e6a38912d3ae70923c83c48d57222e7","modified":1669908959160},{"_id":"node_modules/hexo-theme-fluid/languages/zh-TW.yml","hash":"596d031dff3826ae8e4ffc8931fff28977b73247","modified":1669908961634},{"_id":"node_modules/hexo-theme-fluid/layout/archive.ejs","hash":"7c1f44005849791feae4abaa10fae4cb983d3277","modified":1669908959166},{"_id":"node_modules/hexo-theme-fluid/layout/categories.ejs","hash":"13859726c27b6c79b5876ec174176d0f9c1ee164","modified":1669908959170},{"_id":"node_modules/hexo-theme-fluid/layout/index.ejs","hash":"db000a6a0cec19d32a6e7e94cd4c478500d9c5ac","modified":1669908959459},{"_id":"node_modules/hexo-theme-fluid/layout/category.ejs","hash":"f099161b738a16a32253f42085b5444f902018ed","modified":1669908959439},{"_id":"node_modules/hexo-theme-fluid/layout/layout.ejs","hash":"7e0023474128fbe4d68c467704c41f1712432415","modified":1669908959459},{"_id":"node_modules/hexo-theme-fluid/layout/links.ejs","hash":"1cac32ec4579aaf7b9fa39d317497331d4c5e1dd","modified":1669908959460},{"_id":"node_modules/hexo-theme-fluid/layout/page.ejs","hash":"ed5007a3feb8f14d3d2843271bfb298eb0c56219","modified":1669908959465},{"_id":"node_modules/hexo-theme-fluid/layout/tag.ejs","hash":"9d686364c4d16a1a9219471623af452035c5b966","modified":1669908959468},{"_id":"node_modules/hexo-theme-fluid/layout/post.ejs","hash":"505bcc06e55066b7cc5551d9ac0694e7713bfab5","modified":1669908959465},{"_id":"node_modules/hexo-theme-fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":1669908959469},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/archive-list.ejs","hash":"7520fbf91f762207c2ab06b2c293235cd5b23905","modified":1669908959166},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-chains.ejs","hash":"18309584aab83bc4deb20723ebad832149dd2e24","modified":1669908959433},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-list.ejs","hash":"f8d2f1907450e61968e6d54443e9be8138196a77","modified":1669908959437},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/css.ejs","hash":"85f6e051550907681ab4ed2e268ac8f6e9ebf931","modified":1669908959449},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments.ejs","hash":"24ef242aa01e5f5bc397cf3f83ae48b1e8353dab","modified":1669908959447},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer.ejs","hash":"10ccfb8eef4e16182183c9a3e175c90d5b6397d3","modified":1669908959456},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/head.ejs","hash":"7b7b1d098726e86687a15fe3d520d178577ffcae","modified":1669908959457},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header.ejs","hash":"0d5e397d30051e5fbabe7b47cfd1f1e6a5820af1","modified":1669908959458},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/markdown-plugins.ejs","hash":"fc4bdf7de0cf1a66d0e5e4fba1b31d6f7ed49468","modified":1669908959461},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/paginator.ejs","hash":"0f38a2c238169edcb63fc46c23bfc529ff3859b7","modified":1669908959465},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/scripts.ejs","hash":"da5810785105e5075861593c7ac22c7aa9665a72","modified":1669908959466},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","hash":"45695ef75c31a4aa57324dd408b7e2327a337018","modified":1669908961612},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/search.ejs","hash":"70e1c929e084ca8a2648cedabf29b372511ea2b8","modified":1669908959467},{"_id":"node_modules/hexo-theme-fluid/LICENSE","hash":"26f9356fd6e84b5a88df6d9014378f41b65ba209","modified":1669908959152},{"_id":"node_modules/hexo-theme-fluid/README.md","hash":"6d752df6f2278033dc2512a7d5be22c8a8eb665a","modified":1669908959661},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1669908959663},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","hash":"a9efc52a646a9e585439c768557e3e3c9e3326dc","modified":1669908961613},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1669908961299},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","hash":"855ae5fe229c51afa57f7645f6997a27a705d7e4","modified":1669908961617},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1669908959626},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1669908961589},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1669908959634},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1669908959648},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1669908959157},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","hash":"89e3561488a618ed0caeb9edf18e441978e29c25","modified":1669908959646},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1669908961625},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","hash":"cebcda5991b6a9ab9307c69542389ce9013f04f7","modified":1669908959653},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1669908959652},{"_id":"node_modules/hexo-theme-fluid/scripts/events/index.js","hash":"79de5a379b28cad759a49048351c7f6b8915bd7d","modified":1669908959649},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","hash":"2333494add51e5e1374602a4e81f0be36a05d4c2","modified":1669908959658},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/local-search.js","hash":"fc2c50405b771b06b7f6cfc4e9de97b992691555","modified":1669908959653},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/default-injects.js","hash":"b2013ae8e189cd07ebc8a2ff48a78e153345210f","modified":1669908959645},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/pages.js","hash":"d9971f15fbb6b775e3d31a1b9b45011959395010","modified":1669908959657},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":1669908959653},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/post-filter.js","hash":"d516b9db63067f9ea9c72cc75ae4ff358417e77d","modified":1669908959658},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/injects.js","hash":"1ad2ae6b11bd8806ee7dd6eb7140d8b54a95d613","modified":1669908959650},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/engine.js","hash":"d3a231d106795ce99cb0bc77eb65f9ae44515933","modified":1669908959645},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/export-config.js","hash":"47e6dba7652a621a54067413490a11c8a89e3d7b","modified":1669908959646},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/date.js","hash":"9bda6382f61b40a20c24af466fe10c8366ebb74c","modified":1669908959643},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/import.js","hash":"ca53e8dbf7d44cfd372cfa79ac60f35a7d5b0076","modified":1669908959649},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/url.js","hash":"2a6a8288176d0e0f6ec008056bf2745a86e8943e","modified":1669908959659},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":1669908959657},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/utils.js","hash":"226f99b465ff513de075a8e78b321d6cb62592ca","modified":1669908959660},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/scope.js","hash":"d41d9d658fcb54964b388598e996747aadb85b0f","modified":1669908959659},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/checkbox.js","hash":"4938610c3543a921a341bc074626d511cb1a4b45","modified":1669908959636},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","hash":"45cc86f099db0a2c36ad49711ce66c2d598a2ab1","modified":1669908959660},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/wordcount.js","hash":"4543b8954c5c2ca91191cc0d53cf071b3f26faaa","modified":1669908959661},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":1669908959636},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":1669908959647},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/compare-versions.js","hash":"dbbc928c914fc2bd242cd66aa0c45971aec13a5d","modified":1669908959640},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/object.js","hash":"33b57e4decdc5e75c518859f168c8ba80b2c665b","modified":1669908959657},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":1669908959650},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/note.js","hash":"f52f3a005b41f48b4da274ac64710177c8d4502f","modified":1669908959656},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/mermaid.js","hash":"75160561e1ef3603b6d2ad2938464ab1cb77fd38","modified":1669908959655},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/changyan.ejs","hash":"c9b2d68ed3d375f1953e7007307d2a3f75ed6249","modified":1669908959441},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/cusdis.ejs","hash":"5f9dc012be27040bbe874d0c093c0d53958cc987","modified":1669908959451},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/resolve.js","hash":"8c4a8b62aa8608f12f1e9046231dff04859dc3e9","modified":1669908959659},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/url-join.js","hash":"718aab5e7b2059a06b093ca738de420d9afa44ba","modified":1669908959659},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/disqus.ejs","hash":"aab4a4d24c55231a37db308ae94414319cecdd9b","modified":1669908959453},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/giscus.ejs","hash":"95f8b866b158eff9352c381c243b332a155a5110","modified":1669908959456},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/livere.ejs","hash":"2264758fed57542a7389c7aa9f00f1aefa17eb87","modified":1669908959461},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/gitalk.ejs","hash":"843bc141a4545eb20d1c92fb63c85d459b4271ec","modified":1669908959457},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/remark42.ejs","hash":"d4e9532feeb02aed61bd15eda536b5b631454dac","modified":1669908959466},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/utterances.ejs","hash":"c7ccf7f28308334a6da6f5425b141a24b5eca0e2","modified":1669908959471},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/beian.ejs","hash":"4fb9b5dd3f3e41a586d6af44e5069afe7c81fff2","modified":1669908959169},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/twikoo.ejs","hash":"e6820fb7f13662c42f8433ec95404238f4c1860c","modified":1669908959471},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/waline.ejs","hash":"12727da7cf3ac83443270f550be4d1c06135b52b","modified":1669908959472},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/statistics.ejs","hash":"454d8dd4c39f9494ebeb03ca0746f5bc122af76a","modified":1669908959468},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/analytics.ejs","hash":"1327395a4dde1ea06c476b047fb110bcd269149f","modified":1669908959162},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/valine.ejs","hash":"19ba937553dddd317f827d682661a1066a7b1f30","modified":1669908959472},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/navigation.ejs","hash":"38990ed9dbccd88342ee4b4cb5e60818e9eb8e8a","modified":1669908959464},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/banner.ejs","hash":"e07757b59e7b89eea213d0e595cb5932f812fd32","modified":1669908959168},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/anchorjs.ejs","hash":"40181442d3a2b8734783a0ad7caf2d2522e3f2ab","modified":1669908959164},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/math.ejs","hash":"dcbf9a381ee76f2f1f75fcbc22c50a502ec85023","modified":1669908959462},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/fancybox.ejs","hash":"9d1ea2a46b8c8ad8c168594d578f40764818ef13","modified":1669908959455},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/code-widget.ejs","hash":"3a505cba37942badf62a56bbb8b605b72af330aa","modified":1669908959444},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/encrypt.ejs","hash":"e3713fa78e0fc14a239360b020068d8513573ae4","modified":1669908959455},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/highlight.ejs","hash":"7529dd215b09d3557804333942377b9e20fa554e","modified":1669908959459},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/nprogress.ejs","hash":"4c2d39ce816b8a6dcd6b53113c8695f8bd650a23","modified":1669908959464},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/mermaid.ejs","hash":"e49506e9895e255e0e53f34a11d325f83109c1b0","modified":1669908959462},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/typed.ejs","hash":"51faef29f8e464bcb2e73049b428b88c8dd8b40a","modified":1669908959471},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/category-bar.ejs","hash":"8772bce97ed297e7a88523f4e939ed6436c22f87","modified":1669908959173},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/copyright.ejs","hash":"9d13392cea94b66d86422ad17c66e5ae67ce1d32","modified":1669908959448},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-left.ejs","hash":"9992c99b3eb728ad195970e1b84d665f2c8691c4","modified":1669908959468},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-top.ejs","hash":"ce6e9f578f4faa45840abddf8f46af3f4b69c177","modified":1669908959464},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-bottom.ejs","hash":"7079b27a7bc15a7dfa9209f6be6051bdec49ebad","modified":1669908959462},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/toc.ejs","hash":"97e003371b76911522fb93c5180c9fdceed29488","modified":1669908959470},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-right.ejs","hash":"d5fcc9b60e02f869a29a8c17a16a6028ecc1e6d8","modified":1669908959468},{"_id":"node_modules/hexo-theme-fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":1669908961602},{"_id":"node_modules/hexo-theme-fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":1669908961601},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/footnote.js","hash":"2ec2ae03c79bb1ae7ac3fcf7e00fb52d1af2898d","modified":1669908959647},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/hello.js","hash":"44c5eb97b98813a07c659d6afedd17fad63b1821","modified":1669908959648},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/compatible-configs.js","hash":"ef474d1fa5bbafc52619ced0f9dc7eaf2affb363","modified":1669908959642},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/highlight.js","hash":"0f02df2244e275595e72163498d42f42bcf0de5e","modified":1669908959648},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/injects.js","hash":"5ae4b07204683e54b5a1b74e931702bbce2ac23e","modified":1669908959649},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/lazyload.js","hash":"9ba0d4bc224e22af8a5a48d6ff13e5a0fcfee2a4","modified":1669908959652},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/merge-configs.js","hash":"7c944c43b2ece5dd84859bd9d1fe955d13427387","modified":1669908959654},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","hash":"ba63f7c3324bc1fdd050a90add9d8faaffc27e07","modified":1669908959638},{"_id":"node_modules/hexo-theme-fluid/source/css/_variables/base.styl","hash":"4ed5f0ae105ef4c7dd92eaf652ceda176c38e502","modified":1669908961604},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_archive/archive.styl","hash":"c475e6681546d30350eaed11f23081ecae80c375","modified":1669908961598},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/base.styl","hash":"643284c567665f96915f0b64e59934dda315f74d","modified":1669908961603},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_about/about.styl","hash":"97fe42516ea531fdad771489b68aa8b2a7f6ae46","modified":1669908961592},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/inline.styl","hash":"411a3fa3f924a87e00ff04d18b5c83283b049a4d","modified":1669908961615},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":1669908961620},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":1669908961615},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/color-schema.styl","hash":"61279540c2623ea4bf93e40613d41380839b92d3","modified":1669908961608},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-bar.styl","hash":"cc6df43fef6bb3efecbfdd8b9e467424a1dea581","modified":1669908961606},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/highlight.styl","hash":"4df764d298fe556e501db4afc2b05686fe6ebcfb","modified":1669908961613},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-chain.styl","hash":"0cdf7ef50dfd0669d3b257821384ff31cd81b7c9","modified":1669908961606},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_index/index.styl","hash":"0acbd71633bcc7191672ea4e1b2277bea350d73b","modified":1669908961614},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_links/links.styl","hash":"5c7f2044e3f1da05a3229537c06bd879836f8d6e","modified":1669908961616},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/comment.styl","hash":"780f3788e7357bcd3f3262d781cb91bb53976a93","modified":1669908961609},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-page.styl","hash":"127bb5391370afe7fef2a297084d76406bc5e902","modified":1669908961620},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/markdown.styl","hash":"1e3d3a82721e7c10bcfcecec6d81cf2979039452","modified":1669908961617},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-list.styl","hash":"7edfe1b571ecca7d08f5f4dbcf76f4ffdcfbf0b5","modified":1669908961607},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-tag.styl","hash":"27f70062415ccf66a9b6f4952db124fc1471fda5","modified":1669908961621},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":1669908961624},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/board.styl","hash":"4397037fc3f0033dbe546c33cd9dbdabd8cb1632","modified":1669908961605},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/anchorjs.styl","hash":"e0cebda4a6f499aff75e71417d88caa7ceb13b94","modified":1669908961596},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/banner.styl","hash":"7a0bd629bc234fc75e3cc8e3715ffada92f09e73","modified":1669908961600},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footer.styl","hash":"2caaca71dd1ff63d583099ed817677dd267b457e","modified":1669908961610},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/code-widget.styl","hash":"b66ab013f0f37d724a149b85b3c7432afcf460ad","modified":1669908961607},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/header.styl","hash":"0aa512c21a4b74ef2e70009786a1858d7c2fae9c","modified":1669908961611},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/copyright.styl","hash":"26f71a9cd60d96bb0cb5bbdf58150b8e524d9707","modified":1669908961610},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":1669908961610},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/ngrogress.styl","hash":"5d225357b4a58d46118e6616377168336ed44cb2","modified":1669908961618},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"78704a94c0436097abfb0e0a57abeb3429c749b7","modified":1669908961621},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/modal.styl","hash":"adf6c1e5c8e1fb41c77ce6e2258001df61245aa2","modified":1669908961618},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/noscript.styl","hash":"0cf2f2bb44f456150d428016675d5876a9d2e2aa","modified":1669908961619},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"f0e429a27fa8a7658fcbddbb4d4dbe4afa12499a","modified":1669908961622},{"_id":"source/img/多项式规约/3-SAT2Ham-Cycle构造.png","hash":"4fdd35cd0772d9b539bdeef8be07426f0620f5c1","modified":1670328714209},{"_id":"source/img/矩阵论/Rayleigh-Ritz定理.png","hash":"db7a94b27a698ea23dc7d102e1823438e6a79775","modified":1670463301905},{"_id":"source/img/矩阵论/对角占优矩阵.png","hash":"7d0b10579793a66949640a5bb73156c900d75c43","modified":1670425621817},{"_id":"source/img/矩阵论/圆盘定理2.png","hash":"7e23d62f7ab859255dfa3aea5aeb084a64e16e30","modified":1670425474066},{"_id":"source/img/矩阵论/盖尔圆盘.png","hash":"1a16c94db4776fd1bd9c5cd691a01e95d42f96d0","modified":1670425376502},{"_id":"source/img/矩阵论/矩阵范数性质-定理1-2.png","hash":"471e4285d0757be59f5bed81fc0469c51e1088f8","modified":1670423095811},{"_id":"source/img/近似算法/WeightedVertexCover-PricingMethod-例子.png","hash":"4799ca4f8e451859055fe19629afc32315f1450b","modified":1670506244972},{"_id":"source/img/最大流最小割/最大流最小割定理.png","hash":"46e2700778a75dc5e59e5d73de4705013dadc97b","modified":1670053289831},{"_id":"source/img/最大流最小割/残余图.png","hash":"32b9449b7cec2790927c7b5c0a679064e7b9e488","modified":1670050457590},{"_id":"source/img/随机过程/平稳过程/严平稳过程定义-2.png","hash":"14df87f81392e89948ca2b498f2e606e50ba7641","modified":1670381137381},{"_id":"source/img/随机过程/平稳过程/定理5.2.2.png","hash":"e125c456ad45917fa055d256b2537c8322fe4343","modified":1670395928841},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/pagination.styl","hash":"8bb1b68e5f3552cb48c2ffa31edbc53646a8fb4c","modified":1669908961620},{"_id":"source/img/随机过程/平稳过程/定理5.2.3.png","hash":"3c8f2b17f5cd261be0065e879bc6837838b484d7","modified":1670398350732},{"_id":"source/img/随机过程/平稳过程/宽平稳过程定义.png","hash":"7d5c498058981fda8f9c9801c773a2261f6d605b","modified":1670381584091},{"_id":"source/img/随机过程/平稳过程/平稳过程自相关函数性质-1.png","hash":"c65e92315b294266e040aa77f62d4e703832213d","modified":1670389225401},{"_id":"source/img/随机过程/平稳过程/自相关函数推论.png","hash":"c7fec8a0dc7d1e4e12a0afb035ce16be8cb3dd5c","modified":1670389480331},{"_id":"source/img/随机过程/平稳过程/自相关证明4.png","hash":"0ce936d175699cac66c9c400d90b0dd999bff4bd","modified":1670395806859},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/toc.styl","hash":"9e7452aa2372153f25d7a4675c9d36d281a65d24","modified":1669908961624},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":1669908961622},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1669908961297},{"_id":"public/local-search.xml","hash":"a9ac352e9aec774bb3346349060d02d2f7e560aa","modified":1670506986705},{"_id":"public/about/index.html","hash":"22a9aa3c2b2226287022102f9ced9713fb07c1f9","modified":1670506986705},{"_id":"public/categories/算法/index.html","hash":"43e9057730ffd45746cd9c50334adb341befb85f","modified":1670506986705},{"_id":"public/categories/数学/index.html","hash":"b60281831c9a554d4c66c3d228c8f5ada3cbe08b","modified":1670506986705},{"_id":"public/categories/数学/矩阵论/index.html","hash":"3a0fc12058f63e296cb8affc8a53b4405c050345","modified":1670506986705},{"_id":"public/categories/数学/随机过程/index.html","hash":"7e600d9ccd9fb3c274ddc38cc124ceb5174dadf6","modified":1670506986705},{"_id":"public/archives/index.html","hash":"2a60571a23aa056d23b6869922bb17c4e8f88a9b","modified":1670506986705},{"_id":"public/archives/page/2/index.html","hash":"37e91409347494830f28f17067056680a3722e38","modified":1670506986705},{"_id":"public/archives/2022/index.html","hash":"8d387937416d04b8f597563fefbb4493e202afd9","modified":1670506986705},{"_id":"public/archives/2022/page/2/index.html","hash":"5bc0147c1f8fc14a2cfe414e212615f5f3807628","modified":1670506986705},{"_id":"public/archives/2022/12/index.html","hash":"c161b1aa5fd4bc74a8e060724f2b73f8901349e2","modified":1670506986705},{"_id":"public/archives/2022/12/page/2/index.html","hash":"84e2720e501495ca16d06fcdd63610d5ae3a1bf3","modified":1670506986705},{"_id":"public/tags/矩阵论/index.html","hash":"2a5103d98adcdd3456174ed0b9115990e3d7619c","modified":1670506986705},{"_id":"public/tags/latex/index.html","hash":"3bb0b91944e6814be513c17f705fed1e71bf2de4","modified":1670506986705},{"_id":"public/tags/杂/index.html","hash":"a6e029313617f1e471e6c1436b20aa4fbe261d0d","modified":1670506986705},{"_id":"public/tags/算法/index.html","hash":"8c01a68f4c334f6ec221e31bdb6b099d86beeb65","modified":1670506986705},{"_id":"public/tags/算法设计与分析/index.html","hash":"b4943bacf0764c30c654e8abf856dab52bda62ae","modified":1670506986705},{"_id":"public/404.html","hash":"8498ed542a51fef27d19970e65293bd5eee2ae6f","modified":1670506986705},{"_id":"public/tags/高级算法设计与分析/index.html","hash":"aca642728c2be0584a04a277bc25a8b9bfd92412","modified":1670506986705},{"_id":"public/tags/随机过程/index.html","hash":"f6fa7b1d5304be09e2e4ed968c65e5b54d7a1e9d","modified":1670506986705},{"_id":"public/tags/index.html","hash":"bfca62cd326f52243141c240eae83d03ad1fb385","modified":1670506986705},{"_id":"public/links/index.html","hash":"0256269874faa920823158e362576142b5ecefd9","modified":1670506986705},{"_id":"public/2022/12/08/近似算法/index.html","hash":"0f6379860f4c2f0847dcfbdca60bbfeba6599cc6","modified":1670506986705},{"_id":"public/2022/12/07/平稳过程/index.html","hash":"663b204d9e562c32f22be65410c10983bd2c52a3","modified":1670506986705},{"_id":"public/2022/12/07/范数/index.html","hash":"515e755ae796e6f16c54d1a988bda4191e2ea058","modified":1670506986705},{"_id":"public/2022/12/07/特征值估计/index.html","hash":"7a7e90b3c5d208c51bb1d281699d4bfd9a54c5fd","modified":1670506986705},{"_id":"public/2022/12/05/NP问题/index.html","hash":"8c034b8ccb911ae2cc5554f203d675a8dfe27c16","modified":1670506986705},{"_id":"public/2022/12/05/广义逆矩阵/index.html","hash":"c41e868dbdf87391a6567c2b915192bdb6cfc8a9","modified":1670506986705},{"_id":"public/2022/12/05/矩阵级数和矩阵函数/index.html","hash":"5debdf7fe90bf708637730fca6fb9cd845ce5413","modified":1670506986705},{"_id":"public/2022/12/05/Jardon标准型/index.html","hash":"c33377a225873037ea0c509483fa0a59a66159b5","modified":1670506986705},{"_id":"public/2022/12/04/Latex常用符号/index.html","hash":"5138cbf1bfa72e865a60f1271fb47bdce30f0176","modified":1670506986705},{"_id":"public/2022/12/03/矩阵分解/index.html","hash":"f9b486ca07bcc648a293aa9242231b1f41bfaa42","modified":1670506986705},{"_id":"public/2022/12/03/多项式规约/index.html","hash":"bf1e38027b2b164faebfef99be58ee74656af24b","modified":1670506986705},{"_id":"public/2022/12/03/最大流最小割/index.html","hash":"85b7c4ec94829079c5710c567a4ca061d5327d8f","modified":1670506986705},{"_id":"public/2022/12/02/动态规划/index.html","hash":"1ca2db451092221327d37812e7b5c1adb11c8620","modified":1670506986705},{"_id":"public/2022/12/02/胜者树败者树/index.html","hash":"495fa6080ba280b36444dc8f85bedceba09106d4","modified":1670506986705},{"_id":"public/index.html","hash":"9b759b129f39c5c147dff9584651bbc9afc1a589","modified":1670506986705},{"_id":"public/2022/12/02/红黑树/index.html","hash":"fe959838054e558d8c9ce7702bf50f5cd1491c51","modified":1670506986705},{"_id":"public/2022/12/02/Git常用命令/index.html","hash":"3183683a181e49705939db92a0a92fd19ecee1a7","modified":1670506986705},{"_id":"public/page/2/index.html","hash":"1cfe58a26864474b95cd4519f41ceb197fbc2d18","modified":1670506986705},{"_id":"public/categories/index.html","hash":"dd8a649c64276f940fb0abacf1073cda9a8fd858","modified":1670506986705},{"_id":"public/img/多项式规约/3-SAT23-COLOLABLE-1.png","hash":"e089ff65920dbdfe299bcbe07b7ed360fef2f900","modified":1670506986705},{"_id":"public/img/多项式规约/3-SAT23-COLOLABLE-2.png","hash":"97a60785bb5ec1fe0501fbdf57c9c088dbb166e2","modified":1670506986705},{"_id":"public/img/多项式规约/3-SAT例子.png","hash":"f3efd838662fb8f18b2cb336619be06dca3140b4","modified":1670506986705},{"_id":"public/img/多项式规约/3-SAT23-COLOLABLE-4.png","hash":"7d65756bf0c1426c068fb4cbab92e15cc833b988","modified":1670506986705},{"_id":"public/img/多项式规约/3-SAT2IndependentSet.png","hash":"99cc5a082dd54fcc1351ea3f741c4eab2b919d09","modified":1670506986705},{"_id":"public/img/多项式规约/DIR-HAM-CYC2Ham-Cycle.png","hash":"68a04c1f4d78a55ddced3f22710e72fd6eaabe58","modified":1670506986705},{"_id":"public/img/多项式规约/HamiltonianCycle定义.png","hash":"a992de285d802d1856bb4ff85e284d359edf044f","modified":1670506986705},{"_id":"public/img/多项式规约/3-SAT23-COLOLABLE-3.png","hash":"f669ea65a9c5b8461c5e52062fe687b070791306","modified":1670506986705},{"_id":"public/img/动态规划/最短路径.png","hash":"0ba147ab707a0e36e3051bff42d30cbaa6759c63","modified":1670506986705},{"_id":"public/img/多项式规约/点覆盖.png","hash":"021805ebf776c01cd678d4c26f21f8a0672e1902","modified":1670506986705},{"_id":"public/img/动态规划/最长上升子序列代码.jpg","hash":"d0c1dbb9c49b2b4264b9e6eca7971f38d06e5455","modified":1670506986705},{"_id":"public/img/多项式规约/VertexCover归约到SetCover例子.png","hash":"097b817dd6a6e3c99f94f2e539b5ff8d31945203","modified":1670506986705},{"_id":"public/img/多项式规约/独立集.png","hash":"c41df5652e2b1ec4fc4c0afa8960ca8db7e7f252","modified":1670506986705},{"_id":"public/img/多项式规约/集合覆盖例子.png","hash":"7a362f1b37966dbfeb1f2d0a62f606dcf5a0f7c1","modified":1670506986705},{"_id":"public/img/动态规划/状态转移方程.svg","hash":"8b5734d7212db7f4d24e95f2d422d7f1c6defb1d","modified":1670506986705},{"_id":"public/img/动态规划/解决方案.jpg","hash":"8500d51aa92b8cf3e1a4faa475de9524d179f978","modified":1670506986705},{"_id":"public/img/矩阵论/Jordan标准型定理2.png","hash":"831a8ebd5f087a8af02f7091a2e98af603e7cd10","modified":1670506986705},{"_id":"public/img/矩阵论/shur不等式证明.png","hash":"598bb2e50b796e085a3b247a5d23138afe2665eb","modified":1670506986705},{"_id":"public/img/矩阵论/Jordan标准型定义.png","hash":"fd7ab301d4a052294fcf9534a52d5f885bb04afa","modified":1670506986705},{"_id":"public/img/矩阵论/例1-2.png","hash":"94772735e5144392761b8dcc93212182df44de20","modified":1670506986705},{"_id":"public/img/矩阵论/例1-1.png","hash":"ce9a8d48eb483edeeb02a69429ed517bce30a157","modified":1670506986705},{"_id":"public/img/矩阵论/例2-2.png","hash":"f021ca4e86c1cdd2b9b2e3cdb6bf39841a7d4da9","modified":1670506986705},{"_id":"public/img/矩阵论/例2-1.png","hash":"e924c3bff5df279c2b041f9575a7b1e777544266","modified":1670506986705},{"_id":"public/img/矩阵论/例2-2.webp","hash":"f021ca4e86c1cdd2b9b2e3cdb6bf39841a7d4da9","modified":1670506986705},{"_id":"public/img/矩阵论/全部广义逆集合定义.png","hash":"9745aa36667cb01985319c2ff500c8904a77bd12","modified":1670506986705},{"_id":"public/img/矩阵论/单边逆定义.png","hash":"63b9c0b8fb1babd332aeb0a9b0655c92e986427f","modified":1670506986705},{"_id":"public/img/矩阵论/圆盘定理1.png","hash":"f3fa0425de576cba18a5440d91003ebcf7861b21","modified":1670506986705},{"_id":"public/img/矩阵论/定理3(v)证明.png","hash":"5cb563931d15a987ce63aab807fd24b3612282d9","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆定理2-2.png","hash":"fd5360153ace174550b2b734b14a9850aa8f273f","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆定理1.png","hash":"9ee64fe21f8c34f28b84fff0502591a6dbd5d07f","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆定理2-1.png","hash":"ba82245e52ea81cb10f25ca11bfb03fa95b256ec","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆定理3-2.png","hash":"10feec4e6b41efcdf89896b7c70eb6259b086b4f","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆定义.png","hash":"15320e82be1884fbcfa9376b82ed5059b7891841","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆推论1.png","hash":"1cabd42b07c99e5a38c8142344a2e733eb9cc149","modified":1670506986705},{"_id":"public/img/矩阵论/特征值估计-shur不等式.png","hash":"04e221d97b35290d2e3f7c6e04c9bfc798c15cfd","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆定理3-1.png","hash":"6ece2ecee1c2acd17ef563183efc325dc896d602","modified":1670506986705},{"_id":"public/img/矩阵论/算子范数定义2.png","hash":"e2eb299b2b17d2a87809b4046d7d766e261b9a42","modified":1670506986705},{"_id":"public/img/矩阵论/矩阵范数性质-定理1.png","hash":"932b41c023d8a8e210e23ac91836bf9279210d07","modified":1670506986705},{"_id":"public/img/矩阵论/自反广义逆矩阵定义.png","hash":"e22b0f9e4ad70bb55c677dc87b0c71795f065f9f","modified":1670506986705},{"_id":"public/img/矩阵论/算子范数定义1.png","hash":"42e65c6cea212584efb01fa60043a94ab1b9c4c7","modified":1670506986705},{"_id":"public/img/矩阵论/算子范数性质-定理3.png","hash":"1af57f8acac0c1c7b6933d5d7c718fd5dd9d3038","modified":1670506986705},{"_id":"public/img/矩阵论/自反广义逆矩阵定理1.png","hash":"c71c853ac1e7ab8e6c4544b8a691c97fb7e10cb8","modified":1670506986705},{"_id":"public/img/胜者树败者树/fig3.jpg","hash":"f65abc86102943457c2fd7f4de3bc2ca6e9ff8ff","modified":1670506986705},{"_id":"public/img/胜者树败者树/fig4.jpg","hash":"8f104f440e15af2f0fa833339e76b58e1c0fc1ee","modified":1670506986705},{"_id":"public/img/胜者树败者树/fig2.jpg","hash":"daaf81658569b19710523c650f4a1c95fa46db4b","modified":1670506986705},{"_id":"public/img/近似算法/CentrerSelectionProblem.png","hash":"0aed6e89774041b4cd29c59ae338a4b2d877879a","modified":1670506986705},{"_id":"public/img/胜者树败者树/fig1.jpg","hash":"97867bf0b5eeedc2a763d42b0ddf3a489ee2a08d","modified":1670506986705},{"_id":"public/img/近似算法/CentrerSelectionProblem贪心算法-证明.png","hash":"72a7e740e3ac52cec0a393eda9c6a8bdf38a86f1","modified":1670506986705},{"_id":"public/img/近似算法/LoadBalancingLPT算法.png","hash":"e69741234fa1bd5aba148ec8da69f0a8a002b66f","modified":1670506986705},{"_id":"public/img/近似算法/LoadBalancing实例-贪心算法.png","hash":"bd73a41af05c16f462ddb6ed7870f24bf17721f9","modified":1670506986705},{"_id":"public/img/近似算法/CentrerSelectionProblem贪心算法.png","hash":"5817c70eb2dd3666c7bd96ff528d5fd4ffc56a34","modified":1670506986705},{"_id":"public/img/近似算法/LoadBalancing实例-最优解.png","hash":"6cd261c033a45ecb72215908067dd49c7135386f","modified":1670506986705},{"_id":"public/img/近似算法/LoadBalancing贪心算法证明-1.png","hash":"c665d1f6a9b7e1bad5373e48b0973da2dcf62abf","modified":1670506986705},{"_id":"public/img/近似算法/LoadBalancing贪心算法.png","hash":"365af0e750226f27615e5fbf425ad9194a66b460","modified":1670506986705},{"_id":"public/img/近似算法/WeightedVertexCover-PricingMethod-求解过程.png","hash":"193fb21ed9c3a5ac4b96ce97a1d0a0c6ea76013e","modified":1670506986705},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子1.png","hash":"67e5f7b1db79d46598fe41b1b57fff2c84dc6d32","modified":1670506986705},{"_id":"public/img/近似算法/WeightedVertexCover-不等式放缩.png","hash":"bb7608412df0ecfc1e017426be27102f3f865f77","modified":1670506986705},{"_id":"public/img/近似算法/证明PricingMethod2倍近似解.png","hash":"9dec755a2bf4e9119b7be6e3cb113cc78c2f50ba","modified":1670506986705},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子2.png","hash":"df88bf8af91a2073fbaaba71def9ebebe949b645","modified":1670506986705},{"_id":"public/img/近似算法/WeightedVertexCover.png","hash":"a09667ced16a32117c7070ab27facb6b79324040","modified":1670506986705},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子5.png","hash":"19e85b264deafb8926b70ed397a59cd495e224f6","modified":1670506986705},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子7.png","hash":"1a935d7a67c1cd2241cdeb2c4a61ca437e65a756","modified":1670506986705},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子3.png","hash":"757c7bb6ff26a30ea9e46deb7777740516f225cc","modified":1670506986705},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子4.png","hash":"e08eea19af73ad0bcc8c8c0181173e5db30e19df","modified":1670506986705},{"_id":"public/img/最大流最小割/iii到i.png","hash":"eb6738e99b57447dcd63fdf8aa241fb8f5c2b321","modified":1670506986705},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子6.png","hash":"6a815e321d3abd5d260709d42b921d4cf35f5bf5","modified":1670506986705},{"_id":"public/img/最大流最小割/最大流.png","hash":"f4671c1a200b41a3ac6608cd4ad0c03b14da6596","modified":1670506986705},{"_id":"public/img/最大流最小割/最小割定义.png","hash":"f3d62ba163797d84ab99a6113baea85c67152a94","modified":1670506986705},{"_id":"public/img/最大流最小割/一个割例子.png","hash":"79f139ef1f807758efb8dd0614723b008117597d","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/M-P广义逆定理3.png","hash":"1322d25010deffde7fc429ef6154b463c8045c0a","modified":1670506986705},{"_id":"public/img/多项式规约/3-SAT2Ham-Cycle构造.png","hash":"4fdd35cd0772d9b539bdeef8be07426f0620f5c1","modified":1670506986705},{"_id":"public/img/矩阵论/Rayleigh-Ritz定理.png","hash":"db7a94b27a698ea23dc7d102e1823438e6a79775","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/M-P广义逆定理1.png","hash":"68b5d35faccba9d90d2dc318e504fcff1ae8881b","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/M-P广义逆定理5.png","hash":"45fc109d729de45c444e89736126775a5f0b8122","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/M-P广义逆定义.png","hash":"db60c9834047722dfb0c84c3e09b482b2c89225f","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-2.png","hash":"d21aec756ff0373dba5460f061c2933f4185c397","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/M-P广义逆的计算定理1.png","hash":"3c9a342f4171ebdc0ff837638e9a596a496291af","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-1.png","hash":"9d029526af7af5e2a3908aa283476e5214ddd795","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/图2.png","hash":"ce4ffa7ddbc0842c2c0c31d7cf45c2ebd36d7395","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/图1.png","hash":"9ed45a13693724b55b9bb54bbe84763571cb67f5","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/引理1.png","hash":"b19c4e62d664f276a53d9d4e9112df6854e55434","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/定理2.png","hash":"4fe34c0040ed10fd0e0abd580ec22ad76c46e10c","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/定理3.png","hash":"0e87e3391df3e87a2b6eb0083ecc9f7b9e5186cc","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/5.2.2证明.png","hash":"7d4827ab30a39501daaf423830f5af0d50ff3c36","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/严平稳过程定义.png","hash":"2c4335e6870993517fb99f132e33b7f8e1536caf","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/最大秩分解法例1-1.png","hash":"652f575341ccd09d3f16f2fa2980454bf7506938","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/平稳过程自相关函数性质-2.png","hash":"36ba8f248bb8481a4b5ccfafeb2aacee432072e5","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/最大秩分解法例1-3.png","hash":"e966d003a7179232a4235cf6053f7ae5ee1e2ca5","modified":1670506986705},{"_id":"public/img/矩阵论/广义逆矩阵/最大秩分解法例1-2.png","hash":"0757c3939b94137f5854e113ab5c44edc6662a11","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/自相关证明3.png","hash":"15c2d6b976b12a09e26c5be3198c97e2a7969fc9","modified":1670506986705},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/自相关证明1.png","hash":"cbd9244966c91b696be1caaa17e157cea133f4fa","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/自相关证明2.png","hash":"97e929ee9ec4961daa05f1d2e344e8d317a4dd9a","modified":1670506986705},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1670506986705},{"_id":"public/img/矩阵论/圆盘定理2.png","hash":"7e23d62f7ab859255dfa3aea5aeb084a64e16e30","modified":1670506986705},{"_id":"public/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1670506986705},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1670506986705},{"_id":"public/img/矩阵论/对角占优矩阵.png","hash":"7d0b10579793a66949640a5bb73156c900d75c43","modified":1670506986705},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1670506986705},{"_id":"public/img/矩阵论/盖尔圆盘.png","hash":"1a16c94db4776fd1bd9c5cd691a01e95d42f96d0","modified":1670506986705},{"_id":"public/img/矩阵论/矩阵范数性质-定理1-2.png","hash":"471e4285d0757be59f5bed81fc0469c51e1088f8","modified":1670506986705},{"_id":"public/img/近似算法/WeightedVertexCover-PricingMethod-例子.png","hash":"4799ca4f8e451859055fe19629afc32315f1450b","modified":1670506986705},{"_id":"public/img/最大流最小割/最大流最小割定理.png","hash":"46e2700778a75dc5e59e5d73de4705013dadc97b","modified":1670506986705},{"_id":"public/img/最大流最小割/残余图.png","hash":"32b9449b7cec2790927c7b5c0a679064e7b9e488","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/严平稳过程定义-2.png","hash":"14df87f81392e89948ca2b498f2e606e50ba7641","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/定理5.2.2.png","hash":"e125c456ad45917fa055d256b2537c8322fe4343","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/平稳过程自相关函数性质-1.png","hash":"c65e92315b294266e040aa77f62d4e703832213d","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/定理5.2.3.png","hash":"3c8f2b17f5cd261be0065e879bc6837838b484d7","modified":1670506986705},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1670506986705},{"_id":"public/css/highlight.css","hash":"0f9a477d33d3b15ebe7e163e756fb7c54c7ded6b","modified":1670506986705},{"_id":"public/css/highlight-dark.css","hash":"2b0daa6e5343da9dbb26d617d224b8397e48556b","modified":1670506986705},{"_id":"public/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1670506986705},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1670506986705},{"_id":"public/js/events.js","hash":"89e3561488a618ed0caeb9edf18e441978e29c25","modified":1670506986705},{"_id":"public/js/color-schema.js","hash":"ba63f7c3324bc1fdd050a90add9d8faaffc27e07","modified":1670506986705},{"_id":"public/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1670506986705},{"_id":"public/js/plugins.js","hash":"2333494add51e5e1374602a4e81f0be36a05d4c2","modified":1670506986705},{"_id":"public/js/utils.js","hash":"45cc86f099db0a2c36ad49711ce66c2d598a2ab1","modified":1670506986705},{"_id":"public/js/local-search.js","hash":"cebcda5991b6a9ab9307c69542389ce9013f04f7","modified":1670506986705},{"_id":"public/css/main.css","hash":"d3b6eb3ef0e222271f1453d3d1214f3ba053792d","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/宽平稳过程定义.png","hash":"7d5c498058981fda8f9c9801c773a2261f6d605b","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/自相关函数推论.png","hash":"c7fec8a0dc7d1e4e12a0afb035ce16be8cb3dd5c","modified":1670506986705},{"_id":"public/img/随机过程/平稳过程/自相关证明4.png","hash":"0ce936d175699cac66c9c400d90b0dd999bff4bd","modified":1670506986705},{"_id":"public/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1670506986705}],"Category":[{"name":"数学","_id":"clbf4q8o70003r4sghiqp7wng"},{"name":"算法","_id":"clbf4q8oa0009r4sg2nz2h93r"},{"name":"矩阵论","parent":"clbf4q8o70003r4sghiqp7wng","_id":"clbf4q8oc000fr4sg9jtqavfk"},{"name":"随机过程","parent":"clbf4q8o70003r4sghiqp7wng","_id":"clbf4q8oi0018r4sg38j47o8i"}],"Data":[],"Page":[{"title":"about","layout":"about","_content":"\n","source":"about/index.md","raw":"---\ntitle: about\nlayout: about\n---\n\n","date":"2022-12-02T04:38:02.134Z","updated":"2022-12-02T04:38:02.134Z","path":"about/index.html","comments":1,"_id":"clbf4q8o10000r4sgfjprauco","content":"\r\n","site":{"data":{}},"excerpt":"","more":"\r\n"}],"Post":[{"title":"Jordan标准型","_content":"\n## Jordan标准型\n\n![Jordan标准型定义](/img/矩阵论/Jordan标准型定义.png)\n\n其中 $J_1(\\lambda_1),J_2(\\lambda_2)$分别构成Jardon块。\n\n即对任意矩阵 $A$，比存在n阶可逆矩阵$P$，使\n$$P^{-1}AP=\\begin{bmatrix}\n    J_1 & & & \\\\ & J_2 & & \\\\ & & \\ddots & \\\\ & & & J_n\n\\end{bmatrix} = J$$\n\n每一个 $J$ 都是Jardon块\n$$J_i=\\begin{bmatrix}\n    \\lambda_i & 1 & & \\\\ & \\lambda_i & \\ddots & & \\\\ & & \\ddots &1 \\\\ & & & \\lambda_i\n\\end{bmatrix}$$\n\n\n### Jordan标准型的结构与结论\n- Jordan标准型的个数$k$是线性无关特征向量的个数\n- 矩阵可对角化当且仅当$k=n$\n- 相应于一个已知特征值的Jordan块的个数是该特征值的几何重数，它是相应的特征子空间的维数，相应于一个已知特征值的所有Jordan的阶数之和，是该特征值的代数重数\n- 特征值的几何重数 < 代数重数\n- 矩阵不同特征值对应的特征向量线性无关\n\n![定理2](/img/矩阵论/Jordan标准型定理2.png)","source":"_posts/Jardon标准型.md","raw":"---\ntitle: Jordan标准型\ntags: 矩阵论\ncategories: \n    - 数学\n    - 矩阵论\n---\n\n## Jordan标准型\n\n![Jordan标准型定义](/img/矩阵论/Jordan标准型定义.png)\n\n其中 $J_1(\\lambda_1),J_2(\\lambda_2)$分别构成Jardon块。\n\n即对任意矩阵 $A$，比存在n阶可逆矩阵$P$，使\n$$P^{-1}AP=\\begin{bmatrix}\n    J_1 & & & \\\\ & J_2 & & \\\\ & & \\ddots & \\\\ & & & J_n\n\\end{bmatrix} = J$$\n\n每一个 $J$ 都是Jardon块\n$$J_i=\\begin{bmatrix}\n    \\lambda_i & 1 & & \\\\ & \\lambda_i & \\ddots & & \\\\ & & \\ddots &1 \\\\ & & & \\lambda_i\n\\end{bmatrix}$$\n\n\n### Jordan标准型的结构与结论\n- Jordan标准型的个数$k$是线性无关特征向量的个数\n- 矩阵可对角化当且仅当$k=n$\n- 相应于一个已知特征值的Jordan块的个数是该特征值的几何重数，它是相应的特征子空间的维数，相应于一个已知特征值的所有Jordan的阶数之和，是该特征值的代数重数\n- 特征值的几何重数 < 代数重数\n- 矩阵不同特征值对应的特征向量线性无关\n\n![定理2](/img/矩阵论/Jordan标准型定理2.png)","slug":"Jardon标准型","published":1,"date":"2022-12-05T07:00:32.678Z","updated":"2022-12-05T12:24:36.290Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8o30001r4sg2b5jfcc7","content":"<h2 id=\"jordan标准型\">Jordan标准型</h2>\r\n<figure>\r\n<img src=\"/img/矩阵论/Jordan标准型定义.png\" alt=\"Jordan标准型定义\" />\r\n<figcaption aria-hidden=\"true\">Jordan标准型定义</figcaption>\r\n</figure>\r\n<p>其中 <span\r\nclass=\"math inline\">\\(J_1(\\lambda_1),J_2(\\lambda_2)\\)</span>分别构成Jardon块。</p>\r\n<p>即对任意矩阵 <span\r\nclass=\"math inline\">\\(A\\)</span>，比存在n阶可逆矩阵<span\r\nclass=\"math inline\">\\(P\\)</span>，使 <span\r\nclass=\"math display\">\\[P^{-1}AP=\\begin{bmatrix}\r\n    J_1 &amp; &amp; &amp; \\\\ &amp; J_2 &amp; &amp; \\\\ &amp; &amp; \\ddots\r\n&amp; \\\\ &amp; &amp; &amp; J_n\r\n\\end{bmatrix} = J\\]</span></p>\r\n<p>每一个 <span class=\"math inline\">\\(J\\)</span> 都是Jardon块 <span\r\nclass=\"math display\">\\[J_i=\\begin{bmatrix}\r\n    \\lambda_i &amp; 1 &amp; &amp; \\\\ &amp; \\lambda_i &amp; \\ddots &amp;\r\n&amp; \\\\ &amp; &amp; \\ddots &amp;1 \\\\ &amp; &amp; &amp; \\lambda_i\r\n\\end{bmatrix}\\]</span></p>\r\n<h3 id=\"jordan标准型的结构与结论\">Jordan标准型的结构与结论</h3>\r\n<ul>\r\n<li>Jordan标准型的个数<span\r\nclass=\"math inline\">\\(k\\)</span>是线性无关特征向量的个数</li>\r\n<li>矩阵可对角化当且仅当<span class=\"math inline\">\\(k=n\\)</span></li>\r\n<li>相应于一个已知特征值的Jordan块的个数是该特征值的几何重数，它是相应的特征子空间的维数，相应于一个已知特征值的所有Jordan的阶数之和，是该特征值的代数重数</li>\r\n<li>特征值的几何重数 &lt; 代数重数</li>\r\n<li>矩阵不同特征值对应的特征向量线性无关</li>\r\n</ul>\r\n<figure>\r\n<img src=\"/img/矩阵论/Jordan标准型定理2.png\" alt=\"定理2\" />\r\n<figcaption aria-hidden=\"true\">定理2</figcaption>\r\n</figure>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"jordan标准型\">Jordan标准型</h2>\r\n<figure>\r\n<img src=\"/img/矩阵论/Jordan标准型定义.png\" alt=\"Jordan标准型定义\" />\r\n<figcaption aria-hidden=\"true\">Jordan标准型定义</figcaption>\r\n</figure>\r\n<p>其中 <span\r\nclass=\"math inline\">\\(J_1(\\lambda_1),J_2(\\lambda_2)\\)</span>分别构成Jardon块。</p>\r\n<p>即对任意矩阵 <span\r\nclass=\"math inline\">\\(A\\)</span>，比存在n阶可逆矩阵<span\r\nclass=\"math inline\">\\(P\\)</span>，使 <span\r\nclass=\"math display\">\\[P^{-1}AP=\\begin{bmatrix}\r\n    J_1 &amp; &amp; &amp; \\\\ &amp; J_2 &amp; &amp; \\\\ &amp; &amp; \\ddots\r\n&amp; \\\\ &amp; &amp; &amp; J_n\r\n\\end{bmatrix} = J\\]</span></p>\r\n<p>每一个 <span class=\"math inline\">\\(J\\)</span> 都是Jardon块 <span\r\nclass=\"math display\">\\[J_i=\\begin{bmatrix}\r\n    \\lambda_i &amp; 1 &amp; &amp; \\\\ &amp; \\lambda_i &amp; \\ddots &amp;\r\n&amp; \\\\ &amp; &amp; \\ddots &amp;1 \\\\ &amp; &amp; &amp; \\lambda_i\r\n\\end{bmatrix}\\]</span></p>\r\n<h3 id=\"jordan标准型的结构与结论\">Jordan标准型的结构与结论</h3>\r\n<ul>\r\n<li>Jordan标准型的个数<span\r\nclass=\"math inline\">\\(k\\)</span>是线性无关特征向量的个数</li>\r\n<li>矩阵可对角化当且仅当<span class=\"math inline\">\\(k=n\\)</span></li>\r\n<li>相应于一个已知特征值的Jordan块的个数是该特征值的几何重数，它是相应的特征子空间的维数，相应于一个已知特征值的所有Jordan的阶数之和，是该特征值的代数重数</li>\r\n<li>特征值的几何重数 &lt; 代数重数</li>\r\n<li>矩阵不同特征值对应的特征向量线性无关</li>\r\n</ul>\r\n<figure>\r\n<img src=\"/img/矩阵论/Jordan标准型定理2.png\" alt=\"定理2\" />\r\n<figcaption aria-hidden=\"true\">定理2</figcaption>\r\n</figure>\r\n"},{"title":"Git常用命令","math":true,"_content":"\n\n## Git撤销commit命令\n当要撤销的提交不是最开始的提交时\n```\ngit reset HEAD~\n```\n当要撤销的提交时最开始的提交时\n```\ngit update -ref -d HEAD\n```\n## Git连接远程仓库\n```\ngit remote add origin url\n```\n注：url为github仓库链接\n## Git删除已经add的文件\n1.要删除的文件少时\n\t一种是 `git rm --cached` \"文件路径\"，不删除物理文件，仅将该文件从缓存中删除；\n\t一种是 `git rm --f`  \"文件路径\"，不仅将该文件从缓存中删除，还会将物理文件删除（不会回收到垃圾桶）。\n\n\n2.要删除的文件多时\n\t`git rm -r --cached` .  清空缓存区\n\t然后将本地文件删除，再次`add`\n\t\n\n## Git创建远程新分支\ngit无法直接通过命令方式创建远程新分支，需要间接来创建,这里我创建的远程新分支名叫 vedio\n\n\n首先 \n\n`git checkout --orphan 分支名`\n![](https://img-blog.csdnimg.cn/20210403164118752.png)\n**git rm -rf .** （这一步很关键）\n然后创建一个文件readme.md（其实任何文件都可以），add并commit，然后\n\n`git push origin 分支名` \n\n就可以啦~如下图红框圈注的命令\n![](https://img-blog.csdnimg.cn/20210403164816128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzOTQyMQ==,size_16,color_FFFFFF,t_70)\n## git强制提交本地分支覆盖远程分支\n```\ngit push origin localBranchName:remoteBranchName --force\n```\n## Git从远程仓库拉取\n`git pull origin main`\n## Git创建与切换分支\n创建分支 `git branch branch_name`\n切换分支 `git checkout branch_name`\n\n\n\n\n\n\n\n\n","source":"_posts/Git常用命令.md","raw":"---\ntitle: Git常用命令\nmath: true\n---\n\n\n## Git撤销commit命令\n当要撤销的提交不是最开始的提交时\n```\ngit reset HEAD~\n```\n当要撤销的提交时最开始的提交时\n```\ngit update -ref -d HEAD\n```\n## Git连接远程仓库\n```\ngit remote add origin url\n```\n注：url为github仓库链接\n## Git删除已经add的文件\n1.要删除的文件少时\n\t一种是 `git rm --cached` \"文件路径\"，不删除物理文件，仅将该文件从缓存中删除；\n\t一种是 `git rm --f`  \"文件路径\"，不仅将该文件从缓存中删除，还会将物理文件删除（不会回收到垃圾桶）。\n\n\n2.要删除的文件多时\n\t`git rm -r --cached` .  清空缓存区\n\t然后将本地文件删除，再次`add`\n\t\n\n## Git创建远程新分支\ngit无法直接通过命令方式创建远程新分支，需要间接来创建,这里我创建的远程新分支名叫 vedio\n\n\n首先 \n\n`git checkout --orphan 分支名`\n![](https://img-blog.csdnimg.cn/20210403164118752.png)\n**git rm -rf .** （这一步很关键）\n然后创建一个文件readme.md（其实任何文件都可以），add并commit，然后\n\n`git push origin 分支名` \n\n就可以啦~如下图红框圈注的命令\n![](https://img-blog.csdnimg.cn/20210403164816128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzOTQyMQ==,size_16,color_FFFFFF,t_70)\n## git强制提交本地分支覆盖远程分支\n```\ngit push origin localBranchName:remoteBranchName --force\n```\n## Git从远程仓库拉取\n`git pull origin main`\n## Git创建与切换分支\n创建分支 `git branch branch_name`\n切换分支 `git checkout branch_name`\n\n\n\n\n\n\n\n\n","slug":"Git常用命令","published":1,"date":"2022-12-02T04:17:50.606Z","updated":"2022-12-03T08:09:29.350Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8o50002r4sg0e9h83kw","content":"<h2 id=\"git撤销commit命令\">Git撤销commit命令</h2>\r\n<p>当要撤销的提交不是最开始的提交时 <figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">git <span class=\"hljs-built_in\">reset</span> HEAD~<br></code></pre></td></tr></table></figure>\r\n当要撤销的提交时最开始的提交时 <figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">git <span class=\"hljs-keyword\">update</span> <span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">ref</span> <span class=\"hljs-operator\">-</span>d HEAD<br></code></pre></td></tr></table></figure> ## Git连接远程仓库\r\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">git remote <span class=\"hljs-keyword\">add </span><span class=\"hljs-keyword\">origin </span>url<br></code></pre></td></tr></table></figure> 注：url为github仓库链接 ## Git删除已经add的文件\r\n1.要删除的文件少时 一种是 <code>git rm --cached</code>\r\n\"文件路径\"，不删除物理文件，仅将该文件从缓存中删除； 一种是\r\n<code>git rm --f</code>\r\n\"文件路径\"，不仅将该文件从缓存中删除，还会将物理文件删除（不会回收到垃圾桶）。</p>\r\n<p>2.要删除的文件多时 <code>git rm -r --cached</code> . 清空缓存区\r\n然后将本地文件删除，再次<code>add</code></p>\r\n<h2 id=\"git创建远程新分支\">Git创建远程新分支</h2>\r\n<p>git无法直接通过命令方式创建远程新分支，需要间接来创建,这里我创建的远程新分支名叫\r\nvedio</p>\r\n<p>首先</p>\r\n<p><code>git checkout --orphan 分支名</code> <img\r\nsrc=\"https://img-blog.csdnimg.cn/20210403164118752.png\" /> <strong>git\r\nrm -rf .</strong> （这一步很关键）\r\n然后创建一个文件readme.md（其实任何文件都可以），add并commit，然后</p>\r\n<p><code>git push origin 分支名</code></p>\r\n<p>就可以啦~如下图红框圈注的命令 <img\r\nsrc=\"https://img-blog.csdnimg.cn/20210403164816128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzOTQyMQ==,size_16,color_FFFFFF,t_70\" />\r\n## git强制提交本地分支覆盖远程分支 <figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">git <span class=\"hljs-built_in\">push</span> <span class=\"hljs-built_in\">origin</span> localBranchName:remoteBranchName --force<br></code></pre></td></tr></table></figure> ## Git从远程仓库拉取\r\n<code>git pull origin main</code> ## Git创建与切换分支 创建分支\r\n<code>git branch branch_name</code> 切换分支\r\n<code>git checkout branch_name</code></p>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"git撤销commit命令\">Git撤销commit命令</h2>\r\n<p>当要撤销的提交不是最开始的提交时 <figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">git <span class=\"hljs-built_in\">reset</span> HEAD~<br></code></pre></td></tr></table></figure>\r\n当要撤销的提交时最开始的提交时 <figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">git <span class=\"hljs-keyword\">update</span> <span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">ref</span> <span class=\"hljs-operator\">-</span>d HEAD<br></code></pre></td></tr></table></figure> ## Git连接远程仓库\r\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">git remote <span class=\"hljs-keyword\">add </span><span class=\"hljs-keyword\">origin </span>url<br></code></pre></td></tr></table></figure> 注：url为github仓库链接 ## Git删除已经add的文件\r\n1.要删除的文件少时 一种是 <code>git rm --cached</code>\r\n\"文件路径\"，不删除物理文件，仅将该文件从缓存中删除； 一种是\r\n<code>git rm --f</code>\r\n\"文件路径\"，不仅将该文件从缓存中删除，还会将物理文件删除（不会回收到垃圾桶）。</p>\r\n<p>2.要删除的文件多时 <code>git rm -r --cached</code> . 清空缓存区\r\n然后将本地文件删除，再次<code>add</code></p>\r\n<h2 id=\"git创建远程新分支\">Git创建远程新分支</h2>\r\n<p>git无法直接通过命令方式创建远程新分支，需要间接来创建,这里我创建的远程新分支名叫\r\nvedio</p>\r\n<p>首先</p>\r\n<p><code>git checkout --orphan 分支名</code> <img\r\nsrc=\"https://img-blog.csdnimg.cn/20210403164118752.png\" /> <strong>git\r\nrm -rf .</strong> （这一步很关键）\r\n然后创建一个文件readme.md（其实任何文件都可以），add并commit，然后</p>\r\n<p><code>git push origin 分支名</code></p>\r\n<p>就可以啦~如下图红框圈注的命令 <img\r\nsrc=\"https://img-blog.csdnimg.cn/20210403164816128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzOTQyMQ==,size_16,color_FFFFFF,t_70\" />\r\n## git强制提交本地分支覆盖远程分支 <figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">git <span class=\"hljs-built_in\">push</span> <span class=\"hljs-built_in\">origin</span> localBranchName:remoteBranchName --force<br></code></pre></td></tr></table></figure> ## Git从远程仓库拉取\r\n<code>git pull origin main</code> ## Git创建与切换分支 创建分支\r\n<code>git branch branch_name</code> 切换分支\r\n<code>git checkout branch_name</code></p>\r\n"},{"title":"Latex常用表示","_content":"\n\n## 希腊字母\n\n\n|小写字母|语法|大写字母|实现|\n|---------|--------|------|-----------|\n|$\\alpha$| `\\alpha` |$A$|`A` |\n|$\\beta$| `\\beta` |$B$|`B` |\n|$\\gamma$|`\\gamma`|$\\Gamma$|`\\Gamma`|\n|$\\delta$|`\\delta` |$\\Delta$|`\\Delta` |\n|$\\epsilon$|`\\epsilon` |$E$|`E` |\n|$\\varepsilon$|`\\varepsilon`|\n|$\\zeta$|`\\zeta`|$Z$ |`Z`|\n|$\\eta$|`\\eta`|$H$|`H`|\n|$\\theta$|`\\theta`|$\\Theta$|`\\Theta`|\n|$\\vartheta$|`\\vartheta` |\n|$\\iota$|`\\iota` |$I$|`I` |\n|$\\kappa$|`\\kappa` |$K$|`K` |\n|$\\lambda$|`\\lambda` |$\\Lambda$|`\\Lambda` |\n|$\\mu$|`\\mu` |$M$|`M`|\n|$\\nu$|`\\nu` |$N$|`N`|\n|$\\xi$|`\\xi`|$\\Xi$|`\\Xi`|\n|$\\omicron$|`\\omicron`|$O$|`O`|\n|$\\pi$|`\\pi`|$\\Pi$|`\\Pi` |\n|$\\varpi$|`\\varpi` |\n|$\\rho$|`\\rho` |$R$|`R` |\n|$\\varrho$|`\\varrho` |\n|$\\sigma$|`\\sigma` |$\\Sigma$|`\\Sigma` |\n|$\\varsigma$|`\\varsigma` |\n|$\\tau$|`\\tau` |$T$|`T` |\n|$\\upsilon$|`\\upsilon` |\n|$\\phi$|`\\phi` |$\\Phi$|`\\Phi` |\n|$\\varphi$|`\\varphi` |\n|$\\chi$|`\\chi` | $X$ | `X` |\n|$\\psi$|`\\psi` |$\\Psi$|`\\Psi` |\n|$\\omega$|`\\omega`|$\\Omega$|`\\Omega`|\n\n\nvar开头的只有小写希腊字母，没有大写。\n\n## 运算符符号\n\n\n|符号|实现|\n|---|---|\n|$\\sum$|`\\sum`|\n|$\\prod$|`\\prod`|\n|$\\int$|`\\int`|\n|$\\oplus$|`\\oplus`|\n|$\\otimes$|`\\otimes`|\n|$\\times$|`\\times`|\n|$\\cdot$|`\\codt`|\n\n\n## 关系符号\n\n\n|符号|实现|\n|---|---|\n|$\\le$|`\\le`|\n|$\\ge$|`\\ge`|\n|$\\ll$|`\\ll`|\n|$\\gg$|`\\gg`|\n|$\\equiv$|`\\equiv`|\n|$\\subseteq$| `\\subseteq` |\n|$\\supseteq$| `\\supseteq` |\n|$\\subset$| `\\subset` |\n|$\\supset$| `\\supset` | \n\n\n## 箭头符号\n\n\n|符号|实现|\n|---|---|\n|$\\Leftarrow$|`\\Leftarrow`|\n|$\\Rightarrow$|`\\Rightarrow`|\n\n\n## 其他符号\n\n\n|符号|实现|含义|\n|---|---|---|\n|$\\infty$|`\\infty`|无穷|\n|$\\exists$|`\\exists`|存在|\n|$\\forall$|`\\forall`|任取|\n|$\\ldots$|`\\ldots`|下三连点|\n|$\\cdots$|`\\cdots`|中三连点|\n|$\\vdots$|`\\vdots`|竖三连点|\n|$\\ddots$|`\\ddots`|斜三连点|\n|$\\overline{x}$|`\\overline{x}`|平均|\n|$\\quad$|`\\quad` |空格|\n\n","source":"_posts/Latex常用符号.md","raw":"---\ntitle: Latex常用表示\ntags: \n    - latex\n    - 杂\n---\n\n\n## 希腊字母\n\n\n|小写字母|语法|大写字母|实现|\n|---------|--------|------|-----------|\n|$\\alpha$| `\\alpha` |$A$|`A` |\n|$\\beta$| `\\beta` |$B$|`B` |\n|$\\gamma$|`\\gamma`|$\\Gamma$|`\\Gamma`|\n|$\\delta$|`\\delta` |$\\Delta$|`\\Delta` |\n|$\\epsilon$|`\\epsilon` |$E$|`E` |\n|$\\varepsilon$|`\\varepsilon`|\n|$\\zeta$|`\\zeta`|$Z$ |`Z`|\n|$\\eta$|`\\eta`|$H$|`H`|\n|$\\theta$|`\\theta`|$\\Theta$|`\\Theta`|\n|$\\vartheta$|`\\vartheta` |\n|$\\iota$|`\\iota` |$I$|`I` |\n|$\\kappa$|`\\kappa` |$K$|`K` |\n|$\\lambda$|`\\lambda` |$\\Lambda$|`\\Lambda` |\n|$\\mu$|`\\mu` |$M$|`M`|\n|$\\nu$|`\\nu` |$N$|`N`|\n|$\\xi$|`\\xi`|$\\Xi$|`\\Xi`|\n|$\\omicron$|`\\omicron`|$O$|`O`|\n|$\\pi$|`\\pi`|$\\Pi$|`\\Pi` |\n|$\\varpi$|`\\varpi` |\n|$\\rho$|`\\rho` |$R$|`R` |\n|$\\varrho$|`\\varrho` |\n|$\\sigma$|`\\sigma` |$\\Sigma$|`\\Sigma` |\n|$\\varsigma$|`\\varsigma` |\n|$\\tau$|`\\tau` |$T$|`T` |\n|$\\upsilon$|`\\upsilon` |\n|$\\phi$|`\\phi` |$\\Phi$|`\\Phi` |\n|$\\varphi$|`\\varphi` |\n|$\\chi$|`\\chi` | $X$ | `X` |\n|$\\psi$|`\\psi` |$\\Psi$|`\\Psi` |\n|$\\omega$|`\\omega`|$\\Omega$|`\\Omega`|\n\n\nvar开头的只有小写希腊字母，没有大写。\n\n## 运算符符号\n\n\n|符号|实现|\n|---|---|\n|$\\sum$|`\\sum`|\n|$\\prod$|`\\prod`|\n|$\\int$|`\\int`|\n|$\\oplus$|`\\oplus`|\n|$\\otimes$|`\\otimes`|\n|$\\times$|`\\times`|\n|$\\cdot$|`\\codt`|\n\n\n## 关系符号\n\n\n|符号|实现|\n|---|---|\n|$\\le$|`\\le`|\n|$\\ge$|`\\ge`|\n|$\\ll$|`\\ll`|\n|$\\gg$|`\\gg`|\n|$\\equiv$|`\\equiv`|\n|$\\subseteq$| `\\subseteq` |\n|$\\supseteq$| `\\supseteq` |\n|$\\subset$| `\\subset` |\n|$\\supset$| `\\supset` | \n\n\n## 箭头符号\n\n\n|符号|实现|\n|---|---|\n|$\\Leftarrow$|`\\Leftarrow`|\n|$\\Rightarrow$|`\\Rightarrow`|\n\n\n## 其他符号\n\n\n|符号|实现|含义|\n|---|---|---|\n|$\\infty$|`\\infty`|无穷|\n|$\\exists$|`\\exists`|存在|\n|$\\forall$|`\\forall`|任取|\n|$\\ldots$|`\\ldots`|下三连点|\n|$\\cdots$|`\\cdots`|中三连点|\n|$\\vdots$|`\\vdots`|竖三连点|\n|$\\ddots$|`\\ddots`|斜三连点|\n|$\\overline{x}$|`\\overline{x}`|平均|\n|$\\quad$|`\\quad` |空格|\n\n","slug":"Latex常用符号","published":1,"date":"2022-12-04T12:38:30.385Z","updated":"2022-12-06T11:21:07.195Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8o80005r4sgchpq6n4s","content":"<h2 id=\"希腊字母\">希腊字母</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>小写字母</th>\r\n<th>语法</th>\r\n<th>大写字母</th>\r\n<th>实现</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\alpha\\)</span></td>\r\n<td><code>\\alpha</code></td>\r\n<td><span class=\"math inline\">\\(A\\)</span></td>\r\n<td><code>A</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\beta\\)</span></td>\r\n<td><code>\\beta</code></td>\r\n<td><span class=\"math inline\">\\(B\\)</span></td>\r\n<td><code>B</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\gamma\\)</span></td>\r\n<td><code>\\gamma</code></td>\r\n<td><span class=\"math inline\">\\(\\Gamma\\)</span></td>\r\n<td><code>\\Gamma</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\delta\\)</span></td>\r\n<td><code>\\delta</code></td>\r\n<td><span class=\"math inline\">\\(\\Delta\\)</span></td>\r\n<td><code>\\Delta</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\epsilon\\)</span></td>\r\n<td><code>\\epsilon</code></td>\r\n<td><span class=\"math inline\">\\(E\\)</span></td>\r\n<td><code>E</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\varepsilon\\)</span></td>\r\n<td><code>\\varepsilon</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\zeta\\)</span></td>\r\n<td><code>\\zeta</code></td>\r\n<td><span class=\"math inline\">\\(Z\\)</span></td>\r\n<td><code>Z</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\eta\\)</span></td>\r\n<td><code>\\eta</code></td>\r\n<td><span class=\"math inline\">\\(H\\)</span></td>\r\n<td><code>H</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\theta\\)</span></td>\r\n<td><code>\\theta</code></td>\r\n<td><span class=\"math inline\">\\(\\Theta\\)</span></td>\r\n<td><code>\\Theta</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\vartheta\\)</span></td>\r\n<td><code>\\vartheta</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\iota\\)</span></td>\r\n<td><code>\\iota</code></td>\r\n<td><span class=\"math inline\">\\(I\\)</span></td>\r\n<td><code>I</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\kappa\\)</span></td>\r\n<td><code>\\kappa</code></td>\r\n<td><span class=\"math inline\">\\(K\\)</span></td>\r\n<td><code>K</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\lambda\\)</span></td>\r\n<td><code>\\lambda</code></td>\r\n<td><span class=\"math inline\">\\(\\Lambda\\)</span></td>\r\n<td><code>\\Lambda</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\mu\\)</span></td>\r\n<td><code>\\mu</code></td>\r\n<td><span class=\"math inline\">\\(M\\)</span></td>\r\n<td><code>M</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\nu\\)</span></td>\r\n<td><code>\\nu</code></td>\r\n<td><span class=\"math inline\">\\(N\\)</span></td>\r\n<td><code>N</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\xi\\)</span></td>\r\n<td><code>\\xi</code></td>\r\n<td><span class=\"math inline\">\\(\\Xi\\)</span></td>\r\n<td><code>\\Xi</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\omicron\\)</span></td>\r\n<td><code>\\omicron</code></td>\r\n<td><span class=\"math inline\">\\(O\\)</span></td>\r\n<td><code>O</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\pi\\)</span></td>\r\n<td><code>\\pi</code></td>\r\n<td><span class=\"math inline\">\\(\\Pi\\)</span></td>\r\n<td><code>\\Pi</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\varpi\\)</span></td>\r\n<td><code>\\varpi</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\rho\\)</span></td>\r\n<td><code>\\rho</code></td>\r\n<td><span class=\"math inline\">\\(R\\)</span></td>\r\n<td><code>R</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\varrho\\)</span></td>\r\n<td><code>\\varrho</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\sigma\\)</span></td>\r\n<td><code>\\sigma</code></td>\r\n<td><span class=\"math inline\">\\(\\Sigma\\)</span></td>\r\n<td><code>\\Sigma</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\varsigma\\)</span></td>\r\n<td><code>\\varsigma</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\tau\\)</span></td>\r\n<td><code>\\tau</code></td>\r\n<td><span class=\"math inline\">\\(T\\)</span></td>\r\n<td><code>T</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\upsilon\\)</span></td>\r\n<td><code>\\upsilon</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\phi\\)</span></td>\r\n<td><code>\\phi</code></td>\r\n<td><span class=\"math inline\">\\(\\Phi\\)</span></td>\r\n<td><code>\\Phi</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\varphi\\)</span></td>\r\n<td><code>\\varphi</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\chi\\)</span></td>\r\n<td><code>\\chi</code></td>\r\n<td><span class=\"math inline\">\\(X\\)</span></td>\r\n<td><code>X</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\psi\\)</span></td>\r\n<td><code>\\psi</code></td>\r\n<td><span class=\"math inline\">\\(\\Psi\\)</span></td>\r\n<td><code>\\Psi</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\omega\\)</span></td>\r\n<td><code>\\omega</code></td>\r\n<td><span class=\"math inline\">\\(\\Omega\\)</span></td>\r\n<td><code>\\Omega</code></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<p>var开头的只有小写希腊字母，没有大写。</p>\r\n<h2 id=\"运算符符号\">运算符符号</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>符号</th>\r\n<th>实现</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\sum\\)</span></td>\r\n<td><code>\\sum</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\prod\\)</span></td>\r\n<td><code>\\prod</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\int\\)</span></td>\r\n<td><code>\\int</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\oplus\\)</span></td>\r\n<td><code>\\oplus</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\otimes\\)</span></td>\r\n<td><code>\\otimes</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\times\\)</span></td>\r\n<td><code>\\times</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\cdot\\)</span></td>\r\n<td><code>\\codt</code></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2 id=\"关系符号\">关系符号</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>符号</th>\r\n<th>实现</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\le\\)</span></td>\r\n<td><code>\\le</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\ge\\)</span></td>\r\n<td><code>\\ge</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\ll\\)</span></td>\r\n<td><code>\\ll</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\gg\\)</span></td>\r\n<td><code>\\gg</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\equiv\\)</span></td>\r\n<td><code>\\equiv</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\subseteq\\)</span></td>\r\n<td><code>\\subseteq</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\supseteq\\)</span></td>\r\n<td><code>\\supseteq</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\subset\\)</span></td>\r\n<td><code>\\subset</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\supset\\)</span></td>\r\n<td><code>\\supset</code></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2 id=\"箭头符号\">箭头符号</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>符号</th>\r\n<th>实现</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\Leftarrow\\)</span></td>\r\n<td><code>\\Leftarrow</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\Rightarrow\\)</span></td>\r\n<td><code>\\Rightarrow</code></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2 id=\"其他符号\">其他符号</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>符号</th>\r\n<th>实现</th>\r\n<th>含义</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\infty\\)</span></td>\r\n<td><code>\\infty</code></td>\r\n<td>无穷</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\exists\\)</span></td>\r\n<td><code>\\exists</code></td>\r\n<td>存在</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\forall\\)</span></td>\r\n<td><code>\\forall</code></td>\r\n<td>任取</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\ldots\\)</span></td>\r\n<td><code>\\ldots</code></td>\r\n<td>下三连点</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\cdots\\)</span></td>\r\n<td><code>\\cdots</code></td>\r\n<td>中三连点</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\vdots\\)</span></td>\r\n<td><code>\\vdots</code></td>\r\n<td>竖三连点</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\ddots\\)</span></td>\r\n<td><code>\\ddots</code></td>\r\n<td>斜三连点</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\overline{x}\\)</span></td>\r\n<td><code>\\overline&#123;x&#125;</code></td>\r\n<td>平均</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\quad\\)</span></td>\r\n<td><code>\\quad</code></td>\r\n<td>空格</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"希腊字母\">希腊字母</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>小写字母</th>\r\n<th>语法</th>\r\n<th>大写字母</th>\r\n<th>实现</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\alpha\\)</span></td>\r\n<td><code>\\alpha</code></td>\r\n<td><span class=\"math inline\">\\(A\\)</span></td>\r\n<td><code>A</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\beta\\)</span></td>\r\n<td><code>\\beta</code></td>\r\n<td><span class=\"math inline\">\\(B\\)</span></td>\r\n<td><code>B</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\gamma\\)</span></td>\r\n<td><code>\\gamma</code></td>\r\n<td><span class=\"math inline\">\\(\\Gamma\\)</span></td>\r\n<td><code>\\Gamma</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\delta\\)</span></td>\r\n<td><code>\\delta</code></td>\r\n<td><span class=\"math inline\">\\(\\Delta\\)</span></td>\r\n<td><code>\\Delta</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\epsilon\\)</span></td>\r\n<td><code>\\epsilon</code></td>\r\n<td><span class=\"math inline\">\\(E\\)</span></td>\r\n<td><code>E</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\varepsilon\\)</span></td>\r\n<td><code>\\varepsilon</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\zeta\\)</span></td>\r\n<td><code>\\zeta</code></td>\r\n<td><span class=\"math inline\">\\(Z\\)</span></td>\r\n<td><code>Z</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\eta\\)</span></td>\r\n<td><code>\\eta</code></td>\r\n<td><span class=\"math inline\">\\(H\\)</span></td>\r\n<td><code>H</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\theta\\)</span></td>\r\n<td><code>\\theta</code></td>\r\n<td><span class=\"math inline\">\\(\\Theta\\)</span></td>\r\n<td><code>\\Theta</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\vartheta\\)</span></td>\r\n<td><code>\\vartheta</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\iota\\)</span></td>\r\n<td><code>\\iota</code></td>\r\n<td><span class=\"math inline\">\\(I\\)</span></td>\r\n<td><code>I</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\kappa\\)</span></td>\r\n<td><code>\\kappa</code></td>\r\n<td><span class=\"math inline\">\\(K\\)</span></td>\r\n<td><code>K</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\lambda\\)</span></td>\r\n<td><code>\\lambda</code></td>\r\n<td><span class=\"math inline\">\\(\\Lambda\\)</span></td>\r\n<td><code>\\Lambda</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\mu\\)</span></td>\r\n<td><code>\\mu</code></td>\r\n<td><span class=\"math inline\">\\(M\\)</span></td>\r\n<td><code>M</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\nu\\)</span></td>\r\n<td><code>\\nu</code></td>\r\n<td><span class=\"math inline\">\\(N\\)</span></td>\r\n<td><code>N</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\xi\\)</span></td>\r\n<td><code>\\xi</code></td>\r\n<td><span class=\"math inline\">\\(\\Xi\\)</span></td>\r\n<td><code>\\Xi</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\omicron\\)</span></td>\r\n<td><code>\\omicron</code></td>\r\n<td><span class=\"math inline\">\\(O\\)</span></td>\r\n<td><code>O</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\pi\\)</span></td>\r\n<td><code>\\pi</code></td>\r\n<td><span class=\"math inline\">\\(\\Pi\\)</span></td>\r\n<td><code>\\Pi</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\varpi\\)</span></td>\r\n<td><code>\\varpi</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\rho\\)</span></td>\r\n<td><code>\\rho</code></td>\r\n<td><span class=\"math inline\">\\(R\\)</span></td>\r\n<td><code>R</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\varrho\\)</span></td>\r\n<td><code>\\varrho</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\sigma\\)</span></td>\r\n<td><code>\\sigma</code></td>\r\n<td><span class=\"math inline\">\\(\\Sigma\\)</span></td>\r\n<td><code>\\Sigma</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\varsigma\\)</span></td>\r\n<td><code>\\varsigma</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\tau\\)</span></td>\r\n<td><code>\\tau</code></td>\r\n<td><span class=\"math inline\">\\(T\\)</span></td>\r\n<td><code>T</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\upsilon\\)</span></td>\r\n<td><code>\\upsilon</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\phi\\)</span></td>\r\n<td><code>\\phi</code></td>\r\n<td><span class=\"math inline\">\\(\\Phi\\)</span></td>\r\n<td><code>\\Phi</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\varphi\\)</span></td>\r\n<td><code>\\varphi</code></td>\r\n<td></td>\r\n<td></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\chi\\)</span></td>\r\n<td><code>\\chi</code></td>\r\n<td><span class=\"math inline\">\\(X\\)</span></td>\r\n<td><code>X</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\psi\\)</span></td>\r\n<td><code>\\psi</code></td>\r\n<td><span class=\"math inline\">\\(\\Psi\\)</span></td>\r\n<td><code>\\Psi</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\omega\\)</span></td>\r\n<td><code>\\omega</code></td>\r\n<td><span class=\"math inline\">\\(\\Omega\\)</span></td>\r\n<td><code>\\Omega</code></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<p>var开头的只有小写希腊字母，没有大写。</p>\r\n<h2 id=\"运算符符号\">运算符符号</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>符号</th>\r\n<th>实现</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\sum\\)</span></td>\r\n<td><code>\\sum</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\prod\\)</span></td>\r\n<td><code>\\prod</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\int\\)</span></td>\r\n<td><code>\\int</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\oplus\\)</span></td>\r\n<td><code>\\oplus</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\otimes\\)</span></td>\r\n<td><code>\\otimes</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\times\\)</span></td>\r\n<td><code>\\times</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\cdot\\)</span></td>\r\n<td><code>\\codt</code></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2 id=\"关系符号\">关系符号</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>符号</th>\r\n<th>实现</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\le\\)</span></td>\r\n<td><code>\\le</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\ge\\)</span></td>\r\n<td><code>\\ge</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\ll\\)</span></td>\r\n<td><code>\\ll</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\gg\\)</span></td>\r\n<td><code>\\gg</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\equiv\\)</span></td>\r\n<td><code>\\equiv</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\subseteq\\)</span></td>\r\n<td><code>\\subseteq</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\supseteq\\)</span></td>\r\n<td><code>\\supseteq</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\subset\\)</span></td>\r\n<td><code>\\subset</code></td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\supset\\)</span></td>\r\n<td><code>\\supset</code></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2 id=\"箭头符号\">箭头符号</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>符号</th>\r\n<th>实现</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\Leftarrow\\)</span></td>\r\n<td><code>\\Leftarrow</code></td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\Rightarrow\\)</span></td>\r\n<td><code>\\Rightarrow</code></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2 id=\"其他符号\">其他符号</h2>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>符号</th>\r\n<th>实现</th>\r\n<th>含义</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\infty\\)</span></td>\r\n<td><code>\\infty</code></td>\r\n<td>无穷</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\exists\\)</span></td>\r\n<td><code>\\exists</code></td>\r\n<td>存在</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\forall\\)</span></td>\r\n<td><code>\\forall</code></td>\r\n<td>任取</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\ldots\\)</span></td>\r\n<td><code>\\ldots</code></td>\r\n<td>下三连点</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\cdots\\)</span></td>\r\n<td><code>\\cdots</code></td>\r\n<td>中三连点</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\vdots\\)</span></td>\r\n<td><code>\\vdots</code></td>\r\n<td>竖三连点</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\ddots\\)</span></td>\r\n<td><code>\\ddots</code></td>\r\n<td>斜三连点</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><span class=\"math inline\">\\(\\overline{x}\\)</span></td>\r\n<td><code>\\overline&#123;x&#125;</code></td>\r\n<td>平均</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><span class=\"math inline\">\\(\\quad\\)</span></td>\r\n<td><code>\\quad</code></td>\r\n<td>空格</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n"},{"title":"动态规划","math":true,"_content":"\n本文大部分转载自知乎[@阮行止](https://www.zhihu.com/people/ruan-xing-zhi)，后添加了自己的一些思考。\n\n## 1. 从一个生活问题谈起\n先来看看生活中经常遇到的事吧——假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，**需要用到尽量少的钞票**。\n\n依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。\n\n这种策略称为“**贪心**”：假设我们面对的局面是“需要凑出w”，贪心策略会**尽快**让w变得更小。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。\n\n但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：  \n　　15=1×11+4×1 （贪心策略使用了5张钞票）  \n　　15=3×5 （正确的策略，只用3张钞票）  \n　　为什么会这样呢？贪心策略错在了哪里？  \n\n**鼠目寸光**。\n\n刚刚已经说过，贪心策略的纲领是：“尽量使接下来面对的w更小”。这样，贪心策略在w=15的局面时，会优先使用11来把w降到4；但是在这个问题中，凑出4的代价是很高的，必须使用4×1。如果使用了5，w会降为10，虽然没有4那么小，但是凑出10只需要两张5元。 \n\n在这里我们发现，贪心是一种**只考虑眼前情况**的策略。\n\n那么，现在我们怎样才能避免鼠目寸光呢？\n\n如果直接暴力枚举凑出w的方案，明显复杂度过高。太多种方法可以凑出w了，枚举它们的时间是不可承受的。我们现在来尝试找一下性质。\n\n重新分析刚刚的例子。w=15时，我们如果取11，接下来就面对w=4的情况；如果取5，则接下来面对w=10的情况。我们发现这些问题都有相同的形式：“给定w，凑出w所用的最少钞票是多少张？”接下来，我们用f(n)来表示“凑出n所需的最少钞票数量”。\n\n那么，如果我们取了11，最后的代价（用掉的钞票总数）是多少呢？  \n\n明显**cost=f(4)+1=4+1=5** ，它的意义是：利用11来凑出15，付出的代价等于f(4)加上自己这一张钞票。现在我们暂时不管f(4)怎么求出来。  \n\n依次类推，马上可以知道：如果我们用5来凑出15，cost就是**f(10)+1=2+1=3** 。\n\n那么，现在w=15的时候，我们该取那种钞票呢？**当然是各种方案中，cost值最低的那一个！**\n\n- 取11：cost=f(4)+1=4+1=5\n- 取5:cost=f(10)+1=2+1=3\n- 取1:cost=f(14)+1=4+1=5\n\n显而易见，cost值最低的是取5的方案。**我们通过上面三个式子，做出了正确的决策！**\n\n这给了我们一个**至关重要**的启示—— f(n)只与f(n-1),f(n-5),f(n-11) 相关；更确切地说：\n\n> f(n)=min{f(n-1),f(n-5),f(n-11)}+1\n\n这个式子是非常激动人心的。我们要求出f(n)，只需要求出几个更小的f值；既然如此，我们从小到大把所有的f(i)求出来不就好了？注意一下边界情况即可。代码如下：\n\n![pic1](/img/动态规划/解决方案.jpg)\n\n我们以O(n)的复杂度解决了这个问题。现在回过头来，我们看看它的原理：\n\n- f(n)只与f(n-1),f(n-5),f(n-11)的值有关。\n- 我们只关心f(w)的值，不关心是怎么凑出w的。\n\n这两个事实，保证了我们做法的正确性。它比起贪心策略，会分别算出取1、5、11的代价，从而做出一个正确决策，这样就避免掉了“鼠目寸光”！\n\n它与暴力的区别在哪里？我们的暴力枚举了“使用的硬币”，然而这属于冗余信息。我们要的是答案，根本不关心这个答案是怎么凑出来的。譬如，要求出f(15)，只需要知道f(14),f(10),f(4)的值。**其他信息并不需要**。我们舍弃了冗余信息。我们只记录了对解决问题有帮助的信息——f(n).\n\n我们能这样干，取决于问题的性质：求出f(n)，只需要知道几个更小的f(c)。**我们将求解f(c)称作求解f(n)的“子问题”**。\n\n**这就是DP（动态规划，dynamic programming）**.\n\n**将一个问题拆成几个子问题，分别求解这些子问题，即可推断出大问题的解。**\n\n## 2. 几个简单的概念\n- **无后效性**  \n    一旦f(n)确定，“我们如何凑出f(n)”就再也用不着了。  \n\n要求出f(15)，只需要知道f(14),f(10),f(4)的值，而f(14),f(10),f(4)是如何算出来的，对之后的问题没有影响。\n\n“**未来与过去无关**”，这就是**无后效性**。\n\n（严格定义：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响。）\n\n- 最优子结构\n\n回顾我们对f(n)的定义：我们记“凑出n所需的最少钞票数量”为f(n).\n\nf(n)的定义就已经蕴含了“最优”。利用w=14,10,4的最优解，我们即可算出w=15的最优解。\n\n大问题的**最优解**可以由小问题的**最优解**推出，这个性质叫做“最优子结构性质”。\n\n引入这两个概念之后，我们如何判断一个问题能否使用DP解决呢？\n\n**能将大问题拆成几个小问题，且满足无后效性、最优子结构性质**。\n\n## 3. DP的典型应用：DAG最短路\n\n问题很简单：给定一个城市的地图，所有的道路都是单行道，而且不会构成环。每条道路都有过路费，问您从S点到T点花费的最少费用。\n\n![最短路径](/img/动态规划/最短路径.png)\n\n这个问题能用DP解决吗？我们先试着记从S到P的最少费用为f(P).\n\n想要到T，要么经过C，要么经过D。从而$f(T)=min\\{f(C)+20,f(D)+10\\}$.\n\n好像看起来可以DP。现在我们检验刚刚那两个性质：\n\n- 无后效性：对于点P，一旦f(P)确定，以后就只关心f(P)的值，不关心怎么去的。\n- 最优子结构：对于P，我们当然只关心到P的最小费用，即f(P)。如果我们从S走到T是$S \\rightarrow P\\rightarrow Q \\rightarrow T$,那肯定S走到Q的最优路径是$S \\rightarrow P\\rightarrow Q$。对一条最优的路径而言，从S走到**沿途上所有的点（子问题）**的最优路径，都是这条大路的一部分。这个问题的最优子结构性质是显然的。\n\n既然这两个性质都满足，那么本题可以DP。式子明显为：\n\n> f(P)=min\\{f(R)+W<sub>$R \\rightarrow P$</sub>\\}\n\n其中R为有路通到P的所有的点， [公式] 为R到P的过路费。\n\n代码实现也很简单，拓扑排序即可。\n\n## 4. 对DP原理的一点讨论\n\n- DP的核心思想\n\nDP为什么会快？\n\n无论是DP还是暴力，我们的算法都是在**可能解空间**内，寻找**最优解**。\n\n来看钞票问题。暴力做法是枚举所有的可能解，这是最大的可能解空间。\n\nDP是枚举**有希望成为答案的解**。这个空间比暴力的小得多。\n\n也就是说：**DP自带剪枝**。\n\nDP舍弃了一大堆不可能成为最优解的答案。譬如：  \n　　15 = 5+5+5 被考虑了。  \n　　15 = 5+5+1+1+1+1+1 从来没有考虑过，因为这不可能成为最优解。\n\n在暴力算法中，可能解空间往往是指数级的大小；如果我们采用DP，那么有可能把解空间的大小降到多项式级。\n\n一般来说，解空间越小，寻找解就越快。这样就完成了优化。\n\n- DP的操作过程\n\n一言以蔽之：**大事化小，小事化了**。\n\n将一个大问题转化成几个小问题；  \n　　求解小问题；  \n　　推出大问题的解。\n\n- 如何设计DP算法\n\n下面介绍比较通用的设计DP算法的步骤。\n\n首先，把我们面对的局面表示为x。这一步称为设计状态。\n\n对于状态x，记我们要求出的答案(e.g. 最小费用)为f(x).我们的目标是求出f(T).\n**找出f(x)与哪些局面有关（记为p）**，写出一个式子（称为状态转移方程），通过f(p)来推出f(x).\n\n- DP三连\n\n设计DP算法，往往可以遵循DP三连：\n\n我是谁？ ——设计状态，表示局面\n\n我从哪里来？\n\n我要到哪里去？ ——设计转移\n\n设计状态是DP的基础。接下来的设计转移，有两种方式：一种是考虑我从哪里来（本文之前提到的两个例子，都是在考虑“我从哪里来”）；另一种是考虑我到哪里去，这常见于求出f(x)之后，**更新能从x走到的一些解**。这种DP也是不少的，我们以后会遇到。\n\n总而言之，“我从哪里来”和“我要到哪里去”只需要考虑清楚其中一个，就能设计出状态转移方程，从而写代码求解问题。前者又称pull型的转移，后者又称push型的转移。\n\n> 思考题：如何把钞票问题的代码改写成“我到哪里去”的形式？  \n> 提示：求出f(x)之后，更新f(x+1),f(x+5),f(x+11).\n\n## 5. 例题：最长上升子序列\n\n扯了这么多形而上的内容，还是做一道例题吧。\n\n最长上升子序列（LIS）问题：给定长度为n的序列a，从a中抽取出一个子序列，这个子序列需要单调递增。问最长的上升子序列（LIS）的长度。  \n　　e.g. 1,5,3,4,6,9,7,8的LIS为1,3,4,6,7,8，长度为6。\n\n如何设计状态（我是谁）？\n\n我们记$f(x)$为以a<sub>x</sub>结尾的LIS长度，那么答案就是 $max\\{f(x)\\}$\n\n状态x从哪里推过来（我从哪里来）？\n\n考虑比x小的每一个p：如果 a<sub>x</sub> > a<sub>p</sub>，那么$f(x)$可以取$f(p)+1$.\n\n解释：我们把 a<sub>x</sub> 接在 a<sub>p</sub> 的后面，肯定能构造一个以 a<sub>x</sub> 结尾的上升子序列，长度比以 a<sub>p</sub> 结尾的LIS大1.那么，我们可以写出状态转移方程了：\n\n![状态转移方程](/img/动态规划/状态转移方程.svg)\n\n至此解决问题。两层for循环，复杂度O(n<sup>2</sup>) 。\n\n![最长上升子序列代码](/img/动态规划/最长上升子序列代码.jpg)\n\n从这三个例题中可以看出，DP是一种思想，一种“大事化小，小事化了”的思想。带着这种思想，DP将会成为我们解决问题的利器。\n\n## 6. 习题\n\n如果读者有兴趣，可以试着完成下面几个习题：\n\n1. 请采取一些优化手段，以 O(n log<sub>2</sub> n) 的复杂度解决LIS问题。\n\n提示：可以参考这篇博客 [Junior Dynamic Programming--动态规划初步·各种子序列问题](https://www.luogu.com.cn/blog/pks-LOVING/junior-dynamic-programming-dong-tai-gui-hua-chu-bu-ge-zhong-zi-xu-lie)\n\n2. “按顺序递推”和“记忆化搜索”是实现DP的两种方式。请查阅资料，简单描述“记忆化搜索”是什么。并采用记忆化搜索写出钞票问题的代码，然后完成[P1541 乌龟棋 - 洛谷](https://www.luogu.com.cn/problem/P1541) 。\n3. 01背包问题是一种常见的DP模型。请完成[P1048 采药 - 洛谷](https://www.luogu.com.cn/problem/P1048)。\n\n## 7. 读后思考：动态规划和分治法的区别与共同点？\n\n### 1. 分治法\n\n分治法(Divide-and-Conquer) : 将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。\n\n分治模式在每一层递归上都有三个步骤：\n\n- 分解(Divide)：将原问题分解成一系列子问题；\n- 解决(Conquer)：递归地解决各个子问题。若子问题足够小，则直接求解。\n- 合并(Combine)：将子问题的结果合并成原问题的解。\n\n合并排序(Merge Sort)是一个典型分治法的例子。其对应的直观的操作如下:\n\n分解： 将n个元素分成各含n/2个元素的子序列；\n\n解决：用合并排序法对两个子序列递归地排序；\n\n合并：合并两个已排序的子序列以得到排序结果。\n\n### 2. 动态规划法\n\n动态规划算法的设计可以分为如下4个步骤：\n\n- 描述最优解的结构\n- 递归定义最优解的值\n- 按自底向上的方式计算最优解的值\n- 由计算出的结果构造一个最优解\n\n**分治法是指将问题划分成一些独立的子问题，递归的求解各子问题，然后合并子问题的解而得到原问题的解。与此不同，动态规划适用于子问题独立且重叠的情况，也就是各子问题包含公共的子子问题。在这种情况下，若用分治法则会做许多不必要的工作，即重复地求解公共的子问题。动态规划算法对每个子子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。**\n\n适合采用动态规划方法的最优化问题中的两个要素：**最优子结构**和**重叠子问题**。\n\n最优子结构：如果问题的一个最优解中包含了子问题的最优解，则该问题具有最优子结构。\n\n重叠子问题：适用于动态规划求解的最优化问题必须具有的第二个要素是子问题的空间要很小，也就是用来求解原问题的递归算法反复地解同样的子问题，而不是总是在产生新的子问题。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则它们是重叠的。\n\nIn a word, **分治法 —— 各子问题独立；动态规划 —— 各子问题重叠**。\n\n算法导论： **动态规划要求其子问题既要独立又要重叠，这看上去似乎有些奇怪。虽然这两点要求听起来可能矛盾的，但它们描述了两种不同的概念，而不是同一个问题的两个方面。如果同一个问题的两个子问题不共享资源，则它们就是独立的。对两个子问题俩说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，是重叠的，则它们是重叠**。","source":"_posts/动态规划.md","raw":"---\ntitle: 动态规划\ncategories: 算法\ntags: 算法\nmath: true\n---\n\n本文大部分转载自知乎[@阮行止](https://www.zhihu.com/people/ruan-xing-zhi)，后添加了自己的一些思考。\n\n## 1. 从一个生活问题谈起\n先来看看生活中经常遇到的事吧——假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，**需要用到尽量少的钞票**。\n\n依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。\n\n这种策略称为“**贪心**”：假设我们面对的局面是“需要凑出w”，贪心策略会**尽快**让w变得更小。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。\n\n但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：  \n　　15=1×11+4×1 （贪心策略使用了5张钞票）  \n　　15=3×5 （正确的策略，只用3张钞票）  \n　　为什么会这样呢？贪心策略错在了哪里？  \n\n**鼠目寸光**。\n\n刚刚已经说过，贪心策略的纲领是：“尽量使接下来面对的w更小”。这样，贪心策略在w=15的局面时，会优先使用11来把w降到4；但是在这个问题中，凑出4的代价是很高的，必须使用4×1。如果使用了5，w会降为10，虽然没有4那么小，但是凑出10只需要两张5元。 \n\n在这里我们发现，贪心是一种**只考虑眼前情况**的策略。\n\n那么，现在我们怎样才能避免鼠目寸光呢？\n\n如果直接暴力枚举凑出w的方案，明显复杂度过高。太多种方法可以凑出w了，枚举它们的时间是不可承受的。我们现在来尝试找一下性质。\n\n重新分析刚刚的例子。w=15时，我们如果取11，接下来就面对w=4的情况；如果取5，则接下来面对w=10的情况。我们发现这些问题都有相同的形式：“给定w，凑出w所用的最少钞票是多少张？”接下来，我们用f(n)来表示“凑出n所需的最少钞票数量”。\n\n那么，如果我们取了11，最后的代价（用掉的钞票总数）是多少呢？  \n\n明显**cost=f(4)+1=4+1=5** ，它的意义是：利用11来凑出15，付出的代价等于f(4)加上自己这一张钞票。现在我们暂时不管f(4)怎么求出来。  \n\n依次类推，马上可以知道：如果我们用5来凑出15，cost就是**f(10)+1=2+1=3** 。\n\n那么，现在w=15的时候，我们该取那种钞票呢？**当然是各种方案中，cost值最低的那一个！**\n\n- 取11：cost=f(4)+1=4+1=5\n- 取5:cost=f(10)+1=2+1=3\n- 取1:cost=f(14)+1=4+1=5\n\n显而易见，cost值最低的是取5的方案。**我们通过上面三个式子，做出了正确的决策！**\n\n这给了我们一个**至关重要**的启示—— f(n)只与f(n-1),f(n-5),f(n-11) 相关；更确切地说：\n\n> f(n)=min{f(n-1),f(n-5),f(n-11)}+1\n\n这个式子是非常激动人心的。我们要求出f(n)，只需要求出几个更小的f值；既然如此，我们从小到大把所有的f(i)求出来不就好了？注意一下边界情况即可。代码如下：\n\n![pic1](/img/动态规划/解决方案.jpg)\n\n我们以O(n)的复杂度解决了这个问题。现在回过头来，我们看看它的原理：\n\n- f(n)只与f(n-1),f(n-5),f(n-11)的值有关。\n- 我们只关心f(w)的值，不关心是怎么凑出w的。\n\n这两个事实，保证了我们做法的正确性。它比起贪心策略，会分别算出取1、5、11的代价，从而做出一个正确决策，这样就避免掉了“鼠目寸光”！\n\n它与暴力的区别在哪里？我们的暴力枚举了“使用的硬币”，然而这属于冗余信息。我们要的是答案，根本不关心这个答案是怎么凑出来的。譬如，要求出f(15)，只需要知道f(14),f(10),f(4)的值。**其他信息并不需要**。我们舍弃了冗余信息。我们只记录了对解决问题有帮助的信息——f(n).\n\n我们能这样干，取决于问题的性质：求出f(n)，只需要知道几个更小的f(c)。**我们将求解f(c)称作求解f(n)的“子问题”**。\n\n**这就是DP（动态规划，dynamic programming）**.\n\n**将一个问题拆成几个子问题，分别求解这些子问题，即可推断出大问题的解。**\n\n## 2. 几个简单的概念\n- **无后效性**  \n    一旦f(n)确定，“我们如何凑出f(n)”就再也用不着了。  \n\n要求出f(15)，只需要知道f(14),f(10),f(4)的值，而f(14),f(10),f(4)是如何算出来的，对之后的问题没有影响。\n\n“**未来与过去无关**”，这就是**无后效性**。\n\n（严格定义：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响。）\n\n- 最优子结构\n\n回顾我们对f(n)的定义：我们记“凑出n所需的最少钞票数量”为f(n).\n\nf(n)的定义就已经蕴含了“最优”。利用w=14,10,4的最优解，我们即可算出w=15的最优解。\n\n大问题的**最优解**可以由小问题的**最优解**推出，这个性质叫做“最优子结构性质”。\n\n引入这两个概念之后，我们如何判断一个问题能否使用DP解决呢？\n\n**能将大问题拆成几个小问题，且满足无后效性、最优子结构性质**。\n\n## 3. DP的典型应用：DAG最短路\n\n问题很简单：给定一个城市的地图，所有的道路都是单行道，而且不会构成环。每条道路都有过路费，问您从S点到T点花费的最少费用。\n\n![最短路径](/img/动态规划/最短路径.png)\n\n这个问题能用DP解决吗？我们先试着记从S到P的最少费用为f(P).\n\n想要到T，要么经过C，要么经过D。从而$f(T)=min\\{f(C)+20,f(D)+10\\}$.\n\n好像看起来可以DP。现在我们检验刚刚那两个性质：\n\n- 无后效性：对于点P，一旦f(P)确定，以后就只关心f(P)的值，不关心怎么去的。\n- 最优子结构：对于P，我们当然只关心到P的最小费用，即f(P)。如果我们从S走到T是$S \\rightarrow P\\rightarrow Q \\rightarrow T$,那肯定S走到Q的最优路径是$S \\rightarrow P\\rightarrow Q$。对一条最优的路径而言，从S走到**沿途上所有的点（子问题）**的最优路径，都是这条大路的一部分。这个问题的最优子结构性质是显然的。\n\n既然这两个性质都满足，那么本题可以DP。式子明显为：\n\n> f(P)=min\\{f(R)+W<sub>$R \\rightarrow P$</sub>\\}\n\n其中R为有路通到P的所有的点， [公式] 为R到P的过路费。\n\n代码实现也很简单，拓扑排序即可。\n\n## 4. 对DP原理的一点讨论\n\n- DP的核心思想\n\nDP为什么会快？\n\n无论是DP还是暴力，我们的算法都是在**可能解空间**内，寻找**最优解**。\n\n来看钞票问题。暴力做法是枚举所有的可能解，这是最大的可能解空间。\n\nDP是枚举**有希望成为答案的解**。这个空间比暴力的小得多。\n\n也就是说：**DP自带剪枝**。\n\nDP舍弃了一大堆不可能成为最优解的答案。譬如：  \n　　15 = 5+5+5 被考虑了。  \n　　15 = 5+5+1+1+1+1+1 从来没有考虑过，因为这不可能成为最优解。\n\n在暴力算法中，可能解空间往往是指数级的大小；如果我们采用DP，那么有可能把解空间的大小降到多项式级。\n\n一般来说，解空间越小，寻找解就越快。这样就完成了优化。\n\n- DP的操作过程\n\n一言以蔽之：**大事化小，小事化了**。\n\n将一个大问题转化成几个小问题；  \n　　求解小问题；  \n　　推出大问题的解。\n\n- 如何设计DP算法\n\n下面介绍比较通用的设计DP算法的步骤。\n\n首先，把我们面对的局面表示为x。这一步称为设计状态。\n\n对于状态x，记我们要求出的答案(e.g. 最小费用)为f(x).我们的目标是求出f(T).\n**找出f(x)与哪些局面有关（记为p）**，写出一个式子（称为状态转移方程），通过f(p)来推出f(x).\n\n- DP三连\n\n设计DP算法，往往可以遵循DP三连：\n\n我是谁？ ——设计状态，表示局面\n\n我从哪里来？\n\n我要到哪里去？ ——设计转移\n\n设计状态是DP的基础。接下来的设计转移，有两种方式：一种是考虑我从哪里来（本文之前提到的两个例子，都是在考虑“我从哪里来”）；另一种是考虑我到哪里去，这常见于求出f(x)之后，**更新能从x走到的一些解**。这种DP也是不少的，我们以后会遇到。\n\n总而言之，“我从哪里来”和“我要到哪里去”只需要考虑清楚其中一个，就能设计出状态转移方程，从而写代码求解问题。前者又称pull型的转移，后者又称push型的转移。\n\n> 思考题：如何把钞票问题的代码改写成“我到哪里去”的形式？  \n> 提示：求出f(x)之后，更新f(x+1),f(x+5),f(x+11).\n\n## 5. 例题：最长上升子序列\n\n扯了这么多形而上的内容，还是做一道例题吧。\n\n最长上升子序列（LIS）问题：给定长度为n的序列a，从a中抽取出一个子序列，这个子序列需要单调递增。问最长的上升子序列（LIS）的长度。  \n　　e.g. 1,5,3,4,6,9,7,8的LIS为1,3,4,6,7,8，长度为6。\n\n如何设计状态（我是谁）？\n\n我们记$f(x)$为以a<sub>x</sub>结尾的LIS长度，那么答案就是 $max\\{f(x)\\}$\n\n状态x从哪里推过来（我从哪里来）？\n\n考虑比x小的每一个p：如果 a<sub>x</sub> > a<sub>p</sub>，那么$f(x)$可以取$f(p)+1$.\n\n解释：我们把 a<sub>x</sub> 接在 a<sub>p</sub> 的后面，肯定能构造一个以 a<sub>x</sub> 结尾的上升子序列，长度比以 a<sub>p</sub> 结尾的LIS大1.那么，我们可以写出状态转移方程了：\n\n![状态转移方程](/img/动态规划/状态转移方程.svg)\n\n至此解决问题。两层for循环，复杂度O(n<sup>2</sup>) 。\n\n![最长上升子序列代码](/img/动态规划/最长上升子序列代码.jpg)\n\n从这三个例题中可以看出，DP是一种思想，一种“大事化小，小事化了”的思想。带着这种思想，DP将会成为我们解决问题的利器。\n\n## 6. 习题\n\n如果读者有兴趣，可以试着完成下面几个习题：\n\n1. 请采取一些优化手段，以 O(n log<sub>2</sub> n) 的复杂度解决LIS问题。\n\n提示：可以参考这篇博客 [Junior Dynamic Programming--动态规划初步·各种子序列问题](https://www.luogu.com.cn/blog/pks-LOVING/junior-dynamic-programming-dong-tai-gui-hua-chu-bu-ge-zhong-zi-xu-lie)\n\n2. “按顺序递推”和“记忆化搜索”是实现DP的两种方式。请查阅资料，简单描述“记忆化搜索”是什么。并采用记忆化搜索写出钞票问题的代码，然后完成[P1541 乌龟棋 - 洛谷](https://www.luogu.com.cn/problem/P1541) 。\n3. 01背包问题是一种常见的DP模型。请完成[P1048 采药 - 洛谷](https://www.luogu.com.cn/problem/P1048)。\n\n## 7. 读后思考：动态规划和分治法的区别与共同点？\n\n### 1. 分治法\n\n分治法(Divide-and-Conquer) : 将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。\n\n分治模式在每一层递归上都有三个步骤：\n\n- 分解(Divide)：将原问题分解成一系列子问题；\n- 解决(Conquer)：递归地解决各个子问题。若子问题足够小，则直接求解。\n- 合并(Combine)：将子问题的结果合并成原问题的解。\n\n合并排序(Merge Sort)是一个典型分治法的例子。其对应的直观的操作如下:\n\n分解： 将n个元素分成各含n/2个元素的子序列；\n\n解决：用合并排序法对两个子序列递归地排序；\n\n合并：合并两个已排序的子序列以得到排序结果。\n\n### 2. 动态规划法\n\n动态规划算法的设计可以分为如下4个步骤：\n\n- 描述最优解的结构\n- 递归定义最优解的值\n- 按自底向上的方式计算最优解的值\n- 由计算出的结果构造一个最优解\n\n**分治法是指将问题划分成一些独立的子问题，递归的求解各子问题，然后合并子问题的解而得到原问题的解。与此不同，动态规划适用于子问题独立且重叠的情况，也就是各子问题包含公共的子子问题。在这种情况下，若用分治法则会做许多不必要的工作，即重复地求解公共的子问题。动态规划算法对每个子子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。**\n\n适合采用动态规划方法的最优化问题中的两个要素：**最优子结构**和**重叠子问题**。\n\n最优子结构：如果问题的一个最优解中包含了子问题的最优解，则该问题具有最优子结构。\n\n重叠子问题：适用于动态规划求解的最优化问题必须具有的第二个要素是子问题的空间要很小，也就是用来求解原问题的递归算法反复地解同样的子问题，而不是总是在产生新的子问题。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则它们是重叠的。\n\nIn a word, **分治法 —— 各子问题独立；动态规划 —— 各子问题重叠**。\n\n算法导论： **动态规划要求其子问题既要独立又要重叠，这看上去似乎有些奇怪。虽然这两点要求听起来可能矛盾的，但它们描述了两种不同的概念，而不是同一个问题的两个方面。如果同一个问题的两个子问题不共享资源，则它们就是独立的。对两个子问题俩说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，是重叠的，则它们是重叠**。","slug":"动态规划","published":1,"date":"2022-12-02T04:31:12.142Z","updated":"2022-12-03T16:11:51.193Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8o90006r4sg9zweajzy","content":"<p>本文大部分转载自知乎<a\r\nhref=\"https://www.zhihu.com/people/ruan-xing-zhi\"><span class=\"citation\"\r\ndata-cites=\"阮行止\">@阮行止</span></a>，后添加了自己的一些思考。</p>\r\n<h2 id=\"从一个生活问题谈起\">1. 从一个生活问题谈起</h2>\r\n<p>先来看看生活中经常遇到的事吧——假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，<strong>需要用到尽量少的钞票</strong>。</p>\r\n<p>依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。</p>\r\n<p>这种策略称为“<strong>贪心</strong>”：假设我们面对的局面是“需要凑出w”，贪心策略会<strong>尽快</strong>让w变得更小。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。</p>\r\n<p>但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：<br />\r\n　　15=1×11+4×1 （贪心策略使用了5张钞票）<br />\r\n　　15=3×5 （正确的策略，只用3张钞票）<br />\r\n　　为什么会这样呢？贪心策略错在了哪里？</p>\r\n<p><strong>鼠目寸光</strong>。</p>\r\n<p>刚刚已经说过，贪心策略的纲领是：“尽量使接下来面对的w更小”。这样，贪心策略在w=15的局面时，会优先使用11来把w降到4；但是在这个问题中，凑出4的代价是很高的，必须使用4×1。如果使用了5，w会降为10，虽然没有4那么小，但是凑出10只需要两张5元。</p>\r\n<p>在这里我们发现，贪心是一种<strong>只考虑眼前情况</strong>的策略。</p>\r\n<p>那么，现在我们怎样才能避免鼠目寸光呢？</p>\r\n<p>如果直接暴力枚举凑出w的方案，明显复杂度过高。太多种方法可以凑出w了，枚举它们的时间是不可承受的。我们现在来尝试找一下性质。</p>\r\n<p>重新分析刚刚的例子。w=15时，我们如果取11，接下来就面对w=4的情况；如果取5，则接下来面对w=10的情况。我们发现这些问题都有相同的形式：“给定w，凑出w所用的最少钞票是多少张？”接下来，我们用f(n)来表示“凑出n所需的最少钞票数量”。</p>\r\n<p>那么，如果我们取了11，最后的代价（用掉的钞票总数）是多少呢？</p>\r\n<p>明显<strong>cost=f(4)+1=4+1=5</strong>\r\n，它的意义是：利用11来凑出15，付出的代价等于f(4)加上自己这一张钞票。现在我们暂时不管f(4)怎么求出来。</p>\r\n<p>依次类推，马上可以知道：如果我们用5来凑出15，cost就是<strong>f(10)+1=2+1=3</strong>\r\n。</p>\r\n<p>那么，现在w=15的时候，我们该取那种钞票呢？<strong>当然是各种方案中，cost值最低的那一个！</strong></p>\r\n<ul>\r\n<li>取11：cost=f(4)+1=4+1=5</li>\r\n<li>取5:cost=f(10)+1=2+1=3</li>\r\n<li>取1:cost=f(14)+1=4+1=5</li>\r\n</ul>\r\n<p>显而易见，cost值最低的是取5的方案。<strong>我们通过上面三个式子，做出了正确的决策！</strong></p>\r\n<p>这给了我们一个<strong>至关重要</strong>的启示——\r\nf(n)只与f(n-1),f(n-5),f(n-11) 相关；更确切地说：</p>\r\n<blockquote>\r\n<p>f(n)=min{f(n-1),f(n-5),f(n-11)}+1</p>\r\n</blockquote>\r\n<p>这个式子是非常激动人心的。我们要求出f(n)，只需要求出几个更小的f值；既然如此，我们从小到大把所有的f(i)求出来不就好了？注意一下边界情况即可。代码如下：</p>\r\n<figure>\r\n<img src=\"/img/动态规划/解决方案.jpg\" alt=\"pic1\" />\r\n<figcaption aria-hidden=\"true\">pic1</figcaption>\r\n</figure>\r\n<p>我们以O(n)的复杂度解决了这个问题。现在回过头来，我们看看它的原理：</p>\r\n<ul>\r\n<li>f(n)只与f(n-1),f(n-5),f(n-11)的值有关。</li>\r\n<li>我们只关心f(w)的值，不关心是怎么凑出w的。</li>\r\n</ul>\r\n<p>这两个事实，保证了我们做法的正确性。它比起贪心策略，会分别算出取1、5、11的代价，从而做出一个正确决策，这样就避免掉了“鼠目寸光”！</p>\r\n<p>它与暴力的区别在哪里？我们的暴力枚举了“使用的硬币”，然而这属于冗余信息。我们要的是答案，根本不关心这个答案是怎么凑出来的。譬如，要求出f(15)，只需要知道f(14),f(10),f(4)的值。<strong>其他信息并不需要</strong>。我们舍弃了冗余信息。我们只记录了对解决问题有帮助的信息——f(n).</p>\r\n<p>我们能这样干，取决于问题的性质：求出f(n)，只需要知道几个更小的f(c)。<strong>我们将求解f(c)称作求解f(n)的“子问题”</strong>。</p>\r\n<p><strong>这就是DP（动态规划，dynamic programming）</strong>.</p>\r\n<p><strong>将一个问题拆成几个子问题，分别求解这些子问题，即可推断出大问题的解。</strong></p>\r\n<h2 id=\"几个简单的概念\">2. 几个简单的概念</h2>\r\n<ul>\r\n<li><strong>无后效性</strong><br />\r\n一旦f(n)确定，“我们如何凑出f(n)”就再也用不着了。</li>\r\n</ul>\r\n<p>要求出f(15)，只需要知道f(14),f(10),f(4)的值，而f(14),f(10),f(4)是如何算出来的，对之后的问题没有影响。</p>\r\n<p>“<strong>未来与过去无关</strong>”，这就是<strong>无后效性</strong>。</p>\r\n<p>（严格定义：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响。）</p>\r\n<ul>\r\n<li>最优子结构</li>\r\n</ul>\r\n<p>回顾我们对f(n)的定义：我们记“凑出n所需的最少钞票数量”为f(n).</p>\r\n<p>f(n)的定义就已经蕴含了“最优”。利用w=14,10,4的最优解，我们即可算出w=15的最优解。</p>\r\n<p>大问题的<strong>最优解</strong>可以由小问题的<strong>最优解</strong>推出，这个性质叫做“最优子结构性质”。</p>\r\n<p>引入这两个概念之后，我们如何判断一个问题能否使用DP解决呢？</p>\r\n<p><strong>能将大问题拆成几个小问题，且满足无后效性、最优子结构性质</strong>。</p>\r\n<h2 id=\"dp的典型应用dag最短路\">3. DP的典型应用：DAG最短路</h2>\r\n<p>问题很简单：给定一个城市的地图，所有的道路都是单行道，而且不会构成环。每条道路都有过路费，问您从S点到T点花费的最少费用。</p>\r\n<figure>\r\n<img src=\"/img/动态规划/最短路径.png\" alt=\"最短路径\" />\r\n<figcaption aria-hidden=\"true\">最短路径</figcaption>\r\n</figure>\r\n<p>这个问题能用DP解决吗？我们先试着记从S到P的最少费用为f(P).</p>\r\n<p>想要到T，要么经过C，要么经过D。从而<span\r\nclass=\"math inline\">\\(f(T)=min\\{f(C)+20,f(D)+10\\}\\)</span>.</p>\r\n<p>好像看起来可以DP。现在我们检验刚刚那两个性质：</p>\r\n<ul>\r\n<li>无后效性：对于点P，一旦f(P)确定，以后就只关心f(P)的值，不关心怎么去的。</li>\r\n<li>最优子结构：对于P，我们当然只关心到P的最小费用，即f(P)。如果我们从S走到T是<span\r\nclass=\"math inline\">\\(S \\rightarrow P\\rightarrow Q \\rightarrow\r\nT\\)</span>,那肯定S走到Q的最优路径是<span class=\"math inline\">\\(S\r\n\\rightarrow P\\rightarrow\r\nQ\\)</span>。对一条最优的路径而言，从S走到<strong>沿途上所有的点（子问题）</strong>的最优路径，都是这条大路的一部分。这个问题的最优子结构性质是显然的。</li>\r\n</ul>\r\n<p>既然这两个性质都满足，那么本题可以DP。式子明显为：</p>\r\n<blockquote>\r\n<p>f(P)=min{f(R)+W<sub><span class=\"math inline\">\\(R \\rightarrow\r\nP\\)</span></sub>}</p>\r\n</blockquote>\r\n<p>其中R为有路通到P的所有的点， [公式] 为R到P的过路费。</p>\r\n<p>代码实现也很简单，拓扑排序即可。</p>\r\n<h2 id=\"对dp原理的一点讨论\">4. 对DP原理的一点讨论</h2>\r\n<ul>\r\n<li>DP的核心思想</li>\r\n</ul>\r\n<p>DP为什么会快？</p>\r\n<p>无论是DP还是暴力，我们的算法都是在<strong>可能解空间</strong>内，寻找<strong>最优解</strong>。</p>\r\n<p>来看钞票问题。暴力做法是枚举所有的可能解，这是最大的可能解空间。</p>\r\n<p>DP是枚举<strong>有希望成为答案的解</strong>。这个空间比暴力的小得多。</p>\r\n<p>也就是说：<strong>DP自带剪枝</strong>。</p>\r\n<p>DP舍弃了一大堆不可能成为最优解的答案。譬如：<br />\r\n　　15 = 5+5+5 被考虑了。<br />\r\n　　15 = 5+5+1+1+1+1+1 从来没有考虑过，因为这不可能成为最优解。</p>\r\n<p>在暴力算法中，可能解空间往往是指数级的大小；如果我们采用DP，那么有可能把解空间的大小降到多项式级。</p>\r\n<p>一般来说，解空间越小，寻找解就越快。这样就完成了优化。</p>\r\n<ul>\r\n<li>DP的操作过程</li>\r\n</ul>\r\n<p>一言以蔽之：<strong>大事化小，小事化了</strong>。</p>\r\n<p>将一个大问题转化成几个小问题；<br />\r\n　　求解小问题；<br />\r\n　　推出大问题的解。</p>\r\n<ul>\r\n<li>如何设计DP算法</li>\r\n</ul>\r\n<p>下面介绍比较通用的设计DP算法的步骤。</p>\r\n<p>首先，把我们面对的局面表示为x。这一步称为设计状态。</p>\r\n<p>对于状态x，记我们要求出的答案(e.g.\r\n最小费用)为f(x).我们的目标是求出f(T).\r\n<strong>找出f(x)与哪些局面有关（记为p）</strong>，写出一个式子（称为状态转移方程），通过f(p)来推出f(x).</p>\r\n<ul>\r\n<li>DP三连</li>\r\n</ul>\r\n<p>设计DP算法，往往可以遵循DP三连：</p>\r\n<p>我是谁？ ——设计状态，表示局面</p>\r\n<p>我从哪里来？</p>\r\n<p>我要到哪里去？ ——设计转移</p>\r\n<p>设计状态是DP的基础。接下来的设计转移，有两种方式：一种是考虑我从哪里来（本文之前提到的两个例子，都是在考虑“我从哪里来”）；另一种是考虑我到哪里去，这常见于求出f(x)之后，<strong>更新能从x走到的一些解</strong>。这种DP也是不少的，我们以后会遇到。</p>\r\n<p>总而言之，“我从哪里来”和“我要到哪里去”只需要考虑清楚其中一个，就能设计出状态转移方程，从而写代码求解问题。前者又称pull型的转移，后者又称push型的转移。</p>\r\n<blockquote>\r\n<p>思考题：如何把钞票问题的代码改写成“我到哪里去”的形式？<br />\r\n提示：求出f(x)之后，更新f(x+1),f(x+5),f(x+11).</p>\r\n</blockquote>\r\n<h2 id=\"例题最长上升子序列\">5. 例题：最长上升子序列</h2>\r\n<p>扯了这么多形而上的内容，还是做一道例题吧。</p>\r\n<p>最长上升子序列（LIS）问题：给定长度为n的序列a，从a中抽取出一个子序列，这个子序列需要单调递增。问最长的上升子序列（LIS）的长度。<br />\r\n　　e.g. 1,5,3,4,6,9,7,8的LIS为1,3,4,6,7,8，长度为6。</p>\r\n<p>如何设计状态（我是谁）？</p>\r\n<p>我们记<span\r\nclass=\"math inline\">\\(f(x)\\)</span>为以a<sub>x</sub>结尾的LIS长度，那么答案就是\r\n<span class=\"math inline\">\\(max\\{f(x)\\}\\)</span></p>\r\n<p>状态x从哪里推过来（我从哪里来）？</p>\r\n<p>考虑比x小的每一个p：如果 a<sub>x</sub> &gt; a<sub>p</sub>，那么<span\r\nclass=\"math inline\">\\(f(x)\\)</span>可以取<span\r\nclass=\"math inline\">\\(f(p)+1\\)</span>.</p>\r\n<p>解释：我们把 a<sub>x</sub> 接在 a<sub>p</sub>\r\n的后面，肯定能构造一个以 a<sub>x</sub> 结尾的上升子序列，长度比以\r\na<sub>p</sub> 结尾的LIS大1.那么，我们可以写出状态转移方程了：</p>\r\n<figure>\r\n<img src=\"/img/动态规划/状态转移方程.svg\" alt=\"状态转移方程\" />\r\n<figcaption aria-hidden=\"true\">状态转移方程</figcaption>\r\n</figure>\r\n<p>至此解决问题。两层for循环，复杂度O(n<sup>2</sup>) 。</p>\r\n<figure>\r\n<img src=\"/img/动态规划/最长上升子序列代码.jpg\"\r\nalt=\"最长上升子序列代码\" />\r\n<figcaption aria-hidden=\"true\">最长上升子序列代码</figcaption>\r\n</figure>\r\n<p>从这三个例题中可以看出，DP是一种思想，一种“大事化小，小事化了”的思想。带着这种思想，DP将会成为我们解决问题的利器。</p>\r\n<h2 id=\"习题\">6. 习题</h2>\r\n<p>如果读者有兴趣，可以试着完成下面几个习题：</p>\r\n<ol type=\"1\">\r\n<li>请采取一些优化手段，以 O(n log<sub>2</sub> n)\r\n的复杂度解决LIS问题。</li>\r\n</ol>\r\n<p>提示：可以参考这篇博客 <a\r\nhref=\"https://www.luogu.com.cn/blog/pks-LOVING/junior-dynamic-programming-dong-tai-gui-hua-chu-bu-ge-zhong-zi-xu-lie\">Junior\r\nDynamic Programming--动态规划初步·各种子序列问题</a></p>\r\n<ol start=\"2\" type=\"1\">\r\n<li>“按顺序递推”和“记忆化搜索”是实现DP的两种方式。请查阅资料，简单描述“记忆化搜索”是什么。并采用记忆化搜索写出钞票问题的代码，然后完成<a\r\nhref=\"https://www.luogu.com.cn/problem/P1541\">P1541 乌龟棋 - 洛谷</a>\r\n。</li>\r\n<li>01背包问题是一种常见的DP模型。请完成<a\r\nhref=\"https://www.luogu.com.cn/problem/P1048\">P1048 采药 -\r\n洛谷</a>。</li>\r\n</ol>\r\n<h2 id=\"读后思考动态规划和分治法的区别与共同点\">7.\r\n读后思考：动态规划和分治法的区别与共同点？</h2>\r\n<h3 id=\"分治法\">1. 分治法</h3>\r\n<p>分治法(Divide-and-Conquer) :\r\n将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。</p>\r\n<p>分治模式在每一层递归上都有三个步骤：</p>\r\n<ul>\r\n<li>分解(Divide)：将原问题分解成一系列子问题；</li>\r\n<li>解决(Conquer)：递归地解决各个子问题。若子问题足够小，则直接求解。</li>\r\n<li>合并(Combine)：将子问题的结果合并成原问题的解。</li>\r\n</ul>\r\n<p>合并排序(Merge\r\nSort)是一个典型分治法的例子。其对应的直观的操作如下:</p>\r\n<p>分解： 将n个元素分成各含n/2个元素的子序列；</p>\r\n<p>解决：用合并排序法对两个子序列递归地排序；</p>\r\n<p>合并：合并两个已排序的子序列以得到排序结果。</p>\r\n<h3 id=\"动态规划法\">2. 动态规划法</h3>\r\n<p>动态规划算法的设计可以分为如下4个步骤：</p>\r\n<ul>\r\n<li>描述最优解的结构</li>\r\n<li>递归定义最优解的值</li>\r\n<li>按自底向上的方式计算最优解的值</li>\r\n<li>由计算出的结果构造一个最优解</li>\r\n</ul>\r\n<p><strong>分治法是指将问题划分成一些独立的子问题，递归的求解各子问题，然后合并子问题的解而得到原问题的解。与此不同，动态规划适用于子问题独立且重叠的情况，也就是各子问题包含公共的子子问题。在这种情况下，若用分治法则会做许多不必要的工作，即重复地求解公共的子问题。动态规划算法对每个子子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。</strong></p>\r\n<p>适合采用动态规划方法的最优化问题中的两个要素：<strong>最优子结构</strong>和<strong>重叠子问题</strong>。</p>\r\n<p>最优子结构：如果问题的一个最优解中包含了子问题的最优解，则该问题具有最优子结构。</p>\r\n<p>重叠子问题：适用于动态规划求解的最优化问题必须具有的第二个要素是子问题的空间要很小，也就是用来求解原问题的递归算法反复地解同样的子问题，而不是总是在产生新的子问题。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则它们是重叠的。</p>\r\n<p>In a word, <strong>分治法 —— 各子问题独立；动态规划 ——\r\n各子问题重叠</strong>。</p>\r\n<p>算法导论：\r\n<strong>动态规划要求其子问题既要独立又要重叠，这看上去似乎有些奇怪。虽然这两点要求听起来可能矛盾的，但它们描述了两种不同的概念，而不是同一个问题的两个方面。如果同一个问题的两个子问题不共享资源，则它们就是独立的。对两个子问题俩说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，是重叠的，则它们是重叠</strong>。</p>\r\n","site":{"data":{}},"excerpt":"","more":"<p>本文大部分转载自知乎<a\r\nhref=\"https://www.zhihu.com/people/ruan-xing-zhi\"><span class=\"citation\"\r\ndata-cites=\"阮行止\">@阮行止</span></a>，后添加了自己的一些思考。</p>\r\n<h2 id=\"从一个生活问题谈起\">1. 从一个生活问题谈起</h2>\r\n<p>先来看看生活中经常遇到的事吧——假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，<strong>需要用到尽量少的钞票</strong>。</p>\r\n<p>依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。</p>\r\n<p>这种策略称为“<strong>贪心</strong>”：假设我们面对的局面是“需要凑出w”，贪心策略会<strong>尽快</strong>让w变得更小。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。</p>\r\n<p>但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：<br />\r\n　　15=1×11+4×1 （贪心策略使用了5张钞票）<br />\r\n　　15=3×5 （正确的策略，只用3张钞票）<br />\r\n　　为什么会这样呢？贪心策略错在了哪里？</p>\r\n<p><strong>鼠目寸光</strong>。</p>\r\n<p>刚刚已经说过，贪心策略的纲领是：“尽量使接下来面对的w更小”。这样，贪心策略在w=15的局面时，会优先使用11来把w降到4；但是在这个问题中，凑出4的代价是很高的，必须使用4×1。如果使用了5，w会降为10，虽然没有4那么小，但是凑出10只需要两张5元。</p>\r\n<p>在这里我们发现，贪心是一种<strong>只考虑眼前情况</strong>的策略。</p>\r\n<p>那么，现在我们怎样才能避免鼠目寸光呢？</p>\r\n<p>如果直接暴力枚举凑出w的方案，明显复杂度过高。太多种方法可以凑出w了，枚举它们的时间是不可承受的。我们现在来尝试找一下性质。</p>\r\n<p>重新分析刚刚的例子。w=15时，我们如果取11，接下来就面对w=4的情况；如果取5，则接下来面对w=10的情况。我们发现这些问题都有相同的形式：“给定w，凑出w所用的最少钞票是多少张？”接下来，我们用f(n)来表示“凑出n所需的最少钞票数量”。</p>\r\n<p>那么，如果我们取了11，最后的代价（用掉的钞票总数）是多少呢？</p>\r\n<p>明显<strong>cost=f(4)+1=4+1=5</strong>\r\n，它的意义是：利用11来凑出15，付出的代价等于f(4)加上自己这一张钞票。现在我们暂时不管f(4)怎么求出来。</p>\r\n<p>依次类推，马上可以知道：如果我们用5来凑出15，cost就是<strong>f(10)+1=2+1=3</strong>\r\n。</p>\r\n<p>那么，现在w=15的时候，我们该取那种钞票呢？<strong>当然是各种方案中，cost值最低的那一个！</strong></p>\r\n<ul>\r\n<li>取11：cost=f(4)+1=4+1=5</li>\r\n<li>取5:cost=f(10)+1=2+1=3</li>\r\n<li>取1:cost=f(14)+1=4+1=5</li>\r\n</ul>\r\n<p>显而易见，cost值最低的是取5的方案。<strong>我们通过上面三个式子，做出了正确的决策！</strong></p>\r\n<p>这给了我们一个<strong>至关重要</strong>的启示——\r\nf(n)只与f(n-1),f(n-5),f(n-11) 相关；更确切地说：</p>\r\n<blockquote>\r\n<p>f(n)=min{f(n-1),f(n-5),f(n-11)}+1</p>\r\n</blockquote>\r\n<p>这个式子是非常激动人心的。我们要求出f(n)，只需要求出几个更小的f值；既然如此，我们从小到大把所有的f(i)求出来不就好了？注意一下边界情况即可。代码如下：</p>\r\n<figure>\r\n<img src=\"/img/动态规划/解决方案.jpg\" alt=\"pic1\" />\r\n<figcaption aria-hidden=\"true\">pic1</figcaption>\r\n</figure>\r\n<p>我们以O(n)的复杂度解决了这个问题。现在回过头来，我们看看它的原理：</p>\r\n<ul>\r\n<li>f(n)只与f(n-1),f(n-5),f(n-11)的值有关。</li>\r\n<li>我们只关心f(w)的值，不关心是怎么凑出w的。</li>\r\n</ul>\r\n<p>这两个事实，保证了我们做法的正确性。它比起贪心策略，会分别算出取1、5、11的代价，从而做出一个正确决策，这样就避免掉了“鼠目寸光”！</p>\r\n<p>它与暴力的区别在哪里？我们的暴力枚举了“使用的硬币”，然而这属于冗余信息。我们要的是答案，根本不关心这个答案是怎么凑出来的。譬如，要求出f(15)，只需要知道f(14),f(10),f(4)的值。<strong>其他信息并不需要</strong>。我们舍弃了冗余信息。我们只记录了对解决问题有帮助的信息——f(n).</p>\r\n<p>我们能这样干，取决于问题的性质：求出f(n)，只需要知道几个更小的f(c)。<strong>我们将求解f(c)称作求解f(n)的“子问题”</strong>。</p>\r\n<p><strong>这就是DP（动态规划，dynamic programming）</strong>.</p>\r\n<p><strong>将一个问题拆成几个子问题，分别求解这些子问题，即可推断出大问题的解。</strong></p>\r\n<h2 id=\"几个简单的概念\">2. 几个简单的概念</h2>\r\n<ul>\r\n<li><strong>无后效性</strong><br />\r\n一旦f(n)确定，“我们如何凑出f(n)”就再也用不着了。</li>\r\n</ul>\r\n<p>要求出f(15)，只需要知道f(14),f(10),f(4)的值，而f(14),f(10),f(4)是如何算出来的，对之后的问题没有影响。</p>\r\n<p>“<strong>未来与过去无关</strong>”，这就是<strong>无后效性</strong>。</p>\r\n<p>（严格定义：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响。）</p>\r\n<ul>\r\n<li>最优子结构</li>\r\n</ul>\r\n<p>回顾我们对f(n)的定义：我们记“凑出n所需的最少钞票数量”为f(n).</p>\r\n<p>f(n)的定义就已经蕴含了“最优”。利用w=14,10,4的最优解，我们即可算出w=15的最优解。</p>\r\n<p>大问题的<strong>最优解</strong>可以由小问题的<strong>最优解</strong>推出，这个性质叫做“最优子结构性质”。</p>\r\n<p>引入这两个概念之后，我们如何判断一个问题能否使用DP解决呢？</p>\r\n<p><strong>能将大问题拆成几个小问题，且满足无后效性、最优子结构性质</strong>。</p>\r\n<h2 id=\"dp的典型应用dag最短路\">3. DP的典型应用：DAG最短路</h2>\r\n<p>问题很简单：给定一个城市的地图，所有的道路都是单行道，而且不会构成环。每条道路都有过路费，问您从S点到T点花费的最少费用。</p>\r\n<figure>\r\n<img src=\"/img/动态规划/最短路径.png\" alt=\"最短路径\" />\r\n<figcaption aria-hidden=\"true\">最短路径</figcaption>\r\n</figure>\r\n<p>这个问题能用DP解决吗？我们先试着记从S到P的最少费用为f(P).</p>\r\n<p>想要到T，要么经过C，要么经过D。从而<span\r\nclass=\"math inline\">\\(f(T)=min\\{f(C)+20,f(D)+10\\}\\)</span>.</p>\r\n<p>好像看起来可以DP。现在我们检验刚刚那两个性质：</p>\r\n<ul>\r\n<li>无后效性：对于点P，一旦f(P)确定，以后就只关心f(P)的值，不关心怎么去的。</li>\r\n<li>最优子结构：对于P，我们当然只关心到P的最小费用，即f(P)。如果我们从S走到T是<span\r\nclass=\"math inline\">\\(S \\rightarrow P\\rightarrow Q \\rightarrow\r\nT\\)</span>,那肯定S走到Q的最优路径是<span class=\"math inline\">\\(S\r\n\\rightarrow P\\rightarrow\r\nQ\\)</span>。对一条最优的路径而言，从S走到<strong>沿途上所有的点（子问题）</strong>的最优路径，都是这条大路的一部分。这个问题的最优子结构性质是显然的。</li>\r\n</ul>\r\n<p>既然这两个性质都满足，那么本题可以DP。式子明显为：</p>\r\n<blockquote>\r\n<p>f(P)=min{f(R)+W<sub><span class=\"math inline\">\\(R \\rightarrow\r\nP\\)</span></sub>}</p>\r\n</blockquote>\r\n<p>其中R为有路通到P的所有的点， [公式] 为R到P的过路费。</p>\r\n<p>代码实现也很简单，拓扑排序即可。</p>\r\n<h2 id=\"对dp原理的一点讨论\">4. 对DP原理的一点讨论</h2>\r\n<ul>\r\n<li>DP的核心思想</li>\r\n</ul>\r\n<p>DP为什么会快？</p>\r\n<p>无论是DP还是暴力，我们的算法都是在<strong>可能解空间</strong>内，寻找<strong>最优解</strong>。</p>\r\n<p>来看钞票问题。暴力做法是枚举所有的可能解，这是最大的可能解空间。</p>\r\n<p>DP是枚举<strong>有希望成为答案的解</strong>。这个空间比暴力的小得多。</p>\r\n<p>也就是说：<strong>DP自带剪枝</strong>。</p>\r\n<p>DP舍弃了一大堆不可能成为最优解的答案。譬如：<br />\r\n　　15 = 5+5+5 被考虑了。<br />\r\n　　15 = 5+5+1+1+1+1+1 从来没有考虑过，因为这不可能成为最优解。</p>\r\n<p>在暴力算法中，可能解空间往往是指数级的大小；如果我们采用DP，那么有可能把解空间的大小降到多项式级。</p>\r\n<p>一般来说，解空间越小，寻找解就越快。这样就完成了优化。</p>\r\n<ul>\r\n<li>DP的操作过程</li>\r\n</ul>\r\n<p>一言以蔽之：<strong>大事化小，小事化了</strong>。</p>\r\n<p>将一个大问题转化成几个小问题；<br />\r\n　　求解小问题；<br />\r\n　　推出大问题的解。</p>\r\n<ul>\r\n<li>如何设计DP算法</li>\r\n</ul>\r\n<p>下面介绍比较通用的设计DP算法的步骤。</p>\r\n<p>首先，把我们面对的局面表示为x。这一步称为设计状态。</p>\r\n<p>对于状态x，记我们要求出的答案(e.g.\r\n最小费用)为f(x).我们的目标是求出f(T).\r\n<strong>找出f(x)与哪些局面有关（记为p）</strong>，写出一个式子（称为状态转移方程），通过f(p)来推出f(x).</p>\r\n<ul>\r\n<li>DP三连</li>\r\n</ul>\r\n<p>设计DP算法，往往可以遵循DP三连：</p>\r\n<p>我是谁？ ——设计状态，表示局面</p>\r\n<p>我从哪里来？</p>\r\n<p>我要到哪里去？ ——设计转移</p>\r\n<p>设计状态是DP的基础。接下来的设计转移，有两种方式：一种是考虑我从哪里来（本文之前提到的两个例子，都是在考虑“我从哪里来”）；另一种是考虑我到哪里去，这常见于求出f(x)之后，<strong>更新能从x走到的一些解</strong>。这种DP也是不少的，我们以后会遇到。</p>\r\n<p>总而言之，“我从哪里来”和“我要到哪里去”只需要考虑清楚其中一个，就能设计出状态转移方程，从而写代码求解问题。前者又称pull型的转移，后者又称push型的转移。</p>\r\n<blockquote>\r\n<p>思考题：如何把钞票问题的代码改写成“我到哪里去”的形式？<br />\r\n提示：求出f(x)之后，更新f(x+1),f(x+5),f(x+11).</p>\r\n</blockquote>\r\n<h2 id=\"例题最长上升子序列\">5. 例题：最长上升子序列</h2>\r\n<p>扯了这么多形而上的内容，还是做一道例题吧。</p>\r\n<p>最长上升子序列（LIS）问题：给定长度为n的序列a，从a中抽取出一个子序列，这个子序列需要单调递增。问最长的上升子序列（LIS）的长度。<br />\r\n　　e.g. 1,5,3,4,6,9,7,8的LIS为1,3,4,6,7,8，长度为6。</p>\r\n<p>如何设计状态（我是谁）？</p>\r\n<p>我们记<span\r\nclass=\"math inline\">\\(f(x)\\)</span>为以a<sub>x</sub>结尾的LIS长度，那么答案就是\r\n<span class=\"math inline\">\\(max\\{f(x)\\}\\)</span></p>\r\n<p>状态x从哪里推过来（我从哪里来）？</p>\r\n<p>考虑比x小的每一个p：如果 a<sub>x</sub> &gt; a<sub>p</sub>，那么<span\r\nclass=\"math inline\">\\(f(x)\\)</span>可以取<span\r\nclass=\"math inline\">\\(f(p)+1\\)</span>.</p>\r\n<p>解释：我们把 a<sub>x</sub> 接在 a<sub>p</sub>\r\n的后面，肯定能构造一个以 a<sub>x</sub> 结尾的上升子序列，长度比以\r\na<sub>p</sub> 结尾的LIS大1.那么，我们可以写出状态转移方程了：</p>\r\n<figure>\r\n<img src=\"/img/动态规划/状态转移方程.svg\" alt=\"状态转移方程\" />\r\n<figcaption aria-hidden=\"true\">状态转移方程</figcaption>\r\n</figure>\r\n<p>至此解决问题。两层for循环，复杂度O(n<sup>2</sup>) 。</p>\r\n<figure>\r\n<img src=\"/img/动态规划/最长上升子序列代码.jpg\"\r\nalt=\"最长上升子序列代码\" />\r\n<figcaption aria-hidden=\"true\">最长上升子序列代码</figcaption>\r\n</figure>\r\n<p>从这三个例题中可以看出，DP是一种思想，一种“大事化小，小事化了”的思想。带着这种思想，DP将会成为我们解决问题的利器。</p>\r\n<h2 id=\"习题\">6. 习题</h2>\r\n<p>如果读者有兴趣，可以试着完成下面几个习题：</p>\r\n<ol type=\"1\">\r\n<li>请采取一些优化手段，以 O(n log<sub>2</sub> n)\r\n的复杂度解决LIS问题。</li>\r\n</ol>\r\n<p>提示：可以参考这篇博客 <a\r\nhref=\"https://www.luogu.com.cn/blog/pks-LOVING/junior-dynamic-programming-dong-tai-gui-hua-chu-bu-ge-zhong-zi-xu-lie\">Junior\r\nDynamic Programming--动态规划初步·各种子序列问题</a></p>\r\n<ol start=\"2\" type=\"1\">\r\n<li>“按顺序递推”和“记忆化搜索”是实现DP的两种方式。请查阅资料，简单描述“记忆化搜索”是什么。并采用记忆化搜索写出钞票问题的代码，然后完成<a\r\nhref=\"https://www.luogu.com.cn/problem/P1541\">P1541 乌龟棋 - 洛谷</a>\r\n。</li>\r\n<li>01背包问题是一种常见的DP模型。请完成<a\r\nhref=\"https://www.luogu.com.cn/problem/P1048\">P1048 采药 -\r\n洛谷</a>。</li>\r\n</ol>\r\n<h2 id=\"读后思考动态规划和分治法的区别与共同点\">7.\r\n读后思考：动态规划和分治法的区别与共同点？</h2>\r\n<h3 id=\"分治法\">1. 分治法</h3>\r\n<p>分治法(Divide-and-Conquer) :\r\n将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。</p>\r\n<p>分治模式在每一层递归上都有三个步骤：</p>\r\n<ul>\r\n<li>分解(Divide)：将原问题分解成一系列子问题；</li>\r\n<li>解决(Conquer)：递归地解决各个子问题。若子问题足够小，则直接求解。</li>\r\n<li>合并(Combine)：将子问题的结果合并成原问题的解。</li>\r\n</ul>\r\n<p>合并排序(Merge\r\nSort)是一个典型分治法的例子。其对应的直观的操作如下:</p>\r\n<p>分解： 将n个元素分成各含n/2个元素的子序列；</p>\r\n<p>解决：用合并排序法对两个子序列递归地排序；</p>\r\n<p>合并：合并两个已排序的子序列以得到排序结果。</p>\r\n<h3 id=\"动态规划法\">2. 动态规划法</h3>\r\n<p>动态规划算法的设计可以分为如下4个步骤：</p>\r\n<ul>\r\n<li>描述最优解的结构</li>\r\n<li>递归定义最优解的值</li>\r\n<li>按自底向上的方式计算最优解的值</li>\r\n<li>由计算出的结果构造一个最优解</li>\r\n</ul>\r\n<p><strong>分治法是指将问题划分成一些独立的子问题，递归的求解各子问题，然后合并子问题的解而得到原问题的解。与此不同，动态规划适用于子问题独立且重叠的情况，也就是各子问题包含公共的子子问题。在这种情况下，若用分治法则会做许多不必要的工作，即重复地求解公共的子问题。动态规划算法对每个子子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。</strong></p>\r\n<p>适合采用动态规划方法的最优化问题中的两个要素：<strong>最优子结构</strong>和<strong>重叠子问题</strong>。</p>\r\n<p>最优子结构：如果问题的一个最优解中包含了子问题的最优解，则该问题具有最优子结构。</p>\r\n<p>重叠子问题：适用于动态规划求解的最优化问题必须具有的第二个要素是子问题的空间要很小，也就是用来求解原问题的递归算法反复地解同样的子问题，而不是总是在产生新的子问题。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则它们是重叠的。</p>\r\n<p>In a word, <strong>分治法 —— 各子问题独立；动态规划 ——\r\n各子问题重叠</strong>。</p>\r\n<p>算法导论：\r\n<strong>动态规划要求其子问题既要独立又要重叠，这看上去似乎有些奇怪。虽然这两点要求听起来可能矛盾的，但它们描述了两种不同的概念，而不是同一个问题的两个方面。如果同一个问题的两个子问题不共享资源，则它们就是独立的。对两个子问题俩说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，是重叠的，则它们是重叠</strong>。</p>\r\n"},{"title":"NP问题","_content":"\n## P、NP、NPC、NPH问题\n**P问题**：存在多项式时间算法的决策问题。\n\n**NP问题** ：能在多项式时间内验证某个猜想答案的正确性，但问题求解可能在无法在多项式时间内完成。比如Composite问题、3-Satisfiability、Hamiltonian Cycle，很容易就确定一个答案是否正确，但确找不到一个公式来描述其规律。\n\n**结论1**：P $\\subseteq$ NP\n\n**结论2**：NP $\\subseteq$ EXP\n\n**EXP问题**：存在指数时间算法的决策问题。\n\n\n**NPC问题**: 需要满足两个条件\n    \n- 它是一个NP问题\n- 所有的NP问题都可以规约到NP-complete\n\n**定理**：若Y是一个NPC问题，那么Y可以在多项式时间内求解**当且仅当**P$=$NP\n\n证明：\n\n$\\Rightarrow$\n\n若P $=$ NP，那么Y可以在多项式时间求解，因为Y是NP（NPC的第一个条件：它要先是一个NP）\n\n$\\Leftarrow$\n\n若Y可以在多项式时间求解：\n- 令X为任意一个NP问题，因为X $\\le_p$ Y，而Y可以在多项式时间求解，故X也可以在多项式时间求解。NP $\\subseteq$ P\n- 又已知P $\\subseteq$ NP,所以 P $=$ NP\n\n\n**如果**我们给NPC问题找到了一个多项式时间复杂度的算法，那么也就意味着我们给所有的NP问题找到了多项式时间复杂度的算法，从而NP=P，因为P=NP，所以“P对NP问题”就可以被解决。但给NPC问题找一个多项式时间复杂度的算法太难了，所以现在人们普遍相信P≠NP。\n\n\n\n**NPH问题** ：满足上面NPC问题的第二个条件，但不一定要满足第一个条件，所以NPH的范围比HPC更大。\n\n### 证明一个问题是NPC问题的步骤\n- 证明这个问题Y属于NP\n- 选择一个NPC问题X\n- 证明X可以多项式规约到Y\n\n### 证明一个问题是NPH问题的步骤\n要证明一个问题是NP-hard，通常是找到一个已被证明了的NPC问题，并把这个NPC问题归约到该问题上去（即NPC $\\le$ NP-hard）,简单来说就是：\n- 对问题A给定限制条件得到一个特例B问题\n- 证明问题B是NPC问题\n\n\n## NPC之间规约的例子\n### 3-SAT $\\le_p$ Independent Set\n**证明：给定一个3-SAT的例子$\\Phi$,可以构造一个大小为$k$的Independent Set当且仅当式子$\\Phi$是可满足的。**\n\n构造:\n- 3-SAT中的每个Clause包含独立集里的三个顶点，其中每个Literal对应一个顶点\n- 连接句子里的点连接形成三角形\n- 连接不同Clause里每个Literal和它对应的非\n\n如下图所示：\n\n![](/img/多项式规约/3-SAT2IndependentSet.png)\n\n\n**证明**：\n\n$\\Rightarrow$\n\n令S为一个大小为$k$的独立集，每个三角形里一定只有一个顶点在$S$里，设该顶点取1，其余顶点取0，则其肯定是一个满足3-SAT的赋值。\n\n$\\Leftarrow$\n\n给定3-SAT一个满足的赋值，在每个三角形中选取一个取值为1的顶点，这样便构成了一个大小为$k$的独立集。\n\n### Hamiltonian Cycle problem\n**Hamiltonian Cycle**:给定一个无向图 $G=(V,E)$，是否存在一个简单的环 $\\Gamma$ 包含 $V$ 中所有的点。\n\n![有奇数个节点的Hamiltonian Cycle](/img/多项式规约/HamiltonianCycle定义.png)\n\n**DIR-HAM-CYCLE**：给定一个有向图 $G=(V,E)$,是否存在一个简单环 $\\Gamma$ 包含$V$中所有顶点？\n\n**DIR-HAM-CYCL $\\le_p$ Ham-Cycle**:\n证明：给定一个有向图$G=(V,E)$,构造一个有$3n$个节点的无向图$G'$，则$G$有Hamiltonian Cycle当且仅当$G'$有Hamiltonian Cycle。\n\n![](/img/多项式规约/DIR-HAM-CYC2Ham-Cycle.png)\n\n$\\Rightarrow$\n\n若$G$中有一个有向的Hamiltonian Cycle，则$G'$中肯定也有一个Hamiltonian Cycle，且顺序与有向图的节点顺序相同。\n\n$\\Leftarrow$\n\n若$G'$中有一个无向的Hamiltonian Cycle，则从蓝色节点出发，节点的颜色出现顺序必然是两种中的一种\n- B,G,R,B,G,R,$\\dots$\n- B,R,G,B,R,G,$\\dots$\n\n若$G'$的Hamiltonian Cycle顺序是第一种，那么对应$G$中的Hamiltonian Cycle的节点顺序与其蓝色节点顺序相同；若$G'$的Hamiltonian Cycle顺序是第二种，那么对应$G$中的Hamiltonian Cycle的节点顺序与其蓝色节点顺序相反。\n\n\n### 3SAT $\\le_p$ Hamiltonian Cycle problem\n<!-- **Vertex Cover**：一组顶点的集合，使得图的每条边至少与集合中的一个顶点相连接。在这里Vertex Cover问题是给定图$G$和点集的个数$k$，要找到图$G$的一个大小为$k$的点覆盖。（也就是常说的最小点覆盖） -->\n\n**构造思路:有$n$个变量的3-SAT有$2^n$种可能的分配，要将其规约到Hamiltonian Cycle，其对应的Hamiltonian Cycle应该也有$2^n$种可能的分配方式。**\n\n构造方法：对一个有$n$个变量和$k$个句子的3-SAT,构造$3k+3$个节点的Hamiltonian Cycle，其中每个变量$x_i$对应$3k+3$个节点，令外再增加一个源点$s$、一个汇点$t$。\n\n![](/img/多项式规约/3-SAT2Ham-Cycle构造.png)\n\n\n如果 $x_i=1$，则形成从左向右的一个路径；如果 $x_i=0$，则形成从右向左的一个路径。\n\n对于每一个clause $c_j=z_1 z_2 z_3$，若$z=x_i$,则添加有向边 $(v_{i,3j},c_j)和(c_j,v_{i,3j+1})$;若$z=\\bar{x}_i$,则添加有向边$(c_j,v_{i,3j})和(v_{i,3j+1},c_j)$，这里$1\\le j\\le m, 1\\le i\\le n$。如上图所示（即若$z=x_i$,该节点与$c$节点的连接顺序是从左边进入$c$节点，然后从右边出$c$节点；反之顺序相反）。\n\n如果选择子句$C_1$中$x_1=1$,则$x_1$对应的路径为从左向右;同理$x_2=0$,则$x_2$对应的路径为从右向左；$x_3=1$,则$x_3$对应的路径为从左向右。其余句子同理，这样就得到了最终的图$G$。\n\n**证明**:\n\n$\\Rightarrow$\n\n假设3-SAT有一个可满足的分配$x^*$：\n\n- 对于$x_i$,若其为1，则第$i$行从左往右遍历；反之，若其为0，则第$i$行从右往左遍历\n- 且对于每个句子节点$c_i$，至少会有一行便利的时候会经过$c_i$，否则便不满足每个句子都为真的条件，也就是该分配并不是可满足的。\n\n$\\Leftarrow$\n\n假设构造的图$G$有一个Ham-Cycle，那么\n\n- 若Ham-Cycle进入句子节点$c_i$，那么它一定会返回相同的行，否则便不存在简单环。\n- 这样Ham-Cycle里的句子节点$c_i$与同一行的两个相邻节点相连，记这两个相邻节点之间的边为$e_i$\n- 去掉句子节点$c_i$，同时用$e_i$替换与$c_i$相连的两条边。\n- 按上面的方法去掉所有的句子节点得到图也必然存在Ham-Cycle，且节点的顺序是相同的。\n- 若Ham-Cycle的第$i$行是从左往右遍历的，便令$x_i=1$;反之则令$x_i=0$，这样便得到一个分配方案，且其是可满足的。\n\n这样便得到一个分配方式，且每个句子都是可满足的。\n\n\n### HAM-CYCLE $\\le_p$ TSP(Traveling Saleperson Problem)\n**TSP(Traveling Saleperson Problem)**：给定一个$n$个城市的集合以及城市之间的距离$d(u,v)$,是否存在一个旅行的路线使行走的距离$\\le n$?\n\n旅行者问题与HAM-CYCLE的区别在于：旅行者问题并不限定简单路径，也就是说一个节点可以通过多次，只需要考虑最后的路径长度。\n\n**DIR-HAM-CYCLE**：给定一个有向图 $G=(V,E)$,是否存在一个简单环 $\\Gamma$ 包含$V$中所有顶点？\n\n$HAM-CYCLE $\\le_p$ TSP(Traveling Saleperson Problem)$\n\n**构造**：给定一个HAM-CYCLE的实例$G=(V,E)$,$V$中的每个节点构造一个城市节点，城市之间的距离根据$E$进行赋值:\n$$d(u,v)= \\begin{cases}\n    1, (u,v) \\in E  \\\\\n    2, (u,v) \\notin E\n\\end{cases}$$\n\n则TSP中有一个旅行路径$\\le n$当且仅当$G$中存在HAM-CYCLE\n\n### 3-SAT $\\le$ 3-Colorable\n**3-Colorable**:给定一个无向图$G$，并给图中的每个节点染上红、蓝、绿的其中一种颜色，那么是否存在一种染色方式使相邻的节点都有不同的颜色？\n\n3-SAT $\\le$ 3-Colorable\n\n**构造**：\n\n- 对每个Literal，构造一个节点\n- 同时添加三个节点$T、F、B$，连接这三个节点形成一个三角形\n- 对每个literal节点，创建一个它的\"非\"并与它相连\n- 所有的Literal节点都与$B$相连\n\n如下图所示：\n![](/img/多项式规约/3-SAT23-COLOLABLE-1.png)\n\n这样构造保证了下面的每个Literal节点都是绿色或红色，且它的“非”与它的颜色刚好相反。\n\n继续接上面：\n\n- 对每个Clause，假设$C_i=x_1 \\vee \\overline{x_2} \\vee x_3$,则对$x_1 , \\overline{x_2} , x_3$添加6个节点以及13条边\n\n![](/img/多项式规约/3-SAT23-COLOLABLE-2.png)\n\n即$x_1 , \\overline{x_2} , x_3$下方的两行一共6个节点，并将左下角的节点、第一行的节点与之前构造的$T$节点相连，右下角的节点与之前的$F$节点相连。\n\n这样构造是为了保证当三个Literal节点全为红色的时候，是不满足三着色的，如下图所示：当三个Literal节点全为红色的时候，他们下面那行节点必须为蓝色，这样最后一行从左到右着色，最后一个节点冲突。\n\n![](/img/多项式规约/3-SAT23-COLOLABLE-3.png)\n\n**3-SAT $\\le$ 3-Colorable**：\n\n$\\Rightarrow$\n\n若图3-Colorable：\n\n- 将所有为绿色的Literal节点设为真\n- 由上面可知，当图3-Colorable的时候三个Literal节点至少有一个是绿色的，那么该句子的输出为真\n\n\n$\\Leftarrow$\n\n若3-SAT是可满足的：则\n- 三个Literal节点至少有一个为真\n- 将为真的Literal节点染为绿色，然后将该节点下面的节点染为红色（否则会冲突），再继续将下面的节点染为蓝色\n- 对中间一行没有染红的节点染为蓝色，然后它们下面一行没有染色的节点可唯一确定颜色\n\n![](/img/多项式规约/3-SAT23-COLOLABLE-4.png)\n\n上面没有染色的Literal节点绿色、红色皆可。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/NP问题.md","raw":"---\ntitle: NP问题\ntags: \n    - 算法\n    - 算法设计与分析\ncategories: 算法\n---\n\n## P、NP、NPC、NPH问题\n**P问题**：存在多项式时间算法的决策问题。\n\n**NP问题** ：能在多项式时间内验证某个猜想答案的正确性，但问题求解可能在无法在多项式时间内完成。比如Composite问题、3-Satisfiability、Hamiltonian Cycle，很容易就确定一个答案是否正确，但确找不到一个公式来描述其规律。\n\n**结论1**：P $\\subseteq$ NP\n\n**结论2**：NP $\\subseteq$ EXP\n\n**EXP问题**：存在指数时间算法的决策问题。\n\n\n**NPC问题**: 需要满足两个条件\n    \n- 它是一个NP问题\n- 所有的NP问题都可以规约到NP-complete\n\n**定理**：若Y是一个NPC问题，那么Y可以在多项式时间内求解**当且仅当**P$=$NP\n\n证明：\n\n$\\Rightarrow$\n\n若P $=$ NP，那么Y可以在多项式时间求解，因为Y是NP（NPC的第一个条件：它要先是一个NP）\n\n$\\Leftarrow$\n\n若Y可以在多项式时间求解：\n- 令X为任意一个NP问题，因为X $\\le_p$ Y，而Y可以在多项式时间求解，故X也可以在多项式时间求解。NP $\\subseteq$ P\n- 又已知P $\\subseteq$ NP,所以 P $=$ NP\n\n\n**如果**我们给NPC问题找到了一个多项式时间复杂度的算法，那么也就意味着我们给所有的NP问题找到了多项式时间复杂度的算法，从而NP=P，因为P=NP，所以“P对NP问题”就可以被解决。但给NPC问题找一个多项式时间复杂度的算法太难了，所以现在人们普遍相信P≠NP。\n\n\n\n**NPH问题** ：满足上面NPC问题的第二个条件，但不一定要满足第一个条件，所以NPH的范围比HPC更大。\n\n### 证明一个问题是NPC问题的步骤\n- 证明这个问题Y属于NP\n- 选择一个NPC问题X\n- 证明X可以多项式规约到Y\n\n### 证明一个问题是NPH问题的步骤\n要证明一个问题是NP-hard，通常是找到一个已被证明了的NPC问题，并把这个NPC问题归约到该问题上去（即NPC $\\le$ NP-hard）,简单来说就是：\n- 对问题A给定限制条件得到一个特例B问题\n- 证明问题B是NPC问题\n\n\n## NPC之间规约的例子\n### 3-SAT $\\le_p$ Independent Set\n**证明：给定一个3-SAT的例子$\\Phi$,可以构造一个大小为$k$的Independent Set当且仅当式子$\\Phi$是可满足的。**\n\n构造:\n- 3-SAT中的每个Clause包含独立集里的三个顶点，其中每个Literal对应一个顶点\n- 连接句子里的点连接形成三角形\n- 连接不同Clause里每个Literal和它对应的非\n\n如下图所示：\n\n![](/img/多项式规约/3-SAT2IndependentSet.png)\n\n\n**证明**：\n\n$\\Rightarrow$\n\n令S为一个大小为$k$的独立集，每个三角形里一定只有一个顶点在$S$里，设该顶点取1，其余顶点取0，则其肯定是一个满足3-SAT的赋值。\n\n$\\Leftarrow$\n\n给定3-SAT一个满足的赋值，在每个三角形中选取一个取值为1的顶点，这样便构成了一个大小为$k$的独立集。\n\n### Hamiltonian Cycle problem\n**Hamiltonian Cycle**:给定一个无向图 $G=(V,E)$，是否存在一个简单的环 $\\Gamma$ 包含 $V$ 中所有的点。\n\n![有奇数个节点的Hamiltonian Cycle](/img/多项式规约/HamiltonianCycle定义.png)\n\n**DIR-HAM-CYCLE**：给定一个有向图 $G=(V,E)$,是否存在一个简单环 $\\Gamma$ 包含$V$中所有顶点？\n\n**DIR-HAM-CYCL $\\le_p$ Ham-Cycle**:\n证明：给定一个有向图$G=(V,E)$,构造一个有$3n$个节点的无向图$G'$，则$G$有Hamiltonian Cycle当且仅当$G'$有Hamiltonian Cycle。\n\n![](/img/多项式规约/DIR-HAM-CYC2Ham-Cycle.png)\n\n$\\Rightarrow$\n\n若$G$中有一个有向的Hamiltonian Cycle，则$G'$中肯定也有一个Hamiltonian Cycle，且顺序与有向图的节点顺序相同。\n\n$\\Leftarrow$\n\n若$G'$中有一个无向的Hamiltonian Cycle，则从蓝色节点出发，节点的颜色出现顺序必然是两种中的一种\n- B,G,R,B,G,R,$\\dots$\n- B,R,G,B,R,G,$\\dots$\n\n若$G'$的Hamiltonian Cycle顺序是第一种，那么对应$G$中的Hamiltonian Cycle的节点顺序与其蓝色节点顺序相同；若$G'$的Hamiltonian Cycle顺序是第二种，那么对应$G$中的Hamiltonian Cycle的节点顺序与其蓝色节点顺序相反。\n\n\n### 3SAT $\\le_p$ Hamiltonian Cycle problem\n<!-- **Vertex Cover**：一组顶点的集合，使得图的每条边至少与集合中的一个顶点相连接。在这里Vertex Cover问题是给定图$G$和点集的个数$k$，要找到图$G$的一个大小为$k$的点覆盖。（也就是常说的最小点覆盖） -->\n\n**构造思路:有$n$个变量的3-SAT有$2^n$种可能的分配，要将其规约到Hamiltonian Cycle，其对应的Hamiltonian Cycle应该也有$2^n$种可能的分配方式。**\n\n构造方法：对一个有$n$个变量和$k$个句子的3-SAT,构造$3k+3$个节点的Hamiltonian Cycle，其中每个变量$x_i$对应$3k+3$个节点，令外再增加一个源点$s$、一个汇点$t$。\n\n![](/img/多项式规约/3-SAT2Ham-Cycle构造.png)\n\n\n如果 $x_i=1$，则形成从左向右的一个路径；如果 $x_i=0$，则形成从右向左的一个路径。\n\n对于每一个clause $c_j=z_1 z_2 z_3$，若$z=x_i$,则添加有向边 $(v_{i,3j},c_j)和(c_j,v_{i,3j+1})$;若$z=\\bar{x}_i$,则添加有向边$(c_j,v_{i,3j})和(v_{i,3j+1},c_j)$，这里$1\\le j\\le m, 1\\le i\\le n$。如上图所示（即若$z=x_i$,该节点与$c$节点的连接顺序是从左边进入$c$节点，然后从右边出$c$节点；反之顺序相反）。\n\n如果选择子句$C_1$中$x_1=1$,则$x_1$对应的路径为从左向右;同理$x_2=0$,则$x_2$对应的路径为从右向左；$x_3=1$,则$x_3$对应的路径为从左向右。其余句子同理，这样就得到了最终的图$G$。\n\n**证明**:\n\n$\\Rightarrow$\n\n假设3-SAT有一个可满足的分配$x^*$：\n\n- 对于$x_i$,若其为1，则第$i$行从左往右遍历；反之，若其为0，则第$i$行从右往左遍历\n- 且对于每个句子节点$c_i$，至少会有一行便利的时候会经过$c_i$，否则便不满足每个句子都为真的条件，也就是该分配并不是可满足的。\n\n$\\Leftarrow$\n\n假设构造的图$G$有一个Ham-Cycle，那么\n\n- 若Ham-Cycle进入句子节点$c_i$，那么它一定会返回相同的行，否则便不存在简单环。\n- 这样Ham-Cycle里的句子节点$c_i$与同一行的两个相邻节点相连，记这两个相邻节点之间的边为$e_i$\n- 去掉句子节点$c_i$，同时用$e_i$替换与$c_i$相连的两条边。\n- 按上面的方法去掉所有的句子节点得到图也必然存在Ham-Cycle，且节点的顺序是相同的。\n- 若Ham-Cycle的第$i$行是从左往右遍历的，便令$x_i=1$;反之则令$x_i=0$，这样便得到一个分配方案，且其是可满足的。\n\n这样便得到一个分配方式，且每个句子都是可满足的。\n\n\n### HAM-CYCLE $\\le_p$ TSP(Traveling Saleperson Problem)\n**TSP(Traveling Saleperson Problem)**：给定一个$n$个城市的集合以及城市之间的距离$d(u,v)$,是否存在一个旅行的路线使行走的距离$\\le n$?\n\n旅行者问题与HAM-CYCLE的区别在于：旅行者问题并不限定简单路径，也就是说一个节点可以通过多次，只需要考虑最后的路径长度。\n\n**DIR-HAM-CYCLE**：给定一个有向图 $G=(V,E)$,是否存在一个简单环 $\\Gamma$ 包含$V$中所有顶点？\n\n$HAM-CYCLE $\\le_p$ TSP(Traveling Saleperson Problem)$\n\n**构造**：给定一个HAM-CYCLE的实例$G=(V,E)$,$V$中的每个节点构造一个城市节点，城市之间的距离根据$E$进行赋值:\n$$d(u,v)= \\begin{cases}\n    1, (u,v) \\in E  \\\\\n    2, (u,v) \\notin E\n\\end{cases}$$\n\n则TSP中有一个旅行路径$\\le n$当且仅当$G$中存在HAM-CYCLE\n\n### 3-SAT $\\le$ 3-Colorable\n**3-Colorable**:给定一个无向图$G$，并给图中的每个节点染上红、蓝、绿的其中一种颜色，那么是否存在一种染色方式使相邻的节点都有不同的颜色？\n\n3-SAT $\\le$ 3-Colorable\n\n**构造**：\n\n- 对每个Literal，构造一个节点\n- 同时添加三个节点$T、F、B$，连接这三个节点形成一个三角形\n- 对每个literal节点，创建一个它的\"非\"并与它相连\n- 所有的Literal节点都与$B$相连\n\n如下图所示：\n![](/img/多项式规约/3-SAT23-COLOLABLE-1.png)\n\n这样构造保证了下面的每个Literal节点都是绿色或红色，且它的“非”与它的颜色刚好相反。\n\n继续接上面：\n\n- 对每个Clause，假设$C_i=x_1 \\vee \\overline{x_2} \\vee x_3$,则对$x_1 , \\overline{x_2} , x_3$添加6个节点以及13条边\n\n![](/img/多项式规约/3-SAT23-COLOLABLE-2.png)\n\n即$x_1 , \\overline{x_2} , x_3$下方的两行一共6个节点，并将左下角的节点、第一行的节点与之前构造的$T$节点相连，右下角的节点与之前的$F$节点相连。\n\n这样构造是为了保证当三个Literal节点全为红色的时候，是不满足三着色的，如下图所示：当三个Literal节点全为红色的时候，他们下面那行节点必须为蓝色，这样最后一行从左到右着色，最后一个节点冲突。\n\n![](/img/多项式规约/3-SAT23-COLOLABLE-3.png)\n\n**3-SAT $\\le$ 3-Colorable**：\n\n$\\Rightarrow$\n\n若图3-Colorable：\n\n- 将所有为绿色的Literal节点设为真\n- 由上面可知，当图3-Colorable的时候三个Literal节点至少有一个是绿色的，那么该句子的输出为真\n\n\n$\\Leftarrow$\n\n若3-SAT是可满足的：则\n- 三个Literal节点至少有一个为真\n- 将为真的Literal节点染为绿色，然后将该节点下面的节点染为红色（否则会冲突），再继续将下面的节点染为蓝色\n- 对中间一行没有染红的节点染为蓝色，然后它们下面一行没有染色的节点可唯一确定颜色\n\n![](/img/多项式规约/3-SAT23-COLOLABLE-4.png)\n\n上面没有染色的Literal节点绿色、红色皆可。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"NP问题","published":1,"date":"2022-12-05T14:49:27.082Z","updated":"2022-12-08T04:23:08.632Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8o90007r4sg6at64sdw","content":"<h2 id=\"pnpnpcnph问题\">P、NP、NPC、NPH问题</h2>\r\n<p><strong>P问题</strong>：存在多项式时间算法的决策问题。</p>\r\n<p><strong>NP问题</strong>\r\n：能在多项式时间内验证某个猜想答案的正确性，但问题求解可能在无法在多项式时间内完成。比如Composite问题、3-Satisfiability、Hamiltonian\r\nCycle，很容易就确定一个答案是否正确，但确找不到一个公式来描述其规律。</p>\r\n<p><strong>结论1</strong>：P <span\r\nclass=\"math inline\">\\(\\subseteq\\)</span> NP</p>\r\n<p><strong>结论2</strong>：NP <span\r\nclass=\"math inline\">\\(\\subseteq\\)</span> EXP</p>\r\n<p><strong>EXP问题</strong>：存在指数时间算法的决策问题。</p>\r\n<p><strong>NPC问题</strong>: 需要满足两个条件</p>\r\n<ul>\r\n<li>它是一个NP问题</li>\r\n<li>所有的NP问题都可以规约到NP-complete</li>\r\n</ul>\r\n<p><strong>定理</strong>：若Y是一个NPC问题，那么Y可以在多项式时间内求解<strong>当且仅当</strong>P<span\r\nclass=\"math inline\">\\(=\\)</span>NP</p>\r\n<p>证明：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>若P <span class=\"math inline\">\\(=\\)</span>\r\nNP，那么Y可以在多项式时间求解，因为Y是NP（NPC的第一个条件：它要先是一个NP）</p>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>若Y可以在多项式时间求解： - 令X为任意一个NP问题，因为X <span\r\nclass=\"math inline\">\\(\\le_p\\)</span>\r\nY，而Y可以在多项式时间求解，故X也可以在多项式时间求解。NP <span\r\nclass=\"math inline\">\\(\\subseteq\\)</span> P - 又已知P <span\r\nclass=\"math inline\">\\(\\subseteq\\)</span> NP,所以 P <span\r\nclass=\"math inline\">\\(=\\)</span> NP</p>\r\n<p><strong>如果</strong>我们给NPC问题找到了一个多项式时间复杂度的算法，那么也就意味着我们给所有的NP问题找到了多项式时间复杂度的算法，从而NP=P，因为P=NP，所以“P对NP问题”就可以被解决。但给NPC问题找一个多项式时间复杂度的算法太难了，所以现在人们普遍相信P≠NP。</p>\r\n<p><strong>NPH问题</strong>\r\n：满足上面NPC问题的第二个条件，但不一定要满足第一个条件，所以NPH的范围比HPC更大。</p>\r\n<h3 id=\"证明一个问题是npc问题的步骤\">证明一个问题是NPC问题的步骤</h3>\r\n<ul>\r\n<li>证明这个问题Y属于NP</li>\r\n<li>选择一个NPC问题X</li>\r\n<li>证明X可以多项式规约到Y</li>\r\n</ul>\r\n<h3 id=\"证明一个问题是nph问题的步骤\">证明一个问题是NPH问题的步骤</h3>\r\n<p>要证明一个问题是NP-hard，通常是找到一个已被证明了的NPC问题，并把这个NPC问题归约到该问题上去（即NPC\r\n<span class=\"math inline\">\\(\\le\\)</span> NP-hard）,简单来说就是： -\r\n对问题A给定限制条件得到一个特例B问题 - 证明问题B是NPC问题</p>\r\n<h2 id=\"npc之间规约的例子\">NPC之间规约的例子</h2>\r\n<h3 id=\"sat-le_p-independent-set\">3-SAT <span\r\nclass=\"math inline\">\\(\\le_p\\)</span> Independent Set</h3>\r\n<p><strong>证明：给定一个3-SAT的例子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>,可以构造一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的Independent Set当且仅当式子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>是可满足的。</strong></p>\r\n<p>构造: -\r\n3-SAT中的每个Clause包含独立集里的三个顶点，其中每个Literal对应一个顶点 -\r\n连接句子里的点连接形成三角形 -\r\n连接不同Clause里每个Literal和它对应的非</p>\r\n<p>如下图所示：</p>\r\n<p><img src=\"/img/多项式规约/3-SAT2IndependentSet.png\" /></p>\r\n<p><strong>证明</strong>：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>令S为一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的独立集，每个三角形里一定只有一个顶点在<span\r\nclass=\"math inline\">\\(S\\)</span>里，设该顶点取1，其余顶点取0，则其肯定是一个满足3-SAT的赋值。</p>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>给定3-SAT一个满足的赋值，在每个三角形中选取一个取值为1的顶点，这样便构成了一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的独立集。</p>\r\n<h3 id=\"hamiltonian-cycle-problem\">Hamiltonian Cycle problem</h3>\r\n<p><strong>Hamiltonian Cycle</strong>:给定一个无向图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>，是否存在一个简单的环 <span\r\nclass=\"math inline\">\\(\\Gamma\\)</span> 包含 <span\r\nclass=\"math inline\">\\(V\\)</span> 中所有的点。</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/HamiltonianCycle定义.png\"\r\nalt=\"有奇数个节点的Hamiltonian Cycle\" />\r\n<figcaption aria-hidden=\"true\">有奇数个节点的Hamiltonian\r\nCycle</figcaption>\r\n</figure>\r\n<p><strong>DIR-HAM-CYCLE</strong>：给定一个有向图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>,是否存在一个简单环 <span\r\nclass=\"math inline\">\\(\\Gamma\\)</span> 包含<span\r\nclass=\"math inline\">\\(V\\)</span>中所有顶点？</p>\r\n<p><strong>DIR-HAM-CYCL <span class=\"math inline\">\\(\\le_p\\)</span>\r\nHam-Cycle</strong>: 证明：给定一个有向图<span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>,构造一个有<span\r\nclass=\"math inline\">\\(3n\\)</span>个节点的无向图<span\r\nclass=\"math inline\">\\(G&#39;\\)</span>，则<span\r\nclass=\"math inline\">\\(G\\)</span>有Hamiltonian Cycle当且仅当<span\r\nclass=\"math inline\">\\(G&#39;\\)</span>有Hamiltonian Cycle。</p>\r\n<p><img src=\"/img/多项式规约/DIR-HAM-CYC2Ham-Cycle.png\" /></p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>若<span class=\"math inline\">\\(G\\)</span>中有一个有向的Hamiltonian\r\nCycle，则<span\r\nclass=\"math inline\">\\(G&#39;\\)</span>中肯定也有一个Hamiltonian\r\nCycle，且顺序与有向图的节点顺序相同。</p>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>若<span\r\nclass=\"math inline\">\\(G&#39;\\)</span>中有一个无向的Hamiltonian\r\nCycle，则从蓝色节点出发，节点的颜色出现顺序必然是两种中的一种 -\r\nB,G,R,B,G,R,<span class=\"math inline\">\\(\\dots\\)</span> -\r\nB,R,G,B,R,G,<span class=\"math inline\">\\(\\dots\\)</span></p>\r\n<p>若<span class=\"math inline\">\\(G&#39;\\)</span>的Hamiltonian\r\nCycle顺序是第一种，那么对应<span\r\nclass=\"math inline\">\\(G\\)</span>中的Hamiltonian\r\nCycle的节点顺序与其蓝色节点顺序相同；若<span\r\nclass=\"math inline\">\\(G&#39;\\)</span>的Hamiltonian\r\nCycle顺序是第二种，那么对应<span\r\nclass=\"math inline\">\\(G\\)</span>中的Hamiltonian\r\nCycle的节点顺序与其蓝色节点顺序相反。</p>\r\n<h3 id=\"sat-le_p-hamiltonian-cycle-problem\">3SAT <span\r\nclass=\"math inline\">\\(\\le_p\\)</span> Hamiltonian Cycle problem</h3>\r\n<!-- **Vertex Cover**：一组顶点的集合，使得图的每条边至少与集合中的一个顶点相连接。在这里Vertex Cover问题是给定图$G$和点集的个数$k$，要找到图$G$的一个大小为$k$的点覆盖。（也就是常说的最小点覆盖） -->\r\n<p><strong>构造思路:有<span\r\nclass=\"math inline\">\\(n\\)</span>个变量的3-SAT有<span\r\nclass=\"math inline\">\\(2^n\\)</span>种可能的分配，要将其规约到Hamiltonian\r\nCycle，其对应的Hamiltonian Cycle应该也有<span\r\nclass=\"math inline\">\\(2^n\\)</span>种可能的分配方式。</strong></p>\r\n<p>构造方法：对一个有<span class=\"math inline\">\\(n\\)</span>个变量和<span\r\nclass=\"math inline\">\\(k\\)</span>个句子的3-SAT,构造<span\r\nclass=\"math inline\">\\(3k+3\\)</span>个节点的Hamiltonian\r\nCycle，其中每个变量<span class=\"math inline\">\\(x_i\\)</span>对应<span\r\nclass=\"math inline\">\\(3k+3\\)</span>个节点，令外再增加一个源点<span\r\nclass=\"math inline\">\\(s\\)</span>、一个汇点<span\r\nclass=\"math inline\">\\(t\\)</span>。</p>\r\n<p><img src=\"/img/多项式规约/3-SAT2Ham-Cycle构造.png\" /></p>\r\n<p>如果 <span\r\nclass=\"math inline\">\\(x_i=1\\)</span>，则形成从左向右的一个路径；如果\r\n<span\r\nclass=\"math inline\">\\(x_i=0\\)</span>，则形成从右向左的一个路径。</p>\r\n<p>对于每一个clause <span class=\"math inline\">\\(c_j=z_1 z_2\r\nz_3\\)</span>，若<span class=\"math inline\">\\(z=x_i\\)</span>,则添加有向边\r\n<span\r\nclass=\"math inline\">\\((v_{i,3j},c_j)和(c_j,v_{i,3j+1})\\)</span>;若<span\r\nclass=\"math inline\">\\(z=\\bar{x}_i\\)</span>,则添加有向边<span\r\nclass=\"math inline\">\\((c_j,v_{i,3j})和(v_{i,3j+1},c_j)\\)</span>，这里<span\r\nclass=\"math inline\">\\(1\\le j\\le m, 1\\le i\\le\r\nn\\)</span>。如上图所示（即若<span\r\nclass=\"math inline\">\\(z=x_i\\)</span>,该节点与<span\r\nclass=\"math inline\">\\(c\\)</span>节点的连接顺序是从左边进入<span\r\nclass=\"math inline\">\\(c\\)</span>节点，然后从右边出<span\r\nclass=\"math inline\">\\(c\\)</span>节点；反之顺序相反）。</p>\r\n<p>如果选择子句<span class=\"math inline\">\\(C_1\\)</span>中<span\r\nclass=\"math inline\">\\(x_1=1\\)</span>,则<span\r\nclass=\"math inline\">\\(x_1\\)</span>对应的路径为从左向右;同理<span\r\nclass=\"math inline\">\\(x_2=0\\)</span>,则<span\r\nclass=\"math inline\">\\(x_2\\)</span>对应的路径为从右向左；<span\r\nclass=\"math inline\">\\(x_3=1\\)</span>,则<span\r\nclass=\"math inline\">\\(x_3\\)</span>对应的路径为从左向右。其余句子同理，这样就得到了最终的图<span\r\nclass=\"math inline\">\\(G\\)</span>。</p>\r\n<p><strong>证明</strong>:</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>假设3-SAT有一个可满足的分配<span\r\nclass=\"math inline\">\\(x^*\\)</span>：</p>\r\n<ul>\r\n<li>对于<span class=\"math inline\">\\(x_i\\)</span>,若其为1，则第<span\r\nclass=\"math inline\">\\(i\\)</span>行从左往右遍历；反之，若其为0，则第<span\r\nclass=\"math inline\">\\(i\\)</span>行从右往左遍历</li>\r\n<li>且对于每个句子节点<span\r\nclass=\"math inline\">\\(c_i\\)</span>，至少会有一行便利的时候会经过<span\r\nclass=\"math inline\">\\(c_i\\)</span>，否则便不满足每个句子都为真的条件，也就是该分配并不是可满足的。</li>\r\n</ul>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>假设构造的图<span\r\nclass=\"math inline\">\\(G\\)</span>有一个Ham-Cycle，那么</p>\r\n<ul>\r\n<li>若Ham-Cycle进入句子节点<span\r\nclass=\"math inline\">\\(c_i\\)</span>，那么它一定会返回相同的行，否则便不存在简单环。</li>\r\n<li>这样Ham-Cycle里的句子节点<span\r\nclass=\"math inline\">\\(c_i\\)</span>与同一行的两个相邻节点相连，记这两个相邻节点之间的边为<span\r\nclass=\"math inline\">\\(e_i\\)</span></li>\r\n<li>去掉句子节点<span class=\"math inline\">\\(c_i\\)</span>，同时用<span\r\nclass=\"math inline\">\\(e_i\\)</span>替换与<span\r\nclass=\"math inline\">\\(c_i\\)</span>相连的两条边。</li>\r\n<li>按上面的方法去掉所有的句子节点得到图也必然存在Ham-Cycle，且节点的顺序是相同的。</li>\r\n<li>若Ham-Cycle的第<span\r\nclass=\"math inline\">\\(i\\)</span>行是从左往右遍历的，便令<span\r\nclass=\"math inline\">\\(x_i=1\\)</span>;反之则令<span\r\nclass=\"math inline\">\\(x_i=0\\)</span>，这样便得到一个分配方案，且其是可满足的。</li>\r\n</ul>\r\n<p>这样便得到一个分配方式，且每个句子都是可满足的。</p>\r\n<h3 id=\"ham-cycle-le_p-tsptraveling-saleperson-problem\">HAM-CYCLE <span\r\nclass=\"math inline\">\\(\\le_p\\)</span> TSP(Traveling Saleperson\r\nProblem)</h3>\r\n<p><strong>TSP(Traveling Saleperson Problem)</strong>：给定一个<span\r\nclass=\"math inline\">\\(n\\)</span>个城市的集合以及城市之间的距离<span\r\nclass=\"math inline\">\\(d(u,v)\\)</span>,是否存在一个旅行的路线使行走的距离<span\r\nclass=\"math inline\">\\(\\le n\\)</span>?</p>\r\n<p>旅行者问题与HAM-CYCLE的区别在于：旅行者问题并不限定简单路径，也就是说一个节点可以通过多次，只需要考虑最后的路径长度。</p>\r\n<p><strong>DIR-HAM-CYCLE</strong>：给定一个有向图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>,是否存在一个简单环 <span\r\nclass=\"math inline\">\\(\\Gamma\\)</span> 包含<span\r\nclass=\"math inline\">\\(V\\)</span>中所有顶点？</p>\r\n<p>$HAM-CYCLE <span class=\"math inline\">\\(\\le_p\\)</span> TSP(Traveling\r\nSaleperson Problem)$</p>\r\n<p><strong>构造</strong>：给定一个HAM-CYCLE的实例<span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>,<span\r\nclass=\"math inline\">\\(V\\)</span>中的每个节点构造一个城市节点，城市之间的距离根据<span\r\nclass=\"math inline\">\\(E\\)</span>进行赋值: <span\r\nclass=\"math display\">\\[d(u,v)= \\begin{cases}\r\n    1, (u,v) \\in E  \\\\\r\n    2, (u,v) \\notin E\r\n\\end{cases}\\]</span></p>\r\n<p>则TSP中有一个旅行路径<span class=\"math inline\">\\(\\le\r\nn\\)</span>当且仅当<span\r\nclass=\"math inline\">\\(G\\)</span>中存在HAM-CYCLE</p>\r\n<h3 id=\"sat-le-3-colorable\">3-SAT <span\r\nclass=\"math inline\">\\(\\le\\)</span> 3-Colorable</h3>\r\n<p><strong>3-Colorable</strong>:给定一个无向图<span\r\nclass=\"math inline\">\\(G\\)</span>，并给图中的每个节点染上红、蓝、绿的其中一种颜色，那么是否存在一种染色方式使相邻的节点都有不同的颜色？</p>\r\n<p>3-SAT <span class=\"math inline\">\\(\\le\\)</span> 3-Colorable</p>\r\n<p><strong>构造</strong>：</p>\r\n<ul>\r\n<li>对每个Literal，构造一个节点</li>\r\n<li>同时添加三个节点<span\r\nclass=\"math inline\">\\(T、F、B\\)</span>，连接这三个节点形成一个三角形</li>\r\n<li>对每个literal节点，创建一个它的\"非\"并与它相连</li>\r\n<li>所有的Literal节点都与<span class=\"math inline\">\\(B\\)</span>相连</li>\r\n</ul>\r\n<p>如下图所示： <img\r\nsrc=\"/img/多项式规约/3-SAT23-COLOLABLE-1.png\" /></p>\r\n<p>这样构造保证了下面的每个Literal节点都是绿色或红色，且它的“非”与它的颜色刚好相反。</p>\r\n<p>继续接上面：</p>\r\n<ul>\r\n<li>对每个Clause，假设<span class=\"math inline\">\\(C_i=x_1 \\vee\r\n\\overline{x_2} \\vee x_3\\)</span>,则对<span class=\"math inline\">\\(x_1 ,\r\n\\overline{x_2} , x_3\\)</span>添加6个节点以及13条边</li>\r\n</ul>\r\n<p><img src=\"/img/多项式规约/3-SAT23-COLOLABLE-2.png\" /></p>\r\n<p>即<span class=\"math inline\">\\(x_1 , \\overline{x_2} ,\r\nx_3\\)</span>下方的两行一共6个节点，并将左下角的节点、第一行的节点与之前构造的<span\r\nclass=\"math inline\">\\(T\\)</span>节点相连，右下角的节点与之前的<span\r\nclass=\"math inline\">\\(F\\)</span>节点相连。</p>\r\n<p>这样构造是为了保证当三个Literal节点全为红色的时候，是不满足三着色的，如下图所示：当三个Literal节点全为红色的时候，他们下面那行节点必须为蓝色，这样最后一行从左到右着色，最后一个节点冲突。</p>\r\n<p><img src=\"/img/多项式规约/3-SAT23-COLOLABLE-3.png\" /></p>\r\n<p><strong>3-SAT <span class=\"math inline\">\\(\\le\\)</span>\r\n3-Colorable</strong>：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>若图3-Colorable：</p>\r\n<ul>\r\n<li>将所有为绿色的Literal节点设为真</li>\r\n<li>由上面可知，当图3-Colorable的时候三个Literal节点至少有一个是绿色的，那么该句子的输出为真</li>\r\n</ul>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>若3-SAT是可满足的：则 - 三个Literal节点至少有一个为真 -\r\n将为真的Literal节点染为绿色，然后将该节点下面的节点染为红色（否则会冲突），再继续将下面的节点染为蓝色\r\n-\r\n对中间一行没有染红的节点染为蓝色，然后它们下面一行没有染色的节点可唯一确定颜色</p>\r\n<p><img src=\"/img/多项式规约/3-SAT23-COLOLABLE-4.png\" /></p>\r\n<p>上面没有染色的Literal节点绿色、红色皆可。</p>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"pnpnpcnph问题\">P、NP、NPC、NPH问题</h2>\r\n<p><strong>P问题</strong>：存在多项式时间算法的决策问题。</p>\r\n<p><strong>NP问题</strong>\r\n：能在多项式时间内验证某个猜想答案的正确性，但问题求解可能在无法在多项式时间内完成。比如Composite问题、3-Satisfiability、Hamiltonian\r\nCycle，很容易就确定一个答案是否正确，但确找不到一个公式来描述其规律。</p>\r\n<p><strong>结论1</strong>：P <span\r\nclass=\"math inline\">\\(\\subseteq\\)</span> NP</p>\r\n<p><strong>结论2</strong>：NP <span\r\nclass=\"math inline\">\\(\\subseteq\\)</span> EXP</p>\r\n<p><strong>EXP问题</strong>：存在指数时间算法的决策问题。</p>\r\n<p><strong>NPC问题</strong>: 需要满足两个条件</p>\r\n<ul>\r\n<li>它是一个NP问题</li>\r\n<li>所有的NP问题都可以规约到NP-complete</li>\r\n</ul>\r\n<p><strong>定理</strong>：若Y是一个NPC问题，那么Y可以在多项式时间内求解<strong>当且仅当</strong>P<span\r\nclass=\"math inline\">\\(=\\)</span>NP</p>\r\n<p>证明：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>若P <span class=\"math inline\">\\(=\\)</span>\r\nNP，那么Y可以在多项式时间求解，因为Y是NP（NPC的第一个条件：它要先是一个NP）</p>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>若Y可以在多项式时间求解： - 令X为任意一个NP问题，因为X <span\r\nclass=\"math inline\">\\(\\le_p\\)</span>\r\nY，而Y可以在多项式时间求解，故X也可以在多项式时间求解。NP <span\r\nclass=\"math inline\">\\(\\subseteq\\)</span> P - 又已知P <span\r\nclass=\"math inline\">\\(\\subseteq\\)</span> NP,所以 P <span\r\nclass=\"math inline\">\\(=\\)</span> NP</p>\r\n<p><strong>如果</strong>我们给NPC问题找到了一个多项式时间复杂度的算法，那么也就意味着我们给所有的NP问题找到了多项式时间复杂度的算法，从而NP=P，因为P=NP，所以“P对NP问题”就可以被解决。但给NPC问题找一个多项式时间复杂度的算法太难了，所以现在人们普遍相信P≠NP。</p>\r\n<p><strong>NPH问题</strong>\r\n：满足上面NPC问题的第二个条件，但不一定要满足第一个条件，所以NPH的范围比HPC更大。</p>\r\n<h3 id=\"证明一个问题是npc问题的步骤\">证明一个问题是NPC问题的步骤</h3>\r\n<ul>\r\n<li>证明这个问题Y属于NP</li>\r\n<li>选择一个NPC问题X</li>\r\n<li>证明X可以多项式规约到Y</li>\r\n</ul>\r\n<h3 id=\"证明一个问题是nph问题的步骤\">证明一个问题是NPH问题的步骤</h3>\r\n<p>要证明一个问题是NP-hard，通常是找到一个已被证明了的NPC问题，并把这个NPC问题归约到该问题上去（即NPC\r\n<span class=\"math inline\">\\(\\le\\)</span> NP-hard）,简单来说就是： -\r\n对问题A给定限制条件得到一个特例B问题 - 证明问题B是NPC问题</p>\r\n<h2 id=\"npc之间规约的例子\">NPC之间规约的例子</h2>\r\n<h3 id=\"sat-le_p-independent-set\">3-SAT <span\r\nclass=\"math inline\">\\(\\le_p\\)</span> Independent Set</h3>\r\n<p><strong>证明：给定一个3-SAT的例子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>,可以构造一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的Independent Set当且仅当式子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>是可满足的。</strong></p>\r\n<p>构造: -\r\n3-SAT中的每个Clause包含独立集里的三个顶点，其中每个Literal对应一个顶点 -\r\n连接句子里的点连接形成三角形 -\r\n连接不同Clause里每个Literal和它对应的非</p>\r\n<p>如下图所示：</p>\r\n<p><img src=\"/img/多项式规约/3-SAT2IndependentSet.png\" /></p>\r\n<p><strong>证明</strong>：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>令S为一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的独立集，每个三角形里一定只有一个顶点在<span\r\nclass=\"math inline\">\\(S\\)</span>里，设该顶点取1，其余顶点取0，则其肯定是一个满足3-SAT的赋值。</p>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>给定3-SAT一个满足的赋值，在每个三角形中选取一个取值为1的顶点，这样便构成了一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的独立集。</p>\r\n<h3 id=\"hamiltonian-cycle-problem\">Hamiltonian Cycle problem</h3>\r\n<p><strong>Hamiltonian Cycle</strong>:给定一个无向图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>，是否存在一个简单的环 <span\r\nclass=\"math inline\">\\(\\Gamma\\)</span> 包含 <span\r\nclass=\"math inline\">\\(V\\)</span> 中所有的点。</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/HamiltonianCycle定义.png\"\r\nalt=\"有奇数个节点的Hamiltonian Cycle\" />\r\n<figcaption aria-hidden=\"true\">有奇数个节点的Hamiltonian\r\nCycle</figcaption>\r\n</figure>\r\n<p><strong>DIR-HAM-CYCLE</strong>：给定一个有向图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>,是否存在一个简单环 <span\r\nclass=\"math inline\">\\(\\Gamma\\)</span> 包含<span\r\nclass=\"math inline\">\\(V\\)</span>中所有顶点？</p>\r\n<p><strong>DIR-HAM-CYCL <span class=\"math inline\">\\(\\le_p\\)</span>\r\nHam-Cycle</strong>: 证明：给定一个有向图<span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>,构造一个有<span\r\nclass=\"math inline\">\\(3n\\)</span>个节点的无向图<span\r\nclass=\"math inline\">\\(G&#39;\\)</span>，则<span\r\nclass=\"math inline\">\\(G\\)</span>有Hamiltonian Cycle当且仅当<span\r\nclass=\"math inline\">\\(G&#39;\\)</span>有Hamiltonian Cycle。</p>\r\n<p><img src=\"/img/多项式规约/DIR-HAM-CYC2Ham-Cycle.png\" /></p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>若<span class=\"math inline\">\\(G\\)</span>中有一个有向的Hamiltonian\r\nCycle，则<span\r\nclass=\"math inline\">\\(G&#39;\\)</span>中肯定也有一个Hamiltonian\r\nCycle，且顺序与有向图的节点顺序相同。</p>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>若<span\r\nclass=\"math inline\">\\(G&#39;\\)</span>中有一个无向的Hamiltonian\r\nCycle，则从蓝色节点出发，节点的颜色出现顺序必然是两种中的一种 -\r\nB,G,R,B,G,R,<span class=\"math inline\">\\(\\dots\\)</span> -\r\nB,R,G,B,R,G,<span class=\"math inline\">\\(\\dots\\)</span></p>\r\n<p>若<span class=\"math inline\">\\(G&#39;\\)</span>的Hamiltonian\r\nCycle顺序是第一种，那么对应<span\r\nclass=\"math inline\">\\(G\\)</span>中的Hamiltonian\r\nCycle的节点顺序与其蓝色节点顺序相同；若<span\r\nclass=\"math inline\">\\(G&#39;\\)</span>的Hamiltonian\r\nCycle顺序是第二种，那么对应<span\r\nclass=\"math inline\">\\(G\\)</span>中的Hamiltonian\r\nCycle的节点顺序与其蓝色节点顺序相反。</p>\r\n<h3 id=\"sat-le_p-hamiltonian-cycle-problem\">3SAT <span\r\nclass=\"math inline\">\\(\\le_p\\)</span> Hamiltonian Cycle problem</h3>\r\n<!-- **Vertex Cover**：一组顶点的集合，使得图的每条边至少与集合中的一个顶点相连接。在这里Vertex Cover问题是给定图$G$和点集的个数$k$，要找到图$G$的一个大小为$k$的点覆盖。（也就是常说的最小点覆盖） -->\r\n<p><strong>构造思路:有<span\r\nclass=\"math inline\">\\(n\\)</span>个变量的3-SAT有<span\r\nclass=\"math inline\">\\(2^n\\)</span>种可能的分配，要将其规约到Hamiltonian\r\nCycle，其对应的Hamiltonian Cycle应该也有<span\r\nclass=\"math inline\">\\(2^n\\)</span>种可能的分配方式。</strong></p>\r\n<p>构造方法：对一个有<span class=\"math inline\">\\(n\\)</span>个变量和<span\r\nclass=\"math inline\">\\(k\\)</span>个句子的3-SAT,构造<span\r\nclass=\"math inline\">\\(3k+3\\)</span>个节点的Hamiltonian\r\nCycle，其中每个变量<span class=\"math inline\">\\(x_i\\)</span>对应<span\r\nclass=\"math inline\">\\(3k+3\\)</span>个节点，令外再增加一个源点<span\r\nclass=\"math inline\">\\(s\\)</span>、一个汇点<span\r\nclass=\"math inline\">\\(t\\)</span>。</p>\r\n<p><img src=\"/img/多项式规约/3-SAT2Ham-Cycle构造.png\" /></p>\r\n<p>如果 <span\r\nclass=\"math inline\">\\(x_i=1\\)</span>，则形成从左向右的一个路径；如果\r\n<span\r\nclass=\"math inline\">\\(x_i=0\\)</span>，则形成从右向左的一个路径。</p>\r\n<p>对于每一个clause <span class=\"math inline\">\\(c_j=z_1 z_2\r\nz_3\\)</span>，若<span class=\"math inline\">\\(z=x_i\\)</span>,则添加有向边\r\n<span\r\nclass=\"math inline\">\\((v_{i,3j},c_j)和(c_j,v_{i,3j+1})\\)</span>;若<span\r\nclass=\"math inline\">\\(z=\\bar{x}_i\\)</span>,则添加有向边<span\r\nclass=\"math inline\">\\((c_j,v_{i,3j})和(v_{i,3j+1},c_j)\\)</span>，这里<span\r\nclass=\"math inline\">\\(1\\le j\\le m, 1\\le i\\le\r\nn\\)</span>。如上图所示（即若<span\r\nclass=\"math inline\">\\(z=x_i\\)</span>,该节点与<span\r\nclass=\"math inline\">\\(c\\)</span>节点的连接顺序是从左边进入<span\r\nclass=\"math inline\">\\(c\\)</span>节点，然后从右边出<span\r\nclass=\"math inline\">\\(c\\)</span>节点；反之顺序相反）。</p>\r\n<p>如果选择子句<span class=\"math inline\">\\(C_1\\)</span>中<span\r\nclass=\"math inline\">\\(x_1=1\\)</span>,则<span\r\nclass=\"math inline\">\\(x_1\\)</span>对应的路径为从左向右;同理<span\r\nclass=\"math inline\">\\(x_2=0\\)</span>,则<span\r\nclass=\"math inline\">\\(x_2\\)</span>对应的路径为从右向左；<span\r\nclass=\"math inline\">\\(x_3=1\\)</span>,则<span\r\nclass=\"math inline\">\\(x_3\\)</span>对应的路径为从左向右。其余句子同理，这样就得到了最终的图<span\r\nclass=\"math inline\">\\(G\\)</span>。</p>\r\n<p><strong>证明</strong>:</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>假设3-SAT有一个可满足的分配<span\r\nclass=\"math inline\">\\(x^*\\)</span>：</p>\r\n<ul>\r\n<li>对于<span class=\"math inline\">\\(x_i\\)</span>,若其为1，则第<span\r\nclass=\"math inline\">\\(i\\)</span>行从左往右遍历；反之，若其为0，则第<span\r\nclass=\"math inline\">\\(i\\)</span>行从右往左遍历</li>\r\n<li>且对于每个句子节点<span\r\nclass=\"math inline\">\\(c_i\\)</span>，至少会有一行便利的时候会经过<span\r\nclass=\"math inline\">\\(c_i\\)</span>，否则便不满足每个句子都为真的条件，也就是该分配并不是可满足的。</li>\r\n</ul>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>假设构造的图<span\r\nclass=\"math inline\">\\(G\\)</span>有一个Ham-Cycle，那么</p>\r\n<ul>\r\n<li>若Ham-Cycle进入句子节点<span\r\nclass=\"math inline\">\\(c_i\\)</span>，那么它一定会返回相同的行，否则便不存在简单环。</li>\r\n<li>这样Ham-Cycle里的句子节点<span\r\nclass=\"math inline\">\\(c_i\\)</span>与同一行的两个相邻节点相连，记这两个相邻节点之间的边为<span\r\nclass=\"math inline\">\\(e_i\\)</span></li>\r\n<li>去掉句子节点<span class=\"math inline\">\\(c_i\\)</span>，同时用<span\r\nclass=\"math inline\">\\(e_i\\)</span>替换与<span\r\nclass=\"math inline\">\\(c_i\\)</span>相连的两条边。</li>\r\n<li>按上面的方法去掉所有的句子节点得到图也必然存在Ham-Cycle，且节点的顺序是相同的。</li>\r\n<li>若Ham-Cycle的第<span\r\nclass=\"math inline\">\\(i\\)</span>行是从左往右遍历的，便令<span\r\nclass=\"math inline\">\\(x_i=1\\)</span>;反之则令<span\r\nclass=\"math inline\">\\(x_i=0\\)</span>，这样便得到一个分配方案，且其是可满足的。</li>\r\n</ul>\r\n<p>这样便得到一个分配方式，且每个句子都是可满足的。</p>\r\n<h3 id=\"ham-cycle-le_p-tsptraveling-saleperson-problem\">HAM-CYCLE <span\r\nclass=\"math inline\">\\(\\le_p\\)</span> TSP(Traveling Saleperson\r\nProblem)</h3>\r\n<p><strong>TSP(Traveling Saleperson Problem)</strong>：给定一个<span\r\nclass=\"math inline\">\\(n\\)</span>个城市的集合以及城市之间的距离<span\r\nclass=\"math inline\">\\(d(u,v)\\)</span>,是否存在一个旅行的路线使行走的距离<span\r\nclass=\"math inline\">\\(\\le n\\)</span>?</p>\r\n<p>旅行者问题与HAM-CYCLE的区别在于：旅行者问题并不限定简单路径，也就是说一个节点可以通过多次，只需要考虑最后的路径长度。</p>\r\n<p><strong>DIR-HAM-CYCLE</strong>：给定一个有向图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>,是否存在一个简单环 <span\r\nclass=\"math inline\">\\(\\Gamma\\)</span> 包含<span\r\nclass=\"math inline\">\\(V\\)</span>中所有顶点？</p>\r\n<p>$HAM-CYCLE <span class=\"math inline\">\\(\\le_p\\)</span> TSP(Traveling\r\nSaleperson Problem)$</p>\r\n<p><strong>构造</strong>：给定一个HAM-CYCLE的实例<span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>,<span\r\nclass=\"math inline\">\\(V\\)</span>中的每个节点构造一个城市节点，城市之间的距离根据<span\r\nclass=\"math inline\">\\(E\\)</span>进行赋值: <span\r\nclass=\"math display\">\\[d(u,v)= \\begin{cases}\r\n    1, (u,v) \\in E  \\\\\r\n    2, (u,v) \\notin E\r\n\\end{cases}\\]</span></p>\r\n<p>则TSP中有一个旅行路径<span class=\"math inline\">\\(\\le\r\nn\\)</span>当且仅当<span\r\nclass=\"math inline\">\\(G\\)</span>中存在HAM-CYCLE</p>\r\n<h3 id=\"sat-le-3-colorable\">3-SAT <span\r\nclass=\"math inline\">\\(\\le\\)</span> 3-Colorable</h3>\r\n<p><strong>3-Colorable</strong>:给定一个无向图<span\r\nclass=\"math inline\">\\(G\\)</span>，并给图中的每个节点染上红、蓝、绿的其中一种颜色，那么是否存在一种染色方式使相邻的节点都有不同的颜色？</p>\r\n<p>3-SAT <span class=\"math inline\">\\(\\le\\)</span> 3-Colorable</p>\r\n<p><strong>构造</strong>：</p>\r\n<ul>\r\n<li>对每个Literal，构造一个节点</li>\r\n<li>同时添加三个节点<span\r\nclass=\"math inline\">\\(T、F、B\\)</span>，连接这三个节点形成一个三角形</li>\r\n<li>对每个literal节点，创建一个它的\"非\"并与它相连</li>\r\n<li>所有的Literal节点都与<span class=\"math inline\">\\(B\\)</span>相连</li>\r\n</ul>\r\n<p>如下图所示： <img\r\nsrc=\"/img/多项式规约/3-SAT23-COLOLABLE-1.png\" /></p>\r\n<p>这样构造保证了下面的每个Literal节点都是绿色或红色，且它的“非”与它的颜色刚好相反。</p>\r\n<p>继续接上面：</p>\r\n<ul>\r\n<li>对每个Clause，假设<span class=\"math inline\">\\(C_i=x_1 \\vee\r\n\\overline{x_2} \\vee x_3\\)</span>,则对<span class=\"math inline\">\\(x_1 ,\r\n\\overline{x_2} , x_3\\)</span>添加6个节点以及13条边</li>\r\n</ul>\r\n<p><img src=\"/img/多项式规约/3-SAT23-COLOLABLE-2.png\" /></p>\r\n<p>即<span class=\"math inline\">\\(x_1 , \\overline{x_2} ,\r\nx_3\\)</span>下方的两行一共6个节点，并将左下角的节点、第一行的节点与之前构造的<span\r\nclass=\"math inline\">\\(T\\)</span>节点相连，右下角的节点与之前的<span\r\nclass=\"math inline\">\\(F\\)</span>节点相连。</p>\r\n<p>这样构造是为了保证当三个Literal节点全为红色的时候，是不满足三着色的，如下图所示：当三个Literal节点全为红色的时候，他们下面那行节点必须为蓝色，这样最后一行从左到右着色，最后一个节点冲突。</p>\r\n<p><img src=\"/img/多项式规约/3-SAT23-COLOLABLE-3.png\" /></p>\r\n<p><strong>3-SAT <span class=\"math inline\">\\(\\le\\)</span>\r\n3-Colorable</strong>：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>若图3-Colorable：</p>\r\n<ul>\r\n<li>将所有为绿色的Literal节点设为真</li>\r\n<li>由上面可知，当图3-Colorable的时候三个Literal节点至少有一个是绿色的，那么该句子的输出为真</li>\r\n</ul>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>若3-SAT是可满足的：则 - 三个Literal节点至少有一个为真 -\r\n将为真的Literal节点染为绿色，然后将该节点下面的节点染为红色（否则会冲突），再继续将下面的节点染为蓝色\r\n-\r\n对中间一行没有染红的节点染为蓝色，然后它们下面一行没有染色的节点可唯一确定颜色</p>\r\n<p><img src=\"/img/多项式规约/3-SAT23-COLOLABLE-4.png\" /></p>\r\n<p>上面没有染色的Literal节点绿色、红色皆可。</p>\r\n"},{"title":"多项式规约","math":true,"_content":"\n## 多项式规约\n定义：若问题X 的任意实例可以由下面两条之和解决\n\n- 问题X可以通过多项式时间的基本运算步骤转换为问题Y；\n- 问题X多项式次调用求解问题Y的算法，且问题Y可以在多项式时间内被求解。\n\n那么称问题X可以多项式规约到问题Y，记为 $ X \\le_{p} Y $。需要注意的是，问题X转换为问题Y之后，问题Y的运行时间是建立在问题Y的输入上。\n\n多项式规约的几个性质：\n\n- 若 $X \\le_{p} Y$，则若Y能在多项式时间内求解，那么X也能在多项式时间内求解。\n- 若 $X \\le_{p} Y$，则若X不能在多项式时间内求解，那么Y也不能在多项式时间内求解。\n- 若 $X \\le_{p} Y$ 且 $Y \\le_{p} X$，那么X和Y是等价的。\n\n\n\n### 基本的规约方法\n    \n- 简单的恒等归约：比如最大独立集和最小点覆盖。\n- 从特殊例子到一般例子：比如 $点覆盖 \\le_{p} 集合覆盖$。  \n- 通过一些小技巧规约。比如 $3-SAT \\le_{p} 独立集$\n\n\n### 简单的恒等规约\n#### 独立集问题（Independent Set）\n**定义**：给定一个图 $G=(V,E)$和一个整数k(V为顶点集，E为边集)，是否有一个V的子集 $S \\subseteq V $使得 $|S| \\ge k$并且S中的每条边至多有一个顶点在S中？\n\n![独立集](/img/多项式规约/独立集.png)\n\n\n#### 点覆盖问题（Vertex Cover）\n**定义**:给定一个图 $G=(V,E)$和一个整数k,是否有一个V的子集 $S \\subseteq V $使得 $|S| \\le k$并且S中的每条边至少有一个顶点在S中？\n\n\n![点覆盖](/img/多项式规约/点覆盖.png)\n\n#### Vertex Cover和Independent Set的关系\n**定理： $点覆盖 \\equiv 独立集$**\n\n证明如下：\n\n$\\Rightarrow$\n\n- 令S为任意独立集\n- 对任意的边 $(u,v)$\n- S是独立集 $\\Rightarrow u \\notin S$ 或 $v \\notin S \\Rightarrow u \\in V - S $ 或 $v \\in V-S$\n- 所以 $V-S$ 是一个点覆盖\n\n$\\Leftarrow$\n\n- 令 $V-S$是一个点覆盖\n- 对两个顶点 $u \\in S$ 及 $v \\in S$\n- 若 $V-S$ 是一个点覆盖,那么 $(u, v) \\notin E$\n- 因此，没有相邻的顶点在 $S$ 中 $\\Rightarrow$ S是独立集 \n\n### 从特殊例子到一般例子\n#### 集合覆盖（Set Cover）\n**定义**：给定一个集合$U$，以及$U$的子集$S_1,S_2,\\dots,S_m$以及一个整数$k$，是否存在小于或等于$k$个子集$S_i$的并等于$U$?\n\n**例子**:\n\n![几何覆盖例子](/img/多项式规约/集合覆盖例子.png)\n\n\n#### Vertex Cover归约到Set Cover\n**证明：给定一个Vertex-Cover的实例$G=(V,E),k$,可以构造一个与Vertex Cover大小相等的Set Cover的实例。（从特殊例子到一般例子）**\n\n- 创建一个Set Cover的实例$k = k,U=E,S_v=\\{e \\in E: 与V相连的边\\}$\n- 可以看到Set Cover的$size \\le k$当且仅当Vertex Cover的$size \\le k$\n\n**例子**：有如下点覆盖\n\n![](/img/多项式规约/VertexCover归约到SetCover例子.png)\n\n构造Set Cover的$U$为Vertex Cover的边集，即$U=(1,2,3,4,5,6)$，Set Cover的每个子集$S_i$为Vertex Cover中对应顶点所连的边,故有\n$$\n    S_a=\\{3,7\\}， \\\\\n    S_b=\\{2,4\\}， \\\\\n    S_c=\\{3,4,5,6\\}， \\\\\n    S_d=\\{5\\}，  \\\\ \n    S_e=\\{1\\}， \\\\\n    S_f=\\{1,2,6,7\\} \n    $$\n\n可以看到$S_c$和$S_f$构成一个Set Cover的实例，而这两个子集对应的顶点恰好组成一个Vertex Cover的实例。\n\n### 通过\"小技巧\"规约\n\n#### 3-SAT问题\n**Literal（字）**：一个布尔变量或者它的非$x_i \\quad or \\quad  \\overline{x_i}$\n\n**Clause（句子）**：Literal的析取 $C_j = x_1 \\vee  \\overline{x_2} \\vee x_3$\n\n**Formula（式子）**：Clause的合取 $\\Phi=C_1 \\wedge C_2 \\wedge C_3 \\wedge C_4$\n\n**SAT**:给定CNF式子$\\Phi$，是否存在一个满足结果是True的分配$x_1,\\dots,x_n$？若有则称式子$\\Phi$是**可满足**的。\n\n**3-SAT**:每个Clause只有三个Literals。\n\n**例子**：\n\n![](/img/多项式规约/3-SAT例子.png)\n\n#### 3-Satisfiability（3-SAT）归约到Independent Set\n**证明：给定一个3-SAT的例子$\\Phi$,可以构造一个大小为$k$的Independent Set当且仅当式子$\\Phi$是可满足的。**\n\n构造:\n- 3-SAT中的每个Clause包含独立集里的三个顶点，其中每个Literal对应一个顶点\n- 连接句子里的点连接形成三角形\n- 连接不同Clause里每个Literal和它对应的非\n\n如下图所示：\n\n![](/img/多项式规约/3-SAT2IndependentSet.png)\n\n\n**证明**：\n\n$\\Rightarrow$\n\n令S为一个大小为$k$的独立集，每个三角形里一定只有一个顶点在$S$里，设该顶点取1，其余顶点取0，则其肯定是一个满足3-SAT的赋值。\n\n$\\Leftarrow$\n\n给定3-SAT一个满足的赋值，在每个三角形中选取一个取值为1的顶点，这样便构成了一个大小为$k$的独立集。\n\n## 自规约（重要）\n**决策问题（Decision Problem）**：诸如\"是否存在一个$size \\ge k$的点覆盖\"\n\n**求解问题（Search Problem）**：诸如\"寻找一个最小的点覆盖\"\n\n**自规约（Self-Reducibility）**：Search Problem $\\le_p$ Search Problem\n","source":"_posts/多项式规约.md","raw":"---\ntitle: 多项式规约\ncategories: 算法\ntags:\n    - 算法\n    - 高级算法设计与分析\nmath: true\n---\n\n## 多项式规约\n定义：若问题X 的任意实例可以由下面两条之和解决\n\n- 问题X可以通过多项式时间的基本运算步骤转换为问题Y；\n- 问题X多项式次调用求解问题Y的算法，且问题Y可以在多项式时间内被求解。\n\n那么称问题X可以多项式规约到问题Y，记为 $ X \\le_{p} Y $。需要注意的是，问题X转换为问题Y之后，问题Y的运行时间是建立在问题Y的输入上。\n\n多项式规约的几个性质：\n\n- 若 $X \\le_{p} Y$，则若Y能在多项式时间内求解，那么X也能在多项式时间内求解。\n- 若 $X \\le_{p} Y$，则若X不能在多项式时间内求解，那么Y也不能在多项式时间内求解。\n- 若 $X \\le_{p} Y$ 且 $Y \\le_{p} X$，那么X和Y是等价的。\n\n\n\n### 基本的规约方法\n    \n- 简单的恒等归约：比如最大独立集和最小点覆盖。\n- 从特殊例子到一般例子：比如 $点覆盖 \\le_{p} 集合覆盖$。  \n- 通过一些小技巧规约。比如 $3-SAT \\le_{p} 独立集$\n\n\n### 简单的恒等规约\n#### 独立集问题（Independent Set）\n**定义**：给定一个图 $G=(V,E)$和一个整数k(V为顶点集，E为边集)，是否有一个V的子集 $S \\subseteq V $使得 $|S| \\ge k$并且S中的每条边至多有一个顶点在S中？\n\n![独立集](/img/多项式规约/独立集.png)\n\n\n#### 点覆盖问题（Vertex Cover）\n**定义**:给定一个图 $G=(V,E)$和一个整数k,是否有一个V的子集 $S \\subseteq V $使得 $|S| \\le k$并且S中的每条边至少有一个顶点在S中？\n\n\n![点覆盖](/img/多项式规约/点覆盖.png)\n\n#### Vertex Cover和Independent Set的关系\n**定理： $点覆盖 \\equiv 独立集$**\n\n证明如下：\n\n$\\Rightarrow$\n\n- 令S为任意独立集\n- 对任意的边 $(u,v)$\n- S是独立集 $\\Rightarrow u \\notin S$ 或 $v \\notin S \\Rightarrow u \\in V - S $ 或 $v \\in V-S$\n- 所以 $V-S$ 是一个点覆盖\n\n$\\Leftarrow$\n\n- 令 $V-S$是一个点覆盖\n- 对两个顶点 $u \\in S$ 及 $v \\in S$\n- 若 $V-S$ 是一个点覆盖,那么 $(u, v) \\notin E$\n- 因此，没有相邻的顶点在 $S$ 中 $\\Rightarrow$ S是独立集 \n\n### 从特殊例子到一般例子\n#### 集合覆盖（Set Cover）\n**定义**：给定一个集合$U$，以及$U$的子集$S_1,S_2,\\dots,S_m$以及一个整数$k$，是否存在小于或等于$k$个子集$S_i$的并等于$U$?\n\n**例子**:\n\n![几何覆盖例子](/img/多项式规约/集合覆盖例子.png)\n\n\n#### Vertex Cover归约到Set Cover\n**证明：给定一个Vertex-Cover的实例$G=(V,E),k$,可以构造一个与Vertex Cover大小相等的Set Cover的实例。（从特殊例子到一般例子）**\n\n- 创建一个Set Cover的实例$k = k,U=E,S_v=\\{e \\in E: 与V相连的边\\}$\n- 可以看到Set Cover的$size \\le k$当且仅当Vertex Cover的$size \\le k$\n\n**例子**：有如下点覆盖\n\n![](/img/多项式规约/VertexCover归约到SetCover例子.png)\n\n构造Set Cover的$U$为Vertex Cover的边集，即$U=(1,2,3,4,5,6)$，Set Cover的每个子集$S_i$为Vertex Cover中对应顶点所连的边,故有\n$$\n    S_a=\\{3,7\\}， \\\\\n    S_b=\\{2,4\\}， \\\\\n    S_c=\\{3,4,5,6\\}， \\\\\n    S_d=\\{5\\}，  \\\\ \n    S_e=\\{1\\}， \\\\\n    S_f=\\{1,2,6,7\\} \n    $$\n\n可以看到$S_c$和$S_f$构成一个Set Cover的实例，而这两个子集对应的顶点恰好组成一个Vertex Cover的实例。\n\n### 通过\"小技巧\"规约\n\n#### 3-SAT问题\n**Literal（字）**：一个布尔变量或者它的非$x_i \\quad or \\quad  \\overline{x_i}$\n\n**Clause（句子）**：Literal的析取 $C_j = x_1 \\vee  \\overline{x_2} \\vee x_3$\n\n**Formula（式子）**：Clause的合取 $\\Phi=C_1 \\wedge C_2 \\wedge C_3 \\wedge C_4$\n\n**SAT**:给定CNF式子$\\Phi$，是否存在一个满足结果是True的分配$x_1,\\dots,x_n$？若有则称式子$\\Phi$是**可满足**的。\n\n**3-SAT**:每个Clause只有三个Literals。\n\n**例子**：\n\n![](/img/多项式规约/3-SAT例子.png)\n\n#### 3-Satisfiability（3-SAT）归约到Independent Set\n**证明：给定一个3-SAT的例子$\\Phi$,可以构造一个大小为$k$的Independent Set当且仅当式子$\\Phi$是可满足的。**\n\n构造:\n- 3-SAT中的每个Clause包含独立集里的三个顶点，其中每个Literal对应一个顶点\n- 连接句子里的点连接形成三角形\n- 连接不同Clause里每个Literal和它对应的非\n\n如下图所示：\n\n![](/img/多项式规约/3-SAT2IndependentSet.png)\n\n\n**证明**：\n\n$\\Rightarrow$\n\n令S为一个大小为$k$的独立集，每个三角形里一定只有一个顶点在$S$里，设该顶点取1，其余顶点取0，则其肯定是一个满足3-SAT的赋值。\n\n$\\Leftarrow$\n\n给定3-SAT一个满足的赋值，在每个三角形中选取一个取值为1的顶点，这样便构成了一个大小为$k$的独立集。\n\n## 自规约（重要）\n**决策问题（Decision Problem）**：诸如\"是否存在一个$size \\ge k$的点覆盖\"\n\n**求解问题（Search Problem）**：诸如\"寻找一个最小的点覆盖\"\n\n**自规约（Self-Reducibility）**：Search Problem $\\le_p$ Search Problem\n","slug":"多项式规约","published":1,"date":"2022-12-03T10:36:46.044Z","updated":"2022-12-05T15:30:45.162Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8oa000br4sgdl5l609u","content":"<h2 id=\"多项式规约\">多项式规约</h2>\r\n<p>定义：若问题X 的任意实例可以由下面两条之和解决</p>\r\n<ul>\r\n<li>问题X可以通过多项式时间的基本运算步骤转换为问题Y；</li>\r\n<li>问题X多项式次调用求解问题Y的算法，且问题Y可以在多项式时间内被求解。</li>\r\n</ul>\r\n<p>那么称问题X可以多项式规约到问题Y，记为 $ X _{p} Y\r\n$。需要注意的是，问题X转换为问题Y之后，问题Y的运行时间是建立在问题Y的输入上。</p>\r\n<p>多项式规约的几个性质：</p>\r\n<ul>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p}\r\nY\\)</span>，则若Y能在多项式时间内求解，那么X也能在多项式时间内求解。</li>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p}\r\nY\\)</span>，则若X不能在多项式时间内求解，那么Y也不能在多项式时间内求解。</li>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p} Y\\)</span> 且 <span\r\nclass=\"math inline\">\\(Y \\le_{p} X\\)</span>，那么X和Y是等价的。</li>\r\n</ul>\r\n<h3 id=\"基本的规约方法\">基本的规约方法</h3>\r\n<ul>\r\n<li>简单的恒等归约：比如最大独立集和最小点覆盖。</li>\r\n<li>从特殊例子到一般例子：比如 <span class=\"math inline\">\\(点覆盖\r\n\\le_{p} 集合覆盖\\)</span>。<br />\r\n</li>\r\n<li>通过一些小技巧规约。比如 <span class=\"math inline\">\\(3-SAT \\le_{p}\r\n独立集\\)</span></li>\r\n</ul>\r\n<h3 id=\"简单的恒等规约\">简单的恒等规约</h3>\r\n<h4 id=\"独立集问题independent-set\">独立集问题（Independent Set）</h4>\r\n<p><strong>定义</strong>：给定一个图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>和一个整数k(V为顶点集，E为边集)，是否有一个V的子集\r\n$S V $使得 <span class=\"math inline\">\\(|S| \\ge\r\nk\\)</span>并且S中的每条边至多有一个顶点在S中？</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/独立集.png\" alt=\"独立集\" />\r\n<figcaption aria-hidden=\"true\">独立集</figcaption>\r\n</figure>\r\n<h4 id=\"点覆盖问题vertex-cover\">点覆盖问题（Vertex Cover）</h4>\r\n<p><strong>定义</strong>:给定一个图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>和一个整数k,是否有一个V的子集 $S V\r\n$使得 <span class=\"math inline\">\\(|S| \\le\r\nk\\)</span>并且S中的每条边至少有一个顶点在S中？</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/点覆盖.png\" alt=\"点覆盖\" />\r\n<figcaption aria-hidden=\"true\">点覆盖</figcaption>\r\n</figure>\r\n<h4 id=\"vertex-cover和independent-set的关系\">Vertex Cover和Independent\r\nSet的关系</h4>\r\n<p><strong>定理： <span class=\"math inline\">\\(点覆盖 \\equiv\r\n独立集\\)</span></strong></p>\r\n<p>证明如下：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<ul>\r\n<li>令S为任意独立集</li>\r\n<li>对任意的边 <span class=\"math inline\">\\((u,v)\\)</span></li>\r\n<li>S是独立集 <span class=\"math inline\">\\(\\Rightarrow u \\notin\r\nS\\)</span> 或 $v S u V - S $ 或 <span class=\"math inline\">\\(v \\in\r\nV-S\\)</span></li>\r\n<li>所以 <span class=\"math inline\">\\(V-S\\)</span> 是一个点覆盖</li>\r\n</ul>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<ul>\r\n<li>令 <span class=\"math inline\">\\(V-S\\)</span>是一个点覆盖</li>\r\n<li>对两个顶点 <span class=\"math inline\">\\(u \\in S\\)</span> 及 <span\r\nclass=\"math inline\">\\(v \\in S\\)</span></li>\r\n<li>若 <span class=\"math inline\">\\(V-S\\)</span> 是一个点覆盖,那么 <span\r\nclass=\"math inline\">\\((u, v) \\notin E\\)</span></li>\r\n<li>因此，没有相邻的顶点在 <span class=\"math inline\">\\(S\\)</span> 中\r\n<span class=\"math inline\">\\(\\Rightarrow\\)</span> S是独立集</li>\r\n</ul>\r\n<h3 id=\"从特殊例子到一般例子\">从特殊例子到一般例子</h3>\r\n<h4 id=\"集合覆盖set-cover\">集合覆盖（Set Cover）</h4>\r\n<p><strong>定义</strong>：给定一个集合<span\r\nclass=\"math inline\">\\(U\\)</span>，以及<span\r\nclass=\"math inline\">\\(U\\)</span>的子集<span\r\nclass=\"math inline\">\\(S_1,S_2,\\dots,S_m\\)</span>以及一个整数<span\r\nclass=\"math inline\">\\(k\\)</span>，是否存在小于或等于<span\r\nclass=\"math inline\">\\(k\\)</span>个子集<span\r\nclass=\"math inline\">\\(S_i\\)</span>的并等于<span\r\nclass=\"math inline\">\\(U\\)</span>?</p>\r\n<p><strong>例子</strong>:</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/集合覆盖例子.png\" alt=\"几何覆盖例子\" />\r\n<figcaption aria-hidden=\"true\">几何覆盖例子</figcaption>\r\n</figure>\r\n<h4 id=\"vertex-cover归约到set-cover\">Vertex Cover归约到Set Cover</h4>\r\n<p><strong>证明：给定一个Vertex-Cover的实例<span\r\nclass=\"math inline\">\\(G=(V,E),k\\)</span>,可以构造一个与Vertex\r\nCover大小相等的Set Cover的实例。（从特殊例子到一般例子）</strong></p>\r\n<ul>\r\n<li>创建一个Set Cover的实例<span class=\"math inline\">\\(k = k,U=E,S_v=\\{e\r\n\\in E: 与V相连的边\\}\\)</span></li>\r\n<li>可以看到Set Cover的<span class=\"math inline\">\\(size \\le\r\nk\\)</span>当且仅当Vertex Cover的<span class=\"math inline\">\\(size \\le\r\nk\\)</span></li>\r\n</ul>\r\n<p><strong>例子</strong>：有如下点覆盖</p>\r\n<p><img src=\"/img/多项式规约/VertexCover归约到SetCover例子.png\" /></p>\r\n<p>构造Set Cover的<span class=\"math inline\">\\(U\\)</span>为Vertex\r\nCover的边集，即<span class=\"math inline\">\\(U=(1,2,3,4,5,6)\\)</span>，Set\r\nCover的每个子集<span class=\"math inline\">\\(S_i\\)</span>为Vertex\r\nCover中对应顶点所连的边,故有 <span class=\"math display\">\\[\r\n    S_a=\\{3,7\\}， \\\\\r\n    S_b=\\{2,4\\}， \\\\\r\n    S_c=\\{3,4,5,6\\}， \\\\\r\n    S_d=\\{5\\}，  \\\\\r\n    S_e=\\{1\\}， \\\\\r\n    S_f=\\{1,2,6,7\\}\r\n    \\]</span></p>\r\n<p>可以看到<span class=\"math inline\">\\(S_c\\)</span>和<span\r\nclass=\"math inline\">\\(S_f\\)</span>构成一个Set\r\nCover的实例，而这两个子集对应的顶点恰好组成一个Vertex Cover的实例。</p>\r\n<h3 id=\"通过小技巧规约\">通过\"小技巧\"规约</h3>\r\n<h4 id=\"sat问题\">3-SAT问题</h4>\r\n<p><strong>Literal（字）</strong>：一个布尔变量或者它的非<span\r\nclass=\"math inline\">\\(x_i \\quad or \\quad \\overline{x_i}\\)</span></p>\r\n<p><strong>Clause（句子）</strong>：Literal的析取 <span\r\nclass=\"math inline\">\\(C_j = x_1 \\vee \\overline{x_2} \\vee\r\nx_3\\)</span></p>\r\n<p><strong>Formula（式子）</strong>：Clause的合取 <span\r\nclass=\"math inline\">\\(\\Phi=C_1 \\wedge C_2 \\wedge C_3 \\wedge\r\nC_4\\)</span></p>\r\n<p><strong>SAT</strong>:给定CNF式子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>，是否存在一个满足结果是True的分配<span\r\nclass=\"math inline\">\\(x_1,\\dots,x_n\\)</span>？若有则称式子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>是<strong>可满足</strong>的。</p>\r\n<p><strong>3-SAT</strong>:每个Clause只有三个Literals。</p>\r\n<p><strong>例子</strong>：</p>\r\n<p><img src=\"/img/多项式规约/3-SAT例子.png\" /></p>\r\n<h4\r\nid=\"satisfiability3-sat归约到independent-set\">3-Satisfiability（3-SAT）归约到Independent\r\nSet</h4>\r\n<p><strong>证明：给定一个3-SAT的例子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>,可以构造一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的Independent Set当且仅当式子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>是可满足的。</strong></p>\r\n<p>构造: -\r\n3-SAT中的每个Clause包含独立集里的三个顶点，其中每个Literal对应一个顶点 -\r\n连接句子里的点连接形成三角形 -\r\n连接不同Clause里每个Literal和它对应的非</p>\r\n<p>如下图所示：</p>\r\n<p><img src=\"/img/多项式规约/3-SAT2IndependentSet.png\" /></p>\r\n<p><strong>证明</strong>：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>令S为一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的独立集，每个三角形里一定只有一个顶点在<span\r\nclass=\"math inline\">\\(S\\)</span>里，设该顶点取1，其余顶点取0，则其肯定是一个满足3-SAT的赋值。</p>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>给定3-SAT一个满足的赋值，在每个三角形中选取一个取值为1的顶点，这样便构成了一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的独立集。</p>\r\n<h2 id=\"自规约重要\">自规约（重要）</h2>\r\n<p><strong>决策问题（Decision Problem）</strong>：诸如\"是否存在一个<span\r\nclass=\"math inline\">\\(size \\ge k\\)</span>的点覆盖\"</p>\r\n<p><strong>求解问题（Search\r\nProblem）</strong>：诸如\"寻找一个最小的点覆盖\"</p>\r\n<p><strong>自规约（Self-Reducibility）</strong>：Search Problem <span\r\nclass=\"math inline\">\\(\\le_p\\)</span> Search Problem</p>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"多项式规约\">多项式规约</h2>\r\n<p>定义：若问题X 的任意实例可以由下面两条之和解决</p>\r\n<ul>\r\n<li>问题X可以通过多项式时间的基本运算步骤转换为问题Y；</li>\r\n<li>问题X多项式次调用求解问题Y的算法，且问题Y可以在多项式时间内被求解。</li>\r\n</ul>\r\n<p>那么称问题X可以多项式规约到问题Y，记为 $ X _{p} Y\r\n$。需要注意的是，问题X转换为问题Y之后，问题Y的运行时间是建立在问题Y的输入上。</p>\r\n<p>多项式规约的几个性质：</p>\r\n<ul>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p}\r\nY\\)</span>，则若Y能在多项式时间内求解，那么X也能在多项式时间内求解。</li>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p}\r\nY\\)</span>，则若X不能在多项式时间内求解，那么Y也不能在多项式时间内求解。</li>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p} Y\\)</span> 且 <span\r\nclass=\"math inline\">\\(Y \\le_{p} X\\)</span>，那么X和Y是等价的。</li>\r\n</ul>\r\n<h3 id=\"基本的规约方法\">基本的规约方法</h3>\r\n<ul>\r\n<li>简单的恒等归约：比如最大独立集和最小点覆盖。</li>\r\n<li>从特殊例子到一般例子：比如 <span class=\"math inline\">\\(点覆盖\r\n\\le_{p} 集合覆盖\\)</span>。<br />\r\n</li>\r\n<li>通过一些小技巧规约。比如 <span class=\"math inline\">\\(3-SAT \\le_{p}\r\n独立集\\)</span></li>\r\n</ul>\r\n<h3 id=\"简单的恒等规约\">简单的恒等规约</h3>\r\n<h4 id=\"独立集问题independent-set\">独立集问题（Independent Set）</h4>\r\n<p><strong>定义</strong>：给定一个图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>和一个整数k(V为顶点集，E为边集)，是否有一个V的子集\r\n$S V $使得 <span class=\"math inline\">\\(|S| \\ge\r\nk\\)</span>并且S中的每条边至多有一个顶点在S中？</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/独立集.png\" alt=\"独立集\" />\r\n<figcaption aria-hidden=\"true\">独立集</figcaption>\r\n</figure>\r\n<h4 id=\"点覆盖问题vertex-cover\">点覆盖问题（Vertex Cover）</h4>\r\n<p><strong>定义</strong>:给定一个图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>和一个整数k,是否有一个V的子集 $S V\r\n$使得 <span class=\"math inline\">\\(|S| \\le\r\nk\\)</span>并且S中的每条边至少有一个顶点在S中？</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/点覆盖.png\" alt=\"点覆盖\" />\r\n<figcaption aria-hidden=\"true\">点覆盖</figcaption>\r\n</figure>\r\n<h4 id=\"vertex-cover和independent-set的关系\">Vertex Cover和Independent\r\nSet的关系</h4>\r\n<p><strong>定理： <span class=\"math inline\">\\(点覆盖 \\equiv\r\n独立集\\)</span></strong></p>\r\n<p>证明如下：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<ul>\r\n<li>令S为任意独立集</li>\r\n<li>对任意的边 <span class=\"math inline\">\\((u,v)\\)</span></li>\r\n<li>S是独立集 <span class=\"math inline\">\\(\\Rightarrow u \\notin\r\nS\\)</span> 或 $v S u V - S $ 或 <span class=\"math inline\">\\(v \\in\r\nV-S\\)</span></li>\r\n<li>所以 <span class=\"math inline\">\\(V-S\\)</span> 是一个点覆盖</li>\r\n</ul>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<ul>\r\n<li>令 <span class=\"math inline\">\\(V-S\\)</span>是一个点覆盖</li>\r\n<li>对两个顶点 <span class=\"math inline\">\\(u \\in S\\)</span> 及 <span\r\nclass=\"math inline\">\\(v \\in S\\)</span></li>\r\n<li>若 <span class=\"math inline\">\\(V-S\\)</span> 是一个点覆盖,那么 <span\r\nclass=\"math inline\">\\((u, v) \\notin E\\)</span></li>\r\n<li>因此，没有相邻的顶点在 <span class=\"math inline\">\\(S\\)</span> 中\r\n<span class=\"math inline\">\\(\\Rightarrow\\)</span> S是独立集</li>\r\n</ul>\r\n<h3 id=\"从特殊例子到一般例子\">从特殊例子到一般例子</h3>\r\n<h4 id=\"集合覆盖set-cover\">集合覆盖（Set Cover）</h4>\r\n<p><strong>定义</strong>：给定一个集合<span\r\nclass=\"math inline\">\\(U\\)</span>，以及<span\r\nclass=\"math inline\">\\(U\\)</span>的子集<span\r\nclass=\"math inline\">\\(S_1,S_2,\\dots,S_m\\)</span>以及一个整数<span\r\nclass=\"math inline\">\\(k\\)</span>，是否存在小于或等于<span\r\nclass=\"math inline\">\\(k\\)</span>个子集<span\r\nclass=\"math inline\">\\(S_i\\)</span>的并等于<span\r\nclass=\"math inline\">\\(U\\)</span>?</p>\r\n<p><strong>例子</strong>:</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/集合覆盖例子.png\" alt=\"几何覆盖例子\" />\r\n<figcaption aria-hidden=\"true\">几何覆盖例子</figcaption>\r\n</figure>\r\n<h4 id=\"vertex-cover归约到set-cover\">Vertex Cover归约到Set Cover</h4>\r\n<p><strong>证明：给定一个Vertex-Cover的实例<span\r\nclass=\"math inline\">\\(G=(V,E),k\\)</span>,可以构造一个与Vertex\r\nCover大小相等的Set Cover的实例。（从特殊例子到一般例子）</strong></p>\r\n<ul>\r\n<li>创建一个Set Cover的实例<span class=\"math inline\">\\(k = k,U=E,S_v=\\{e\r\n\\in E: 与V相连的边\\}\\)</span></li>\r\n<li>可以看到Set Cover的<span class=\"math inline\">\\(size \\le\r\nk\\)</span>当且仅当Vertex Cover的<span class=\"math inline\">\\(size \\le\r\nk\\)</span></li>\r\n</ul>\r\n<p><strong>例子</strong>：有如下点覆盖</p>\r\n<p><img src=\"/img/多项式规约/VertexCover归约到SetCover例子.png\" /></p>\r\n<p>构造Set Cover的<span class=\"math inline\">\\(U\\)</span>为Vertex\r\nCover的边集，即<span class=\"math inline\">\\(U=(1,2,3,4,5,6)\\)</span>，Set\r\nCover的每个子集<span class=\"math inline\">\\(S_i\\)</span>为Vertex\r\nCover中对应顶点所连的边,故有 <span class=\"math display\">\\[\r\n    S_a=\\{3,7\\}， \\\\\r\n    S_b=\\{2,4\\}， \\\\\r\n    S_c=\\{3,4,5,6\\}， \\\\\r\n    S_d=\\{5\\}，  \\\\\r\n    S_e=\\{1\\}， \\\\\r\n    S_f=\\{1,2,6,7\\}\r\n    \\]</span></p>\r\n<p>可以看到<span class=\"math inline\">\\(S_c\\)</span>和<span\r\nclass=\"math inline\">\\(S_f\\)</span>构成一个Set\r\nCover的实例，而这两个子集对应的顶点恰好组成一个Vertex Cover的实例。</p>\r\n<h3 id=\"通过小技巧规约\">通过\"小技巧\"规约</h3>\r\n<h4 id=\"sat问题\">3-SAT问题</h4>\r\n<p><strong>Literal（字）</strong>：一个布尔变量或者它的非<span\r\nclass=\"math inline\">\\(x_i \\quad or \\quad \\overline{x_i}\\)</span></p>\r\n<p><strong>Clause（句子）</strong>：Literal的析取 <span\r\nclass=\"math inline\">\\(C_j = x_1 \\vee \\overline{x_2} \\vee\r\nx_3\\)</span></p>\r\n<p><strong>Formula（式子）</strong>：Clause的合取 <span\r\nclass=\"math inline\">\\(\\Phi=C_1 \\wedge C_2 \\wedge C_3 \\wedge\r\nC_4\\)</span></p>\r\n<p><strong>SAT</strong>:给定CNF式子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>，是否存在一个满足结果是True的分配<span\r\nclass=\"math inline\">\\(x_1,\\dots,x_n\\)</span>？若有则称式子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>是<strong>可满足</strong>的。</p>\r\n<p><strong>3-SAT</strong>:每个Clause只有三个Literals。</p>\r\n<p><strong>例子</strong>：</p>\r\n<p><img src=\"/img/多项式规约/3-SAT例子.png\" /></p>\r\n<h4\r\nid=\"satisfiability3-sat归约到independent-set\">3-Satisfiability（3-SAT）归约到Independent\r\nSet</h4>\r\n<p><strong>证明：给定一个3-SAT的例子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>,可以构造一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的Independent Set当且仅当式子<span\r\nclass=\"math inline\">\\(\\Phi\\)</span>是可满足的。</strong></p>\r\n<p>构造: -\r\n3-SAT中的每个Clause包含独立集里的三个顶点，其中每个Literal对应一个顶点 -\r\n连接句子里的点连接形成三角形 -\r\n连接不同Clause里每个Literal和它对应的非</p>\r\n<p>如下图所示：</p>\r\n<p><img src=\"/img/多项式规约/3-SAT2IndependentSet.png\" /></p>\r\n<p><strong>证明</strong>：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span></p>\r\n<p>令S为一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的独立集，每个三角形里一定只有一个顶点在<span\r\nclass=\"math inline\">\\(S\\)</span>里，设该顶点取1，其余顶点取0，则其肯定是一个满足3-SAT的赋值。</p>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span></p>\r\n<p>给定3-SAT一个满足的赋值，在每个三角形中选取一个取值为1的顶点，这样便构成了一个大小为<span\r\nclass=\"math inline\">\\(k\\)</span>的独立集。</p>\r\n<h2 id=\"自规约重要\">自规约（重要）</h2>\r\n<p><strong>决策问题（Decision Problem）</strong>：诸如\"是否存在一个<span\r\nclass=\"math inline\">\\(size \\ge k\\)</span>的点覆盖\"</p>\r\n<p><strong>求解问题（Search\r\nProblem）</strong>：诸如\"寻找一个最小的点覆盖\"</p>\r\n<p><strong>自规约（Self-Reducibility）</strong>：Search Problem <span\r\nclass=\"math inline\">\\(\\le_p\\)</span> Search Problem</p>\r\n"},{"title":"最大流最小割","math":true,"_content":"\n\n## 最小割\n在图论中，去掉其中所有边能使一张网络流图不再连通（即分成两个子图）的边集称为图的割。一个$ st-cut $即去掉的边把源点s和汇点t划分在两个不同的部分。\n\n![最小割定义](/img/最大流最小割/最小割定义.png)\n\n一般来说，一张图中有多个不同的$st-cut$，如下图便为其中一个 $st-cut$ 。\n\n\n![一个割例子](/img/最大流最小割/一个割例子.png)\n\n\n但是在实际应用中，我们去掉每条边往往都是有代价的，以边的容量作为权值，一个割中去掉的边的权值之和为这个割的值，那么最小割就是这张图上最小的割。\n\n\n\n## 最大流\n为了求解最小割，需要引入最大流的概念。用边的权值表示边的最大流量，一个 $st-flow$ 是从源点s到汇点t的流量。通俗的讲，最大流就是从源点s到汇点t的最大流量。\n\n![最大流](/img/最大流最小割/最大流.png)\n\n\n\n## 求解最大流\n### 贪心算法\n\n- 开始时对每条边e令$f(e)=0$\n- 找到一条从源点s到汇点t的路径 $s \\rightarrow t$ 使路径上的每条边e满足 $f(e)<c(e)$ ,其中 $c(e)$ 为边e的权值\n- $flow = flow + 路径上的流量$\n- 重复上述步骤直至找不到新的路径\n\n\n### Ford-Fulkerson算法\n#### 残留图(Residual Graph)\n在另一个图中，额外构造一个反向边，权值是实际流过该边的流量 $f(e)$ 。\n\n![残余图](/img/最大流最小割/残余图.png)\n\n剩余图有以下性质：\n- **增广路径(Augmenting Path)**:一个增广路径P是从残余图中的一条简单路径 $s \\rightarrow t$\n- 增广路径的容量是该条路径所有边中的最小权值\n\n#### 算法说明\n- 每次找到一条从s到t的增广路径，并调整flow和残留图，不断调整直到没有增广路径\n- 当残留图中不存在从s到t的增广路径时，该图已经达到最大流\n\n#### 例子\n\n初始时没有反向边,此时残留图等于原图\n\n![](/img/最大流最小割/Ford-Fulkerson例子1.png)\n\n从中选取一条增广路径,并更新残留图和原图\n\n![](/img/最大流最小割/Ford-Fulkerson例子2.png)\n\n重复上面的步骤,注意**增广路径一定要从残留图中找**,且可以使用残留图中的反向边.\n\n\n![](/img/最大流最小割/Ford-Fulkerson例子3.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子4.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子5.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子6.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子7.png)\n\n此时,没有新的增广路径,则最大流的值等于流出源点s的流量减去流进s的流量,即 $flow = s_{out} - s_{in}$\n\n## 最大流与最小割的关系\n**最大流最小割定理：最大流=最小割。** 最大流-最小割定理用来证明Ford-Fulkson方法的确达到了最大流.\n\n![最大流最小割定理](/img/最大流最小割/最大流最小割定理.png)\n\n\n证明:\n-  $(i) \\Rightarrow (ii)$ :弱对偶性法则的推论\n-  $(ii) \\Rightarrow (iii)$ :反证法  \n若f是一个最大流,且仍存在增广路径,那么可以让f加上增广路径的流量,与f是一个最大流相悖.故$(ii) \\Rightarrow (iii)$成立\n- $(iii) \\Rightarrow (i)$\n设f是一个流,且没有增广路径,令A等于s的可达顶点集,则\n\n![](/img/最大流最小割/iii到i.png)\n\n\n","source":"_posts/最大流最小割.md","raw":"---\ntitle: 最大流最小割\ntags: \n    - 算法\n    - 高级算法设计与分析\ncategories: 算法\nmath: true\n---\n\n\n## 最小割\n在图论中，去掉其中所有边能使一张网络流图不再连通（即分成两个子图）的边集称为图的割。一个$ st-cut $即去掉的边把源点s和汇点t划分在两个不同的部分。\n\n![最小割定义](/img/最大流最小割/最小割定义.png)\n\n一般来说，一张图中有多个不同的$st-cut$，如下图便为其中一个 $st-cut$ 。\n\n\n![一个割例子](/img/最大流最小割/一个割例子.png)\n\n\n但是在实际应用中，我们去掉每条边往往都是有代价的，以边的容量作为权值，一个割中去掉的边的权值之和为这个割的值，那么最小割就是这张图上最小的割。\n\n\n\n## 最大流\n为了求解最小割，需要引入最大流的概念。用边的权值表示边的最大流量，一个 $st-flow$ 是从源点s到汇点t的流量。通俗的讲，最大流就是从源点s到汇点t的最大流量。\n\n![最大流](/img/最大流最小割/最大流.png)\n\n\n\n## 求解最大流\n### 贪心算法\n\n- 开始时对每条边e令$f(e)=0$\n- 找到一条从源点s到汇点t的路径 $s \\rightarrow t$ 使路径上的每条边e满足 $f(e)<c(e)$ ,其中 $c(e)$ 为边e的权值\n- $flow = flow + 路径上的流量$\n- 重复上述步骤直至找不到新的路径\n\n\n### Ford-Fulkerson算法\n#### 残留图(Residual Graph)\n在另一个图中，额外构造一个反向边，权值是实际流过该边的流量 $f(e)$ 。\n\n![残余图](/img/最大流最小割/残余图.png)\n\n剩余图有以下性质：\n- **增广路径(Augmenting Path)**:一个增广路径P是从残余图中的一条简单路径 $s \\rightarrow t$\n- 增广路径的容量是该条路径所有边中的最小权值\n\n#### 算法说明\n- 每次找到一条从s到t的增广路径，并调整flow和残留图，不断调整直到没有增广路径\n- 当残留图中不存在从s到t的增广路径时，该图已经达到最大流\n\n#### 例子\n\n初始时没有反向边,此时残留图等于原图\n\n![](/img/最大流最小割/Ford-Fulkerson例子1.png)\n\n从中选取一条增广路径,并更新残留图和原图\n\n![](/img/最大流最小割/Ford-Fulkerson例子2.png)\n\n重复上面的步骤,注意**增广路径一定要从残留图中找**,且可以使用残留图中的反向边.\n\n\n![](/img/最大流最小割/Ford-Fulkerson例子3.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子4.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子5.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子6.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子7.png)\n\n此时,没有新的增广路径,则最大流的值等于流出源点s的流量减去流进s的流量,即 $flow = s_{out} - s_{in}$\n\n## 最大流与最小割的关系\n**最大流最小割定理：最大流=最小割。** 最大流-最小割定理用来证明Ford-Fulkson方法的确达到了最大流.\n\n![最大流最小割定理](/img/最大流最小割/最大流最小割定理.png)\n\n\n证明:\n-  $(i) \\Rightarrow (ii)$ :弱对偶性法则的推论\n-  $(ii) \\Rightarrow (iii)$ :反证法  \n若f是一个最大流,且仍存在增广路径,那么可以让f加上增广路径的流量,与f是一个最大流相悖.故$(ii) \\Rightarrow (iii)$成立\n- $(iii) \\Rightarrow (i)$\n设f是一个流,且没有增广路径,令A等于s的可达顶点集,则\n\n![](/img/最大流最小割/iii到i.png)\n\n\n","slug":"最大流最小割","published":1,"date":"2022-12-03T04:40:24.747Z","updated":"2022-12-05T14:50:48.625Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8ob000cr4sgdala6ml9","content":"<h2 id=\"最小割\">最小割</h2>\r\n<p>在图论中，去掉其中所有边能使一张网络流图不再连通（即分成两个子图）的边集称为图的割。一个$\r\nst-cut $即去掉的边把源点s和汇点t划分在两个不同的部分。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最小割定义.png\" alt=\"最小割定义\" />\r\n<figcaption aria-hidden=\"true\">最小割定义</figcaption>\r\n</figure>\r\n<p>一般来说，一张图中有多个不同的<span\r\nclass=\"math inline\">\\(st-cut\\)</span>，如下图便为其中一个 <span\r\nclass=\"math inline\">\\(st-cut\\)</span> 。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/一个割例子.png\" alt=\"一个割例子\" />\r\n<figcaption aria-hidden=\"true\">一个割例子</figcaption>\r\n</figure>\r\n<p>但是在实际应用中，我们去掉每条边往往都是有代价的，以边的容量作为权值，一个割中去掉的边的权值之和为这个割的值，那么最小割就是这张图上最小的割。</p>\r\n<h2 id=\"最大流\">最大流</h2>\r\n<p>为了求解最小割，需要引入最大流的概念。用边的权值表示边的最大流量，一个\r\n<span class=\"math inline\">\\(st-flow\\)</span>\r\n是从源点s到汇点t的流量。通俗的讲，最大流就是从源点s到汇点t的最大流量。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最大流.png\" alt=\"最大流\" />\r\n<figcaption aria-hidden=\"true\">最大流</figcaption>\r\n</figure>\r\n<h2 id=\"求解最大流\">求解最大流</h2>\r\n<h3 id=\"贪心算法\">贪心算法</h3>\r\n<ul>\r\n<li>开始时对每条边e令<span class=\"math inline\">\\(f(e)=0\\)</span></li>\r\n<li>找到一条从源点s到汇点t的路径 <span class=\"math inline\">\\(s\r\n\\rightarrow t\\)</span> 使路径上的每条边e满足 <span\r\nclass=\"math inline\">\\(f(e)&lt;c(e)\\)</span> ,其中 <span\r\nclass=\"math inline\">\\(c(e)\\)</span> 为边e的权值</li>\r\n<li><span class=\"math inline\">\\(flow = flow + 路径上的流量\\)</span></li>\r\n<li>重复上述步骤直至找不到新的路径</li>\r\n</ul>\r\n<h3 id=\"ford-fulkerson算法\">Ford-Fulkerson算法</h3>\r\n<h4 id=\"残留图residual-graph\">残留图(Residual Graph)</h4>\r\n<p>在另一个图中，额外构造一个反向边，权值是实际流过该边的流量 <span\r\nclass=\"math inline\">\\(f(e)\\)</span> 。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/残余图.png\" alt=\"残余图\" />\r\n<figcaption aria-hidden=\"true\">残余图</figcaption>\r\n</figure>\r\n<p>剩余图有以下性质： - <strong>增广路径(Augmenting\r\nPath)</strong>:一个增广路径P是从残余图中的一条简单路径 <span\r\nclass=\"math inline\">\\(s \\rightarrow t\\)</span> -\r\n增广路径的容量是该条路径所有边中的最小权值</p>\r\n<h4 id=\"算法说明\">算法说明</h4>\r\n<ul>\r\n<li>每次找到一条从s到t的增广路径，并调整flow和残留图，不断调整直到没有增广路径</li>\r\n<li>当残留图中不存在从s到t的增广路径时，该图已经达到最大流</li>\r\n</ul>\r\n<h4 id=\"例子\">例子</h4>\r\n<p>初始时没有反向边,此时残留图等于原图</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子1.png\" /></p>\r\n<p>从中选取一条增广路径,并更新残留图和原图</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子2.png\" /></p>\r\n<p>重复上面的步骤,注意<strong>增广路径一定要从残留图中找</strong>,且可以使用残留图中的反向边.</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子3.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子4.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子5.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子6.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子7.png\" /></p>\r\n<p>此时,没有新的增广路径,则最大流的值等于流出源点s的流量减去流进s的流量,即\r\n<span class=\"math inline\">\\(flow = s_{out} - s_{in}\\)</span></p>\r\n<h2 id=\"最大流与最小割的关系\">最大流与最小割的关系</h2>\r\n<p><strong>最大流最小割定理：最大流=最小割。</strong>\r\n最大流-最小割定理用来证明Ford-Fulkson方法的确达到了最大流.</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最大流最小割定理.png\"\r\nalt=\"最大流最小割定理\" />\r\n<figcaption aria-hidden=\"true\">最大流最小割定理</figcaption>\r\n</figure>\r\n<p>证明: - <span class=\"math inline\">\\((i) \\Rightarrow (ii)\\)</span>\r\n:弱对偶性法则的推论 - <span class=\"math inline\">\\((ii) \\Rightarrow\r\n(iii)\\)</span> :反证法<br />\r\n若f是一个最大流,且仍存在增广路径,那么可以让f加上增广路径的流量,与f是一个最大流相悖.故<span\r\nclass=\"math inline\">\\((ii) \\Rightarrow (iii)\\)</span>成立 - <span\r\nclass=\"math inline\">\\((iii) \\Rightarrow (i)\\)</span>\r\n设f是一个流,且没有增广路径,令A等于s的可达顶点集,则</p>\r\n<p><img src=\"/img/最大流最小割/iii到i.png\" /></p>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"最小割\">最小割</h2>\r\n<p>在图论中，去掉其中所有边能使一张网络流图不再连通（即分成两个子图）的边集称为图的割。一个$\r\nst-cut $即去掉的边把源点s和汇点t划分在两个不同的部分。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最小割定义.png\" alt=\"最小割定义\" />\r\n<figcaption aria-hidden=\"true\">最小割定义</figcaption>\r\n</figure>\r\n<p>一般来说，一张图中有多个不同的<span\r\nclass=\"math inline\">\\(st-cut\\)</span>，如下图便为其中一个 <span\r\nclass=\"math inline\">\\(st-cut\\)</span> 。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/一个割例子.png\" alt=\"一个割例子\" />\r\n<figcaption aria-hidden=\"true\">一个割例子</figcaption>\r\n</figure>\r\n<p>但是在实际应用中，我们去掉每条边往往都是有代价的，以边的容量作为权值，一个割中去掉的边的权值之和为这个割的值，那么最小割就是这张图上最小的割。</p>\r\n<h2 id=\"最大流\">最大流</h2>\r\n<p>为了求解最小割，需要引入最大流的概念。用边的权值表示边的最大流量，一个\r\n<span class=\"math inline\">\\(st-flow\\)</span>\r\n是从源点s到汇点t的流量。通俗的讲，最大流就是从源点s到汇点t的最大流量。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最大流.png\" alt=\"最大流\" />\r\n<figcaption aria-hidden=\"true\">最大流</figcaption>\r\n</figure>\r\n<h2 id=\"求解最大流\">求解最大流</h2>\r\n<h3 id=\"贪心算法\">贪心算法</h3>\r\n<ul>\r\n<li>开始时对每条边e令<span class=\"math inline\">\\(f(e)=0\\)</span></li>\r\n<li>找到一条从源点s到汇点t的路径 <span class=\"math inline\">\\(s\r\n\\rightarrow t\\)</span> 使路径上的每条边e满足 <span\r\nclass=\"math inline\">\\(f(e)&lt;c(e)\\)</span> ,其中 <span\r\nclass=\"math inline\">\\(c(e)\\)</span> 为边e的权值</li>\r\n<li><span class=\"math inline\">\\(flow = flow + 路径上的流量\\)</span></li>\r\n<li>重复上述步骤直至找不到新的路径</li>\r\n</ul>\r\n<h3 id=\"ford-fulkerson算法\">Ford-Fulkerson算法</h3>\r\n<h4 id=\"残留图residual-graph\">残留图(Residual Graph)</h4>\r\n<p>在另一个图中，额外构造一个反向边，权值是实际流过该边的流量 <span\r\nclass=\"math inline\">\\(f(e)\\)</span> 。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/残余图.png\" alt=\"残余图\" />\r\n<figcaption aria-hidden=\"true\">残余图</figcaption>\r\n</figure>\r\n<p>剩余图有以下性质： - <strong>增广路径(Augmenting\r\nPath)</strong>:一个增广路径P是从残余图中的一条简单路径 <span\r\nclass=\"math inline\">\\(s \\rightarrow t\\)</span> -\r\n增广路径的容量是该条路径所有边中的最小权值</p>\r\n<h4 id=\"算法说明\">算法说明</h4>\r\n<ul>\r\n<li>每次找到一条从s到t的增广路径，并调整flow和残留图，不断调整直到没有增广路径</li>\r\n<li>当残留图中不存在从s到t的增广路径时，该图已经达到最大流</li>\r\n</ul>\r\n<h4 id=\"例子\">例子</h4>\r\n<p>初始时没有反向边,此时残留图等于原图</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子1.png\" /></p>\r\n<p>从中选取一条增广路径,并更新残留图和原图</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子2.png\" /></p>\r\n<p>重复上面的步骤,注意<strong>增广路径一定要从残留图中找</strong>,且可以使用残留图中的反向边.</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子3.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子4.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子5.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子6.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子7.png\" /></p>\r\n<p>此时,没有新的增广路径,则最大流的值等于流出源点s的流量减去流进s的流量,即\r\n<span class=\"math inline\">\\(flow = s_{out} - s_{in}\\)</span></p>\r\n<h2 id=\"最大流与最小割的关系\">最大流与最小割的关系</h2>\r\n<p><strong>最大流最小割定理：最大流=最小割。</strong>\r\n最大流-最小割定理用来证明Ford-Fulkson方法的确达到了最大流.</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最大流最小割定理.png\"\r\nalt=\"最大流最小割定理\" />\r\n<figcaption aria-hidden=\"true\">最大流最小割定理</figcaption>\r\n</figure>\r\n<p>证明: - <span class=\"math inline\">\\((i) \\Rightarrow (ii)\\)</span>\r\n:弱对偶性法则的推论 - <span class=\"math inline\">\\((ii) \\Rightarrow\r\n(iii)\\)</span> :反证法<br />\r\n若f是一个最大流,且仍存在增广路径,那么可以让f加上增广路径的流量,与f是一个最大流相悖.故<span\r\nclass=\"math inline\">\\((ii) \\Rightarrow (iii)\\)</span>成立 - <span\r\nclass=\"math inline\">\\((iii) \\Rightarrow (i)\\)</span>\r\n设f是一个流,且没有增广路径,令A等于s的可达顶点集,则</p>\r\n<p><img src=\"/img/最大流最小割/iii到i.png\" /></p>\r\n"},{"title":"广义逆矩阵","_content":"\n## 单边逆\n所谓矩阵的单边逆就是指矩阵的左逆和右逆。\n\n![矩阵的单边逆](/img/矩阵论/单边逆定义.png)\n\n**定理1**:设 $A \\in \\mathbb{C}^{m × n}$,则\n\n- $A$左可逆的充要条件是$A$为列满秩矩阵\n- $A$右可逆的充要条件是$A$为行满秩矩阵\n\n**推论1**:设 $A \\in \\mathbb{C}^{m × n}$,则\n\n- $A$左可逆的充要条件是$N(A)=\\{0\\}$\n- $A$右可逆的充要条件是$R(A)=\\mathbb{C}^m$\n\n\n### 单边逆的求法\n**例1**:\n![](/img/矩阵论/例1-1.png)\n![](/img/矩阵论/例1-2.png)\n\n**例2**:\n![](/img/矩阵论/例2-1.png)\n![](/img/矩阵论/例2-2.png)\n\n\n需要注意的是例1求左逆矩阵进行的是初等行变换,例2求右逆矩阵是进行的初等列变换，初等行变换我们在线性代数中常用，比较熟悉，但是要求右逆矩阵一定要进行初等列变换。\n\n## 广义逆矩阵\n**定义**:\n![](/img/矩阵论/广义逆定义.png)\n\n**性质**:\n![](/img/矩阵论/广义逆定理1.png)\n\n推论:\n![](/img/矩阵论/广义逆推论1.png)\n\n\n需要注意的是，同线性代数中的矩阵的逆不同的是，这里求的广义逆一般不唯一。既然不唯一，有许多解的话，我们就考虑是否有一个通解可以将所有的广义逆全部表示呢？的确有，下面我们就介绍定理2，该定理表示的就是全部的广义逆：\n\n![](/img/矩阵论/全部广义逆集合定义.png)\n\n**定理2**(不常考):\n![](/img/矩阵论/广义逆定理2-1.png)\n![](/img/矩阵论/广义逆定理2-2.png)\n\n**定理3**:\n![](/img/矩阵论/广义逆定理3-1.png)\n![](/img/矩阵论/广义逆定理3-2.png)\n\n- (i)是逆矩阵性质在广义逆的推广\n- (ii)说的是一个矩阵乘以他的广义矩阵是幂等矩阵，且他们矩阵的秩相等\n- (iii)可以看出0矩阵的广义逆矩阵可以是任何矩阵（包括0矩阵）\n- (v)说的是$AA^{-1}$与$A$的值域相同,$A^{-1}A$与$A$的零空间相同,证明如下:\n\n![](/img/矩阵论/定理3(v)证明.png)\n\n## 自反广义逆矩阵\n自反广义逆矩阵是广义逆矩阵里的一类特殊矩阵,其定义如下:\n![](/img/矩阵论/自反广义逆矩阵定义.png)\n\n\n**定理1**:\n![](/img/矩阵论/自反广义逆矩阵定理1.png)\n\n需要注意的是，自反广义逆矩阵并不唯一。事实上，对于\n![](/img/矩阵论/广义逆矩阵/图1.png)\n\n构造这样的矩阵\n![](/img/矩阵论/广义逆矩阵/图2.png)\n\n\n所有满足这样条件的矩阵G，就是A的自反广义逆。所以自反广义逆并不唯一.\n\n**定理2**(考试不要求):\n![](/img/矩阵论/广义逆矩阵/定理2.png)\n\n定理2给出了自反广义逆矩阵的一种具体的构造方法,\n\n**定理3**:\n![](/img/矩阵论/广义逆矩阵/定理3.png)\n\n定理3给出了在广义逆矩阵中，区分自反广义逆的一种有效方法。当广义逆矩阵的秩等于矩阵A的秩的时候是自反广义逆。当广义逆的秩大于矩阵A的秩的时候是广义逆矩阵而不是自反广义逆矩阵。\n\n\n## M-P广义逆矩阵\nM-P广义逆矩阵（Moore-Penrose）矩阵是在自反广义逆矩阵之上又加了两个条件形成的矩阵，要求更加苛刻。我们一般用 $A^+$ 来表示M-P广义逆矩阵。\n![](/img/矩阵论/广义逆矩阵/M-P广义逆定义.png)\n\n这四个条件，共同保证了 $A^+$ 的**唯一性**。\n\n**定理1**:\n![](/img/矩阵论/广义逆矩阵/M-P广义逆定理1.png)\n\n该定理给出了$A^+$  的具体计算方法。定理的证明直接用该式子验证定义中的四个式子即可.\n\n**定理2**:设 $A \\in \\mathbb{C}^{m × n}$,则 $A^+$是唯一的.\n\n这一点已经在上面提到过了,定义中的四个式子保证了$A^+$的唯一.\n\n\n### M-P广义逆的性质\n![](/img/矩阵论/广义逆矩阵/M-P广义逆定理3.png)\n\n**定理5**:\n![](/img/矩阵论/广义逆矩阵/M-P广义逆定理5.png)\n\n\n### M-P广义逆的计算\n#### 最大秩分解\n![](/img/矩阵论/广义逆矩阵/引理1.png)\n\n**定理1**:\n![](/img/矩阵论/广义逆矩阵/M-P广义逆的计算定理1.png)\n\n\n**例1**:\n![](/img/矩阵论/广义逆矩阵/最大秩分解法例1-1.png)\n![](/img/矩阵论/广义逆矩阵/最大秩分解法例1-2.png)\n![](/img/矩阵论/广义逆矩阵/最大秩分解法例1-3.png)\n\n#### 奇异值分解法\n**定理2**:\n![](/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-1.png)\n![](/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-2.png)\n\n\n\n\n\n\n\n","source":"_posts/广义逆矩阵.md","raw":"---\ntitle: 广义逆矩阵\ntags: 矩阵论\ncategories:\n    - 数学\n    - 矩阵论\n---\n\n## 单边逆\n所谓矩阵的单边逆就是指矩阵的左逆和右逆。\n\n![矩阵的单边逆](/img/矩阵论/单边逆定义.png)\n\n**定理1**:设 $A \\in \\mathbb{C}^{m × n}$,则\n\n- $A$左可逆的充要条件是$A$为列满秩矩阵\n- $A$右可逆的充要条件是$A$为行满秩矩阵\n\n**推论1**:设 $A \\in \\mathbb{C}^{m × n}$,则\n\n- $A$左可逆的充要条件是$N(A)=\\{0\\}$\n- $A$右可逆的充要条件是$R(A)=\\mathbb{C}^m$\n\n\n### 单边逆的求法\n**例1**:\n![](/img/矩阵论/例1-1.png)\n![](/img/矩阵论/例1-2.png)\n\n**例2**:\n![](/img/矩阵论/例2-1.png)\n![](/img/矩阵论/例2-2.png)\n\n\n需要注意的是例1求左逆矩阵进行的是初等行变换,例2求右逆矩阵是进行的初等列变换，初等行变换我们在线性代数中常用，比较熟悉，但是要求右逆矩阵一定要进行初等列变换。\n\n## 广义逆矩阵\n**定义**:\n![](/img/矩阵论/广义逆定义.png)\n\n**性质**:\n![](/img/矩阵论/广义逆定理1.png)\n\n推论:\n![](/img/矩阵论/广义逆推论1.png)\n\n\n需要注意的是，同线性代数中的矩阵的逆不同的是，这里求的广义逆一般不唯一。既然不唯一，有许多解的话，我们就考虑是否有一个通解可以将所有的广义逆全部表示呢？的确有，下面我们就介绍定理2，该定理表示的就是全部的广义逆：\n\n![](/img/矩阵论/全部广义逆集合定义.png)\n\n**定理2**(不常考):\n![](/img/矩阵论/广义逆定理2-1.png)\n![](/img/矩阵论/广义逆定理2-2.png)\n\n**定理3**:\n![](/img/矩阵论/广义逆定理3-1.png)\n![](/img/矩阵论/广义逆定理3-2.png)\n\n- (i)是逆矩阵性质在广义逆的推广\n- (ii)说的是一个矩阵乘以他的广义矩阵是幂等矩阵，且他们矩阵的秩相等\n- (iii)可以看出0矩阵的广义逆矩阵可以是任何矩阵（包括0矩阵）\n- (v)说的是$AA^{-1}$与$A$的值域相同,$A^{-1}A$与$A$的零空间相同,证明如下:\n\n![](/img/矩阵论/定理3(v)证明.png)\n\n## 自反广义逆矩阵\n自反广义逆矩阵是广义逆矩阵里的一类特殊矩阵,其定义如下:\n![](/img/矩阵论/自反广义逆矩阵定义.png)\n\n\n**定理1**:\n![](/img/矩阵论/自反广义逆矩阵定理1.png)\n\n需要注意的是，自反广义逆矩阵并不唯一。事实上，对于\n![](/img/矩阵论/广义逆矩阵/图1.png)\n\n构造这样的矩阵\n![](/img/矩阵论/广义逆矩阵/图2.png)\n\n\n所有满足这样条件的矩阵G，就是A的自反广义逆。所以自反广义逆并不唯一.\n\n**定理2**(考试不要求):\n![](/img/矩阵论/广义逆矩阵/定理2.png)\n\n定理2给出了自反广义逆矩阵的一种具体的构造方法,\n\n**定理3**:\n![](/img/矩阵论/广义逆矩阵/定理3.png)\n\n定理3给出了在广义逆矩阵中，区分自反广义逆的一种有效方法。当广义逆矩阵的秩等于矩阵A的秩的时候是自反广义逆。当广义逆的秩大于矩阵A的秩的时候是广义逆矩阵而不是自反广义逆矩阵。\n\n\n## M-P广义逆矩阵\nM-P广义逆矩阵（Moore-Penrose）矩阵是在自反广义逆矩阵之上又加了两个条件形成的矩阵，要求更加苛刻。我们一般用 $A^+$ 来表示M-P广义逆矩阵。\n![](/img/矩阵论/广义逆矩阵/M-P广义逆定义.png)\n\n这四个条件，共同保证了 $A^+$ 的**唯一性**。\n\n**定理1**:\n![](/img/矩阵论/广义逆矩阵/M-P广义逆定理1.png)\n\n该定理给出了$A^+$  的具体计算方法。定理的证明直接用该式子验证定义中的四个式子即可.\n\n**定理2**:设 $A \\in \\mathbb{C}^{m × n}$,则 $A^+$是唯一的.\n\n这一点已经在上面提到过了,定义中的四个式子保证了$A^+$的唯一.\n\n\n### M-P广义逆的性质\n![](/img/矩阵论/广义逆矩阵/M-P广义逆定理3.png)\n\n**定理5**:\n![](/img/矩阵论/广义逆矩阵/M-P广义逆定理5.png)\n\n\n### M-P广义逆的计算\n#### 最大秩分解\n![](/img/矩阵论/广义逆矩阵/引理1.png)\n\n**定理1**:\n![](/img/矩阵论/广义逆矩阵/M-P广义逆的计算定理1.png)\n\n\n**例1**:\n![](/img/矩阵论/广义逆矩阵/最大秩分解法例1-1.png)\n![](/img/矩阵论/广义逆矩阵/最大秩分解法例1-2.png)\n![](/img/矩阵论/广义逆矩阵/最大秩分解法例1-3.png)\n\n#### 奇异值分解法\n**定理2**:\n![](/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-1.png)\n![](/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-2.png)\n\n\n\n\n\n\n\n","slug":"广义逆矩阵","published":1,"date":"2022-12-05T08:54:01.844Z","updated":"2022-12-08T04:21:53.673Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8ob000er4sg0etwcx1o","content":"<h2 id=\"单边逆\">单边逆</h2>\r\n<p>所谓矩阵的单边逆就是指矩阵的左逆和右逆。</p>\r\n<figure>\r\n<img src=\"/img/矩阵论/单边逆定义.png\" alt=\"矩阵的单边逆\" />\r\n<figcaption aria-hidden=\"true\">矩阵的单边逆</figcaption>\r\n</figure>\r\n<p><strong>定理1</strong>:设 <span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{m × n}\\)</span>,则</p>\r\n<ul>\r\n<li><span class=\"math inline\">\\(A\\)</span>左可逆的充要条件是<span\r\nclass=\"math inline\">\\(A\\)</span>为列满秩矩阵</li>\r\n<li><span class=\"math inline\">\\(A\\)</span>右可逆的充要条件是<span\r\nclass=\"math inline\">\\(A\\)</span>为行满秩矩阵</li>\r\n</ul>\r\n<p><strong>推论1</strong>:设 <span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{m × n}\\)</span>,则</p>\r\n<ul>\r\n<li><span class=\"math inline\">\\(A\\)</span>左可逆的充要条件是<span\r\nclass=\"math inline\">\\(N(A)=\\{0\\}\\)</span></li>\r\n<li><span class=\"math inline\">\\(A\\)</span>右可逆的充要条件是<span\r\nclass=\"math inline\">\\(R(A)=\\mathbb{C}^m\\)</span></li>\r\n</ul>\r\n<h3 id=\"单边逆的求法\">单边逆的求法</h3>\r\n<p><strong>例1</strong>: <img src=\"/img/矩阵论/例1-1.png\" /> <img\r\nsrc=\"/img/矩阵论/例1-2.png\" /></p>\r\n<p><strong>例2</strong>: <img src=\"/img/矩阵论/例2-1.png\" /> <img\r\nsrc=\"/img/矩阵论/例2-2.png\" /></p>\r\n<p>需要注意的是例1求左逆矩阵进行的是初等行变换,例2求右逆矩阵是进行的初等列变换，初等行变换我们在线性代数中常用，比较熟悉，但是要求右逆矩阵一定要进行初等列变换。</p>\r\n<h2 id=\"广义逆矩阵\">广义逆矩阵</h2>\r\n<p><strong>定义</strong>: <img src=\"/img/矩阵论/广义逆定义.png\" /></p>\r\n<p><strong>性质</strong>: <img src=\"/img/矩阵论/广义逆定理1.png\" /></p>\r\n<p>推论: <img src=\"/img/矩阵论/广义逆推论1.png\" /></p>\r\n<p>需要注意的是，同线性代数中的矩阵的逆不同的是，这里求的广义逆一般不唯一。既然不唯一，有许多解的话，我们就考虑是否有一个通解可以将所有的广义逆全部表示呢？的确有，下面我们就介绍定理2，该定理表示的就是全部的广义逆：</p>\r\n<p><img src=\"/img/矩阵论/全部广义逆集合定义.png\" /></p>\r\n<p><strong>定理2</strong>(不常考): <img\r\nsrc=\"/img/矩阵论/广义逆定理2-1.png\" /> <img\r\nsrc=\"/img/矩阵论/广义逆定理2-2.png\" /></p>\r\n<p><strong>定理3</strong>: <img src=\"/img/矩阵论/广义逆定理3-1.png\" />\r\n<img src=\"/img/矩阵论/广义逆定理3-2.png\" /></p>\r\n<ul>\r\n<li>(i)是逆矩阵性质在广义逆的推广</li>\r\n<li>(ii)说的是一个矩阵乘以他的广义矩阵是幂等矩阵，且他们矩阵的秩相等</li>\r\n<li>(iii)可以看出0矩阵的广义逆矩阵可以是任何矩阵（包括0矩阵）</li>\r\n<li>(v)说的是<span class=\"math inline\">\\(AA^{-1}\\)</span>与<span\r\nclass=\"math inline\">\\(A\\)</span>的值域相同,<span\r\nclass=\"math inline\">\\(A^{-1}A\\)</span>与<span\r\nclass=\"math inline\">\\(A\\)</span>的零空间相同,证明如下:</li>\r\n</ul>\r\n<p><img src=\"/img/矩阵论/定理3(v)证明.png\" /></p>\r\n<h2 id=\"自反广义逆矩阵\">自反广义逆矩阵</h2>\r\n<p>自反广义逆矩阵是广义逆矩阵里的一类特殊矩阵,其定义如下: <img\r\nsrc=\"/img/矩阵论/自反广义逆矩阵定义.png\" /></p>\r\n<p><strong>定理1</strong>: <img\r\nsrc=\"/img/矩阵论/自反广义逆矩阵定理1.png\" /></p>\r\n<p>需要注意的是，自反广义逆矩阵并不唯一。事实上，对于 <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/图1.png\" /></p>\r\n<p>构造这样的矩阵 <img src=\"/img/矩阵论/广义逆矩阵/图2.png\" /></p>\r\n<p>所有满足这样条件的矩阵G，就是A的自反广义逆。所以自反广义逆并不唯一.</p>\r\n<p><strong>定理2</strong>(考试不要求): <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/定理2.png\" /></p>\r\n<p>定理2给出了自反广义逆矩阵的一种具体的构造方法,</p>\r\n<p><strong>定理3</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/定理3.png\" /></p>\r\n<p>定理3给出了在广义逆矩阵中，区分自反广义逆的一种有效方法。当广义逆矩阵的秩等于矩阵A的秩的时候是自反广义逆。当广义逆的秩大于矩阵A的秩的时候是广义逆矩阵而不是自反广义逆矩阵。</p>\r\n<h2 id=\"m-p广义逆矩阵\">M-P广义逆矩阵</h2>\r\n<p>M-P广义逆矩阵（Moore-Penrose）矩阵是在自反广义逆矩阵之上又加了两个条件形成的矩阵，要求更加苛刻。我们一般用\r\n<span class=\"math inline\">\\(A^+\\)</span> 来表示M-P广义逆矩阵。 <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆定义.png\" /></p>\r\n<p>这四个条件，共同保证了 <span class=\"math inline\">\\(A^+\\)</span>\r\n的<strong>唯一性</strong>。</p>\r\n<p><strong>定理1</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆定理1.png\" /></p>\r\n<p>该定理给出了<span class=\"math inline\">\\(A^+\\)</span>\r\n的具体计算方法。定理的证明直接用该式子验证定义中的四个式子即可.</p>\r\n<p><strong>定理2</strong>:设 <span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{m × n}\\)</span>,则 <span\r\nclass=\"math inline\">\\(A^+\\)</span>是唯一的.</p>\r\n<p>这一点已经在上面提到过了,定义中的四个式子保证了<span\r\nclass=\"math inline\">\\(A^+\\)</span>的唯一.</p>\r\n<h3 id=\"m-p广义逆的性质\">M-P广义逆的性质</h3>\r\n<p><img src=\"/img/矩阵论/广义逆矩阵/M-P广义逆定理3.png\" /></p>\r\n<p><strong>定理5</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆定理5.png\" /></p>\r\n<h3 id=\"m-p广义逆的计算\">M-P广义逆的计算</h3>\r\n<h4 id=\"最大秩分解\">最大秩分解</h4>\r\n<p><img src=\"/img/矩阵论/广义逆矩阵/引理1.png\" /></p>\r\n<p><strong>定理1</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆的计算定理1.png\" /></p>\r\n<p><strong>例1</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/最大秩分解法例1-1.png\" /> <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/最大秩分解法例1-2.png\" /> <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/最大秩分解法例1-3.png\" /></p>\r\n<h4 id=\"奇异值分解法\">奇异值分解法</h4>\r\n<p><strong>定理2</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-1.png\" /> <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-2.png\" /></p>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"单边逆\">单边逆</h2>\r\n<p>所谓矩阵的单边逆就是指矩阵的左逆和右逆。</p>\r\n<figure>\r\n<img src=\"/img/矩阵论/单边逆定义.png\" alt=\"矩阵的单边逆\" />\r\n<figcaption aria-hidden=\"true\">矩阵的单边逆</figcaption>\r\n</figure>\r\n<p><strong>定理1</strong>:设 <span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{m × n}\\)</span>,则</p>\r\n<ul>\r\n<li><span class=\"math inline\">\\(A\\)</span>左可逆的充要条件是<span\r\nclass=\"math inline\">\\(A\\)</span>为列满秩矩阵</li>\r\n<li><span class=\"math inline\">\\(A\\)</span>右可逆的充要条件是<span\r\nclass=\"math inline\">\\(A\\)</span>为行满秩矩阵</li>\r\n</ul>\r\n<p><strong>推论1</strong>:设 <span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{m × n}\\)</span>,则</p>\r\n<ul>\r\n<li><span class=\"math inline\">\\(A\\)</span>左可逆的充要条件是<span\r\nclass=\"math inline\">\\(N(A)=\\{0\\}\\)</span></li>\r\n<li><span class=\"math inline\">\\(A\\)</span>右可逆的充要条件是<span\r\nclass=\"math inline\">\\(R(A)=\\mathbb{C}^m\\)</span></li>\r\n</ul>\r\n<h3 id=\"单边逆的求法\">单边逆的求法</h3>\r\n<p><strong>例1</strong>: <img src=\"/img/矩阵论/例1-1.png\" /> <img\r\nsrc=\"/img/矩阵论/例1-2.png\" /></p>\r\n<p><strong>例2</strong>: <img src=\"/img/矩阵论/例2-1.png\" /> <img\r\nsrc=\"/img/矩阵论/例2-2.png\" /></p>\r\n<p>需要注意的是例1求左逆矩阵进行的是初等行变换,例2求右逆矩阵是进行的初等列变换，初等行变换我们在线性代数中常用，比较熟悉，但是要求右逆矩阵一定要进行初等列变换。</p>\r\n<h2 id=\"广义逆矩阵\">广义逆矩阵</h2>\r\n<p><strong>定义</strong>: <img src=\"/img/矩阵论/广义逆定义.png\" /></p>\r\n<p><strong>性质</strong>: <img src=\"/img/矩阵论/广义逆定理1.png\" /></p>\r\n<p>推论: <img src=\"/img/矩阵论/广义逆推论1.png\" /></p>\r\n<p>需要注意的是，同线性代数中的矩阵的逆不同的是，这里求的广义逆一般不唯一。既然不唯一，有许多解的话，我们就考虑是否有一个通解可以将所有的广义逆全部表示呢？的确有，下面我们就介绍定理2，该定理表示的就是全部的广义逆：</p>\r\n<p><img src=\"/img/矩阵论/全部广义逆集合定义.png\" /></p>\r\n<p><strong>定理2</strong>(不常考): <img\r\nsrc=\"/img/矩阵论/广义逆定理2-1.png\" /> <img\r\nsrc=\"/img/矩阵论/广义逆定理2-2.png\" /></p>\r\n<p><strong>定理3</strong>: <img src=\"/img/矩阵论/广义逆定理3-1.png\" />\r\n<img src=\"/img/矩阵论/广义逆定理3-2.png\" /></p>\r\n<ul>\r\n<li>(i)是逆矩阵性质在广义逆的推广</li>\r\n<li>(ii)说的是一个矩阵乘以他的广义矩阵是幂等矩阵，且他们矩阵的秩相等</li>\r\n<li>(iii)可以看出0矩阵的广义逆矩阵可以是任何矩阵（包括0矩阵）</li>\r\n<li>(v)说的是<span class=\"math inline\">\\(AA^{-1}\\)</span>与<span\r\nclass=\"math inline\">\\(A\\)</span>的值域相同,<span\r\nclass=\"math inline\">\\(A^{-1}A\\)</span>与<span\r\nclass=\"math inline\">\\(A\\)</span>的零空间相同,证明如下:</li>\r\n</ul>\r\n<p><img src=\"/img/矩阵论/定理3(v)证明.png\" /></p>\r\n<h2 id=\"自反广义逆矩阵\">自反广义逆矩阵</h2>\r\n<p>自反广义逆矩阵是广义逆矩阵里的一类特殊矩阵,其定义如下: <img\r\nsrc=\"/img/矩阵论/自反广义逆矩阵定义.png\" /></p>\r\n<p><strong>定理1</strong>: <img\r\nsrc=\"/img/矩阵论/自反广义逆矩阵定理1.png\" /></p>\r\n<p>需要注意的是，自反广义逆矩阵并不唯一。事实上，对于 <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/图1.png\" /></p>\r\n<p>构造这样的矩阵 <img src=\"/img/矩阵论/广义逆矩阵/图2.png\" /></p>\r\n<p>所有满足这样条件的矩阵G，就是A的自反广义逆。所以自反广义逆并不唯一.</p>\r\n<p><strong>定理2</strong>(考试不要求): <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/定理2.png\" /></p>\r\n<p>定理2给出了自反广义逆矩阵的一种具体的构造方法,</p>\r\n<p><strong>定理3</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/定理3.png\" /></p>\r\n<p>定理3给出了在广义逆矩阵中，区分自反广义逆的一种有效方法。当广义逆矩阵的秩等于矩阵A的秩的时候是自反广义逆。当广义逆的秩大于矩阵A的秩的时候是广义逆矩阵而不是自反广义逆矩阵。</p>\r\n<h2 id=\"m-p广义逆矩阵\">M-P广义逆矩阵</h2>\r\n<p>M-P广义逆矩阵（Moore-Penrose）矩阵是在自反广义逆矩阵之上又加了两个条件形成的矩阵，要求更加苛刻。我们一般用\r\n<span class=\"math inline\">\\(A^+\\)</span> 来表示M-P广义逆矩阵。 <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆定义.png\" /></p>\r\n<p>这四个条件，共同保证了 <span class=\"math inline\">\\(A^+\\)</span>\r\n的<strong>唯一性</strong>。</p>\r\n<p><strong>定理1</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆定理1.png\" /></p>\r\n<p>该定理给出了<span class=\"math inline\">\\(A^+\\)</span>\r\n的具体计算方法。定理的证明直接用该式子验证定义中的四个式子即可.</p>\r\n<p><strong>定理2</strong>:设 <span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{m × n}\\)</span>,则 <span\r\nclass=\"math inline\">\\(A^+\\)</span>是唯一的.</p>\r\n<p>这一点已经在上面提到过了,定义中的四个式子保证了<span\r\nclass=\"math inline\">\\(A^+\\)</span>的唯一.</p>\r\n<h3 id=\"m-p广义逆的性质\">M-P广义逆的性质</h3>\r\n<p><img src=\"/img/矩阵论/广义逆矩阵/M-P广义逆定理3.png\" /></p>\r\n<p><strong>定理5</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆定理5.png\" /></p>\r\n<h3 id=\"m-p广义逆的计算\">M-P广义逆的计算</h3>\r\n<h4 id=\"最大秩分解\">最大秩分解</h4>\r\n<p><img src=\"/img/矩阵论/广义逆矩阵/引理1.png\" /></p>\r\n<p><strong>定理1</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆的计算定理1.png\" /></p>\r\n<p><strong>例1</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/最大秩分解法例1-1.png\" /> <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/最大秩分解法例1-2.png\" /> <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/最大秩分解法例1-3.png\" /></p>\r\n<h4 id=\"奇异值分解法\">奇异值分解法</h4>\r\n<p><strong>定理2</strong>: <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-1.png\" /> <img\r\nsrc=\"/img/矩阵论/广义逆矩阵/M-P广义逆计算定理2-2.png\" /></p>\r\n"},{"title":"平稳过程","_content":"\n## 严平稳过程\n![](/img/随机过程/平稳过程/严平稳过程定义.png)\n![严平稳过程定义](/img/随机过程/平稳过程/严平稳过程定义-2.png)\n\n严平稳过程有限维分布不随时间的推移而改变，，它的当前变化情况与过去的情况有不可忽视的联系。\n\n严平稳过程的一维分布与时间无关，而二维分布仅与$t_1$和$t_2$的时间间隔有关，与时间起点无关。\n\n## 宽平稳过程\n由于\n\n- 工程中确定一个过程的有限维分布函数族,进而判定过程的严平稳性十分困难；\n- 部分随机过程(如正态过程)的概率特征主要由一阶和二阶矩函数确定；\n- 工程实际中,通常仅需在相关理论范畴内考虑平稳过程,即只限于研究一、二阶矩（均值、相关函数等）理论.\n\n所以有了宽平稳过程。\n\n定义：\n![宽平稳过程定义](/img/随机过程/平稳过程/宽平稳过程定义.png)\n\n其中$R_x(\\tau)$为$\\{X(t),t \\in T\\}$的自相关函数。其协方差函数为\n$$C_X(s,t)=R_X(s,t)-|m_X|^2=R_X(\\tau)-|m_X|^2$$\n\n自协方差函数与自相关函数都仅依赖于$t－s$\n\n\n**维纳过程不是宽平稳过程，但是维纳过程是增量宽平稳过程，即**\n$$X(t)=W(t+a)-W(t), t \\ge 0, \\quad (a>0)$$\n\n是宽平稳过程\n\n## 两种平稳性的关系\n- 严平稳过程不一定是宽平稳的;\n\n因宽平稳过程一定是二阶矩过程, 而严平稳过程未必是二阶矩过程.\n\n- 宽平稳不一定 严平稳;\n- 严平稳过程是宽平稳过程的充要条件是其二阶矩存在.\n- 对于正态过程, 宽平稳性与严平稳性等价.\n\n\n## 平稳过程的自相关函数\n\n![](/img/随机过程/平稳过程/平稳过程自相关函数性质-1.png)\n![](/img/随机过程/平稳过程/平稳过程自相关函数性质-2.png)\n\n证明:\n\n1. ![](/img/随机过程/平稳过程/自相关证明1.png)\n2. ![](/img/随机过程/平稳过程/自相关证明2.png)\n3. ![](/img/随机过程/平稳过程/自相关证明3.png)\n4. ![](/img/随机过程/平稳过程/自相关证明4.png)\n\n推论：\n![](/img/随机过程/平稳过程/自相关函数推论.png)\n\n定理：\n![](/img/随机过程/平稳过程/定理5.2.2.png)\n\n证明：\n![](/img/随机过程/平稳过程/5.2.2证明.png)\n\n定理:\n![](/img/随机过程/平稳过程/定理5.2.3.png)\n\n\n","source":"_posts/平稳过程.md","raw":"---\ntitle: 平稳过程\ntags: \n    - 随机过程\ncategories: \n    - 数学\n    - 随机过程\n---\n\n## 严平稳过程\n![](/img/随机过程/平稳过程/严平稳过程定义.png)\n![严平稳过程定义](/img/随机过程/平稳过程/严平稳过程定义-2.png)\n\n严平稳过程有限维分布不随时间的推移而改变，，它的当前变化情况与过去的情况有不可忽视的联系。\n\n严平稳过程的一维分布与时间无关，而二维分布仅与$t_1$和$t_2$的时间间隔有关，与时间起点无关。\n\n## 宽平稳过程\n由于\n\n- 工程中确定一个过程的有限维分布函数族,进而判定过程的严平稳性十分困难；\n- 部分随机过程(如正态过程)的概率特征主要由一阶和二阶矩函数确定；\n- 工程实际中,通常仅需在相关理论范畴内考虑平稳过程,即只限于研究一、二阶矩（均值、相关函数等）理论.\n\n所以有了宽平稳过程。\n\n定义：\n![宽平稳过程定义](/img/随机过程/平稳过程/宽平稳过程定义.png)\n\n其中$R_x(\\tau)$为$\\{X(t),t \\in T\\}$的自相关函数。其协方差函数为\n$$C_X(s,t)=R_X(s,t)-|m_X|^2=R_X(\\tau)-|m_X|^2$$\n\n自协方差函数与自相关函数都仅依赖于$t－s$\n\n\n**维纳过程不是宽平稳过程，但是维纳过程是增量宽平稳过程，即**\n$$X(t)=W(t+a)-W(t), t \\ge 0, \\quad (a>0)$$\n\n是宽平稳过程\n\n## 两种平稳性的关系\n- 严平稳过程不一定是宽平稳的;\n\n因宽平稳过程一定是二阶矩过程, 而严平稳过程未必是二阶矩过程.\n\n- 宽平稳不一定 严平稳;\n- 严平稳过程是宽平稳过程的充要条件是其二阶矩存在.\n- 对于正态过程, 宽平稳性与严平稳性等价.\n\n\n## 平稳过程的自相关函数\n\n![](/img/随机过程/平稳过程/平稳过程自相关函数性质-1.png)\n![](/img/随机过程/平稳过程/平稳过程自相关函数性质-2.png)\n\n证明:\n\n1. ![](/img/随机过程/平稳过程/自相关证明1.png)\n2. ![](/img/随机过程/平稳过程/自相关证明2.png)\n3. ![](/img/随机过程/平稳过程/自相关证明3.png)\n4. ![](/img/随机过程/平稳过程/自相关证明4.png)\n\n推论：\n![](/img/随机过程/平稳过程/自相关函数推论.png)\n\n定理：\n![](/img/随机过程/平稳过程/定理5.2.2.png)\n\n证明：\n![](/img/随机过程/平稳过程/5.2.2证明.png)\n\n定理:\n![](/img/随机过程/平稳过程/定理5.2.3.png)\n\n\n","slug":"平稳过程","published":1,"date":"2022-12-07T02:32:01.062Z","updated":"2022-12-07T07:45:45.494Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8oc000gr4sg66je50y1","content":"<h2 id=\"严平稳过程\">严平稳过程</h2>\r\n<p><img src=\"/img/随机过程/平稳过程/严平稳过程定义.png\" /> <img\r\nsrc=\"/img/随机过程/平稳过程/严平稳过程定义-2.png\"\r\nalt=\"严平稳过程定义\" /></p>\r\n<p>严平稳过程有限维分布不随时间的推移而改变，，它的当前变化情况与过去的情况有不可忽视的联系。</p>\r\n<p>严平稳过程的一维分布与时间无关，而二维分布仅与<span\r\nclass=\"math inline\">\\(t_1\\)</span>和<span\r\nclass=\"math inline\">\\(t_2\\)</span>的时间间隔有关，与时间起点无关。</p>\r\n<h2 id=\"宽平稳过程\">宽平稳过程</h2>\r\n<p>由于</p>\r\n<ul>\r\n<li>工程中确定一个过程的有限维分布函数族,进而判定过程的严平稳性十分困难；</li>\r\n<li>部分随机过程(如正态过程)的概率特征主要由一阶和二阶矩函数确定；</li>\r\n<li>工程实际中,通常仅需在相关理论范畴内考虑平稳过程,即只限于研究一、二阶矩（均值、相关函数等）理论.</li>\r\n</ul>\r\n<p>所以有了宽平稳过程。</p>\r\n<p>定义： <img src=\"/img/随机过程/平稳过程/宽平稳过程定义.png\"\r\nalt=\"宽平稳过程定义\" /></p>\r\n<p>其中<span class=\"math inline\">\\(R_x(\\tau)\\)</span>为<span\r\nclass=\"math inline\">\\(\\{X(t),t \\in\r\nT\\}\\)</span>的自相关函数。其协方差函数为 <span\r\nclass=\"math display\">\\[C_X(s,t)=R_X(s,t)-|m_X|^2=R_X(\\tau)-|m_X|^2\\]</span></p>\r\n<p>自协方差函数与自相关函数都仅依赖于<span\r\nclass=\"math inline\">\\(t－s\\)</span></p>\r\n<p><strong>维纳过程不是宽平稳过程，但是维纳过程是增量宽平稳过程，即</strong>\r\n<span class=\"math display\">\\[X(t)=W(t+a)-W(t), t \\ge 0, \\quad\r\n(a&gt;0)\\]</span></p>\r\n<p>是宽平稳过程</p>\r\n<h2 id=\"两种平稳性的关系\">两种平稳性的关系</h2>\r\n<ul>\r\n<li>严平稳过程不一定是宽平稳的;</li>\r\n</ul>\r\n<p>因宽平稳过程一定是二阶矩过程, 而严平稳过程未必是二阶矩过程.</p>\r\n<ul>\r\n<li>宽平稳不一定 严平稳;</li>\r\n<li>严平稳过程是宽平稳过程的充要条件是其二阶矩存在.</li>\r\n<li>对于正态过程, 宽平稳性与严平稳性等价.</li>\r\n</ul>\r\n<h2 id=\"平稳过程的自相关函数\">平稳过程的自相关函数</h2>\r\n<p><img src=\"/img/随机过程/平稳过程/平稳过程自相关函数性质-1.png\" />\r\n<img src=\"/img/随机过程/平稳过程/平稳过程自相关函数性质-2.png\" /></p>\r\n<p>证明:</p>\r\n<ol type=\"1\">\r\n<li><img src=\"/img/随机过程/平稳过程/自相关证明1.png\" /></li>\r\n<li><img src=\"/img/随机过程/平稳过程/自相关证明2.png\" /></li>\r\n<li><img src=\"/img/随机过程/平稳过程/自相关证明3.png\" /></li>\r\n<li><img src=\"/img/随机过程/平稳过程/自相关证明4.png\" /></li>\r\n</ol>\r\n<p>推论： <img src=\"/img/随机过程/平稳过程/自相关函数推论.png\" /></p>\r\n<p>定理： <img src=\"/img/随机过程/平稳过程/定理5.2.2.png\" /></p>\r\n<p>证明： <img src=\"/img/随机过程/平稳过程/5.2.2证明.png\" /></p>\r\n<p>定理: <img src=\"/img/随机过程/平稳过程/定理5.2.3.png\" /></p>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"严平稳过程\">严平稳过程</h2>\r\n<p><img src=\"/img/随机过程/平稳过程/严平稳过程定义.png\" /> <img\r\nsrc=\"/img/随机过程/平稳过程/严平稳过程定义-2.png\"\r\nalt=\"严平稳过程定义\" /></p>\r\n<p>严平稳过程有限维分布不随时间的推移而改变，，它的当前变化情况与过去的情况有不可忽视的联系。</p>\r\n<p>严平稳过程的一维分布与时间无关，而二维分布仅与<span\r\nclass=\"math inline\">\\(t_1\\)</span>和<span\r\nclass=\"math inline\">\\(t_2\\)</span>的时间间隔有关，与时间起点无关。</p>\r\n<h2 id=\"宽平稳过程\">宽平稳过程</h2>\r\n<p>由于</p>\r\n<ul>\r\n<li>工程中确定一个过程的有限维分布函数族,进而判定过程的严平稳性十分困难；</li>\r\n<li>部分随机过程(如正态过程)的概率特征主要由一阶和二阶矩函数确定；</li>\r\n<li>工程实际中,通常仅需在相关理论范畴内考虑平稳过程,即只限于研究一、二阶矩（均值、相关函数等）理论.</li>\r\n</ul>\r\n<p>所以有了宽平稳过程。</p>\r\n<p>定义： <img src=\"/img/随机过程/平稳过程/宽平稳过程定义.png\"\r\nalt=\"宽平稳过程定义\" /></p>\r\n<p>其中<span class=\"math inline\">\\(R_x(\\tau)\\)</span>为<span\r\nclass=\"math inline\">\\(\\{X(t),t \\in\r\nT\\}\\)</span>的自相关函数。其协方差函数为 <span\r\nclass=\"math display\">\\[C_X(s,t)=R_X(s,t)-|m_X|^2=R_X(\\tau)-|m_X|^2\\]</span></p>\r\n<p>自协方差函数与自相关函数都仅依赖于<span\r\nclass=\"math inline\">\\(t－s\\)</span></p>\r\n<p><strong>维纳过程不是宽平稳过程，但是维纳过程是增量宽平稳过程，即</strong>\r\n<span class=\"math display\">\\[X(t)=W(t+a)-W(t), t \\ge 0, \\quad\r\n(a&gt;0)\\]</span></p>\r\n<p>是宽平稳过程</p>\r\n<h2 id=\"两种平稳性的关系\">两种平稳性的关系</h2>\r\n<ul>\r\n<li>严平稳过程不一定是宽平稳的;</li>\r\n</ul>\r\n<p>因宽平稳过程一定是二阶矩过程, 而严平稳过程未必是二阶矩过程.</p>\r\n<ul>\r\n<li>宽平稳不一定 严平稳;</li>\r\n<li>严平稳过程是宽平稳过程的充要条件是其二阶矩存在.</li>\r\n<li>对于正态过程, 宽平稳性与严平稳性等价.</li>\r\n</ul>\r\n<h2 id=\"平稳过程的自相关函数\">平稳过程的自相关函数</h2>\r\n<p><img src=\"/img/随机过程/平稳过程/平稳过程自相关函数性质-1.png\" />\r\n<img src=\"/img/随机过程/平稳过程/平稳过程自相关函数性质-2.png\" /></p>\r\n<p>证明:</p>\r\n<ol type=\"1\">\r\n<li><img src=\"/img/随机过程/平稳过程/自相关证明1.png\" /></li>\r\n<li><img src=\"/img/随机过程/平稳过程/自相关证明2.png\" /></li>\r\n<li><img src=\"/img/随机过程/平稳过程/自相关证明3.png\" /></li>\r\n<li><img src=\"/img/随机过程/平稳过程/自相关证明4.png\" /></li>\r\n</ol>\r\n<p>推论： <img src=\"/img/随机过程/平稳过程/自相关函数推论.png\" /></p>\r\n<p>定理： <img src=\"/img/随机过程/平稳过程/定理5.2.2.png\" /></p>\r\n<p>证明： <img src=\"/img/随机过程/平稳过程/5.2.2证明.png\" /></p>\r\n<p>定理: <img src=\"/img/随机过程/平稳过程/定理5.2.3.png\" /></p>\r\n"},{"title":"矩阵分解","_content":"\n<!-- <link href=\"https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css\" rel=\"stylesheet\"> -->\n\n## 三角分解(QR分解)\n### 正交三角分解(通过Schmidt正交化)\n若 $n$ 阶实矩阵 $A\\in \\mathbb {C}^{n\\times n}$ 满秩，且 \n$$A = [\\alpha_1,...,\\alpha_n]$$\n\n其中 $\\alpha_1,...,\\alpha_n$ 是 $\\mathbb {C}^{n\\times n}$  中线性无关向量组\n\n**正交化**\n\n令\n\n$$ \\begin{aligned} \\beta_1&=\\alpha_1\\\\ \\beta_2&=\\alpha_2 - \\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1 \\\\ \\vdots \\\\ \\beta_n &= \\alpha_n - \\frac{\\left<\\beta_n,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1-\\cdots-\\frac{\\left<\\beta_{n-1},\\alpha_n\\right>}{\\left<\\beta_{n-1},\\alpha_{n-1}\\right>}\\beta_{n-1} \\end{aligned} $$\n\n变形得 \n\n$$ \\begin{aligned} \\alpha_1 &= \\beta_1\\\\ \\alpha_2 &= \\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1 + \\beta_2\\\\ \\vdots \\\\ \\alpha_n &= \\frac{\\left<\\beta_n,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1-\\cdots-\\frac{\\left<\\beta_{n-1},\\alpha_n\\right>}{\\left<\\beta_{n-1},\\alpha_{n-1}\\right>}\\beta_{n-1} + \\beta_n \\end{aligned} $$\n\n写成矩阵形式\n\n$$ \\begin{aligned} \\begin{bmatrix}\\alpha_1,\\alpha_2,...,\\alpha_n\\end{bmatrix} &= \\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix}\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &\\triangleq B\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix} \\end{aligned} $$\n\n**单位化**\n\n令 \n\n$$ q_1=\\frac{\\beta_1}{||\\beta_1||} \\\\ \\vdots \\\\ q_n = \\frac{\\beta_n}{||\\beta_n||} $$\n\n变形得 \n\n$$\\beta_1 = q_1||\\beta_1|| \\\\ \\vdots \\\\ \\beta_n = q_n ||\\beta_n|| $$\n\n写成矩阵形式 \n\n$$ \\begin{aligned} \\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix} &= \\begin{bmatrix}q_1,q_2,...,q_n\\end{bmatrix}\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\\\ &\\triangleq Q\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix} \\end{aligned} $$\n\n综上，结合正交化和单位化可得 \n\n$$ \\begin{aligned} A &= B\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &=Q\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &=Q\\begin{bmatrix}||\\beta_1||&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&||\\beta_2||&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\\\ &\\triangleq QR \\end{aligned} $$\n\n**QR 分解定理** : $A\\in \\mathbb {C}^{n\\times n}$ ,则存在酉矩阵 $Q$ 和正线上三角阵 $R$ ，使 $$A=QR$$\n\n且分解唯一\n\n**正交三角分解的求法**\n1. 取矩阵 $A=(A_1,A_2,...,A_n)$ 的列向量，进行 **Schmidt 标准正交化**,得 $v_1,v_2,...,v_n$ ，有 $$Q=(v_1,v_2,...,v_n)$$\n2. 再由 $R=Q^HA$ 得到 $R$ , 于是 $A=QR$\n\n\n\n### HouseHolder变换分解\n将矩阵A按列划分为 $(\\alpha_1,\\alpha_2,\\dots,\\alpha_n)$,以4阶方阵为例，\n\n第一步\n令\n$$\\omega_1=\\frac{\\alpha_1-a_1*e_1}{||\\alpha_1-a_1*e_1||_2}，a_1=||\\alpha_1||_2$$\n\n于是\n$$H_1A=(H_1\\alpha_1,H_1\\alpha_2，...，H_1\\alpha_n)\n=\\left\\{\\begin{matrix} a_1 & * & \\cdots & * \\\\\n                   0      & \\\\\n                   \\vdots & &B_1 \\\\\n0\\end{matrix}\\right\\}$$\n\n第二步\n\n从第一步中得到 $B_1=(\\beta_2,\\beta_2,\\cdots,\\beta_n)\\in R^{n-1}$\n\n取 $$\\omega_2=\\frac{\\beta_2-b_2*e_1}{||\\beta_2-b_2*e_1||_2}，b_1=||\\beta_2||_2$$\n\n则 $$\\widehat{H_2}=I-2*\\omega_2*\\omega_2^T,H_2=\\left\\{\\begin{matrix} 1 & 0^T \\\\ \n                                                              0 & \\widehat{H_2}，\n                                              \\end{matrix} \\right\\}$$\n\n得到\n$$H_2(H_1*A) = \\begin{bmatrix}   a_1 & * & * & \\cdots &* \\\\ \n                                       0 & a_2 & * & \\cdots &* \\\\\n                                       0 & 0 &  &\\\\\n                                       \\vdots & \\vdots &  &C_2& \\\\\n                                       0 & 0\n\\end{bmatrix} , C_2\\in R^{n-2}$$\n\n依次类推，进行第n步时，得到第n-1个 $H_{n-1}$阵,使得\n$$H_{n-1} \\cdots H_2H_1*A = \\begin{bmatrix}   a_1 & * & * & \\cdots & * \\\\ \n                                                   0 & a_2 & * & \\cdots & * \\\\\n                                                   0 & 0 & a_3 & \\cdots & *\\\\\n                                                  \\vdots & \\vdots & &\\ddots \\\\\n                                                    0 & 0 & 0 & \\cdots &a_n\n\\end{bmatrix}=R$$\n\n\n其中 $H_{n-1} \\cdots H_2H_1*A=H$也称为HouseHolder矩阵，也为自逆矩阵 $H=H^{-1}$\n\n$$H_{n-1} \\cdots H_2H_1*A=R$$\n$$\\Rightarrow (H_{n-1} \\cdots H_2*H_1)^{-1}*H_{n-1} \\cdots H_2H_1*A=(H_{n-1} \\cdots H_2*H_1)^{-1}*R$$\n$$\\Rightarrow A=H_1^{-1} \\cdots H_{n-1}^{-1}*R$$\n$$\\Rightarrow A=H_1\\cdots H_{n-1}*R$$\n\n得到 $A=QR$,其中 $Q$为正交矩阵， $R$为上三角矩阵\n$$\\begin{cases}\nQ = H_1\\cdots H_{n-1}\\\\\nR = Q^{-1}A=QA \n\\end{cases}$$\n\n### 三角分解的性质\n**定理1**:设 $A\\in \\mathbb {C}_r^{m\\times n}$，则 $A$ 可以唯一地分解为\n$$A=U_1 R$$\n\n其中 $U_1$是酉矩阵， $R$ 是正线上三角复矩阵，或 $A$ 可以唯一地分解为\n$$A=L U_2$$\n\n其中 $L$是正线下三角复矩阵， $U_2$是酉矩阵\n\n\n**推论1**：设 $A \\in \\mathbb {R}^{n × n}_n$,则 $A$可以唯一地分解为\n$$A=Q_1 R$$\n\n其中 $Q_1$是则正交矩阵，$R$是正线上三角实矩阵，或 $A$可以唯一地分解为\n$$A=L Q_2$$\n\n其中 $L$是正线下三角实矩阵， $Q_2$是正交矩阵。\n\n**推论2**：设A是实对称正定矩阵，则存在唯一正线上三角实矩阵 $R$，使得\n$$A=R^T R$$\n\n**推论3**：设 $A$是正定Hermite矩阵，则存在唯一正线上三角复矩阵$R$，使得\n$$A=R^H R$$\n\n\n## 矩阵的满秩分解\n设 $A\\in \\mathbb {C}_r^{m\\times n}$，则存在 $B\\in \\mathbb {C}_r^{m\\times r}, C\\in \\mathbb {C}_r^{r\\times n}$，满足\n$$ A = BC $$\n\n$\\mathbb {C}_r$ 表示矩阵的秩为 $r$\n\n实际上上述定理用文字描述就是，一个亏秩的矩阵可以分解成一个列满秩与行满秩矩阵的乘积\n\n证明：因为 $rank (A)=r$，所以一定可以找到与 $A$ 相似的一个矩阵\n\n$$ A \\simeq \\begin{bmatrix}E_r&0_{r\\times (n-r)}\\\\0_{(m-r)\\times r}&0_{(m-r)\\times (n-r)}\\end{bmatrix}=\\begin{bmatrix}E_r\\\\0_{(m-r)\\times r}\\end{bmatrix}\\begin{bmatrix}E_r&0_{r\\times (n-r)}\\end{bmatrix} $$\n\n因此存在两个可逆矩阵 $P,Q$，使 $PAQ=\\begin {bmatrix} E_r&0\\\\0&0\\end {bmatrix}$，则\n\n$$ \\begin{aligned} A &= P^{-1}\\begin{bmatrix}E_r\\\\0\\end{bmatrix}\\begin{bmatrix}E_r&0\\end{bmatrix}Q^{-1}\\\\ &\\triangleq BC \\end{aligned} $$\n\n因为 $P^{-1}$ 是可逆矩阵，$\\begin {bmatrix} E_r\\\\0\\end {bmatrix}$ 是一个列满秩矩阵，所以 $B=P^{-1}\\begin {bmatrix} E_r\\\\0\\end {bmatrix}$ 仍是一个列满秩矩阵；同理，$C=\\begin {bmatrix} E_r&0\\end {bmatrix} Q^{-1}$ 是一个行满秩矩阵\n\n### 矩阵满秩分解的计算\n如何在给定矩阵 $A$ 的情况下，求出矩阵 $B,C$ 呢？\n\n设\n\n$$ A = [\\alpha_1,\\alpha_2,...,\\alpha_n]\\\\ B = [\\beta_1,\\beta_2,...,\\beta_r]$$\n\n其中 $\\beta_1,...,\\beta_r$ 线性无关 \n\n所以 \n$$ \\begin{aligned} &A=BC\\\\ &\\Rightarrow[\\alpha_1,\\alpha_2,...,\\alpha_n]=[\\beta_1,...,\\beta_r]\\begin{bmatrix}c_{11}&\\cdots &c_{1n}\\\\\\vdots &\\ddots&\\vdots\\\\c_{r1}&\\cdots &c_{rn}\\end{bmatrix} \\end{aligned} $$\n\n实际上我们可以取 $\\beta_1,...,\\beta_r$ 为 $\\alpha_1,...,\\alpha_n$ 的一个极大线性无关组，因此 $B$ 就是矩阵 $A$ 列向量组的一个极大线性无关组，$C$ 就是用该线性无关组去表示 $A$ 时的系数\n\n#### 例 1\n\n求矩阵 $A=\\begin {bmatrix} 1&4&-1&5&6\\\\2&0&0&0&-14\\\\-1&2&-4&0&1\\\\2&6&-5&5&-7\\end {bmatrix}$ 的满秩分解\n\n**解**：对矩阵 $A$ 只作初等行变换\n$$ A=\\begin{bmatrix}1&4&-1&5&6\\\\2&0&0&0&-14\\\\-1&2&-4&0&1\\\\2&6&-5&5&-7\\end{bmatrix}\\to ···\\to\\begin{bmatrix}1&0&0&0&-7\\\\0&1&0&\\frac{10}{7}&\\frac{29}{7}\\\\0&0&1&\\frac{5}{7}&\\frac{25}{7}\\\\0&0&0&0&0\\end{bmatrix} $$\n\n$A$ 的秩为 3，且前三个列向量线性无关，故\n$$ B = \\begin{bmatrix}1&4&-1\\\\2&0&0\\\\-1&2&-4\\\\2&6&-5\\end{bmatrix}，C=\\begin{bmatrix}1&0&0&0&-7\\\\0&1&0&\\frac{10}{7}&\\frac{29}{7}\\\\0&0&1&\\frac{5}{7}&\\frac{25}{7}\\end{bmatrix} $$\n\n#### 例 2\n求矩阵 $A=\\begin {bmatrix} 2&1&-2&3&1\\\\2&5&-1&4&1\\\\1&3&-1&2&1\\end {bmatrix}$ 的满秩分解\n\n**解**：对矩阵 $A$ 只作初等行变换\n\n$$ A=\\begin{bmatrix}2&1&-2&3&1\\\\2&5&-1&4&1\\\\1&3&-1&2&1\\end{bmatrix}\\to ···\\to \\begin{bmatrix}1&0&0&\\frac{8}{5}&-\\frac{2}{5}\\\\0&1&0&\\frac{1}{5}&\\frac{1}{5}\\\\0&0&1&\\frac{1}{5}&-\\frac{4}{5}\\end{bmatrix} $$\n\n$A$ 的秩为 3，且前三个列向量线性无关，故\n$$ B = \\begin{bmatrix}2&1&-2\\\\2&5&-1\\\\1&3&-1\\end{bmatrix},C = \\begin{bmatrix}1&0&0&\\frac{8}{5}&-\\frac{2}{5}\\\\0&1&0&\\frac{1}{5}&\\frac{1}{5}\\\\0&0&1&\\frac{1}{5}&-\\frac{4}{5}\\end{bmatrix} $$\n\n## 矩阵的LU分解\nLU 分解（LU Decomposition）是矩阵分解的一种，可以将一个矩阵分解为一个单位下三角矩阵和一个上三角矩阵的乘积，以四阶矩阵为例\n$$ L = \\begin{bmatrix}1&0&0&0 \\\\ *&1&0&0\\\\ *&*&1&0\\\\ *&*&*&1\\end{bmatrix}, U=\\begin{bmatrix}*&*&*&*\\\\0&*&*&*\\\\0&0&*&*\\\\0&0&0&*\\end{bmatrix} $$\n\nLU 矩阵是否一定存在？答案是否，具体看下面的例子\n\n设 $\\begin {bmatrix} 0&1 \\\\1&0\\end {bmatrix}=\\begin {bmatrix} a&0\\\\b&c\\end {bmatrix}\\begin {bmatrix} l&m\\\\0&n\\end {bmatrix}$，则应该满足如下 4 个式子\n\n$$ \\begin{cases} al=0\\\\ am=1\\\\ bl=1\\\\ bm+cn=0 \\end{cases} $$\n\n由 $al=0$ 得 $a=0$ 或 $l=0$，但实际上这两种情况带入上面的式子都会推出矛盾，因此不是所有情况 LU 分解都存在\n\n**LU 分解定理** ：设 $A\\in \\mathbb {C}_n^{n\\times n}$，$A$ 有唯一的 LU 分解 $\\Leftrightarrow A$ 的各阶顺序主子式 $\\Delta k \\neq 0,\\ k=1,2...,n$\n\n$k$ 阶顺序主子式指的是矩阵左上角 $k\\times k$ 个元素组成的行列式\n\n将矩阵 $A$ 分解为 $L$ 和 $U$ 之后，解方程组 $Ax=b$ 就变得简单了，因为 $A=LU$，所以 $(LU) x=b\\Rightarrow L (Ux)=b\\Rightarrow \\begin {cases} Ly=b\\\\Ux=y\\end {cases}$\n\n所以 $x=U^{-1} y=U^{-1} L^{-1} b$\n\n### LU 矩阵的求法\n实际上 LU 矩阵有非常多的求法，这里列举一种比较简单的待定系数法\n\n设 $A = \\begin {bmatrix} 2&3&4\\\\1&1&9\\\\1&2&-6\\end {bmatrix}$，求矩阵 $A$ 的 LU 分解矩阵 $L$ 和 $U$\n\n**解**：令\n$$ L=\\begin{bmatrix}1&0&0\\\\l_1&1&0\\\\l_2&l_3&1\\end{bmatrix},U = \\begin{bmatrix}u_1&u_2&u_3\\\\0&u_4&u_5\\\\0&0&u_6\\end{bmatrix} $$\n\n由于 $A=LU$，所以有\n\n$$ \\begin{cases} u_1=2\\\\ u_2=3\\\\ u_3=4\\\\ l_1u_1=1\\\\ l_1u_2+u_4=1\\\\ l_1u_3+u_5=9\\\\ l_2u_1=1\\\\ l_2u_2+l_3u_4=2\\\\ l_2u_3+l_3u_5+u_6=-6 \\end{cases} $$\n\n上面的方程组非常容易解，最后求出\n\n$$ L = \\begin{bmatrix}1&0&0\\\\\\frac{1}{2}&1&0\\\\\\frac{1}{2}&-1&1\\end{bmatrix},U=\\begin{bmatrix}2&3&4\\\\0&-\\frac{1}{2}&7\\\\0&0&-1\\end{bmatrix} $$\n\n\n\n## 奇异值分解\n**奇异值**：设 $A \\in \\mathbb{C}^{m × n}_r,AA^H$ 的特征值为\n$$\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_n = 0$$\n\n则称 $\\sigma_i=\\sqrt{\\lambda_i}$ 为矩阵A的正奇异值。**$A$ 和$A^H$相同的奇异值**。\n\n**奇异值分解**：当给定一个大小为$m × n$的矩阵$A$,虽然矩阵$A$不一定是方阵，但大小为$m × m$的$AA^T$和$n × n$的$AA^T$是对称矩阵,若$AA^T=P \\Lambda_1 Q^T$,$A^T A=Q\\Lambda_2 Q^T$,则矩阵A的奇异值分解为\n$$A=P\\Sigma Q^T$$\n\n其中，矩阵$P=(\\overrightarrow{p_1}, \\overrightarrow{p_2}, \\dots, \\overrightarrow{p_m})$的大小为 $m × m$，列向量 $\\overrightarrow{p_1}, \\overrightarrow{p_2}, \\dots, \\overrightarrow{p_m}$是 $AA^T$的特征向量，也被称为矩阵$A$的左奇异向量（left singular vector）；矩阵$Q=(\\overrightarrow{q_1}, \\overrightarrow{q_2}, \\dots, \\overrightarrow{q_m})$的大小为 $n × n$，列向量 $\\overrightarrow{q_1}, \\overrightarrow{q_2}, \\dots, \\overrightarrow{q_m}$是 $A^TA$的特征向量，也被称为矩阵$A$的右奇异向量（left singular vector）；矩阵$\\Lambda_1$的大小为$m × m$，矩阵$\\Lambda_2$的大小为$n × n$，两个矩阵对角线上的非零元素相同（即矩阵$AA^T$和$A^TA$的非零特征值相同）；矩阵$\\Sigma$的大小为$m × n$，位于对角线上的元素被称为**奇异值**（singular value）。\n\n设$A$的秩为r，当 $m \\ne n$时，矩阵$\\Lambda_1$和$\\Lambda_2$的大小显然是不同的，但是他们对角线上的非零元素是相同的，记矩阵$\\Lambda_1$(或$\\Lambda_2$)对角线上的非零元素为$\\lambda_1,\\lambda_2,\\dots,\\lambda_r$，这些数皆为非负数，又记矩阵$\\Sigma$对角线上的非零元素分别为$\\sigma_1,\\sigma_2,\\dots,\\sigma_r$，则\n$$\\sigma_1=\\sqrt{\\lambda_1},\\sigma_2=\\sqrt{\\lambda_2},\\dots,\\sigma_r=\\sqrt{\\lambda_r}$$\n\n即非零奇异值的平方对应着矩阵$\\Lambda_1$（或矩阵$\\Lambda_2$）的非零特征值，到这里，我们就不难看出奇异值分解与对称对角化分解的关系了，即我们可以由对称对角化分解得到我们想要的奇异值分解。\n\n**例1**：一个$3×2$的矩阵$A=\\begin{bmatrix}\n    1&2 \\\\ 0&0 \\\\ 0&0\n\\end{bmatrix}$，求其奇异值分解。\n\n由\n$$AA^T=\\begin{bmatrix}\n    5&0&0 \\\\ 0&0&0 \\\\ 0&0&0\n\\end{bmatrix}$$\n\n得到其特征值$\\lambda_1=5,\\lambda_2=\\lambda_3=0$，特征向量为$\\overrightarrow{p_1}=(1,0,0)^T,\\overrightarrow{p_2}=(0,1,0)^T,\\overrightarrow{p_3}=(0,0,1)^T$\n\n由\n$$A^TA=\\begin{bmatrix}\n    1&2 \\\\ 2&4\n\\end{bmatrix}$$\n\n得到其特征值$\\lambda_1=5,\\lambda_2=0$，特征向量为$\\overrightarrow{q_1}=(\\frac{\\sqrt{5}}{5},\\frac{2\\sqrt{5}}{5})^T,\\overrightarrow{q_2}=(-\\frac{\\sqrt{5}}{5},\\frac{2\\sqrt{5}}{5})^T$\n\n令\n$$\\Sigma=\\begin{bmatrix}\n    \\sqrt{5}&0 \\\\ 0&0 \\\\ 0&0\n\\end{bmatrix}$$\n\n注意矩阵$\\Sigma$的大小为$3 × 2$，此时，矩阵$A$的奇异值分解为\n$$A=P\\Sigma Q^T=(\\overrightarrow{p_1}, \\overrightarrow{p_2}, \\overrightarrow{p_3})\\Sigma (\\overrightarrow{q_1}, \\overrightarrow{q_2})^T \\\\ =\\begin{bmatrix}\n    1&0&0 \\\\ 0&1&0 \\\\ 0&0&1\n\\end{bmatrix} \\begin{bmatrix}\n    \\sqrt{5}&0 \\\\ 0&0 \\\\ 0&0\n\\end{bmatrix} \\begin{bmatrix}\n    \\frac{\\sqrt{5}}{5}&\\frac{2\\sqrt{5}}{5} \\\\ \\frac{-2\\sqrt{5}}{5}&\\frac{\\sqrt{5}}{5}\n\\end{bmatrix} = \\begin{bmatrix}\n    1&2 \\\\ 0&0 \\\\ 0&0\n\\end{bmatrix}$$\n\n\n**例2**：求对称矩阵$A=\\begin{bmatrix}\n    2&1 \\\\ 1&2\n\\end{bmatrix}$的奇异值分解。\n\n经计算可以发现$A^TA=AA^T=\\begin{bmatrix}\n    2&1 \\\\ 1&2\n\\end{bmatrix} \n\\begin{bmatrix}\n    2&1 \\\\ 1&2\n\\end{bmatrix}=\\begin{bmatrix}\n    5&4 \\\\ 4&5\n\\end{bmatrix}$，左奇异向量和右奇异向量构成的矩阵也是相等的，即\n$$P=Q=\\begin{bmatrix}\n    \\frac{\\sqrt{2}}{2}&\\frac{\\sqrt{2}}{2} \\\\ -\\frac{\\sqrt{2}}{2}&\\frac{\\sqrt{2}}{2}\n\\end{bmatrix}$$\n\n则其奇异值分解为\n$$A=P\\Sigma Q^T=\\begin{bmatrix}\n    \\frac{\\sqrt{2}}{2}&\\frac{\\sqrt{2}}{2} \\\\ - \\frac{\\sqrt{2}}{2}& \\frac{\\sqrt{2}}{2}\n\\end{bmatrix}\n\\begin{bmatrix}\n    3&0 \\\\ 0&1\n\\end{bmatrix}\\begin{bmatrix}\n    \\frac{\\sqrt{2}}{2}&\\frac{\\sqrt{2}}{2} \\\\ -\\frac{\\sqrt{2}}{2}&\\frac{\\sqrt{2}}{2}\n\\end{bmatrix}$$\n\n**注**：这是由于当矩阵$A$为对称矩阵时，其可以被正交对角化，这时奇异值分解等于正交对角化分解。\n\n## 谱分解\n\n**谱分解**：设 $A \\in \\mathbb{C}^{n × n}$是单纯矩阵，则 $A$可以分解为一系列幂等矩阵 $A_i(i=1,2, \\dots,n)$的加权和\n$$A=\\sum_{i=1}^n \\lambda_i A_i$$\n\n其中 $\\lambda_i(i=1,2,\\dots,n)$是A的特征值。\n\n**单纯矩阵**：若矩阵 $A$的**代数重数**等于**几何重数**，则称$A$为单纯矩阵。**代数重数**为矩阵 $A$特征值的重数，**几何重数**为齐次方程组$Ax=\\lambda_i x(i=1,2,\\dots,k)$的解空间$V_{\\lambda_i}$的维数，也即特征值对应的最多无关特征向量数。\n\n**幂等矩阵**：若 $A$为方阵，且 $A^2=A$，则称$A$为幂等矩阵。所有幂等矩阵都相似与对角元全为0或1的对角阵。\n\n**更一般的单纯矩阵谱分解定理**：设 $A \\in \\mathbb{C}^{n × n}$，他有 $k$个相异特征值 $\\lambda_i(i=1,2,\\dots,k)$，则 $A$是单纯矩阵的充要条件是存在$k$个矩阵$A_i(i=1,2,\\dots,k)$满足\n\n\n1. $A_i A_j = \\begin{cases}\n    A_i, i=j \\\\ 0, i\\ne j\n\\end{cases}$\n2. $\\sum_{i=1}^k A_i = E_n$\n3. $A=\\sum_{i=1}^k \\lambda_i A_i$\n\n该定理比定理3要求放宽了，不再要求必须要有n个特征值了，这里的k可以小于等于n。\n\n\n**例1**：求正规矩阵 $A = \\begin{bmatrix}\n    0&1&1&1 \\\\ 1&0&-1&1 \\\\ 1&-1&0&1 \\\\ -1&1&1&0\n\\end{bmatrix}$的谱分解表达式。\n\n**解**：首先计算 $A$的特征值和特征向量\n$$|\\lambda_ I - A |=(\\lambda - 1)^3 (\\lambda + 3)$$\n\n从而 $A$的特征值为\n$$\\lambda_1=\\lambda_2=\\lambda_3=1,\\lambda_4=-3$$\n\n当$\\lambda=1$时，求得无关的特征向量为\n$$\\alpha_1=(1,1,0,0)^T \\\\ \\alpha_2=(1,0,1,0)^T \\\\ \\alpha_3=(-1,0,0,1)^T$$\n\n当$\\lambda=-3$时，求得无关的特征向量为\n$$\\alpha_4=(1,-1,-1,1)^T$$\n\n将 $\\alpha_1,\\alpha_2,\\alpha_3$正交化并单位化得\n$$\\eta_1=(\\frac{1}{\\sqrt{2}},\\frac{1}{\\sqrt{2}},0,0)^T \\\\ \n\\eta_2=(\\frac{1}{\\sqrt{6}},\\frac{1}{\\sqrt{6}},\\frac{2}{\\sqrt{6}},0)^T \\\\\n\\eta_3=(-\\frac{1}{2\\sqrt{3}},\\frac{1}{2\\sqrt{3}},\\frac{1}{\\sqrt{3}},\\frac{3}{2\\sqrt{3}})^T$$\n\n将$\\alpha_4$单位话得\n$$\\eta_4=(\\frac{1}{2}, -\\frac{1}{2},-\\frac{1}{2},\\frac{1}{2})$$\n\n故有\n$$G_1=\\eta_1 \\eta_1^H+\\eta_2 \\eta_2^H +\\eta_3 \\eta_3^H \\\\ \n= \\begin{bmatrix}\n    \\frac{3}{4}&\\frac{1}{4}&\\frac{1}{4}&-\\frac{1}{4} \\\\\n    \\frac{1}{4}&\\frac{3}{4}&-\\frac{1}{4}&\\frac{1}{4} \\\\\n    \\frac{1}{4}&-\\frac{1}{4}&\\frac{3}{4}&\\frac{1}{4} \\\\\n    -\\frac{1}{4}&\\frac{1}{4}&\\frac{1}{4}&\\frac{3}{4}    \n\\end{bmatrix}$$\n\n$$G_2=\\eta_4 \\eta_4^H \\\\\n=\\begin{bmatrix}\n    \\frac{1}{4}&-\\frac{1}{4}&-\\frac{1}{4}&\\frac{1}{4} \\\\\n    -\\frac{1}{4}&\\frac{1}{4}&\\frac{1}{4}&-\\frac{1}{4} \\\\\n    -\\frac{1}{4}&\\frac{1}{4}&\\frac{1}{4}&-\\frac{1}{4} \\\\\n    \\frac{1}{4}&-\\frac{1}{4}&-\\frac{1}{4}&\\frac{1}{4} \n\\end{bmatrix}$$\n\n这样其谱分解表达式为\n$$A=G_1 - 3G_2$$\n\n注意$G_1$和$G_2$的系数$\\lambda_i$为其对应的特征值。\n<!-- https://www.cnblogs.com/blairgrowing/p/15800825.html -->\n\n\n\n\n\n","source":"_posts/矩阵分解.md","raw":"---\ntitle: 矩阵分解\ncategories: \n    - 数学\n    - 矩阵论\ntags: 矩阵论\n---\n\n<!-- <link href=\"https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css\" rel=\"stylesheet\"> -->\n\n## 三角分解(QR分解)\n### 正交三角分解(通过Schmidt正交化)\n若 $n$ 阶实矩阵 $A\\in \\mathbb {C}^{n\\times n}$ 满秩，且 \n$$A = [\\alpha_1,...,\\alpha_n]$$\n\n其中 $\\alpha_1,...,\\alpha_n$ 是 $\\mathbb {C}^{n\\times n}$  中线性无关向量组\n\n**正交化**\n\n令\n\n$$ \\begin{aligned} \\beta_1&=\\alpha_1\\\\ \\beta_2&=\\alpha_2 - \\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1 \\\\ \\vdots \\\\ \\beta_n &= \\alpha_n - \\frac{\\left<\\beta_n,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1-\\cdots-\\frac{\\left<\\beta_{n-1},\\alpha_n\\right>}{\\left<\\beta_{n-1},\\alpha_{n-1}\\right>}\\beta_{n-1} \\end{aligned} $$\n\n变形得 \n\n$$ \\begin{aligned} \\alpha_1 &= \\beta_1\\\\ \\alpha_2 &= \\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1 + \\beta_2\\\\ \\vdots \\\\ \\alpha_n &= \\frac{\\left<\\beta_n,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1-\\cdots-\\frac{\\left<\\beta_{n-1},\\alpha_n\\right>}{\\left<\\beta_{n-1},\\alpha_{n-1}\\right>}\\beta_{n-1} + \\beta_n \\end{aligned} $$\n\n写成矩阵形式\n\n$$ \\begin{aligned} \\begin{bmatrix}\\alpha_1,\\alpha_2,...,\\alpha_n\\end{bmatrix} &= \\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix}\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &\\triangleq B\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix} \\end{aligned} $$\n\n**单位化**\n\n令 \n\n$$ q_1=\\frac{\\beta_1}{||\\beta_1||} \\\\ \\vdots \\\\ q_n = \\frac{\\beta_n}{||\\beta_n||} $$\n\n变形得 \n\n$$\\beta_1 = q_1||\\beta_1|| \\\\ \\vdots \\\\ \\beta_n = q_n ||\\beta_n|| $$\n\n写成矩阵形式 \n\n$$ \\begin{aligned} \\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix} &= \\begin{bmatrix}q_1,q_2,...,q_n\\end{bmatrix}\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\\\ &\\triangleq Q\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix} \\end{aligned} $$\n\n综上，结合正交化和单位化可得 \n\n$$ \\begin{aligned} A &= B\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &=Q\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &=Q\\begin{bmatrix}||\\beta_1||&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&||\\beta_2||&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\\\ &\\triangleq QR \\end{aligned} $$\n\n**QR 分解定理** : $A\\in \\mathbb {C}^{n\\times n}$ ,则存在酉矩阵 $Q$ 和正线上三角阵 $R$ ，使 $$A=QR$$\n\n且分解唯一\n\n**正交三角分解的求法**\n1. 取矩阵 $A=(A_1,A_2,...,A_n)$ 的列向量，进行 **Schmidt 标准正交化**,得 $v_1,v_2,...,v_n$ ，有 $$Q=(v_1,v_2,...,v_n)$$\n2. 再由 $R=Q^HA$ 得到 $R$ , 于是 $A=QR$\n\n\n\n### HouseHolder变换分解\n将矩阵A按列划分为 $(\\alpha_1,\\alpha_2,\\dots,\\alpha_n)$,以4阶方阵为例，\n\n第一步\n令\n$$\\omega_1=\\frac{\\alpha_1-a_1*e_1}{||\\alpha_1-a_1*e_1||_2}，a_1=||\\alpha_1||_2$$\n\n于是\n$$H_1A=(H_1\\alpha_1,H_1\\alpha_2，...，H_1\\alpha_n)\n=\\left\\{\\begin{matrix} a_1 & * & \\cdots & * \\\\\n                   0      & \\\\\n                   \\vdots & &B_1 \\\\\n0\\end{matrix}\\right\\}$$\n\n第二步\n\n从第一步中得到 $B_1=(\\beta_2,\\beta_2,\\cdots,\\beta_n)\\in R^{n-1}$\n\n取 $$\\omega_2=\\frac{\\beta_2-b_2*e_1}{||\\beta_2-b_2*e_1||_2}，b_1=||\\beta_2||_2$$\n\n则 $$\\widehat{H_2}=I-2*\\omega_2*\\omega_2^T,H_2=\\left\\{\\begin{matrix} 1 & 0^T \\\\ \n                                                              0 & \\widehat{H_2}，\n                                              \\end{matrix} \\right\\}$$\n\n得到\n$$H_2(H_1*A) = \\begin{bmatrix}   a_1 & * & * & \\cdots &* \\\\ \n                                       0 & a_2 & * & \\cdots &* \\\\\n                                       0 & 0 &  &\\\\\n                                       \\vdots & \\vdots &  &C_2& \\\\\n                                       0 & 0\n\\end{bmatrix} , C_2\\in R^{n-2}$$\n\n依次类推，进行第n步时，得到第n-1个 $H_{n-1}$阵,使得\n$$H_{n-1} \\cdots H_2H_1*A = \\begin{bmatrix}   a_1 & * & * & \\cdots & * \\\\ \n                                                   0 & a_2 & * & \\cdots & * \\\\\n                                                   0 & 0 & a_3 & \\cdots & *\\\\\n                                                  \\vdots & \\vdots & &\\ddots \\\\\n                                                    0 & 0 & 0 & \\cdots &a_n\n\\end{bmatrix}=R$$\n\n\n其中 $H_{n-1} \\cdots H_2H_1*A=H$也称为HouseHolder矩阵，也为自逆矩阵 $H=H^{-1}$\n\n$$H_{n-1} \\cdots H_2H_1*A=R$$\n$$\\Rightarrow (H_{n-1} \\cdots H_2*H_1)^{-1}*H_{n-1} \\cdots H_2H_1*A=(H_{n-1} \\cdots H_2*H_1)^{-1}*R$$\n$$\\Rightarrow A=H_1^{-1} \\cdots H_{n-1}^{-1}*R$$\n$$\\Rightarrow A=H_1\\cdots H_{n-1}*R$$\n\n得到 $A=QR$,其中 $Q$为正交矩阵， $R$为上三角矩阵\n$$\\begin{cases}\nQ = H_1\\cdots H_{n-1}\\\\\nR = Q^{-1}A=QA \n\\end{cases}$$\n\n### 三角分解的性质\n**定理1**:设 $A\\in \\mathbb {C}_r^{m\\times n}$，则 $A$ 可以唯一地分解为\n$$A=U_1 R$$\n\n其中 $U_1$是酉矩阵， $R$ 是正线上三角复矩阵，或 $A$ 可以唯一地分解为\n$$A=L U_2$$\n\n其中 $L$是正线下三角复矩阵， $U_2$是酉矩阵\n\n\n**推论1**：设 $A \\in \\mathbb {R}^{n × n}_n$,则 $A$可以唯一地分解为\n$$A=Q_1 R$$\n\n其中 $Q_1$是则正交矩阵，$R$是正线上三角实矩阵，或 $A$可以唯一地分解为\n$$A=L Q_2$$\n\n其中 $L$是正线下三角实矩阵， $Q_2$是正交矩阵。\n\n**推论2**：设A是实对称正定矩阵，则存在唯一正线上三角实矩阵 $R$，使得\n$$A=R^T R$$\n\n**推论3**：设 $A$是正定Hermite矩阵，则存在唯一正线上三角复矩阵$R$，使得\n$$A=R^H R$$\n\n\n## 矩阵的满秩分解\n设 $A\\in \\mathbb {C}_r^{m\\times n}$，则存在 $B\\in \\mathbb {C}_r^{m\\times r}, C\\in \\mathbb {C}_r^{r\\times n}$，满足\n$$ A = BC $$\n\n$\\mathbb {C}_r$ 表示矩阵的秩为 $r$\n\n实际上上述定理用文字描述就是，一个亏秩的矩阵可以分解成一个列满秩与行满秩矩阵的乘积\n\n证明：因为 $rank (A)=r$，所以一定可以找到与 $A$ 相似的一个矩阵\n\n$$ A \\simeq \\begin{bmatrix}E_r&0_{r\\times (n-r)}\\\\0_{(m-r)\\times r}&0_{(m-r)\\times (n-r)}\\end{bmatrix}=\\begin{bmatrix}E_r\\\\0_{(m-r)\\times r}\\end{bmatrix}\\begin{bmatrix}E_r&0_{r\\times (n-r)}\\end{bmatrix} $$\n\n因此存在两个可逆矩阵 $P,Q$，使 $PAQ=\\begin {bmatrix} E_r&0\\\\0&0\\end {bmatrix}$，则\n\n$$ \\begin{aligned} A &= P^{-1}\\begin{bmatrix}E_r\\\\0\\end{bmatrix}\\begin{bmatrix}E_r&0\\end{bmatrix}Q^{-1}\\\\ &\\triangleq BC \\end{aligned} $$\n\n因为 $P^{-1}$ 是可逆矩阵，$\\begin {bmatrix} E_r\\\\0\\end {bmatrix}$ 是一个列满秩矩阵，所以 $B=P^{-1}\\begin {bmatrix} E_r\\\\0\\end {bmatrix}$ 仍是一个列满秩矩阵；同理，$C=\\begin {bmatrix} E_r&0\\end {bmatrix} Q^{-1}$ 是一个行满秩矩阵\n\n### 矩阵满秩分解的计算\n如何在给定矩阵 $A$ 的情况下，求出矩阵 $B,C$ 呢？\n\n设\n\n$$ A = [\\alpha_1,\\alpha_2,...,\\alpha_n]\\\\ B = [\\beta_1,\\beta_2,...,\\beta_r]$$\n\n其中 $\\beta_1,...,\\beta_r$ 线性无关 \n\n所以 \n$$ \\begin{aligned} &A=BC\\\\ &\\Rightarrow[\\alpha_1,\\alpha_2,...,\\alpha_n]=[\\beta_1,...,\\beta_r]\\begin{bmatrix}c_{11}&\\cdots &c_{1n}\\\\\\vdots &\\ddots&\\vdots\\\\c_{r1}&\\cdots &c_{rn}\\end{bmatrix} \\end{aligned} $$\n\n实际上我们可以取 $\\beta_1,...,\\beta_r$ 为 $\\alpha_1,...,\\alpha_n$ 的一个极大线性无关组，因此 $B$ 就是矩阵 $A$ 列向量组的一个极大线性无关组，$C$ 就是用该线性无关组去表示 $A$ 时的系数\n\n#### 例 1\n\n求矩阵 $A=\\begin {bmatrix} 1&4&-1&5&6\\\\2&0&0&0&-14\\\\-1&2&-4&0&1\\\\2&6&-5&5&-7\\end {bmatrix}$ 的满秩分解\n\n**解**：对矩阵 $A$ 只作初等行变换\n$$ A=\\begin{bmatrix}1&4&-1&5&6\\\\2&0&0&0&-14\\\\-1&2&-4&0&1\\\\2&6&-5&5&-7\\end{bmatrix}\\to ···\\to\\begin{bmatrix}1&0&0&0&-7\\\\0&1&0&\\frac{10}{7}&\\frac{29}{7}\\\\0&0&1&\\frac{5}{7}&\\frac{25}{7}\\\\0&0&0&0&0\\end{bmatrix} $$\n\n$A$ 的秩为 3，且前三个列向量线性无关，故\n$$ B = \\begin{bmatrix}1&4&-1\\\\2&0&0\\\\-1&2&-4\\\\2&6&-5\\end{bmatrix}，C=\\begin{bmatrix}1&0&0&0&-7\\\\0&1&0&\\frac{10}{7}&\\frac{29}{7}\\\\0&0&1&\\frac{5}{7}&\\frac{25}{7}\\end{bmatrix} $$\n\n#### 例 2\n求矩阵 $A=\\begin {bmatrix} 2&1&-2&3&1\\\\2&5&-1&4&1\\\\1&3&-1&2&1\\end {bmatrix}$ 的满秩分解\n\n**解**：对矩阵 $A$ 只作初等行变换\n\n$$ A=\\begin{bmatrix}2&1&-2&3&1\\\\2&5&-1&4&1\\\\1&3&-1&2&1\\end{bmatrix}\\to ···\\to \\begin{bmatrix}1&0&0&\\frac{8}{5}&-\\frac{2}{5}\\\\0&1&0&\\frac{1}{5}&\\frac{1}{5}\\\\0&0&1&\\frac{1}{5}&-\\frac{4}{5}\\end{bmatrix} $$\n\n$A$ 的秩为 3，且前三个列向量线性无关，故\n$$ B = \\begin{bmatrix}2&1&-2\\\\2&5&-1\\\\1&3&-1\\end{bmatrix},C = \\begin{bmatrix}1&0&0&\\frac{8}{5}&-\\frac{2}{5}\\\\0&1&0&\\frac{1}{5}&\\frac{1}{5}\\\\0&0&1&\\frac{1}{5}&-\\frac{4}{5}\\end{bmatrix} $$\n\n## 矩阵的LU分解\nLU 分解（LU Decomposition）是矩阵分解的一种，可以将一个矩阵分解为一个单位下三角矩阵和一个上三角矩阵的乘积，以四阶矩阵为例\n$$ L = \\begin{bmatrix}1&0&0&0 \\\\ *&1&0&0\\\\ *&*&1&0\\\\ *&*&*&1\\end{bmatrix}, U=\\begin{bmatrix}*&*&*&*\\\\0&*&*&*\\\\0&0&*&*\\\\0&0&0&*\\end{bmatrix} $$\n\nLU 矩阵是否一定存在？答案是否，具体看下面的例子\n\n设 $\\begin {bmatrix} 0&1 \\\\1&0\\end {bmatrix}=\\begin {bmatrix} a&0\\\\b&c\\end {bmatrix}\\begin {bmatrix} l&m\\\\0&n\\end {bmatrix}$，则应该满足如下 4 个式子\n\n$$ \\begin{cases} al=0\\\\ am=1\\\\ bl=1\\\\ bm+cn=0 \\end{cases} $$\n\n由 $al=0$ 得 $a=0$ 或 $l=0$，但实际上这两种情况带入上面的式子都会推出矛盾，因此不是所有情况 LU 分解都存在\n\n**LU 分解定理** ：设 $A\\in \\mathbb {C}_n^{n\\times n}$，$A$ 有唯一的 LU 分解 $\\Leftrightarrow A$ 的各阶顺序主子式 $\\Delta k \\neq 0,\\ k=1,2...,n$\n\n$k$ 阶顺序主子式指的是矩阵左上角 $k\\times k$ 个元素组成的行列式\n\n将矩阵 $A$ 分解为 $L$ 和 $U$ 之后，解方程组 $Ax=b$ 就变得简单了，因为 $A=LU$，所以 $(LU) x=b\\Rightarrow L (Ux)=b\\Rightarrow \\begin {cases} Ly=b\\\\Ux=y\\end {cases}$\n\n所以 $x=U^{-1} y=U^{-1} L^{-1} b$\n\n### LU 矩阵的求法\n实际上 LU 矩阵有非常多的求法，这里列举一种比较简单的待定系数法\n\n设 $A = \\begin {bmatrix} 2&3&4\\\\1&1&9\\\\1&2&-6\\end {bmatrix}$，求矩阵 $A$ 的 LU 分解矩阵 $L$ 和 $U$\n\n**解**：令\n$$ L=\\begin{bmatrix}1&0&0\\\\l_1&1&0\\\\l_2&l_3&1\\end{bmatrix},U = \\begin{bmatrix}u_1&u_2&u_3\\\\0&u_4&u_5\\\\0&0&u_6\\end{bmatrix} $$\n\n由于 $A=LU$，所以有\n\n$$ \\begin{cases} u_1=2\\\\ u_2=3\\\\ u_3=4\\\\ l_1u_1=1\\\\ l_1u_2+u_4=1\\\\ l_1u_3+u_5=9\\\\ l_2u_1=1\\\\ l_2u_2+l_3u_4=2\\\\ l_2u_3+l_3u_5+u_6=-6 \\end{cases} $$\n\n上面的方程组非常容易解，最后求出\n\n$$ L = \\begin{bmatrix}1&0&0\\\\\\frac{1}{2}&1&0\\\\\\frac{1}{2}&-1&1\\end{bmatrix},U=\\begin{bmatrix}2&3&4\\\\0&-\\frac{1}{2}&7\\\\0&0&-1\\end{bmatrix} $$\n\n\n\n## 奇异值分解\n**奇异值**：设 $A \\in \\mathbb{C}^{m × n}_r,AA^H$ 的特征值为\n$$\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_n = 0$$\n\n则称 $\\sigma_i=\\sqrt{\\lambda_i}$ 为矩阵A的正奇异值。**$A$ 和$A^H$相同的奇异值**。\n\n**奇异值分解**：当给定一个大小为$m × n$的矩阵$A$,虽然矩阵$A$不一定是方阵，但大小为$m × m$的$AA^T$和$n × n$的$AA^T$是对称矩阵,若$AA^T=P \\Lambda_1 Q^T$,$A^T A=Q\\Lambda_2 Q^T$,则矩阵A的奇异值分解为\n$$A=P\\Sigma Q^T$$\n\n其中，矩阵$P=(\\overrightarrow{p_1}, \\overrightarrow{p_2}, \\dots, \\overrightarrow{p_m})$的大小为 $m × m$，列向量 $\\overrightarrow{p_1}, \\overrightarrow{p_2}, \\dots, \\overrightarrow{p_m}$是 $AA^T$的特征向量，也被称为矩阵$A$的左奇异向量（left singular vector）；矩阵$Q=(\\overrightarrow{q_1}, \\overrightarrow{q_2}, \\dots, \\overrightarrow{q_m})$的大小为 $n × n$，列向量 $\\overrightarrow{q_1}, \\overrightarrow{q_2}, \\dots, \\overrightarrow{q_m}$是 $A^TA$的特征向量，也被称为矩阵$A$的右奇异向量（left singular vector）；矩阵$\\Lambda_1$的大小为$m × m$，矩阵$\\Lambda_2$的大小为$n × n$，两个矩阵对角线上的非零元素相同（即矩阵$AA^T$和$A^TA$的非零特征值相同）；矩阵$\\Sigma$的大小为$m × n$，位于对角线上的元素被称为**奇异值**（singular value）。\n\n设$A$的秩为r，当 $m \\ne n$时，矩阵$\\Lambda_1$和$\\Lambda_2$的大小显然是不同的，但是他们对角线上的非零元素是相同的，记矩阵$\\Lambda_1$(或$\\Lambda_2$)对角线上的非零元素为$\\lambda_1,\\lambda_2,\\dots,\\lambda_r$，这些数皆为非负数，又记矩阵$\\Sigma$对角线上的非零元素分别为$\\sigma_1,\\sigma_2,\\dots,\\sigma_r$，则\n$$\\sigma_1=\\sqrt{\\lambda_1},\\sigma_2=\\sqrt{\\lambda_2},\\dots,\\sigma_r=\\sqrt{\\lambda_r}$$\n\n即非零奇异值的平方对应着矩阵$\\Lambda_1$（或矩阵$\\Lambda_2$）的非零特征值，到这里，我们就不难看出奇异值分解与对称对角化分解的关系了，即我们可以由对称对角化分解得到我们想要的奇异值分解。\n\n**例1**：一个$3×2$的矩阵$A=\\begin{bmatrix}\n    1&2 \\\\ 0&0 \\\\ 0&0\n\\end{bmatrix}$，求其奇异值分解。\n\n由\n$$AA^T=\\begin{bmatrix}\n    5&0&0 \\\\ 0&0&0 \\\\ 0&0&0\n\\end{bmatrix}$$\n\n得到其特征值$\\lambda_1=5,\\lambda_2=\\lambda_3=0$，特征向量为$\\overrightarrow{p_1}=(1,0,0)^T,\\overrightarrow{p_2}=(0,1,0)^T,\\overrightarrow{p_3}=(0,0,1)^T$\n\n由\n$$A^TA=\\begin{bmatrix}\n    1&2 \\\\ 2&4\n\\end{bmatrix}$$\n\n得到其特征值$\\lambda_1=5,\\lambda_2=0$，特征向量为$\\overrightarrow{q_1}=(\\frac{\\sqrt{5}}{5},\\frac{2\\sqrt{5}}{5})^T,\\overrightarrow{q_2}=(-\\frac{\\sqrt{5}}{5},\\frac{2\\sqrt{5}}{5})^T$\n\n令\n$$\\Sigma=\\begin{bmatrix}\n    \\sqrt{5}&0 \\\\ 0&0 \\\\ 0&0\n\\end{bmatrix}$$\n\n注意矩阵$\\Sigma$的大小为$3 × 2$，此时，矩阵$A$的奇异值分解为\n$$A=P\\Sigma Q^T=(\\overrightarrow{p_1}, \\overrightarrow{p_2}, \\overrightarrow{p_3})\\Sigma (\\overrightarrow{q_1}, \\overrightarrow{q_2})^T \\\\ =\\begin{bmatrix}\n    1&0&0 \\\\ 0&1&0 \\\\ 0&0&1\n\\end{bmatrix} \\begin{bmatrix}\n    \\sqrt{5}&0 \\\\ 0&0 \\\\ 0&0\n\\end{bmatrix} \\begin{bmatrix}\n    \\frac{\\sqrt{5}}{5}&\\frac{2\\sqrt{5}}{5} \\\\ \\frac{-2\\sqrt{5}}{5}&\\frac{\\sqrt{5}}{5}\n\\end{bmatrix} = \\begin{bmatrix}\n    1&2 \\\\ 0&0 \\\\ 0&0\n\\end{bmatrix}$$\n\n\n**例2**：求对称矩阵$A=\\begin{bmatrix}\n    2&1 \\\\ 1&2\n\\end{bmatrix}$的奇异值分解。\n\n经计算可以发现$A^TA=AA^T=\\begin{bmatrix}\n    2&1 \\\\ 1&2\n\\end{bmatrix} \n\\begin{bmatrix}\n    2&1 \\\\ 1&2\n\\end{bmatrix}=\\begin{bmatrix}\n    5&4 \\\\ 4&5\n\\end{bmatrix}$，左奇异向量和右奇异向量构成的矩阵也是相等的，即\n$$P=Q=\\begin{bmatrix}\n    \\frac{\\sqrt{2}}{2}&\\frac{\\sqrt{2}}{2} \\\\ -\\frac{\\sqrt{2}}{2}&\\frac{\\sqrt{2}}{2}\n\\end{bmatrix}$$\n\n则其奇异值分解为\n$$A=P\\Sigma Q^T=\\begin{bmatrix}\n    \\frac{\\sqrt{2}}{2}&\\frac{\\sqrt{2}}{2} \\\\ - \\frac{\\sqrt{2}}{2}& \\frac{\\sqrt{2}}{2}\n\\end{bmatrix}\n\\begin{bmatrix}\n    3&0 \\\\ 0&1\n\\end{bmatrix}\\begin{bmatrix}\n    \\frac{\\sqrt{2}}{2}&\\frac{\\sqrt{2}}{2} \\\\ -\\frac{\\sqrt{2}}{2}&\\frac{\\sqrt{2}}{2}\n\\end{bmatrix}$$\n\n**注**：这是由于当矩阵$A$为对称矩阵时，其可以被正交对角化，这时奇异值分解等于正交对角化分解。\n\n## 谱分解\n\n**谱分解**：设 $A \\in \\mathbb{C}^{n × n}$是单纯矩阵，则 $A$可以分解为一系列幂等矩阵 $A_i(i=1,2, \\dots,n)$的加权和\n$$A=\\sum_{i=1}^n \\lambda_i A_i$$\n\n其中 $\\lambda_i(i=1,2,\\dots,n)$是A的特征值。\n\n**单纯矩阵**：若矩阵 $A$的**代数重数**等于**几何重数**，则称$A$为单纯矩阵。**代数重数**为矩阵 $A$特征值的重数，**几何重数**为齐次方程组$Ax=\\lambda_i x(i=1,2,\\dots,k)$的解空间$V_{\\lambda_i}$的维数，也即特征值对应的最多无关特征向量数。\n\n**幂等矩阵**：若 $A$为方阵，且 $A^2=A$，则称$A$为幂等矩阵。所有幂等矩阵都相似与对角元全为0或1的对角阵。\n\n**更一般的单纯矩阵谱分解定理**：设 $A \\in \\mathbb{C}^{n × n}$，他有 $k$个相异特征值 $\\lambda_i(i=1,2,\\dots,k)$，则 $A$是单纯矩阵的充要条件是存在$k$个矩阵$A_i(i=1,2,\\dots,k)$满足\n\n\n1. $A_i A_j = \\begin{cases}\n    A_i, i=j \\\\ 0, i\\ne j\n\\end{cases}$\n2. $\\sum_{i=1}^k A_i = E_n$\n3. $A=\\sum_{i=1}^k \\lambda_i A_i$\n\n该定理比定理3要求放宽了，不再要求必须要有n个特征值了，这里的k可以小于等于n。\n\n\n**例1**：求正规矩阵 $A = \\begin{bmatrix}\n    0&1&1&1 \\\\ 1&0&-1&1 \\\\ 1&-1&0&1 \\\\ -1&1&1&0\n\\end{bmatrix}$的谱分解表达式。\n\n**解**：首先计算 $A$的特征值和特征向量\n$$|\\lambda_ I - A |=(\\lambda - 1)^3 (\\lambda + 3)$$\n\n从而 $A$的特征值为\n$$\\lambda_1=\\lambda_2=\\lambda_3=1,\\lambda_4=-3$$\n\n当$\\lambda=1$时，求得无关的特征向量为\n$$\\alpha_1=(1,1,0,0)^T \\\\ \\alpha_2=(1,0,1,0)^T \\\\ \\alpha_3=(-1,0,0,1)^T$$\n\n当$\\lambda=-3$时，求得无关的特征向量为\n$$\\alpha_4=(1,-1,-1,1)^T$$\n\n将 $\\alpha_1,\\alpha_2,\\alpha_3$正交化并单位化得\n$$\\eta_1=(\\frac{1}{\\sqrt{2}},\\frac{1}{\\sqrt{2}},0,0)^T \\\\ \n\\eta_2=(\\frac{1}{\\sqrt{6}},\\frac{1}{\\sqrt{6}},\\frac{2}{\\sqrt{6}},0)^T \\\\\n\\eta_3=(-\\frac{1}{2\\sqrt{3}},\\frac{1}{2\\sqrt{3}},\\frac{1}{\\sqrt{3}},\\frac{3}{2\\sqrt{3}})^T$$\n\n将$\\alpha_4$单位话得\n$$\\eta_4=(\\frac{1}{2}, -\\frac{1}{2},-\\frac{1}{2},\\frac{1}{2})$$\n\n故有\n$$G_1=\\eta_1 \\eta_1^H+\\eta_2 \\eta_2^H +\\eta_3 \\eta_3^H \\\\ \n= \\begin{bmatrix}\n    \\frac{3}{4}&\\frac{1}{4}&\\frac{1}{4}&-\\frac{1}{4} \\\\\n    \\frac{1}{4}&\\frac{3}{4}&-\\frac{1}{4}&\\frac{1}{4} \\\\\n    \\frac{1}{4}&-\\frac{1}{4}&\\frac{3}{4}&\\frac{1}{4} \\\\\n    -\\frac{1}{4}&\\frac{1}{4}&\\frac{1}{4}&\\frac{3}{4}    \n\\end{bmatrix}$$\n\n$$G_2=\\eta_4 \\eta_4^H \\\\\n=\\begin{bmatrix}\n    \\frac{1}{4}&-\\frac{1}{4}&-\\frac{1}{4}&\\frac{1}{4} \\\\\n    -\\frac{1}{4}&\\frac{1}{4}&\\frac{1}{4}&-\\frac{1}{4} \\\\\n    -\\frac{1}{4}&\\frac{1}{4}&\\frac{1}{4}&-\\frac{1}{4} \\\\\n    \\frac{1}{4}&-\\frac{1}{4}&-\\frac{1}{4}&\\frac{1}{4} \n\\end{bmatrix}$$\n\n这样其谱分解表达式为\n$$A=G_1 - 3G_2$$\n\n注意$G_1$和$G_2$的系数$\\lambda_i$为其对应的特征值。\n<!-- https://www.cnblogs.com/blairgrowing/p/15800825.html -->\n\n\n\n\n\n","slug":"矩阵分解","published":1,"date":"2022-12-03T13:15:58.658Z","updated":"2022-12-06T15:52:58.786Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8od000jr4sg411me7kn","content":"<!-- <link href=\"https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css\" rel=\"stylesheet\"> -->\r\n<h2 id=\"三角分解qr分解\">三角分解(QR分解)</h2>\r\n<h3\r\nid=\"正交三角分解通过schmidt正交化\">正交三角分解(通过Schmidt正交化)</h3>\r\n<p>若 <span class=\"math inline\">\\(n\\)</span> 阶实矩阵 <span\r\nclass=\"math inline\">\\(A\\in \\mathbb {C}^{n\\times n}\\)</span> 满秩，且\r\n<span class=\"math display\">\\[A = [\\alpha_1,...,\\alpha_n]\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(\\alpha_1,...,\\alpha_n\\)</span> 是\r\n<span class=\"math inline\">\\(\\mathbb {C}^{n\\times n}\\)</span>\r\n中线性无关向量组</p>\r\n<p><strong>正交化</strong></p>\r\n<p>令</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} \\beta_1&amp;=\\alpha_1\\\\\r\n\\beta_2&amp;=\\alpha_2 -\r\n\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1\r\n\\\\ \\vdots \\\\ \\beta_n &amp;= \\alpha_n -\r\n\\frac{\\left&lt;\\beta_n,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1-\\cdots-\\frac{\\left&lt;\\beta_{n-1},\\alpha_n\\right&gt;}{\\left&lt;\\beta_{n-1},\\alpha_{n-1}\\right&gt;}\\beta_{n-1}\r\n\\end{aligned} \\]</span></p>\r\n<p>变形得</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} \\alpha_1 &amp;=\r\n\\beta_1\\\\ \\alpha_2 &amp;=\r\n\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1\r\n+ \\beta_2\\\\ \\vdots \\\\ \\alpha_n &amp;=\r\n\\frac{\\left&lt;\\beta_n,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1-\\cdots-\\frac{\\left&lt;\\beta_{n-1},\\alpha_n\\right&gt;}{\\left&lt;\\beta_{n-1},\\alpha_{n-1}\\right&gt;}\\beta_{n-1}\r\n+ \\beta_n \\end{aligned} \\]</span></p>\r\n<p>写成矩阵形式</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned}\r\n\\begin{bmatrix}\\alpha_1,\\alpha_2,...,\\alpha_n\\end{bmatrix} &amp;=\r\n\\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix}\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;\\triangleq\r\nB\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix} \\end{aligned}\r\n\\]</span></p>\r\n<p><strong>单位化</strong></p>\r\n<p>令</p>\r\n<p><span class=\"math display\">\\[ q_1=\\frac{\\beta_1}{||\\beta_1||} \\\\\r\n\\vdots \\\\ q_n = \\frac{\\beta_n}{||\\beta_n||} \\]</span></p>\r\n<p>变形得</p>\r\n<p><span class=\"math display\">\\[\\beta_1 = q_1||\\beta_1|| \\\\ \\vdots \\\\\r\n\\beta_n = q_n ||\\beta_n|| \\]</span></p>\r\n<p>写成矩阵形式</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned}\r\n\\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix} &amp;=\r\n\\begin{bmatrix}q_1,q_2,...,q_n\\end{bmatrix}\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\\\\\r\n&amp;\\triangleq Q\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\r\n\\end{aligned} \\]</span></p>\r\n<p>综上，结合正交化和单位化可得</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} A &amp;=\r\nB\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;=Q\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp;\r\n||\\beta_n||\\end{bmatrix}\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;=Q\\begin{bmatrix}||\\beta_1||&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\\\\\r\n&amp;\\triangleq QR \\end{aligned} \\]</span></p>\r\n<p><strong>QR 分解定理</strong> : <span class=\"math inline\">\\(A\\in\r\n\\mathbb {C}^{n\\times n}\\)</span> ,则存在酉矩阵 <span\r\nclass=\"math inline\">\\(Q\\)</span> 和正线上三角阵 <span\r\nclass=\"math inline\">\\(R\\)</span> ，使 <span\r\nclass=\"math display\">\\[A=QR\\]</span></p>\r\n<p>且分解唯一</p>\r\n<p><strong>正交三角分解的求法</strong> 1. 取矩阵 <span\r\nclass=\"math inline\">\\(A=(A_1,A_2,...,A_n)\\)</span> 的列向量，进行\r\n<strong>Schmidt 标准正交化</strong>,得 <span\r\nclass=\"math inline\">\\(v_1,v_2,...,v_n\\)</span> ，有 <span\r\nclass=\"math display\">\\[Q=(v_1,v_2,...,v_n)\\]</span> 2. 再由 <span\r\nclass=\"math inline\">\\(R=Q^HA\\)</span> 得到 <span\r\nclass=\"math inline\">\\(R\\)</span> , 于是 <span\r\nclass=\"math inline\">\\(A=QR\\)</span></p>\r\n<h3 id=\"householder变换分解\">HouseHolder变换分解</h3>\r\n<p>将矩阵A按列划分为 <span\r\nclass=\"math inline\">\\((\\alpha_1,\\alpha_2,\\dots,\\alpha_n)\\)</span>,以4阶方阵为例，</p>\r\n<p>第一步 令 <span\r\nclass=\"math display\">\\[\\omega_1=\\frac{\\alpha_1-a_1*e_1}{||\\alpha_1-a_1*e_1||_2}，a_1=||\\alpha_1||_2\\]</span></p>\r\n<p>于是 <span\r\nclass=\"math display\">\\[H_1A=(H_1\\alpha_1,H_1\\alpha_2，...，H_1\\alpha_n)\r\n=\\left\\{\\begin{matrix} a_1 &amp; * &amp; \\cdots &amp; * \\\\\r\n                   0      &amp; \\\\\r\n                   \\vdots &amp; &amp;B_1 \\\\\r\n0\\end{matrix}\\right\\}\\]</span></p>\r\n<p>第二步</p>\r\n<p>从第一步中得到 <span\r\nclass=\"math inline\">\\(B_1=(\\beta_2,\\beta_2,\\cdots,\\beta_n)\\in\r\nR^{n-1}\\)</span></p>\r\n<p>取 <span\r\nclass=\"math display\">\\[\\omega_2=\\frac{\\beta_2-b_2*e_1}{||\\beta_2-b_2*e_1||_2}，b_1=||\\beta_2||_2\\]</span></p>\r\n<p>则 <span\r\nclass=\"math display\">\\[\\widehat{H_2}=I-2*\\omega_2*\\omega_2^T,H_2=\\left\\{\\begin{matrix}\r\n1 &amp; 0^T \\\\\r\n                                                              0 &amp;\r\n\\widehat{H_2}，\r\n                                              \\end{matrix}\r\n\\right\\}\\]</span></p>\r\n<p>得到 <span class=\"math display\">\\[H_2(H_1*A) = \\begin{bmatrix}   a_1\r\n&amp; * &amp; * &amp; \\cdots &amp;* \\\\\r\n                                       0 &amp; a_2 &amp; * &amp; \\cdots\r\n&amp;* \\\\\r\n                                       0 &amp; 0 &amp;  &amp;\\\\\r\n                                       \\vdots &amp; \\vdots\r\n&amp;  &amp;C_2&amp; \\\\\r\n                                       0 &amp; 0\r\n\\end{bmatrix} , C_2\\in R^{n-2}\\]</span></p>\r\n<p>依次类推，进行第n步时，得到第n-1个 <span\r\nclass=\"math inline\">\\(H_{n-1}\\)</span>阵,使得 <span\r\nclass=\"math display\">\\[H_{n-1} \\cdots H_2H_1*A = \\begin{bmatrix}   a_1\r\n&amp; * &amp; * &amp; \\cdots &amp; * \\\\\r\n                                                   0 &amp; a_2 &amp; *\r\n&amp; \\cdots &amp; * \\\\\r\n                                                   0 &amp; 0 &amp; a_3\r\n&amp; \\cdots &amp; *\\\\\r\n                                                  \\vdots &amp; \\vdots\r\n&amp; &amp;\\ddots \\\\\r\n                                                    0 &amp; 0 &amp; 0\r\n&amp; \\cdots &amp;a_n\r\n\\end{bmatrix}=R\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(H_{n-1} \\cdots\r\nH_2H_1*A=H\\)</span>也称为HouseHolder矩阵，也为自逆矩阵 <span\r\nclass=\"math inline\">\\(H=H^{-1}\\)</span></p>\r\n<p><span class=\"math display\">\\[H_{n-1} \\cdots H_2H_1*A=R\\]</span> <span\r\nclass=\"math display\">\\[\\Rightarrow (H_{n-1} \\cdots H_2*H_1)^{-1}*H_{n-1}\r\n\\cdots H_2H_1*A=(H_{n-1} \\cdots H_2*H_1)^{-1}*R\\]</span> <span\r\nclass=\"math display\">\\[\\Rightarrow A=H_1^{-1} \\cdots\r\nH_{n-1}^{-1}*R\\]</span> <span class=\"math display\">\\[\\Rightarrow\r\nA=H_1\\cdots H_{n-1}*R\\]</span></p>\r\n<p>得到 <span class=\"math inline\">\\(A=QR\\)</span>,其中 <span\r\nclass=\"math inline\">\\(Q\\)</span>为正交矩阵， <span\r\nclass=\"math inline\">\\(R\\)</span>为上三角矩阵 <span\r\nclass=\"math display\">\\[\\begin{cases}\r\nQ = H_1\\cdots H_{n-1}\\\\\r\nR = Q^{-1}A=QA\r\n\\end{cases}\\]</span></p>\r\n<h3 id=\"三角分解的性质\">三角分解的性质</h3>\r\n<p><strong>定理1</strong>:设 <span class=\"math inline\">\\(A\\in \\mathbb\r\n{C}_r^{m\\times n}\\)</span>，则 <span class=\"math inline\">\\(A\\)</span>\r\n可以唯一地分解为 <span class=\"math display\">\\[A=U_1 R\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(U_1\\)</span>是酉矩阵， <span\r\nclass=\"math inline\">\\(R\\)</span> 是正线上三角复矩阵，或 <span\r\nclass=\"math inline\">\\(A\\)</span> 可以唯一地分解为 <span\r\nclass=\"math display\">\\[A=L U_2\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(L\\)</span>是正线下三角复矩阵， <span\r\nclass=\"math inline\">\\(U_2\\)</span>是酉矩阵</p>\r\n<p><strong>推论1</strong>：设 <span class=\"math inline\">\\(A \\in \\mathbb\r\n{R}^{n × n}_n\\)</span>,则 <span\r\nclass=\"math inline\">\\(A\\)</span>可以唯一地分解为 <span\r\nclass=\"math display\">\\[A=Q_1 R\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(Q_1\\)</span>是则正交矩阵，<span\r\nclass=\"math inline\">\\(R\\)</span>是正线上三角实矩阵，或 <span\r\nclass=\"math inline\">\\(A\\)</span>可以唯一地分解为 <span\r\nclass=\"math display\">\\[A=L Q_2\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(L\\)</span>是正线下三角实矩阵， <span\r\nclass=\"math inline\">\\(Q_2\\)</span>是正交矩阵。</p>\r\n<p><strong>推论2</strong>：设A是实对称正定矩阵，则存在唯一正线上三角实矩阵\r\n<span class=\"math inline\">\\(R\\)</span>，使得 <span\r\nclass=\"math display\">\\[A=R^T R\\]</span></p>\r\n<p><strong>推论3</strong>：设 <span\r\nclass=\"math inline\">\\(A\\)</span>是正定Hermite矩阵，则存在唯一正线上三角复矩阵<span\r\nclass=\"math inline\">\\(R\\)</span>，使得 <span\r\nclass=\"math display\">\\[A=R^H R\\]</span></p>\r\n<h2 id=\"矩阵的满秩分解\">矩阵的满秩分解</h2>\r\n<p>设 <span class=\"math inline\">\\(A\\in \\mathbb {C}_r^{m\\times\r\nn}\\)</span>，则存在 <span class=\"math inline\">\\(B\\in \\mathbb\r\n{C}_r^{m\\times r}, C\\in \\mathbb {C}_r^{r\\times n}\\)</span>，满足 <span\r\nclass=\"math display\">\\[ A = BC \\]</span></p>\r\n<p><span class=\"math inline\">\\(\\mathbb {C}_r\\)</span> 表示矩阵的秩为\r\n<span class=\"math inline\">\\(r\\)</span></p>\r\n<p>实际上上述定理用文字描述就是，一个亏秩的矩阵可以分解成一个列满秩与行满秩矩阵的乘积</p>\r\n<p>证明：因为 <span class=\"math inline\">\\(rank\r\n(A)=r\\)</span>，所以一定可以找到与 <span\r\nclass=\"math inline\">\\(A\\)</span> 相似的一个矩阵</p>\r\n<p><span class=\"math display\">\\[ A \\simeq\r\n\\begin{bmatrix}E_r&amp;0_{r\\times (n-r)}\\\\0_{(m-r)\\times\r\nr}&amp;0_{(m-r)\\times\r\n(n-r)}\\end{bmatrix}=\\begin{bmatrix}E_r\\\\0_{(m-r)\\times\r\nr}\\end{bmatrix}\\begin{bmatrix}E_r&amp;0_{r\\times (n-r)}\\end{bmatrix}\r\n\\]</span></p>\r\n<p>因此存在两个可逆矩阵 <span class=\"math inline\">\\(P,Q\\)</span>，使\r\n<span class=\"math inline\">\\(PAQ=\\begin {bmatrix} E_r&amp;0\\\\0&amp;0\\end\r\n{bmatrix}\\)</span>，则</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} A &amp;=\r\nP^{-1}\\begin{bmatrix}E_r\\\\0\\end{bmatrix}\\begin{bmatrix}E_r&amp;0\\end{bmatrix}Q^{-1}\\\\\r\n&amp;\\triangleq BC \\end{aligned} \\]</span></p>\r\n<p>因为 <span class=\"math inline\">\\(P^{-1}\\)</span> 是可逆矩阵，<span\r\nclass=\"math inline\">\\(\\begin {bmatrix} E_r\\\\0\\end {bmatrix}\\)</span>\r\n是一个列满秩矩阵，所以 <span class=\"math inline\">\\(B=P^{-1}\\begin\r\n{bmatrix} E_r\\\\0\\end {bmatrix}\\)</span> 仍是一个列满秩矩阵；同理，<span\r\nclass=\"math inline\">\\(C=\\begin {bmatrix} E_r&amp;0\\end {bmatrix}\r\nQ^{-1}\\)</span> 是一个行满秩矩阵</p>\r\n<h3 id=\"矩阵满秩分解的计算\">矩阵满秩分解的计算</h3>\r\n<p>如何在给定矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n的情况下，求出矩阵 <span class=\"math inline\">\\(B,C\\)</span> 呢？</p>\r\n<p>设</p>\r\n<p><span class=\"math display\">\\[ A = [\\alpha_1,\\alpha_2,...,\\alpha_n]\\\\\r\nB = [\\beta_1,\\beta_2,...,\\beta_r]\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(\\beta_1,...,\\beta_r\\)</span>\r\n线性无关</p>\r\n<p>所以 <span class=\"math display\">\\[ \\begin{aligned} &amp;A=BC\\\\\r\n&amp;\\Rightarrow[\\alpha_1,\\alpha_2,...,\\alpha_n]=[\\beta_1,...,\\beta_r]\\begin{bmatrix}c_{11}&amp;\\cdots\r\n&amp;c_{1n}\\\\\\vdots &amp;\\ddots&amp;\\vdots\\\\c_{r1}&amp;\\cdots\r\n&amp;c_{rn}\\end{bmatrix} \\end{aligned} \\]</span></p>\r\n<p>实际上我们可以取 <span\r\nclass=\"math inline\">\\(\\beta_1,...,\\beta_r\\)</span> 为 <span\r\nclass=\"math inline\">\\(\\alpha_1,...,\\alpha_n\\)</span>\r\n的一个极大线性无关组，因此 <span class=\"math inline\">\\(B\\)</span>\r\n就是矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n列向量组的一个极大线性无关组，<span class=\"math inline\">\\(C\\)</span>\r\n就是用该线性无关组去表示 <span class=\"math inline\">\\(A\\)</span>\r\n时的系数</p>\r\n<h4 id=\"例-1\">例 1</h4>\r\n<p>求矩阵 <span class=\"math inline\">\\(A=\\begin {bmatrix}\r\n1&amp;4&amp;-1&amp;5&amp;6\\\\2&amp;0&amp;0&amp;0&amp;-14\\\\-1&amp;2&amp;-4&amp;0&amp;1\\\\2&amp;6&amp;-5&amp;5&amp;-7\\end\r\n{bmatrix}\\)</span> 的满秩分解</p>\r\n<p><strong>解</strong>：对矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n只作初等行变换 <span class=\"math display\">\\[\r\nA=\\begin{bmatrix}1&amp;4&amp;-1&amp;5&amp;6\\\\2&amp;0&amp;0&amp;0&amp;-14\\\\-1&amp;2&amp;-4&amp;0&amp;1\\\\2&amp;6&amp;-5&amp;5&amp;-7\\end{bmatrix}\\to\r\n···\\to\\begin{bmatrix}1&amp;0&amp;0&amp;0&amp;-7\\\\0&amp;1&amp;0&amp;\\frac{10}{7}&amp;\\frac{29}{7}\\\\0&amp;0&amp;1&amp;\\frac{5}{7}&amp;\\frac{25}{7}\\\\0&amp;0&amp;0&amp;0&amp;0\\end{bmatrix}\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(A\\)</span> 的秩为\r\n3，且前三个列向量线性无关，故 <span class=\"math display\">\\[ B =\r\n\\begin{bmatrix}1&amp;4&amp;-1\\\\2&amp;0&amp;0\\\\-1&amp;2&amp;-4\\\\2&amp;6&amp;-5\\end{bmatrix}，C=\\begin{bmatrix}1&amp;0&amp;0&amp;0&amp;-7\\\\0&amp;1&amp;0&amp;\\frac{10}{7}&amp;\\frac{29}{7}\\\\0&amp;0&amp;1&amp;\\frac{5}{7}&amp;\\frac{25}{7}\\end{bmatrix}\r\n\\]</span></p>\r\n<h4 id=\"例-2\">例 2</h4>\r\n<p>求矩阵 <span class=\"math inline\">\\(A=\\begin {bmatrix}\r\n2&amp;1&amp;-2&amp;3&amp;1\\\\2&amp;5&amp;-1&amp;4&amp;1\\\\1&amp;3&amp;-1&amp;2&amp;1\\end\r\n{bmatrix}\\)</span> 的满秩分解</p>\r\n<p><strong>解</strong>：对矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n只作初等行变换</p>\r\n<p><span class=\"math display\">\\[\r\nA=\\begin{bmatrix}2&amp;1&amp;-2&amp;3&amp;1\\\\2&amp;5&amp;-1&amp;4&amp;1\\\\1&amp;3&amp;-1&amp;2&amp;1\\end{bmatrix}\\to\r\n···\\to\r\n\\begin{bmatrix}1&amp;0&amp;0&amp;\\frac{8}{5}&amp;-\\frac{2}{5}\\\\0&amp;1&amp;0&amp;\\frac{1}{5}&amp;\\frac{1}{5}\\\\0&amp;0&amp;1&amp;\\frac{1}{5}&amp;-\\frac{4}{5}\\end{bmatrix}\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(A\\)</span> 的秩为\r\n3，且前三个列向量线性无关，故 <span class=\"math display\">\\[ B =\r\n\\begin{bmatrix}2&amp;1&amp;-2\\\\2&amp;5&amp;-1\\\\1&amp;3&amp;-1\\end{bmatrix},C\r\n=\r\n\\begin{bmatrix}1&amp;0&amp;0&amp;\\frac{8}{5}&amp;-\\frac{2}{5}\\\\0&amp;1&amp;0&amp;\\frac{1}{5}&amp;\\frac{1}{5}\\\\0&amp;0&amp;1&amp;\\frac{1}{5}&amp;-\\frac{4}{5}\\end{bmatrix}\r\n\\]</span></p>\r\n<h2 id=\"矩阵的lu分解\">矩阵的LU分解</h2>\r\n<p>LU 分解（LU\r\nDecomposition）是矩阵分解的一种，可以将一个矩阵分解为一个单位下三角矩阵和一个上三角矩阵的乘积，以四阶矩阵为例\r\n<span class=\"math display\">\\[ L = \\begin{bmatrix}1&amp;0&amp;0&amp;0 \\\\\r\n*&amp;1&amp;0&amp;0\\\\ *&amp;*&amp;1&amp;0\\\\\r\n*&amp;*&amp;*&amp;1\\end{bmatrix},\r\nU=\\begin{bmatrix}*&amp;*&amp;*&amp;*\\\\0&amp;*&amp;*&amp;*\\\\0&amp;0&amp;*&amp;*\\\\0&amp;0&amp;0&amp;*\\end{bmatrix}\r\n\\]</span></p>\r\n<p>LU 矩阵是否一定存在？答案是否，具体看下面的例子</p>\r\n<p>设 <span class=\"math inline\">\\(\\begin {bmatrix} 0&amp;1 \\\\1&amp;0\\end\r\n{bmatrix}=\\begin {bmatrix} a&amp;0\\\\b&amp;c\\end {bmatrix}\\begin\r\n{bmatrix} l&amp;m\\\\0&amp;n\\end {bmatrix}\\)</span>，则应该满足如下 4\r\n个式子</p>\r\n<p><span class=\"math display\">\\[ \\begin{cases} al=0\\\\ am=1\\\\ bl=1\\\\\r\nbm+cn=0 \\end{cases} \\]</span></p>\r\n<p>由 <span class=\"math inline\">\\(al=0\\)</span> 得 <span\r\nclass=\"math inline\">\\(a=0\\)</span> 或 <span\r\nclass=\"math inline\">\\(l=0\\)</span>，但实际上这两种情况带入上面的式子都会推出矛盾，因此不是所有情况\r\nLU 分解都存在</p>\r\n<p><strong>LU 分解定理</strong> ：设 <span class=\"math inline\">\\(A\\in\r\n\\mathbb {C}_n^{n\\times n}\\)</span>，<span\r\nclass=\"math inline\">\\(A\\)</span> 有唯一的 LU 分解 <span\r\nclass=\"math inline\">\\(\\Leftrightarrow A\\)</span> 的各阶顺序主子式 <span\r\nclass=\"math inline\">\\(\\Delta k \\neq 0,\\ k=1,2...,n\\)</span></p>\r\n<p><span class=\"math inline\">\\(k\\)</span> 阶顺序主子式指的是矩阵左上角\r\n<span class=\"math inline\">\\(k\\times k\\)</span> 个元素组成的行列式</p>\r\n<p>将矩阵 <span class=\"math inline\">\\(A\\)</span> 分解为 <span\r\nclass=\"math inline\">\\(L\\)</span> 和 <span\r\nclass=\"math inline\">\\(U\\)</span> 之后，解方程组 <span\r\nclass=\"math inline\">\\(Ax=b\\)</span> 就变得简单了，因为 <span\r\nclass=\"math inline\">\\(A=LU\\)</span>，所以 <span\r\nclass=\"math inline\">\\((LU) x=b\\Rightarrow L (Ux)=b\\Rightarrow \\begin\r\n{cases} Ly=b\\\\Ux=y\\end {cases}\\)</span></p>\r\n<p>所以 <span class=\"math inline\">\\(x=U^{-1} y=U^{-1} L^{-1}\r\nb\\)</span></p>\r\n<h3 id=\"lu-矩阵的求法\">LU 矩阵的求法</h3>\r\n<p>实际上 LU 矩阵有非常多的求法，这里列举一种比较简单的待定系数法</p>\r\n<p>设 <span class=\"math inline\">\\(A = \\begin {bmatrix}\r\n2&amp;3&amp;4\\\\1&amp;1&amp;9\\\\1&amp;2&amp;-6\\end\r\n{bmatrix}\\)</span>，求矩阵 <span class=\"math inline\">\\(A\\)</span> 的 LU\r\n分解矩阵 <span class=\"math inline\">\\(L\\)</span> 和 <span\r\nclass=\"math inline\">\\(U\\)</span></p>\r\n<p><strong>解</strong>：令 <span class=\"math display\">\\[\r\nL=\\begin{bmatrix}1&amp;0&amp;0\\\\l_1&amp;1&amp;0\\\\l_2&amp;l_3&amp;1\\end{bmatrix},U\r\n=\r\n\\begin{bmatrix}u_1&amp;u_2&amp;u_3\\\\0&amp;u_4&amp;u_5\\\\0&amp;0&amp;u_6\\end{bmatrix}\r\n\\]</span></p>\r\n<p>由于 <span class=\"math inline\">\\(A=LU\\)</span>，所以有</p>\r\n<p><span class=\"math display\">\\[ \\begin{cases} u_1=2\\\\ u_2=3\\\\ u_3=4\\\\\r\nl_1u_1=1\\\\ l_1u_2+u_4=1\\\\ l_1u_3+u_5=9\\\\ l_2u_1=1\\\\ l_2u_2+l_3u_4=2\\\\\r\nl_2u_3+l_3u_5+u_6=-6 \\end{cases} \\]</span></p>\r\n<p>上面的方程组非常容易解，最后求出</p>\r\n<p><span class=\"math display\">\\[ L =\r\n\\begin{bmatrix}1&amp;0&amp;0\\\\\\frac{1}{2}&amp;1&amp;0\\\\\\frac{1}{2}&amp;-1&amp;1\\end{bmatrix},U=\\begin{bmatrix}2&amp;3&amp;4\\\\0&amp;-\\frac{1}{2}&amp;7\\\\0&amp;0&amp;-1\\end{bmatrix}\r\n\\]</span></p>\r\n<h2 id=\"奇异值分解\">奇异值分解</h2>\r\n<p><strong>奇异值</strong>：设 <span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{m × n}_r,AA^H\\)</span> 的特征值为 <span\r\nclass=\"math display\">\\[\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_n =\r\n0\\]</span></p>\r\n<p>则称 <span class=\"math inline\">\\(\\sigma_i=\\sqrt{\\lambda_i}\\)</span>\r\n为矩阵A的正奇异值。<strong><span class=\"math inline\">\\(A\\)</span>\r\n和<span class=\"math inline\">\\(A^H\\)</span>相同的奇异值</strong>。</p>\r\n<p><strong>奇异值分解</strong>：当给定一个大小为<span\r\nclass=\"math inline\">\\(m × n\\)</span>的矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>,虽然矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>不一定是方阵，但大小为<span\r\nclass=\"math inline\">\\(m × m\\)</span>的<span\r\nclass=\"math inline\">\\(AA^T\\)</span>和<span class=\"math inline\">\\(n ×\r\nn\\)</span>的<span class=\"math inline\">\\(AA^T\\)</span>是对称矩阵,若<span\r\nclass=\"math inline\">\\(AA^T=P \\Lambda_1 Q^T\\)</span>,<span\r\nclass=\"math inline\">\\(A^T A=Q\\Lambda_2\r\nQ^T\\)</span>,则矩阵A的奇异值分解为 <span\r\nclass=\"math display\">\\[A=P\\Sigma Q^T\\]</span></p>\r\n<p>其中，矩阵<span class=\"math inline\">\\(P=(\\overrightarrow{p_1},\r\n\\overrightarrow{p_2}, \\dots, \\overrightarrow{p_m})\\)</span>的大小为\r\n<span class=\"math inline\">\\(m × m\\)</span>，列向量 <span\r\nclass=\"math inline\">\\(\\overrightarrow{p_1}, \\overrightarrow{p_2}, \\dots,\r\n\\overrightarrow{p_m}\\)</span>是 <span\r\nclass=\"math inline\">\\(AA^T\\)</span>的特征向量，也被称为矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>的左奇异向量（left singular\r\nvector）；矩阵<span class=\"math inline\">\\(Q=(\\overrightarrow{q_1},\r\n\\overrightarrow{q_2}, \\dots, \\overrightarrow{q_m})\\)</span>的大小为\r\n<span class=\"math inline\">\\(n × n\\)</span>，列向量 <span\r\nclass=\"math inline\">\\(\\overrightarrow{q_1}, \\overrightarrow{q_2}, \\dots,\r\n\\overrightarrow{q_m}\\)</span>是 <span\r\nclass=\"math inline\">\\(A^TA\\)</span>的特征向量，也被称为矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>的右奇异向量（left singular\r\nvector）；矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_1\\)</span>的大小为<span\r\nclass=\"math inline\">\\(m × m\\)</span>，矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_2\\)</span>的大小为<span\r\nclass=\"math inline\">\\(n ×\r\nn\\)</span>，两个矩阵对角线上的非零元素相同（即矩阵<span\r\nclass=\"math inline\">\\(AA^T\\)</span>和<span\r\nclass=\"math inline\">\\(A^TA\\)</span>的非零特征值相同）；矩阵<span\r\nclass=\"math inline\">\\(\\Sigma\\)</span>的大小为<span\r\nclass=\"math inline\">\\(m ×\r\nn\\)</span>，位于对角线上的元素被称为<strong>奇异值</strong>（singular\r\nvalue）。</p>\r\n<p>设<span class=\"math inline\">\\(A\\)</span>的秩为r，当 <span\r\nclass=\"math inline\">\\(m \\ne n\\)</span>时，矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_1\\)</span>和<span\r\nclass=\"math inline\">\\(\\Lambda_2\\)</span>的大小显然是不同的，但是他们对角线上的非零元素是相同的，记矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_1\\)</span>(或<span\r\nclass=\"math inline\">\\(\\Lambda_2\\)</span>)对角线上的非零元素为<span\r\nclass=\"math inline\">\\(\\lambda_1,\\lambda_2,\\dots,\\lambda_r\\)</span>，这些数皆为非负数，又记矩阵<span\r\nclass=\"math inline\">\\(\\Sigma\\)</span>对角线上的非零元素分别为<span\r\nclass=\"math inline\">\\(\\sigma_1,\\sigma_2,\\dots,\\sigma_r\\)</span>，则\r\n<span\r\nclass=\"math display\">\\[\\sigma_1=\\sqrt{\\lambda_1},\\sigma_2=\\sqrt{\\lambda_2},\\dots,\\sigma_r=\\sqrt{\\lambda_r}\\]</span></p>\r\n<p>即非零奇异值的平方对应着矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_1\\)</span>（或矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_2\\)</span>）的非零特征值，到这里，我们就不难看出奇异值分解与对称对角化分解的关系了，即我们可以由对称对角化分解得到我们想要的奇异值分解。</p>\r\n<p><strong>例1</strong>：一个<span\r\nclass=\"math inline\">\\(3×2\\)</span>的矩阵<span\r\nclass=\"math inline\">\\(A=\\begin{bmatrix}  1&amp;2 \\\\ 0&amp;0 \\\\ 0&amp;0\r\n\\end{bmatrix}\\)</span>，求其奇异值分解。</p>\r\n<p>由 <span class=\"math display\">\\[AA^T=\\begin{bmatrix}\r\n    5&amp;0&amp;0 \\\\ 0&amp;0&amp;0 \\\\ 0&amp;0&amp;0\r\n\\end{bmatrix}\\]</span></p>\r\n<p>得到其特征值<span\r\nclass=\"math inline\">\\(\\lambda_1=5,\\lambda_2=\\lambda_3=0\\)</span>，特征向量为<span\r\nclass=\"math inline\">\\(\\overrightarrow{p_1}=(1,0,0)^T,\\overrightarrow{p_2}=(0,1,0)^T,\\overrightarrow{p_3}=(0,0,1)^T\\)</span></p>\r\n<p>由 <span class=\"math display\">\\[A^TA=\\begin{bmatrix}\r\n    1&amp;2 \\\\ 2&amp;4\r\n\\end{bmatrix}\\]</span></p>\r\n<p>得到其特征值<span\r\nclass=\"math inline\">\\(\\lambda_1=5,\\lambda_2=0\\)</span>，特征向量为<span\r\nclass=\"math inline\">\\(\\overrightarrow{q_1}=(\\frac{\\sqrt{5}}{5},\\frac{2\\sqrt{5}}{5})^T,\\overrightarrow{q_2}=(-\\frac{\\sqrt{5}}{5},\\frac{2\\sqrt{5}}{5})^T\\)</span></p>\r\n<p>令 <span class=\"math display\">\\[\\Sigma=\\begin{bmatrix}\r\n    \\sqrt{5}&amp;0 \\\\ 0&amp;0 \\\\ 0&amp;0\r\n\\end{bmatrix}\\]</span></p>\r\n<p>注意矩阵<span class=\"math inline\">\\(\\Sigma\\)</span>的大小为<span\r\nclass=\"math inline\">\\(3 × 2\\)</span>，此时，矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>的奇异值分解为 <span\r\nclass=\"math display\">\\[A=P\\Sigma Q^T=(\\overrightarrow{p_1},\r\n\\overrightarrow{p_2}, \\overrightarrow{p_3})\\Sigma (\\overrightarrow{q_1},\r\n\\overrightarrow{q_2})^T \\\\ =\\begin{bmatrix}\r\n    1&amp;0&amp;0 \\\\ 0&amp;1&amp;0 \\\\ 0&amp;0&amp;1\r\n\\end{bmatrix} \\begin{bmatrix}\r\n    \\sqrt{5}&amp;0 \\\\ 0&amp;0 \\\\ 0&amp;0\r\n\\end{bmatrix} \\begin{bmatrix}\r\n    \\frac{\\sqrt{5}}{5}&amp;\\frac{2\\sqrt{5}}{5} \\\\\r\n\\frac{-2\\sqrt{5}}{5}&amp;\\frac{\\sqrt{5}}{5}\r\n\\end{bmatrix} = \\begin{bmatrix}\r\n    1&amp;2 \\\\ 0&amp;0 \\\\ 0&amp;0\r\n\\end{bmatrix}\\]</span></p>\r\n<p><strong>例2</strong>：求对称矩阵<span\r\nclass=\"math inline\">\\(A=\\begin{bmatrix}  2&amp;1 \\\\ 1&amp;2\r\n\\end{bmatrix}\\)</span>的奇异值分解。</p>\r\n<p>经计算可以发现<span\r\nclass=\"math inline\">\\(A^TA=AA^T=\\begin{bmatrix}  2&amp;1 \\\\ 1&amp;2\r\n\\end{bmatrix} \\begin{bmatrix}  2&amp;1 \\\\ 1&amp;2\r\n\\end{bmatrix}=\\begin{bmatrix}  5&amp;4 \\\\ 4&amp;5\r\n\\end{bmatrix}\\)</span>，左奇异向量和右奇异向量构成的矩阵也是相等的，即\r\n<span class=\"math display\">\\[P=Q=\\begin{bmatrix}\r\n    \\frac{\\sqrt{2}}{2}&amp;\\frac{\\sqrt{2}}{2} \\\\\r\n-\\frac{\\sqrt{2}}{2}&amp;\\frac{\\sqrt{2}}{2}\r\n\\end{bmatrix}\\]</span></p>\r\n<p>则其奇异值分解为 <span class=\"math display\">\\[A=P\\Sigma\r\nQ^T=\\begin{bmatrix}\r\n    \\frac{\\sqrt{2}}{2}&amp;\\frac{\\sqrt{2}}{2} \\\\ -\r\n\\frac{\\sqrt{2}}{2}&amp; \\frac{\\sqrt{2}}{2}\r\n\\end{bmatrix}\r\n\\begin{bmatrix}\r\n    3&amp;0 \\\\ 0&amp;1\r\n\\end{bmatrix}\\begin{bmatrix}\r\n    \\frac{\\sqrt{2}}{2}&amp;\\frac{\\sqrt{2}}{2} \\\\\r\n-\\frac{\\sqrt{2}}{2}&amp;\\frac{\\sqrt{2}}{2}\r\n\\end{bmatrix}\\]</span></p>\r\n<p><strong>注</strong>：这是由于当矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>为对称矩阵时，其可以被正交对角化，这时奇异值分解等于正交对角化分解。</p>\r\n<h2 id=\"谱分解\">谱分解</h2>\r\n<p><strong>谱分解</strong>：设 <span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{n × n}\\)</span>是单纯矩阵，则 <span\r\nclass=\"math inline\">\\(A\\)</span>可以分解为一系列幂等矩阵 <span\r\nclass=\"math inline\">\\(A_i(i=1,2, \\dots,n)\\)</span>的加权和 <span\r\nclass=\"math display\">\\[A=\\sum_{i=1}^n \\lambda_i A_i\\]</span></p>\r\n<p>其中 <span\r\nclass=\"math inline\">\\(\\lambda_i(i=1,2,\\dots,n)\\)</span>是A的特征值。</p>\r\n<p><strong>单纯矩阵</strong>：若矩阵 <span\r\nclass=\"math inline\">\\(A\\)</span>的<strong>代数重数</strong>等于<strong>几何重数</strong>，则称<span\r\nclass=\"math inline\">\\(A\\)</span>为单纯矩阵。<strong>代数重数</strong>为矩阵\r\n<span\r\nclass=\"math inline\">\\(A\\)</span>特征值的重数，<strong>几何重数</strong>为齐次方程组<span\r\nclass=\"math inline\">\\(Ax=\\lambda_i\r\nx(i=1,2,\\dots,k)\\)</span>的解空间<span\r\nclass=\"math inline\">\\(V_{\\lambda_i}\\)</span>的维数，也即特征值对应的最多无关特征向量数。</p>\r\n<p><strong>幂等矩阵</strong>：若 <span\r\nclass=\"math inline\">\\(A\\)</span>为方阵，且 <span\r\nclass=\"math inline\">\\(A^2=A\\)</span>，则称<span\r\nclass=\"math inline\">\\(A\\)</span>为幂等矩阵。所有幂等矩阵都相似与对角元全为0或1的对角阵。</p>\r\n<p><strong>更一般的单纯矩阵谱分解定理</strong>：设 <span\r\nclass=\"math inline\">\\(A \\in \\mathbb{C}^{n × n}\\)</span>，他有 <span\r\nclass=\"math inline\">\\(k\\)</span>个相异特征值 <span\r\nclass=\"math inline\">\\(\\lambda_i(i=1,2,\\dots,k)\\)</span>，则 <span\r\nclass=\"math inline\">\\(A\\)</span>是单纯矩阵的充要条件是存在<span\r\nclass=\"math inline\">\\(k\\)</span>个矩阵<span\r\nclass=\"math inline\">\\(A_i(i=1,2,\\dots,k)\\)</span>满足</p>\r\n<ol type=\"1\">\r\n<li><span class=\"math inline\">\\(A_i A_j = \\begin{cases}  A_i, i=j \\\\ 0,\r\ni\\ne j \\end{cases}\\)</span></li>\r\n<li><span class=\"math inline\">\\(\\sum_{i=1}^k A_i = E_n\\)</span></li>\r\n<li><span class=\"math inline\">\\(A=\\sum_{i=1}^k \\lambda_i\r\nA_i\\)</span></li>\r\n</ol>\r\n<p>该定理比定理3要求放宽了，不再要求必须要有n个特征值了，这里的k可以小于等于n。</p>\r\n<p><strong>例1</strong>：求正规矩阵 <span class=\"math inline\">\\(A =\r\n\\begin{bmatrix}  0&amp;1&amp;1&amp;1 \\\\ 1&amp;0&amp;-1&amp;1 \\\\\r\n1&amp;-1&amp;0&amp;1 \\\\ -1&amp;1&amp;1&amp;0\r\n\\end{bmatrix}\\)</span>的谱分解表达式。</p>\r\n<p><strong>解</strong>：首先计算 <span\r\nclass=\"math inline\">\\(A\\)</span>的特征值和特征向量 <span\r\nclass=\"math display\">\\[|\\lambda_ I - A |=(\\lambda - 1)^3 (\\lambda +\r\n3)\\]</span></p>\r\n<p>从而 <span class=\"math inline\">\\(A\\)</span>的特征值为 <span\r\nclass=\"math display\">\\[\\lambda_1=\\lambda_2=\\lambda_3=1,\\lambda_4=-3\\]</span></p>\r\n<p>当<span\r\nclass=\"math inline\">\\(\\lambda=1\\)</span>时，求得无关的特征向量为 <span\r\nclass=\"math display\">\\[\\alpha_1=(1,1,0,0)^T \\\\ \\alpha_2=(1,0,1,0)^T \\\\\r\n\\alpha_3=(-1,0,0,1)^T\\]</span></p>\r\n<p>当<span\r\nclass=\"math inline\">\\(\\lambda=-3\\)</span>时，求得无关的特征向量为 <span\r\nclass=\"math display\">\\[\\alpha_4=(1,-1,-1,1)^T\\]</span></p>\r\n<p>将 <span\r\nclass=\"math inline\">\\(\\alpha_1,\\alpha_2,\\alpha_3\\)</span>正交化并单位化得\r\n<span\r\nclass=\"math display\">\\[\\eta_1=(\\frac{1}{\\sqrt{2}},\\frac{1}{\\sqrt{2}},0,0)^T\r\n\\\\\r\n\\eta_2=(\\frac{1}{\\sqrt{6}},\\frac{1}{\\sqrt{6}},\\frac{2}{\\sqrt{6}},0)^T \\\\\r\n\\eta_3=(-\\frac{1}{2\\sqrt{3}},\\frac{1}{2\\sqrt{3}},\\frac{1}{\\sqrt{3}},\\frac{3}{2\\sqrt{3}})^T\\]</span></p>\r\n<p>将<span class=\"math inline\">\\(\\alpha_4\\)</span>单位话得 <span\r\nclass=\"math display\">\\[\\eta_4=(\\frac{1}{2},\r\n-\\frac{1}{2},-\\frac{1}{2},\\frac{1}{2})\\]</span></p>\r\n<p>故有 <span class=\"math display\">\\[G_1=\\eta_1 \\eta_1^H+\\eta_2 \\eta_2^H\r\n+\\eta_3 \\eta_3^H \\\\\r\n= \\begin{bmatrix}\r\n    \\frac{3}{4}&amp;\\frac{1}{4}&amp;\\frac{1}{4}&amp;-\\frac{1}{4} \\\\\r\n    \\frac{1}{4}&amp;\\frac{3}{4}&amp;-\\frac{1}{4}&amp;\\frac{1}{4} \\\\\r\n    \\frac{1}{4}&amp;-\\frac{1}{4}&amp;\\frac{3}{4}&amp;\\frac{1}{4} \\\\\r\n    -\\frac{1}{4}&amp;\\frac{1}{4}&amp;\\frac{1}{4}&amp;\\frac{3}{4}    \r\n\\end{bmatrix}\\]</span></p>\r\n<p><span class=\"math display\">\\[G_2=\\eta_4 \\eta_4^H \\\\\r\n=\\begin{bmatrix}\r\n    \\frac{1}{4}&amp;-\\frac{1}{4}&amp;-\\frac{1}{4}&amp;\\frac{1}{4} \\\\\r\n    -\\frac{1}{4}&amp;\\frac{1}{4}&amp;\\frac{1}{4}&amp;-\\frac{1}{4} \\\\\r\n    -\\frac{1}{4}&amp;\\frac{1}{4}&amp;\\frac{1}{4}&amp;-\\frac{1}{4} \\\\\r\n    \\frac{1}{4}&amp;-\\frac{1}{4}&amp;-\\frac{1}{4}&amp;\\frac{1}{4}\r\n\\end{bmatrix}\\]</span></p>\r\n<p>这样其谱分解表达式为 <span class=\"math display\">\\[A=G_1 -\r\n3G_2\\]</span></p>\r\n<p>注意<span class=\"math inline\">\\(G_1\\)</span>和<span\r\nclass=\"math inline\">\\(G_2\\)</span>的系数<span\r\nclass=\"math inline\">\\(\\lambda_i\\)</span>为其对应的特征值。\r\n<!-- https://www.cnblogs.com/blairgrowing/p/15800825.html --></p>\r\n","site":{"data":{}},"excerpt":"","more":"<!-- <link href=\"https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css\" rel=\"stylesheet\"> -->\r\n<h2 id=\"三角分解qr分解\">三角分解(QR分解)</h2>\r\n<h3\r\nid=\"正交三角分解通过schmidt正交化\">正交三角分解(通过Schmidt正交化)</h3>\r\n<p>若 <span class=\"math inline\">\\(n\\)</span> 阶实矩阵 <span\r\nclass=\"math inline\">\\(A\\in \\mathbb {C}^{n\\times n}\\)</span> 满秩，且\r\n<span class=\"math display\">\\[A = [\\alpha_1,...,\\alpha_n]\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(\\alpha_1,...,\\alpha_n\\)</span> 是\r\n<span class=\"math inline\">\\(\\mathbb {C}^{n\\times n}\\)</span>\r\n中线性无关向量组</p>\r\n<p><strong>正交化</strong></p>\r\n<p>令</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} \\beta_1&amp;=\\alpha_1\\\\\r\n\\beta_2&amp;=\\alpha_2 -\r\n\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1\r\n\\\\ \\vdots \\\\ \\beta_n &amp;= \\alpha_n -\r\n\\frac{\\left&lt;\\beta_n,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1-\\cdots-\\frac{\\left&lt;\\beta_{n-1},\\alpha_n\\right&gt;}{\\left&lt;\\beta_{n-1},\\alpha_{n-1}\\right&gt;}\\beta_{n-1}\r\n\\end{aligned} \\]</span></p>\r\n<p>变形得</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} \\alpha_1 &amp;=\r\n\\beta_1\\\\ \\alpha_2 &amp;=\r\n\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1\r\n+ \\beta_2\\\\ \\vdots \\\\ \\alpha_n &amp;=\r\n\\frac{\\left&lt;\\beta_n,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1-\\cdots-\\frac{\\left&lt;\\beta_{n-1},\\alpha_n\\right&gt;}{\\left&lt;\\beta_{n-1},\\alpha_{n-1}\\right&gt;}\\beta_{n-1}\r\n+ \\beta_n \\end{aligned} \\]</span></p>\r\n<p>写成矩阵形式</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned}\r\n\\begin{bmatrix}\\alpha_1,\\alpha_2,...,\\alpha_n\\end{bmatrix} &amp;=\r\n\\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix}\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;\\triangleq\r\nB\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix} \\end{aligned}\r\n\\]</span></p>\r\n<p><strong>单位化</strong></p>\r\n<p>令</p>\r\n<p><span class=\"math display\">\\[ q_1=\\frac{\\beta_1}{||\\beta_1||} \\\\\r\n\\vdots \\\\ q_n = \\frac{\\beta_n}{||\\beta_n||} \\]</span></p>\r\n<p>变形得</p>\r\n<p><span class=\"math display\">\\[\\beta_1 = q_1||\\beta_1|| \\\\ \\vdots \\\\\r\n\\beta_n = q_n ||\\beta_n|| \\]</span></p>\r\n<p>写成矩阵形式</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned}\r\n\\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix} &amp;=\r\n\\begin{bmatrix}q_1,q_2,...,q_n\\end{bmatrix}\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\\\\\r\n&amp;\\triangleq Q\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\r\n\\end{aligned} \\]</span></p>\r\n<p>综上，结合正交化和单位化可得</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} A &amp;=\r\nB\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;=Q\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp;\r\n||\\beta_n||\\end{bmatrix}\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;=Q\\begin{bmatrix}||\\beta_1||&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\\\\\r\n&amp;\\triangleq QR \\end{aligned} \\]</span></p>\r\n<p><strong>QR 分解定理</strong> : <span class=\"math inline\">\\(A\\in\r\n\\mathbb {C}^{n\\times n}\\)</span> ,则存在酉矩阵 <span\r\nclass=\"math inline\">\\(Q\\)</span> 和正线上三角阵 <span\r\nclass=\"math inline\">\\(R\\)</span> ，使 <span\r\nclass=\"math display\">\\[A=QR\\]</span></p>\r\n<p>且分解唯一</p>\r\n<p><strong>正交三角分解的求法</strong> 1. 取矩阵 <span\r\nclass=\"math inline\">\\(A=(A_1,A_2,...,A_n)\\)</span> 的列向量，进行\r\n<strong>Schmidt 标准正交化</strong>,得 <span\r\nclass=\"math inline\">\\(v_1,v_2,...,v_n\\)</span> ，有 <span\r\nclass=\"math display\">\\[Q=(v_1,v_2,...,v_n)\\]</span> 2. 再由 <span\r\nclass=\"math inline\">\\(R=Q^HA\\)</span> 得到 <span\r\nclass=\"math inline\">\\(R\\)</span> , 于是 <span\r\nclass=\"math inline\">\\(A=QR\\)</span></p>\r\n<h3 id=\"householder变换分解\">HouseHolder变换分解</h3>\r\n<p>将矩阵A按列划分为 <span\r\nclass=\"math inline\">\\((\\alpha_1,\\alpha_2,\\dots,\\alpha_n)\\)</span>,以4阶方阵为例，</p>\r\n<p>第一步 令 <span\r\nclass=\"math display\">\\[\\omega_1=\\frac{\\alpha_1-a_1*e_1}{||\\alpha_1-a_1*e_1||_2}，a_1=||\\alpha_1||_2\\]</span></p>\r\n<p>于是 <span\r\nclass=\"math display\">\\[H_1A=(H_1\\alpha_1,H_1\\alpha_2，...，H_1\\alpha_n)\r\n=\\left\\{\\begin{matrix} a_1 &amp; * &amp; \\cdots &amp; * \\\\\r\n                   0      &amp; \\\\\r\n                   \\vdots &amp; &amp;B_1 \\\\\r\n0\\end{matrix}\\right\\}\\]</span></p>\r\n<p>第二步</p>\r\n<p>从第一步中得到 <span\r\nclass=\"math inline\">\\(B_1=(\\beta_2,\\beta_2,\\cdots,\\beta_n)\\in\r\nR^{n-1}\\)</span></p>\r\n<p>取 <span\r\nclass=\"math display\">\\[\\omega_2=\\frac{\\beta_2-b_2*e_1}{||\\beta_2-b_2*e_1||_2}，b_1=||\\beta_2||_2\\]</span></p>\r\n<p>则 <span\r\nclass=\"math display\">\\[\\widehat{H_2}=I-2*\\omega_2*\\omega_2^T,H_2=\\left\\{\\begin{matrix}\r\n1 &amp; 0^T \\\\\r\n                                                              0 &amp;\r\n\\widehat{H_2}，\r\n                                              \\end{matrix}\r\n\\right\\}\\]</span></p>\r\n<p>得到 <span class=\"math display\">\\[H_2(H_1*A) = \\begin{bmatrix}   a_1\r\n&amp; * &amp; * &amp; \\cdots &amp;* \\\\\r\n                                       0 &amp; a_2 &amp; * &amp; \\cdots\r\n&amp;* \\\\\r\n                                       0 &amp; 0 &amp;  &amp;\\\\\r\n                                       \\vdots &amp; \\vdots\r\n&amp;  &amp;C_2&amp; \\\\\r\n                                       0 &amp; 0\r\n\\end{bmatrix} , C_2\\in R^{n-2}\\]</span></p>\r\n<p>依次类推，进行第n步时，得到第n-1个 <span\r\nclass=\"math inline\">\\(H_{n-1}\\)</span>阵,使得 <span\r\nclass=\"math display\">\\[H_{n-1} \\cdots H_2H_1*A = \\begin{bmatrix}   a_1\r\n&amp; * &amp; * &amp; \\cdots &amp; * \\\\\r\n                                                   0 &amp; a_2 &amp; *\r\n&amp; \\cdots &amp; * \\\\\r\n                                                   0 &amp; 0 &amp; a_3\r\n&amp; \\cdots &amp; *\\\\\r\n                                                  \\vdots &amp; \\vdots\r\n&amp; &amp;\\ddots \\\\\r\n                                                    0 &amp; 0 &amp; 0\r\n&amp; \\cdots &amp;a_n\r\n\\end{bmatrix}=R\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(H_{n-1} \\cdots\r\nH_2H_1*A=H\\)</span>也称为HouseHolder矩阵，也为自逆矩阵 <span\r\nclass=\"math inline\">\\(H=H^{-1}\\)</span></p>\r\n<p><span class=\"math display\">\\[H_{n-1} \\cdots H_2H_1*A=R\\]</span> <span\r\nclass=\"math display\">\\[\\Rightarrow (H_{n-1} \\cdots H_2*H_1)^{-1}*H_{n-1}\r\n\\cdots H_2H_1*A=(H_{n-1} \\cdots H_2*H_1)^{-1}*R\\]</span> <span\r\nclass=\"math display\">\\[\\Rightarrow A=H_1^{-1} \\cdots\r\nH_{n-1}^{-1}*R\\]</span> <span class=\"math display\">\\[\\Rightarrow\r\nA=H_1\\cdots H_{n-1}*R\\]</span></p>\r\n<p>得到 <span class=\"math inline\">\\(A=QR\\)</span>,其中 <span\r\nclass=\"math inline\">\\(Q\\)</span>为正交矩阵， <span\r\nclass=\"math inline\">\\(R\\)</span>为上三角矩阵 <span\r\nclass=\"math display\">\\[\\begin{cases}\r\nQ = H_1\\cdots H_{n-1}\\\\\r\nR = Q^{-1}A=QA\r\n\\end{cases}\\]</span></p>\r\n<h3 id=\"三角分解的性质\">三角分解的性质</h3>\r\n<p><strong>定理1</strong>:设 <span class=\"math inline\">\\(A\\in \\mathbb\r\n{C}_r^{m\\times n}\\)</span>，则 <span class=\"math inline\">\\(A\\)</span>\r\n可以唯一地分解为 <span class=\"math display\">\\[A=U_1 R\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(U_1\\)</span>是酉矩阵， <span\r\nclass=\"math inline\">\\(R\\)</span> 是正线上三角复矩阵，或 <span\r\nclass=\"math inline\">\\(A\\)</span> 可以唯一地分解为 <span\r\nclass=\"math display\">\\[A=L U_2\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(L\\)</span>是正线下三角复矩阵， <span\r\nclass=\"math inline\">\\(U_2\\)</span>是酉矩阵</p>\r\n<p><strong>推论1</strong>：设 <span class=\"math inline\">\\(A \\in \\mathbb\r\n{R}^{n × n}_n\\)</span>,则 <span\r\nclass=\"math inline\">\\(A\\)</span>可以唯一地分解为 <span\r\nclass=\"math display\">\\[A=Q_1 R\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(Q_1\\)</span>是则正交矩阵，<span\r\nclass=\"math inline\">\\(R\\)</span>是正线上三角实矩阵，或 <span\r\nclass=\"math inline\">\\(A\\)</span>可以唯一地分解为 <span\r\nclass=\"math display\">\\[A=L Q_2\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(L\\)</span>是正线下三角实矩阵， <span\r\nclass=\"math inline\">\\(Q_2\\)</span>是正交矩阵。</p>\r\n<p><strong>推论2</strong>：设A是实对称正定矩阵，则存在唯一正线上三角实矩阵\r\n<span class=\"math inline\">\\(R\\)</span>，使得 <span\r\nclass=\"math display\">\\[A=R^T R\\]</span></p>\r\n<p><strong>推论3</strong>：设 <span\r\nclass=\"math inline\">\\(A\\)</span>是正定Hermite矩阵，则存在唯一正线上三角复矩阵<span\r\nclass=\"math inline\">\\(R\\)</span>，使得 <span\r\nclass=\"math display\">\\[A=R^H R\\]</span></p>\r\n<h2 id=\"矩阵的满秩分解\">矩阵的满秩分解</h2>\r\n<p>设 <span class=\"math inline\">\\(A\\in \\mathbb {C}_r^{m\\times\r\nn}\\)</span>，则存在 <span class=\"math inline\">\\(B\\in \\mathbb\r\n{C}_r^{m\\times r}, C\\in \\mathbb {C}_r^{r\\times n}\\)</span>，满足 <span\r\nclass=\"math display\">\\[ A = BC \\]</span></p>\r\n<p><span class=\"math inline\">\\(\\mathbb {C}_r\\)</span> 表示矩阵的秩为\r\n<span class=\"math inline\">\\(r\\)</span></p>\r\n<p>实际上上述定理用文字描述就是，一个亏秩的矩阵可以分解成一个列满秩与行满秩矩阵的乘积</p>\r\n<p>证明：因为 <span class=\"math inline\">\\(rank\r\n(A)=r\\)</span>，所以一定可以找到与 <span\r\nclass=\"math inline\">\\(A\\)</span> 相似的一个矩阵</p>\r\n<p><span class=\"math display\">\\[ A \\simeq\r\n\\begin{bmatrix}E_r&amp;0_{r\\times (n-r)}\\\\0_{(m-r)\\times\r\nr}&amp;0_{(m-r)\\times\r\n(n-r)}\\end{bmatrix}=\\begin{bmatrix}E_r\\\\0_{(m-r)\\times\r\nr}\\end{bmatrix}\\begin{bmatrix}E_r&amp;0_{r\\times (n-r)}\\end{bmatrix}\r\n\\]</span></p>\r\n<p>因此存在两个可逆矩阵 <span class=\"math inline\">\\(P,Q\\)</span>，使\r\n<span class=\"math inline\">\\(PAQ=\\begin {bmatrix} E_r&amp;0\\\\0&amp;0\\end\r\n{bmatrix}\\)</span>，则</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} A &amp;=\r\nP^{-1}\\begin{bmatrix}E_r\\\\0\\end{bmatrix}\\begin{bmatrix}E_r&amp;0\\end{bmatrix}Q^{-1}\\\\\r\n&amp;\\triangleq BC \\end{aligned} \\]</span></p>\r\n<p>因为 <span class=\"math inline\">\\(P^{-1}\\)</span> 是可逆矩阵，<span\r\nclass=\"math inline\">\\(\\begin {bmatrix} E_r\\\\0\\end {bmatrix}\\)</span>\r\n是一个列满秩矩阵，所以 <span class=\"math inline\">\\(B=P^{-1}\\begin\r\n{bmatrix} E_r\\\\0\\end {bmatrix}\\)</span> 仍是一个列满秩矩阵；同理，<span\r\nclass=\"math inline\">\\(C=\\begin {bmatrix} E_r&amp;0\\end {bmatrix}\r\nQ^{-1}\\)</span> 是一个行满秩矩阵</p>\r\n<h3 id=\"矩阵满秩分解的计算\">矩阵满秩分解的计算</h3>\r\n<p>如何在给定矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n的情况下，求出矩阵 <span class=\"math inline\">\\(B,C\\)</span> 呢？</p>\r\n<p>设</p>\r\n<p><span class=\"math display\">\\[ A = [\\alpha_1,\\alpha_2,...,\\alpha_n]\\\\\r\nB = [\\beta_1,\\beta_2,...,\\beta_r]\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(\\beta_1,...,\\beta_r\\)</span>\r\n线性无关</p>\r\n<p>所以 <span class=\"math display\">\\[ \\begin{aligned} &amp;A=BC\\\\\r\n&amp;\\Rightarrow[\\alpha_1,\\alpha_2,...,\\alpha_n]=[\\beta_1,...,\\beta_r]\\begin{bmatrix}c_{11}&amp;\\cdots\r\n&amp;c_{1n}\\\\\\vdots &amp;\\ddots&amp;\\vdots\\\\c_{r1}&amp;\\cdots\r\n&amp;c_{rn}\\end{bmatrix} \\end{aligned} \\]</span></p>\r\n<p>实际上我们可以取 <span\r\nclass=\"math inline\">\\(\\beta_1,...,\\beta_r\\)</span> 为 <span\r\nclass=\"math inline\">\\(\\alpha_1,...,\\alpha_n\\)</span>\r\n的一个极大线性无关组，因此 <span class=\"math inline\">\\(B\\)</span>\r\n就是矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n列向量组的一个极大线性无关组，<span class=\"math inline\">\\(C\\)</span>\r\n就是用该线性无关组去表示 <span class=\"math inline\">\\(A\\)</span>\r\n时的系数</p>\r\n<h4 id=\"例-1\">例 1</h4>\r\n<p>求矩阵 <span class=\"math inline\">\\(A=\\begin {bmatrix}\r\n1&amp;4&amp;-1&amp;5&amp;6\\\\2&amp;0&amp;0&amp;0&amp;-14\\\\-1&amp;2&amp;-4&amp;0&amp;1\\\\2&amp;6&amp;-5&amp;5&amp;-7\\end\r\n{bmatrix}\\)</span> 的满秩分解</p>\r\n<p><strong>解</strong>：对矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n只作初等行变换 <span class=\"math display\">\\[\r\nA=\\begin{bmatrix}1&amp;4&amp;-1&amp;5&amp;6\\\\2&amp;0&amp;0&amp;0&amp;-14\\\\-1&amp;2&amp;-4&amp;0&amp;1\\\\2&amp;6&amp;-5&amp;5&amp;-7\\end{bmatrix}\\to\r\n···\\to\\begin{bmatrix}1&amp;0&amp;0&amp;0&amp;-7\\\\0&amp;1&amp;0&amp;\\frac{10}{7}&amp;\\frac{29}{7}\\\\0&amp;0&amp;1&amp;\\frac{5}{7}&amp;\\frac{25}{7}\\\\0&amp;0&amp;0&amp;0&amp;0\\end{bmatrix}\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(A\\)</span> 的秩为\r\n3，且前三个列向量线性无关，故 <span class=\"math display\">\\[ B =\r\n\\begin{bmatrix}1&amp;4&amp;-1\\\\2&amp;0&amp;0\\\\-1&amp;2&amp;-4\\\\2&amp;6&amp;-5\\end{bmatrix}，C=\\begin{bmatrix}1&amp;0&amp;0&amp;0&amp;-7\\\\0&amp;1&amp;0&amp;\\frac{10}{7}&amp;\\frac{29}{7}\\\\0&amp;0&amp;1&amp;\\frac{5}{7}&amp;\\frac{25}{7}\\end{bmatrix}\r\n\\]</span></p>\r\n<h4 id=\"例-2\">例 2</h4>\r\n<p>求矩阵 <span class=\"math inline\">\\(A=\\begin {bmatrix}\r\n2&amp;1&amp;-2&amp;3&amp;1\\\\2&amp;5&amp;-1&amp;4&amp;1\\\\1&amp;3&amp;-1&amp;2&amp;1\\end\r\n{bmatrix}\\)</span> 的满秩分解</p>\r\n<p><strong>解</strong>：对矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n只作初等行变换</p>\r\n<p><span class=\"math display\">\\[\r\nA=\\begin{bmatrix}2&amp;1&amp;-2&amp;3&amp;1\\\\2&amp;5&amp;-1&amp;4&amp;1\\\\1&amp;3&amp;-1&amp;2&amp;1\\end{bmatrix}\\to\r\n···\\to\r\n\\begin{bmatrix}1&amp;0&amp;0&amp;\\frac{8}{5}&amp;-\\frac{2}{5}\\\\0&amp;1&amp;0&amp;\\frac{1}{5}&amp;\\frac{1}{5}\\\\0&amp;0&amp;1&amp;\\frac{1}{5}&amp;-\\frac{4}{5}\\end{bmatrix}\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(A\\)</span> 的秩为\r\n3，且前三个列向量线性无关，故 <span class=\"math display\">\\[ B =\r\n\\begin{bmatrix}2&amp;1&amp;-2\\\\2&amp;5&amp;-1\\\\1&amp;3&amp;-1\\end{bmatrix},C\r\n=\r\n\\begin{bmatrix}1&amp;0&amp;0&amp;\\frac{8}{5}&amp;-\\frac{2}{5}\\\\0&amp;1&amp;0&amp;\\frac{1}{5}&amp;\\frac{1}{5}\\\\0&amp;0&amp;1&amp;\\frac{1}{5}&amp;-\\frac{4}{5}\\end{bmatrix}\r\n\\]</span></p>\r\n<h2 id=\"矩阵的lu分解\">矩阵的LU分解</h2>\r\n<p>LU 分解（LU\r\nDecomposition）是矩阵分解的一种，可以将一个矩阵分解为一个单位下三角矩阵和一个上三角矩阵的乘积，以四阶矩阵为例\r\n<span class=\"math display\">\\[ L = \\begin{bmatrix}1&amp;0&amp;0&amp;0 \\\\\r\n*&amp;1&amp;0&amp;0\\\\ *&amp;*&amp;1&amp;0\\\\\r\n*&amp;*&amp;*&amp;1\\end{bmatrix},\r\nU=\\begin{bmatrix}*&amp;*&amp;*&amp;*\\\\0&amp;*&amp;*&amp;*\\\\0&amp;0&amp;*&amp;*\\\\0&amp;0&amp;0&amp;*\\end{bmatrix}\r\n\\]</span></p>\r\n<p>LU 矩阵是否一定存在？答案是否，具体看下面的例子</p>\r\n<p>设 <span class=\"math inline\">\\(\\begin {bmatrix} 0&amp;1 \\\\1&amp;0\\end\r\n{bmatrix}=\\begin {bmatrix} a&amp;0\\\\b&amp;c\\end {bmatrix}\\begin\r\n{bmatrix} l&amp;m\\\\0&amp;n\\end {bmatrix}\\)</span>，则应该满足如下 4\r\n个式子</p>\r\n<p><span class=\"math display\">\\[ \\begin{cases} al=0\\\\ am=1\\\\ bl=1\\\\\r\nbm+cn=0 \\end{cases} \\]</span></p>\r\n<p>由 <span class=\"math inline\">\\(al=0\\)</span> 得 <span\r\nclass=\"math inline\">\\(a=0\\)</span> 或 <span\r\nclass=\"math inline\">\\(l=0\\)</span>，但实际上这两种情况带入上面的式子都会推出矛盾，因此不是所有情况\r\nLU 分解都存在</p>\r\n<p><strong>LU 分解定理</strong> ：设 <span class=\"math inline\">\\(A\\in\r\n\\mathbb {C}_n^{n\\times n}\\)</span>，<span\r\nclass=\"math inline\">\\(A\\)</span> 有唯一的 LU 分解 <span\r\nclass=\"math inline\">\\(\\Leftrightarrow A\\)</span> 的各阶顺序主子式 <span\r\nclass=\"math inline\">\\(\\Delta k \\neq 0,\\ k=1,2...,n\\)</span></p>\r\n<p><span class=\"math inline\">\\(k\\)</span> 阶顺序主子式指的是矩阵左上角\r\n<span class=\"math inline\">\\(k\\times k\\)</span> 个元素组成的行列式</p>\r\n<p>将矩阵 <span class=\"math inline\">\\(A\\)</span> 分解为 <span\r\nclass=\"math inline\">\\(L\\)</span> 和 <span\r\nclass=\"math inline\">\\(U\\)</span> 之后，解方程组 <span\r\nclass=\"math inline\">\\(Ax=b\\)</span> 就变得简单了，因为 <span\r\nclass=\"math inline\">\\(A=LU\\)</span>，所以 <span\r\nclass=\"math inline\">\\((LU) x=b\\Rightarrow L (Ux)=b\\Rightarrow \\begin\r\n{cases} Ly=b\\\\Ux=y\\end {cases}\\)</span></p>\r\n<p>所以 <span class=\"math inline\">\\(x=U^{-1} y=U^{-1} L^{-1}\r\nb\\)</span></p>\r\n<h3 id=\"lu-矩阵的求法\">LU 矩阵的求法</h3>\r\n<p>实际上 LU 矩阵有非常多的求法，这里列举一种比较简单的待定系数法</p>\r\n<p>设 <span class=\"math inline\">\\(A = \\begin {bmatrix}\r\n2&amp;3&amp;4\\\\1&amp;1&amp;9\\\\1&amp;2&amp;-6\\end\r\n{bmatrix}\\)</span>，求矩阵 <span class=\"math inline\">\\(A\\)</span> 的 LU\r\n分解矩阵 <span class=\"math inline\">\\(L\\)</span> 和 <span\r\nclass=\"math inline\">\\(U\\)</span></p>\r\n<p><strong>解</strong>：令 <span class=\"math display\">\\[\r\nL=\\begin{bmatrix}1&amp;0&amp;0\\\\l_1&amp;1&amp;0\\\\l_2&amp;l_3&amp;1\\end{bmatrix},U\r\n=\r\n\\begin{bmatrix}u_1&amp;u_2&amp;u_3\\\\0&amp;u_4&amp;u_5\\\\0&amp;0&amp;u_6\\end{bmatrix}\r\n\\]</span></p>\r\n<p>由于 <span class=\"math inline\">\\(A=LU\\)</span>，所以有</p>\r\n<p><span class=\"math display\">\\[ \\begin{cases} u_1=2\\\\ u_2=3\\\\ u_3=4\\\\\r\nl_1u_1=1\\\\ l_1u_2+u_4=1\\\\ l_1u_3+u_5=9\\\\ l_2u_1=1\\\\ l_2u_2+l_3u_4=2\\\\\r\nl_2u_3+l_3u_5+u_6=-6 \\end{cases} \\]</span></p>\r\n<p>上面的方程组非常容易解，最后求出</p>\r\n<p><span class=\"math display\">\\[ L =\r\n\\begin{bmatrix}1&amp;0&amp;0\\\\\\frac{1}{2}&amp;1&amp;0\\\\\\frac{1}{2}&amp;-1&amp;1\\end{bmatrix},U=\\begin{bmatrix}2&amp;3&amp;4\\\\0&amp;-\\frac{1}{2}&amp;7\\\\0&amp;0&amp;-1\\end{bmatrix}\r\n\\]</span></p>\r\n<h2 id=\"奇异值分解\">奇异值分解</h2>\r\n<p><strong>奇异值</strong>：设 <span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{m × n}_r,AA^H\\)</span> 的特征值为 <span\r\nclass=\"math display\">\\[\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_n =\r\n0\\]</span></p>\r\n<p>则称 <span class=\"math inline\">\\(\\sigma_i=\\sqrt{\\lambda_i}\\)</span>\r\n为矩阵A的正奇异值。<strong><span class=\"math inline\">\\(A\\)</span>\r\n和<span class=\"math inline\">\\(A^H\\)</span>相同的奇异值</strong>。</p>\r\n<p><strong>奇异值分解</strong>：当给定一个大小为<span\r\nclass=\"math inline\">\\(m × n\\)</span>的矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>,虽然矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>不一定是方阵，但大小为<span\r\nclass=\"math inline\">\\(m × m\\)</span>的<span\r\nclass=\"math inline\">\\(AA^T\\)</span>和<span class=\"math inline\">\\(n ×\r\nn\\)</span>的<span class=\"math inline\">\\(AA^T\\)</span>是对称矩阵,若<span\r\nclass=\"math inline\">\\(AA^T=P \\Lambda_1 Q^T\\)</span>,<span\r\nclass=\"math inline\">\\(A^T A=Q\\Lambda_2\r\nQ^T\\)</span>,则矩阵A的奇异值分解为 <span\r\nclass=\"math display\">\\[A=P\\Sigma Q^T\\]</span></p>\r\n<p>其中，矩阵<span class=\"math inline\">\\(P=(\\overrightarrow{p_1},\r\n\\overrightarrow{p_2}, \\dots, \\overrightarrow{p_m})\\)</span>的大小为\r\n<span class=\"math inline\">\\(m × m\\)</span>，列向量 <span\r\nclass=\"math inline\">\\(\\overrightarrow{p_1}, \\overrightarrow{p_2}, \\dots,\r\n\\overrightarrow{p_m}\\)</span>是 <span\r\nclass=\"math inline\">\\(AA^T\\)</span>的特征向量，也被称为矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>的左奇异向量（left singular\r\nvector）；矩阵<span class=\"math inline\">\\(Q=(\\overrightarrow{q_1},\r\n\\overrightarrow{q_2}, \\dots, \\overrightarrow{q_m})\\)</span>的大小为\r\n<span class=\"math inline\">\\(n × n\\)</span>，列向量 <span\r\nclass=\"math inline\">\\(\\overrightarrow{q_1}, \\overrightarrow{q_2}, \\dots,\r\n\\overrightarrow{q_m}\\)</span>是 <span\r\nclass=\"math inline\">\\(A^TA\\)</span>的特征向量，也被称为矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>的右奇异向量（left singular\r\nvector）；矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_1\\)</span>的大小为<span\r\nclass=\"math inline\">\\(m × m\\)</span>，矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_2\\)</span>的大小为<span\r\nclass=\"math inline\">\\(n ×\r\nn\\)</span>，两个矩阵对角线上的非零元素相同（即矩阵<span\r\nclass=\"math inline\">\\(AA^T\\)</span>和<span\r\nclass=\"math inline\">\\(A^TA\\)</span>的非零特征值相同）；矩阵<span\r\nclass=\"math inline\">\\(\\Sigma\\)</span>的大小为<span\r\nclass=\"math inline\">\\(m ×\r\nn\\)</span>，位于对角线上的元素被称为<strong>奇异值</strong>（singular\r\nvalue）。</p>\r\n<p>设<span class=\"math inline\">\\(A\\)</span>的秩为r，当 <span\r\nclass=\"math inline\">\\(m \\ne n\\)</span>时，矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_1\\)</span>和<span\r\nclass=\"math inline\">\\(\\Lambda_2\\)</span>的大小显然是不同的，但是他们对角线上的非零元素是相同的，记矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_1\\)</span>(或<span\r\nclass=\"math inline\">\\(\\Lambda_2\\)</span>)对角线上的非零元素为<span\r\nclass=\"math inline\">\\(\\lambda_1,\\lambda_2,\\dots,\\lambda_r\\)</span>，这些数皆为非负数，又记矩阵<span\r\nclass=\"math inline\">\\(\\Sigma\\)</span>对角线上的非零元素分别为<span\r\nclass=\"math inline\">\\(\\sigma_1,\\sigma_2,\\dots,\\sigma_r\\)</span>，则\r\n<span\r\nclass=\"math display\">\\[\\sigma_1=\\sqrt{\\lambda_1},\\sigma_2=\\sqrt{\\lambda_2},\\dots,\\sigma_r=\\sqrt{\\lambda_r}\\]</span></p>\r\n<p>即非零奇异值的平方对应着矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_1\\)</span>（或矩阵<span\r\nclass=\"math inline\">\\(\\Lambda_2\\)</span>）的非零特征值，到这里，我们就不难看出奇异值分解与对称对角化分解的关系了，即我们可以由对称对角化分解得到我们想要的奇异值分解。</p>\r\n<p><strong>例1</strong>：一个<span\r\nclass=\"math inline\">\\(3×2\\)</span>的矩阵<span\r\nclass=\"math inline\">\\(A=\\begin{bmatrix}  1&amp;2 \\\\ 0&amp;0 \\\\ 0&amp;0\r\n\\end{bmatrix}\\)</span>，求其奇异值分解。</p>\r\n<p>由 <span class=\"math display\">\\[AA^T=\\begin{bmatrix}\r\n    5&amp;0&amp;0 \\\\ 0&amp;0&amp;0 \\\\ 0&amp;0&amp;0\r\n\\end{bmatrix}\\]</span></p>\r\n<p>得到其特征值<span\r\nclass=\"math inline\">\\(\\lambda_1=5,\\lambda_2=\\lambda_3=0\\)</span>，特征向量为<span\r\nclass=\"math inline\">\\(\\overrightarrow{p_1}=(1,0,0)^T,\\overrightarrow{p_2}=(0,1,0)^T,\\overrightarrow{p_3}=(0,0,1)^T\\)</span></p>\r\n<p>由 <span class=\"math display\">\\[A^TA=\\begin{bmatrix}\r\n    1&amp;2 \\\\ 2&amp;4\r\n\\end{bmatrix}\\]</span></p>\r\n<p>得到其特征值<span\r\nclass=\"math inline\">\\(\\lambda_1=5,\\lambda_2=0\\)</span>，特征向量为<span\r\nclass=\"math inline\">\\(\\overrightarrow{q_1}=(\\frac{\\sqrt{5}}{5},\\frac{2\\sqrt{5}}{5})^T,\\overrightarrow{q_2}=(-\\frac{\\sqrt{5}}{5},\\frac{2\\sqrt{5}}{5})^T\\)</span></p>\r\n<p>令 <span class=\"math display\">\\[\\Sigma=\\begin{bmatrix}\r\n    \\sqrt{5}&amp;0 \\\\ 0&amp;0 \\\\ 0&amp;0\r\n\\end{bmatrix}\\]</span></p>\r\n<p>注意矩阵<span class=\"math inline\">\\(\\Sigma\\)</span>的大小为<span\r\nclass=\"math inline\">\\(3 × 2\\)</span>，此时，矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>的奇异值分解为 <span\r\nclass=\"math display\">\\[A=P\\Sigma Q^T=(\\overrightarrow{p_1},\r\n\\overrightarrow{p_2}, \\overrightarrow{p_3})\\Sigma (\\overrightarrow{q_1},\r\n\\overrightarrow{q_2})^T \\\\ =\\begin{bmatrix}\r\n    1&amp;0&amp;0 \\\\ 0&amp;1&amp;0 \\\\ 0&amp;0&amp;1\r\n\\end{bmatrix} \\begin{bmatrix}\r\n    \\sqrt{5}&amp;0 \\\\ 0&amp;0 \\\\ 0&amp;0\r\n\\end{bmatrix} \\begin{bmatrix}\r\n    \\frac{\\sqrt{5}}{5}&amp;\\frac{2\\sqrt{5}}{5} \\\\\r\n\\frac{-2\\sqrt{5}}{5}&amp;\\frac{\\sqrt{5}}{5}\r\n\\end{bmatrix} = \\begin{bmatrix}\r\n    1&amp;2 \\\\ 0&amp;0 \\\\ 0&amp;0\r\n\\end{bmatrix}\\]</span></p>\r\n<p><strong>例2</strong>：求对称矩阵<span\r\nclass=\"math inline\">\\(A=\\begin{bmatrix}  2&amp;1 \\\\ 1&amp;2\r\n\\end{bmatrix}\\)</span>的奇异值分解。</p>\r\n<p>经计算可以发现<span\r\nclass=\"math inline\">\\(A^TA=AA^T=\\begin{bmatrix}  2&amp;1 \\\\ 1&amp;2\r\n\\end{bmatrix} \\begin{bmatrix}  2&amp;1 \\\\ 1&amp;2\r\n\\end{bmatrix}=\\begin{bmatrix}  5&amp;4 \\\\ 4&amp;5\r\n\\end{bmatrix}\\)</span>，左奇异向量和右奇异向量构成的矩阵也是相等的，即\r\n<span class=\"math display\">\\[P=Q=\\begin{bmatrix}\r\n    \\frac{\\sqrt{2}}{2}&amp;\\frac{\\sqrt{2}}{2} \\\\\r\n-\\frac{\\sqrt{2}}{2}&amp;\\frac{\\sqrt{2}}{2}\r\n\\end{bmatrix}\\]</span></p>\r\n<p>则其奇异值分解为 <span class=\"math display\">\\[A=P\\Sigma\r\nQ^T=\\begin{bmatrix}\r\n    \\frac{\\sqrt{2}}{2}&amp;\\frac{\\sqrt{2}}{2} \\\\ -\r\n\\frac{\\sqrt{2}}{2}&amp; \\frac{\\sqrt{2}}{2}\r\n\\end{bmatrix}\r\n\\begin{bmatrix}\r\n    3&amp;0 \\\\ 0&amp;1\r\n\\end{bmatrix}\\begin{bmatrix}\r\n    \\frac{\\sqrt{2}}{2}&amp;\\frac{\\sqrt{2}}{2} \\\\\r\n-\\frac{\\sqrt{2}}{2}&amp;\\frac{\\sqrt{2}}{2}\r\n\\end{bmatrix}\\]</span></p>\r\n<p><strong>注</strong>：这是由于当矩阵<span\r\nclass=\"math inline\">\\(A\\)</span>为对称矩阵时，其可以被正交对角化，这时奇异值分解等于正交对角化分解。</p>\r\n<h2 id=\"谱分解\">谱分解</h2>\r\n<p><strong>谱分解</strong>：设 <span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{n × n}\\)</span>是单纯矩阵，则 <span\r\nclass=\"math inline\">\\(A\\)</span>可以分解为一系列幂等矩阵 <span\r\nclass=\"math inline\">\\(A_i(i=1,2, \\dots,n)\\)</span>的加权和 <span\r\nclass=\"math display\">\\[A=\\sum_{i=1}^n \\lambda_i A_i\\]</span></p>\r\n<p>其中 <span\r\nclass=\"math inline\">\\(\\lambda_i(i=1,2,\\dots,n)\\)</span>是A的特征值。</p>\r\n<p><strong>单纯矩阵</strong>：若矩阵 <span\r\nclass=\"math inline\">\\(A\\)</span>的<strong>代数重数</strong>等于<strong>几何重数</strong>，则称<span\r\nclass=\"math inline\">\\(A\\)</span>为单纯矩阵。<strong>代数重数</strong>为矩阵\r\n<span\r\nclass=\"math inline\">\\(A\\)</span>特征值的重数，<strong>几何重数</strong>为齐次方程组<span\r\nclass=\"math inline\">\\(Ax=\\lambda_i\r\nx(i=1,2,\\dots,k)\\)</span>的解空间<span\r\nclass=\"math inline\">\\(V_{\\lambda_i}\\)</span>的维数，也即特征值对应的最多无关特征向量数。</p>\r\n<p><strong>幂等矩阵</strong>：若 <span\r\nclass=\"math inline\">\\(A\\)</span>为方阵，且 <span\r\nclass=\"math inline\">\\(A^2=A\\)</span>，则称<span\r\nclass=\"math inline\">\\(A\\)</span>为幂等矩阵。所有幂等矩阵都相似与对角元全为0或1的对角阵。</p>\r\n<p><strong>更一般的单纯矩阵谱分解定理</strong>：设 <span\r\nclass=\"math inline\">\\(A \\in \\mathbb{C}^{n × n}\\)</span>，他有 <span\r\nclass=\"math inline\">\\(k\\)</span>个相异特征值 <span\r\nclass=\"math inline\">\\(\\lambda_i(i=1,2,\\dots,k)\\)</span>，则 <span\r\nclass=\"math inline\">\\(A\\)</span>是单纯矩阵的充要条件是存在<span\r\nclass=\"math inline\">\\(k\\)</span>个矩阵<span\r\nclass=\"math inline\">\\(A_i(i=1,2,\\dots,k)\\)</span>满足</p>\r\n<ol type=\"1\">\r\n<li><span class=\"math inline\">\\(A_i A_j = \\begin{cases}  A_i, i=j \\\\ 0,\r\ni\\ne j \\end{cases}\\)</span></li>\r\n<li><span class=\"math inline\">\\(\\sum_{i=1}^k A_i = E_n\\)</span></li>\r\n<li><span class=\"math inline\">\\(A=\\sum_{i=1}^k \\lambda_i\r\nA_i\\)</span></li>\r\n</ol>\r\n<p>该定理比定理3要求放宽了，不再要求必须要有n个特征值了，这里的k可以小于等于n。</p>\r\n<p><strong>例1</strong>：求正规矩阵 <span class=\"math inline\">\\(A =\r\n\\begin{bmatrix}  0&amp;1&amp;1&amp;1 \\\\ 1&amp;0&amp;-1&amp;1 \\\\\r\n1&amp;-1&amp;0&amp;1 \\\\ -1&amp;1&amp;1&amp;0\r\n\\end{bmatrix}\\)</span>的谱分解表达式。</p>\r\n<p><strong>解</strong>：首先计算 <span\r\nclass=\"math inline\">\\(A\\)</span>的特征值和特征向量 <span\r\nclass=\"math display\">\\[|\\lambda_ I - A |=(\\lambda - 1)^3 (\\lambda +\r\n3)\\]</span></p>\r\n<p>从而 <span class=\"math inline\">\\(A\\)</span>的特征值为 <span\r\nclass=\"math display\">\\[\\lambda_1=\\lambda_2=\\lambda_3=1,\\lambda_4=-3\\]</span></p>\r\n<p>当<span\r\nclass=\"math inline\">\\(\\lambda=1\\)</span>时，求得无关的特征向量为 <span\r\nclass=\"math display\">\\[\\alpha_1=(1,1,0,0)^T \\\\ \\alpha_2=(1,0,1,0)^T \\\\\r\n\\alpha_3=(-1,0,0,1)^T\\]</span></p>\r\n<p>当<span\r\nclass=\"math inline\">\\(\\lambda=-3\\)</span>时，求得无关的特征向量为 <span\r\nclass=\"math display\">\\[\\alpha_4=(1,-1,-1,1)^T\\]</span></p>\r\n<p>将 <span\r\nclass=\"math inline\">\\(\\alpha_1,\\alpha_2,\\alpha_3\\)</span>正交化并单位化得\r\n<span\r\nclass=\"math display\">\\[\\eta_1=(\\frac{1}{\\sqrt{2}},\\frac{1}{\\sqrt{2}},0,0)^T\r\n\\\\\r\n\\eta_2=(\\frac{1}{\\sqrt{6}},\\frac{1}{\\sqrt{6}},\\frac{2}{\\sqrt{6}},0)^T \\\\\r\n\\eta_3=(-\\frac{1}{2\\sqrt{3}},\\frac{1}{2\\sqrt{3}},\\frac{1}{\\sqrt{3}},\\frac{3}{2\\sqrt{3}})^T\\]</span></p>\r\n<p>将<span class=\"math inline\">\\(\\alpha_4\\)</span>单位话得 <span\r\nclass=\"math display\">\\[\\eta_4=(\\frac{1}{2},\r\n-\\frac{1}{2},-\\frac{1}{2},\\frac{1}{2})\\]</span></p>\r\n<p>故有 <span class=\"math display\">\\[G_1=\\eta_1 \\eta_1^H+\\eta_2 \\eta_2^H\r\n+\\eta_3 \\eta_3^H \\\\\r\n= \\begin{bmatrix}\r\n    \\frac{3}{4}&amp;\\frac{1}{4}&amp;\\frac{1}{4}&amp;-\\frac{1}{4} \\\\\r\n    \\frac{1}{4}&amp;\\frac{3}{4}&amp;-\\frac{1}{4}&amp;\\frac{1}{4} \\\\\r\n    \\frac{1}{4}&amp;-\\frac{1}{4}&amp;\\frac{3}{4}&amp;\\frac{1}{4} \\\\\r\n    -\\frac{1}{4}&amp;\\frac{1}{4}&amp;\\frac{1}{4}&amp;\\frac{3}{4}    \r\n\\end{bmatrix}\\]</span></p>\r\n<p><span class=\"math display\">\\[G_2=\\eta_4 \\eta_4^H \\\\\r\n=\\begin{bmatrix}\r\n    \\frac{1}{4}&amp;-\\frac{1}{4}&amp;-\\frac{1}{4}&amp;\\frac{1}{4} \\\\\r\n    -\\frac{1}{4}&amp;\\frac{1}{4}&amp;\\frac{1}{4}&amp;-\\frac{1}{4} \\\\\r\n    -\\frac{1}{4}&amp;\\frac{1}{4}&amp;\\frac{1}{4}&amp;-\\frac{1}{4} \\\\\r\n    \\frac{1}{4}&amp;-\\frac{1}{4}&amp;-\\frac{1}{4}&amp;\\frac{1}{4}\r\n\\end{bmatrix}\\]</span></p>\r\n<p>这样其谱分解表达式为 <span class=\"math display\">\\[A=G_1 -\r\n3G_2\\]</span></p>\r\n<p>注意<span class=\"math inline\">\\(G_1\\)</span>和<span\r\nclass=\"math inline\">\\(G_2\\)</span>的系数<span\r\nclass=\"math inline\">\\(\\lambda_i\\)</span>为其对应的特征值。\r\n<!-- https://www.cnblogs.com/blairgrowing/p/15800825.html --></p>\r\n"},{"title":"特征值估计","_content":"**shur不等式**\n![](/img/矩阵论/特征值估计-shur不等式.png)\n\n证明如下：\n![](/img/矩阵论/shur不等式证明.png)\n\n**行盖尔圆盘和列盖尔圆盘**：\n![](/img/矩阵论/盖尔圆盘.png)\n\n**圆盘定理**：\n![](/img/矩阵论/圆盘定理1.png)\n![](/img/矩阵论/圆盘定理2.png)\n\n推论1：设$n$阶方阵$A$的$n$个盖尔圆盘两两互不相交，则$A$相似于对角阵.\n\n推论2： 设$n$阶实阵$A$的$n$个盖尔圆盘两两互不相交，则$A$特征值全为实数.\n\n**对角占优矩阵**：\n\n![](/img/矩阵论/对角占优矩阵.png)\n\n**Rayleigh商**：设$A \\in \\mathbb{C}^{n \\times n}$为Hermite矩阵，$x \\in \\mathbb{C}$，称\n$$R(x)=\\frac{x^HAx}{x^Hx}, x \\ne 0$$\n\n为$A$的Rayleigh商。\n\n**定理（Rayleigh-Ritz）**:\n![](/img/矩阵论/Rayleigh-Ritz定理.png)\n\n","source":"_posts/特征值估计.md","raw":"---\ntitle: 特征值估计\ntags: 矩阵论\ncategories: \n    - 数学\n    - 矩阵论\n---\n**shur不等式**\n![](/img/矩阵论/特征值估计-shur不等式.png)\n\n证明如下：\n![](/img/矩阵论/shur不等式证明.png)\n\n**行盖尔圆盘和列盖尔圆盘**：\n![](/img/矩阵论/盖尔圆盘.png)\n\n**圆盘定理**：\n![](/img/矩阵论/圆盘定理1.png)\n![](/img/矩阵论/圆盘定理2.png)\n\n推论1：设$n$阶方阵$A$的$n$个盖尔圆盘两两互不相交，则$A$相似于对角阵.\n\n推论2： 设$n$阶实阵$A$的$n$个盖尔圆盘两两互不相交，则$A$特征值全为实数.\n\n**对角占优矩阵**：\n\n![](/img/矩阵论/对角占优矩阵.png)\n\n**Rayleigh商**：设$A \\in \\mathbb{C}^{n \\times n}$为Hermite矩阵，$x \\in \\mathbb{C}$，称\n$$R(x)=\\frac{x^HAx}{x^Hx}, x \\ne 0$$\n\n为$A$的Rayleigh商。\n\n**定理（Rayleigh-Ritz）**:\n![](/img/矩阵论/Rayleigh-Ritz定理.png)\n\n","slug":"特征值估计","published":1,"date":"2022-12-07T14:46:35.987Z","updated":"2022-12-08T01:35:49.575Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8oe000nr4sghcmtbwke","content":"<p><strong>shur不等式</strong> <img\r\nsrc=\"/img/矩阵论/特征值估计-shur不等式.png\" /></p>\r\n<p>证明如下： <img src=\"/img/矩阵论/shur不等式证明.png\" /></p>\r\n<p><strong>行盖尔圆盘和列盖尔圆盘</strong>： <img\r\nsrc=\"/img/矩阵论/盖尔圆盘.png\" /></p>\r\n<p><strong>圆盘定理</strong>： <img src=\"/img/矩阵论/圆盘定理1.png\" />\r\n<img src=\"/img/矩阵论/圆盘定理2.png\" /></p>\r\n<p>推论1：设<span class=\"math inline\">\\(n\\)</span>阶方阵<span\r\nclass=\"math inline\">\\(A\\)</span>的<span\r\nclass=\"math inline\">\\(n\\)</span>个盖尔圆盘两两互不相交，则<span\r\nclass=\"math inline\">\\(A\\)</span>相似于对角阵.</p>\r\n<p>推论2： 设<span class=\"math inline\">\\(n\\)</span>阶实阵<span\r\nclass=\"math inline\">\\(A\\)</span>的<span\r\nclass=\"math inline\">\\(n\\)</span>个盖尔圆盘两两互不相交，则<span\r\nclass=\"math inline\">\\(A\\)</span>特征值全为实数.</p>\r\n<p><strong>对角占优矩阵</strong>：</p>\r\n<p><img src=\"/img/矩阵论/对角占优矩阵.png\" /></p>\r\n<p><strong>Rayleigh商</strong>：设<span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{n \\times n}\\)</span>为Hermite矩阵，<span\r\nclass=\"math inline\">\\(x \\in \\mathbb{C}\\)</span>，称 <span\r\nclass=\"math display\">\\[R(x)=\\frac{x^HAx}{x^Hx}, x \\ne 0\\]</span></p>\r\n<p>为<span class=\"math inline\">\\(A\\)</span>的Rayleigh商。</p>\r\n<p><strong>定理（Rayleigh-Ritz）</strong>: <img\r\nsrc=\"/img/矩阵论/Rayleigh-Ritz定理.png\" /></p>\r\n","site":{"data":{}},"excerpt":"","more":"<p><strong>shur不等式</strong> <img\r\nsrc=\"/img/矩阵论/特征值估计-shur不等式.png\" /></p>\r\n<p>证明如下： <img src=\"/img/矩阵论/shur不等式证明.png\" /></p>\r\n<p><strong>行盖尔圆盘和列盖尔圆盘</strong>： <img\r\nsrc=\"/img/矩阵论/盖尔圆盘.png\" /></p>\r\n<p><strong>圆盘定理</strong>： <img src=\"/img/矩阵论/圆盘定理1.png\" />\r\n<img src=\"/img/矩阵论/圆盘定理2.png\" /></p>\r\n<p>推论1：设<span class=\"math inline\">\\(n\\)</span>阶方阵<span\r\nclass=\"math inline\">\\(A\\)</span>的<span\r\nclass=\"math inline\">\\(n\\)</span>个盖尔圆盘两两互不相交，则<span\r\nclass=\"math inline\">\\(A\\)</span>相似于对角阵.</p>\r\n<p>推论2： 设<span class=\"math inline\">\\(n\\)</span>阶实阵<span\r\nclass=\"math inline\">\\(A\\)</span>的<span\r\nclass=\"math inline\">\\(n\\)</span>个盖尔圆盘两两互不相交，则<span\r\nclass=\"math inline\">\\(A\\)</span>特征值全为实数.</p>\r\n<p><strong>对角占优矩阵</strong>：</p>\r\n<p><img src=\"/img/矩阵论/对角占优矩阵.png\" /></p>\r\n<p><strong>Rayleigh商</strong>：设<span class=\"math inline\">\\(A \\in\r\n\\mathbb{C}^{n \\times n}\\)</span>为Hermite矩阵，<span\r\nclass=\"math inline\">\\(x \\in \\mathbb{C}\\)</span>，称 <span\r\nclass=\"math display\">\\[R(x)=\\frac{x^HAx}{x^Hx}, x \\ne 0\\]</span></p>\r\n<p>为<span class=\"math inline\">\\(A\\)</span>的Rayleigh商。</p>\r\n<p><strong>定理（Rayleigh-Ritz）</strong>: <img\r\nsrc=\"/img/矩阵论/Rayleigh-Ritz定理.png\" /></p>\r\n"},{"title":"红黑树","categorires":"算法","math":true,"_content":"\n\n# 红黑树\n红黑树是一种特化的AVL树（平衡二叉树），都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。 \n\n它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的： 它可以在O(log n)时间内做查找，插入和删除，这里的n 是树中元素的数目。\n\n## 红黑树的性质\n1. 每个节点要么是黑色，要么是红色。\n2. 根节点是黑色。\n3. 每个叶子节点（NIL）是黑色。\n4. 每个红色结点的两个子结点一定都是黑色\n5. 任意一结点到每个叶子结点的路径都包含数量相同的黑结点。（保证这棵树尽量是平衡的。）\n\n由性质5我们可以推出：  \n    性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点。\n\n## 红黑树和AVL的区别\n1. 如果插入一个node引起了树的不平衡，AVL和RB-Tree都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度。\n\n2. 其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。\n\n3. map的实现只是折衷了两者在search、insert以及delete下的效率。总体来说，RB-tree的统计性能是高于AVL的。","source":"_posts/红黑树.md","raw":"---\ntitle: 红黑树\ncategorires: 算法\ntags: 算法\nmath: true\n---\n\n\n# 红黑树\n红黑树是一种特化的AVL树（平衡二叉树），都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。 \n\n它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的： 它可以在O(log n)时间内做查找，插入和删除，这里的n 是树中元素的数目。\n\n## 红黑树的性质\n1. 每个节点要么是黑色，要么是红色。\n2. 根节点是黑色。\n3. 每个叶子节点（NIL）是黑色。\n4. 每个红色结点的两个子结点一定都是黑色\n5. 任意一结点到每个叶子结点的路径都包含数量相同的黑结点。（保证这棵树尽量是平衡的。）\n\n由性质5我们可以推出：  \n    性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点。\n\n## 红黑树和AVL的区别\n1. 如果插入一个node引起了树的不平衡，AVL和RB-Tree都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度。\n\n2. 其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。\n\n3. map的实现只是折衷了两者在search、insert以及delete下的效率。总体来说，RB-tree的统计性能是高于AVL的。","slug":"红黑树","published":1,"date":"2022-12-02T04:29:47.325Z","updated":"2022-12-05T14:50:57.012Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8of000rr4sg2z6c8zza","content":"<h1 id=\"红黑树\">红黑树</h1>\r\n<p>红黑树是一种特化的AVL树（平衡二叉树），都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。</p>\r\n<p>它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的：\r\n它可以在O(log n)时间内做查找，插入和删除，这里的n 是树中元素的数目。</p>\r\n<h2 id=\"红黑树的性质\">红黑树的性质</h2>\r\n<ol type=\"1\">\r\n<li>每个节点要么是黑色，要么是红色。</li>\r\n<li>根节点是黑色。</li>\r\n<li>每个叶子节点（NIL）是黑色。</li>\r\n<li>每个红色结点的两个子结点一定都是黑色</li>\r\n<li>任意一结点到每个叶子结点的路径都包含数量相同的黑结点。（保证这棵树尽量是平衡的。）</li>\r\n</ol>\r\n<p>由性质5我们可以推出：<br />\r\n性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点。</p>\r\n<h2 id=\"红黑树和avl的区别\">红黑树和AVL的区别</h2>\r\n<ol type=\"1\">\r\n<li><p>如果插入一个node引起了树的不平衡，AVL和RB-Tree都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度。</p></li>\r\n<li><p>其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。</p></li>\r\n<li><p>map的实现只是折衷了两者在search、insert以及delete下的效率。总体来说，RB-tree的统计性能是高于AVL的。</p></li>\r\n</ol>\r\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"红黑树\">红黑树</h1>\r\n<p>红黑树是一种特化的AVL树（平衡二叉树），都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。</p>\r\n<p>它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的：\r\n它可以在O(log n)时间内做查找，插入和删除，这里的n 是树中元素的数目。</p>\r\n<h2 id=\"红黑树的性质\">红黑树的性质</h2>\r\n<ol type=\"1\">\r\n<li>每个节点要么是黑色，要么是红色。</li>\r\n<li>根节点是黑色。</li>\r\n<li>每个叶子节点（NIL）是黑色。</li>\r\n<li>每个红色结点的两个子结点一定都是黑色</li>\r\n<li>任意一结点到每个叶子结点的路径都包含数量相同的黑结点。（保证这棵树尽量是平衡的。）</li>\r\n</ol>\r\n<p>由性质5我们可以推出：<br />\r\n性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点。</p>\r\n<h2 id=\"红黑树和avl的区别\">红黑树和AVL的区别</h2>\r\n<ol type=\"1\">\r\n<li><p>如果插入一个node引起了树的不平衡，AVL和RB-Tree都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度。</p></li>\r\n<li><p>其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。</p></li>\r\n<li><p>map的实现只是折衷了两者在search、insert以及delete下的效率。总体来说，RB-tree的统计性能是高于AVL的。</p></li>\r\n</ol>\r\n"},{"title":"范数","_content":"\n不管向量范数、矩阵范数还是算子范数，都需要满足三个特性:\n\n- 正定性\n- 齐次性\n- 三角不等式\n\n## 向量范数\n**1 - 范数**：$\\Vert \\boldsymbol {x}\\Vert_1=\\sum\\limits_{i=1}^N |x_i|$，即向量元素绝对值之和\n\n**2 - 范数**：$\\Vert \\boldsymbol {x}\\Vert_2=(\\sum\\limits_{i=1}^N (x_i)^2)^{\\frac {1}{2}}$，也叫欧几里得范数，常用于计算向量长度，即向量元素的平方和再开方\n\n**$\\infty$- 范数**:$\\Vert \\boldsymbol {x}\\Vert_{\\infty}=\\max\\limits_{i} |x_i|$，即所有向量元素中绝对值的最大值\n\n<!-- **-$\\infty$- 范数**:$\\Vert \\boldsymbol {x}\\Vert_{-\\infty}=\\min\\limits_{i} |x_i|$，即所有向量元素绝对值中的最小值 -->\n\n**P - 范数**:$\\Vert \\boldsymbol {x}\\Vert_p=(\\sum\\limits_{i=1}^N (x_i)^p)^{\\frac {1}{p}}$，即向量元素的 p 次方和再开 p 次方\n\n\n## 矩阵范数\n设$A \\in \\mathbb{C}^{m × n}$，则\n\n${||A||}_{m_1} = \\sum\\limits^{n}_{j=1} \\sum\\limits^{m}_{i=1} |a_{ij}|$\n\n$||A||_{m_2} = {||A||}_{F} =\\sqrt{\\sum\\limits^{n}_{j=1} \\sum\\limits^{m}_{i=1} |a_{ij}^2|} = \\sqrt{tr(A^HA)} = \\sqrt{tr(AA^H)}$\n\n$||A||_{m_\\infty}=\\max\\limits_{i,j}\\{|a_{ij}|\\}, 1\\le i \\le m, 1 \\le j \\le n$\n\n\n\n### 矩阵范数的性质\n![](/img/矩阵论/矩阵范数性质-定理1.png)\n![](/img/矩阵论/矩阵范数性质-定理1-2.png)\n\n- ${||A||}_{m_1}$ 范数与向量范数$||x||_1$相容\n- ${||A||}_{m_2}$ 范数与向量范数$||x||_2$相容\n- ${||A||}_{m_{\\infty}}$范数与向量范数 $||x||_\\infty$ 不相容\n## 算子范数\n算子范数定义1：\n![](/img/矩阵论/算子范数定义1.png)\n\n注意：并不是所以的矩阵范数都与向量范数相容。只有满足该条件的矩阵范数才与向量范数是相容的。\n\n算子范数定义2：\n![](/img/矩阵论/算子范数定义2.png)\n\n**则称此矩阵范数为从属于向量范数 $||x||$ 的算子范数**。这里的x可是n维空间的任意取向。\n\n**算子范数表示**：\n\n${||A||}_1=\\max\\limits_{1 \\le j \\le n}\\{\\sum\\limits^{s}_{j=1}|a_{ij}|\\}$, 列模和范数，即所有矩阵列向量绝对值之和的最大值\n\n$||A||_2=\\sqrt{\\rho(A^HA)}$， 谱范数\n\n$||A||_\\infty=\\max\\limits_{1 \\le i \\le s}\\{\\sum^n_{j=1}|a_{ij}|\\}$, 行模和范数,即所有矩阵行向量绝对值之和的最大值\n\n### 算子范数性质\n- ${||A||}_{1}$ 范数与向量范数 $||x||_1$ 相容\n- ${||A||}_{2}$ 范数与向量范数 $||x||_2$ 相容\n- $||·||_a$是算子范数 $\\Rightarrow ||E||_a = 1$\n- 设$A \\in \\mathbb{C}^{n × n}， ||A||$是从属向量范数$||x||$的算子范数，若$||A|| < 1$,则 $E \t\\pm A$ 可逆，且$||(E \\pm A)^{-1} \\le 1 - ||A||^{-1}$ \n\n![](/img/矩阵论/算子范数性质-定理3.png)","source":"_posts/范数.md","raw":"---\ntitle: 范数\ntags: \n    - 矩阵论\ncategories: \n    - 数学\n    - 矩阵论\n---\n\n不管向量范数、矩阵范数还是算子范数，都需要满足三个特性:\n\n- 正定性\n- 齐次性\n- 三角不等式\n\n## 向量范数\n**1 - 范数**：$\\Vert \\boldsymbol {x}\\Vert_1=\\sum\\limits_{i=1}^N |x_i|$，即向量元素绝对值之和\n\n**2 - 范数**：$\\Vert \\boldsymbol {x}\\Vert_2=(\\sum\\limits_{i=1}^N (x_i)^2)^{\\frac {1}{2}}$，也叫欧几里得范数，常用于计算向量长度，即向量元素的平方和再开方\n\n**$\\infty$- 范数**:$\\Vert \\boldsymbol {x}\\Vert_{\\infty}=\\max\\limits_{i} |x_i|$，即所有向量元素中绝对值的最大值\n\n<!-- **-$\\infty$- 范数**:$\\Vert \\boldsymbol {x}\\Vert_{-\\infty}=\\min\\limits_{i} |x_i|$，即所有向量元素绝对值中的最小值 -->\n\n**P - 范数**:$\\Vert \\boldsymbol {x}\\Vert_p=(\\sum\\limits_{i=1}^N (x_i)^p)^{\\frac {1}{p}}$，即向量元素的 p 次方和再开 p 次方\n\n\n## 矩阵范数\n设$A \\in \\mathbb{C}^{m × n}$，则\n\n${||A||}_{m_1} = \\sum\\limits^{n}_{j=1} \\sum\\limits^{m}_{i=1} |a_{ij}|$\n\n$||A||_{m_2} = {||A||}_{F} =\\sqrt{\\sum\\limits^{n}_{j=1} \\sum\\limits^{m}_{i=1} |a_{ij}^2|} = \\sqrt{tr(A^HA)} = \\sqrt{tr(AA^H)}$\n\n$||A||_{m_\\infty}=\\max\\limits_{i,j}\\{|a_{ij}|\\}, 1\\le i \\le m, 1 \\le j \\le n$\n\n\n\n### 矩阵范数的性质\n![](/img/矩阵论/矩阵范数性质-定理1.png)\n![](/img/矩阵论/矩阵范数性质-定理1-2.png)\n\n- ${||A||}_{m_1}$ 范数与向量范数$||x||_1$相容\n- ${||A||}_{m_2}$ 范数与向量范数$||x||_2$相容\n- ${||A||}_{m_{\\infty}}$范数与向量范数 $||x||_\\infty$ 不相容\n## 算子范数\n算子范数定义1：\n![](/img/矩阵论/算子范数定义1.png)\n\n注意：并不是所以的矩阵范数都与向量范数相容。只有满足该条件的矩阵范数才与向量范数是相容的。\n\n算子范数定义2：\n![](/img/矩阵论/算子范数定义2.png)\n\n**则称此矩阵范数为从属于向量范数 $||x||$ 的算子范数**。这里的x可是n维空间的任意取向。\n\n**算子范数表示**：\n\n${||A||}_1=\\max\\limits_{1 \\le j \\le n}\\{\\sum\\limits^{s}_{j=1}|a_{ij}|\\}$, 列模和范数，即所有矩阵列向量绝对值之和的最大值\n\n$||A||_2=\\sqrt{\\rho(A^HA)}$， 谱范数\n\n$||A||_\\infty=\\max\\limits_{1 \\le i \\le s}\\{\\sum^n_{j=1}|a_{ij}|\\}$, 行模和范数,即所有矩阵行向量绝对值之和的最大值\n\n### 算子范数性质\n- ${||A||}_{1}$ 范数与向量范数 $||x||_1$ 相容\n- ${||A||}_{2}$ 范数与向量范数 $||x||_2$ 相容\n- $||·||_a$是算子范数 $\\Rightarrow ||E||_a = 1$\n- 设$A \\in \\mathbb{C}^{n × n}， ||A||$是从属向量范数$||x||$的算子范数，若$||A|| < 1$,则 $E \t\\pm A$ 可逆，且$||(E \\pm A)^{-1} \\le 1 - ||A||^{-1}$ \n\n![](/img/矩阵论/算子范数性质-定理3.png)","slug":"范数","published":1,"date":"2022-12-07T13:41:37.028Z","updated":"2022-12-08T04:26:41.492Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8og000vr4sgbghm1yxq","content":"<p>不管向量范数、矩阵范数还是算子范数，都需要满足三个特性:</p>\r\n<ul>\r\n<li>正定性</li>\r\n<li>齐次性</li>\r\n<li>三角不等式</li>\r\n</ul>\r\n<h2 id=\"向量范数\">向量范数</h2>\r\n<p><strong>1 - 范数</strong>：<span class=\"math inline\">\\(\\Vert\r\n\\boldsymbol {x}\\Vert_1=\\sum\\limits_{i=1}^N\r\n|x_i|\\)</span>，即向量元素绝对值之和</p>\r\n<p><strong>2 - 范数</strong>：<span class=\"math inline\">\\(\\Vert\r\n\\boldsymbol {x}\\Vert_2=(\\sum\\limits_{i=1}^N (x_i)^2)^{\\frac\r\n{1}{2}}\\)</span>，也叫欧几里得范数，常用于计算向量长度，即向量元素的平方和再开方</p>\r\n<p><strong><span class=\"math inline\">\\(\\infty\\)</span>-\r\n范数</strong>:<span class=\"math inline\">\\(\\Vert \\boldsymbol\r\n{x}\\Vert_{\\infty}=\\max\\limits_{i}\r\n|x_i|\\)</span>，即所有向量元素中绝对值的最大值</p>\r\n<!-- **-$\\infty$- 范数**:$\\Vert \\boldsymbol {x}\\Vert_{-\\infty}=\\min\\limits_{i} |x_i|$，即所有向量元素绝对值中的最小值 -->\r\n<p><strong>P - 范数</strong>:<span class=\"math inline\">\\(\\Vert\r\n\\boldsymbol {x}\\Vert_p=(\\sum\\limits_{i=1}^N (x_i)^p)^{\\frac\r\n{1}{p}}\\)</span>，即向量元素的 p 次方和再开 p 次方</p>\r\n<h2 id=\"矩阵范数\">矩阵范数</h2>\r\n<p>设<span class=\"math inline\">\\(A \\in \\mathbb{C}^{m ×\r\nn}\\)</span>，则</p>\r\n<p><span class=\"math inline\">\\({||A||}_{m_1} = \\sum\\limits^{n}_{j=1}\r\n\\sum\\limits^{m}_{i=1} |a_{ij}|\\)</span></p>\r\n<p><span class=\"math inline\">\\(||A||_{m_2} = {||A||}_{F}\r\n=\\sqrt{\\sum\\limits^{n}_{j=1} \\sum\\limits^{m}_{i=1} |a_{ij}^2|} =\r\n\\sqrt{tr(A^HA)} = \\sqrt{tr(AA^H)}\\)</span></p>\r\n<p><span\r\nclass=\"math inline\">\\(||A||_{m_\\infty}=\\max\\limits_{i,j}\\{|a_{ij}|\\},\r\n1\\le i \\le m, 1 \\le j \\le n\\)</span></p>\r\n<h3 id=\"矩阵范数的性质\">矩阵范数的性质</h3>\r\n<p><img src=\"/img/矩阵论/矩阵范数性质-定理1.png\" /> <img\r\nsrc=\"/img/矩阵论/矩阵范数性质-定理1-2.png\" /></p>\r\n<ul>\r\n<li><span class=\"math inline\">\\({||A||}_{m_1}\\)</span>\r\n范数与向量范数<span class=\"math inline\">\\(||x||_1\\)</span>相容</li>\r\n<li><span class=\"math inline\">\\({||A||}_{m_2}\\)</span>\r\n范数与向量范数<span class=\"math inline\">\\(||x||_2\\)</span>相容</li>\r\n<li><span\r\nclass=\"math inline\">\\({||A||}_{m_{\\infty}}\\)</span>范数与向量范数 <span\r\nclass=\"math inline\">\\(||x||_\\infty\\)</span> 不相容 ## 算子范数\r\n算子范数定义1： <img src=\"/img/矩阵论/算子范数定义1.png\" /></li>\r\n</ul>\r\n<p>注意：并不是所以的矩阵范数都与向量范数相容。只有满足该条件的矩阵范数才与向量范数是相容的。</p>\r\n<p>算子范数定义2： <img src=\"/img/矩阵论/算子范数定义2.png\" /></p>\r\n<p><strong>则称此矩阵范数为从属于向量范数 <span\r\nclass=\"math inline\">\\(||x||\\)</span>\r\n的算子范数</strong>。这里的x可是n维空间的任意取向。</p>\r\n<p><strong>算子范数表示</strong>：</p>\r\n<p><span class=\"math inline\">\\({||A||}_1=\\max\\limits_{1 \\le j \\le\r\nn}\\{\\sum\\limits^{s}_{j=1}|a_{ij}|\\}\\)</span>,\r\n列模和范数，即所有矩阵列向量绝对值之和的最大值</p>\r\n<p><span class=\"math inline\">\\(||A||_2=\\sqrt{\\rho(A^HA)}\\)</span>，\r\n谱范数</p>\r\n<p><span class=\"math inline\">\\(||A||_\\infty=\\max\\limits_{1 \\le i \\le\r\ns}\\{\\sum^n_{j=1}|a_{ij}|\\}\\)</span>,\r\n行模和范数,即所有矩阵行向量绝对值之和的最大值</p>\r\n<h3 id=\"算子范数性质\">算子范数性质</h3>\r\n<ul>\r\n<li><span class=\"math inline\">\\({||A||}_{1}\\)</span> 范数与向量范数\r\n<span class=\"math inline\">\\(||x||_1\\)</span> 相容</li>\r\n<li><span class=\"math inline\">\\({||A||}_{2}\\)</span> 范数与向量范数\r\n<span class=\"math inline\">\\(||x||_2\\)</span> 相容</li>\r\n<li><span class=\"math inline\">\\(||·||_a\\)</span>是算子范数 <span\r\nclass=\"math inline\">\\(\\Rightarrow ||E||_a = 1\\)</span></li>\r\n<li>设<span class=\"math inline\">\\(A \\in \\mathbb{C}^{n × n}，\r\n||A||\\)</span>是从属向量范数<span\r\nclass=\"math inline\">\\(||x||\\)</span>的算子范数，若<span\r\nclass=\"math inline\">\\(||A|| &lt; 1\\)</span>,则 <span\r\nclass=\"math inline\">\\(E \\pm A\\)</span> 可逆，且<span\r\nclass=\"math inline\">\\(||(E \\pm A)^{-1} \\le 1 - ||A||^{-1}\\)</span></li>\r\n</ul>\r\n<p><img src=\"/img/矩阵论/算子范数性质-定理3.png\" /></p>\r\n","site":{"data":{}},"excerpt":"","more":"<p>不管向量范数、矩阵范数还是算子范数，都需要满足三个特性:</p>\r\n<ul>\r\n<li>正定性</li>\r\n<li>齐次性</li>\r\n<li>三角不等式</li>\r\n</ul>\r\n<h2 id=\"向量范数\">向量范数</h2>\r\n<p><strong>1 - 范数</strong>：<span class=\"math inline\">\\(\\Vert\r\n\\boldsymbol {x}\\Vert_1=\\sum\\limits_{i=1}^N\r\n|x_i|\\)</span>，即向量元素绝对值之和</p>\r\n<p><strong>2 - 范数</strong>：<span class=\"math inline\">\\(\\Vert\r\n\\boldsymbol {x}\\Vert_2=(\\sum\\limits_{i=1}^N (x_i)^2)^{\\frac\r\n{1}{2}}\\)</span>，也叫欧几里得范数，常用于计算向量长度，即向量元素的平方和再开方</p>\r\n<p><strong><span class=\"math inline\">\\(\\infty\\)</span>-\r\n范数</strong>:<span class=\"math inline\">\\(\\Vert \\boldsymbol\r\n{x}\\Vert_{\\infty}=\\max\\limits_{i}\r\n|x_i|\\)</span>，即所有向量元素中绝对值的最大值</p>\r\n<!-- **-$\\infty$- 范数**:$\\Vert \\boldsymbol {x}\\Vert_{-\\infty}=\\min\\limits_{i} |x_i|$，即所有向量元素绝对值中的最小值 -->\r\n<p><strong>P - 范数</strong>:<span class=\"math inline\">\\(\\Vert\r\n\\boldsymbol {x}\\Vert_p=(\\sum\\limits_{i=1}^N (x_i)^p)^{\\frac\r\n{1}{p}}\\)</span>，即向量元素的 p 次方和再开 p 次方</p>\r\n<h2 id=\"矩阵范数\">矩阵范数</h2>\r\n<p>设<span class=\"math inline\">\\(A \\in \\mathbb{C}^{m ×\r\nn}\\)</span>，则</p>\r\n<p><span class=\"math inline\">\\({||A||}_{m_1} = \\sum\\limits^{n}_{j=1}\r\n\\sum\\limits^{m}_{i=1} |a_{ij}|\\)</span></p>\r\n<p><span class=\"math inline\">\\(||A||_{m_2} = {||A||}_{F}\r\n=\\sqrt{\\sum\\limits^{n}_{j=1} \\sum\\limits^{m}_{i=1} |a_{ij}^2|} =\r\n\\sqrt{tr(A^HA)} = \\sqrt{tr(AA^H)}\\)</span></p>\r\n<p><span\r\nclass=\"math inline\">\\(||A||_{m_\\infty}=\\max\\limits_{i,j}\\{|a_{ij}|\\},\r\n1\\le i \\le m, 1 \\le j \\le n\\)</span></p>\r\n<h3 id=\"矩阵范数的性质\">矩阵范数的性质</h3>\r\n<p><img src=\"/img/矩阵论/矩阵范数性质-定理1.png\" /> <img\r\nsrc=\"/img/矩阵论/矩阵范数性质-定理1-2.png\" /></p>\r\n<ul>\r\n<li><span class=\"math inline\">\\({||A||}_{m_1}\\)</span>\r\n范数与向量范数<span class=\"math inline\">\\(||x||_1\\)</span>相容</li>\r\n<li><span class=\"math inline\">\\({||A||}_{m_2}\\)</span>\r\n范数与向量范数<span class=\"math inline\">\\(||x||_2\\)</span>相容</li>\r\n<li><span\r\nclass=\"math inline\">\\({||A||}_{m_{\\infty}}\\)</span>范数与向量范数 <span\r\nclass=\"math inline\">\\(||x||_\\infty\\)</span> 不相容 ## 算子范数\r\n算子范数定义1： <img src=\"/img/矩阵论/算子范数定义1.png\" /></li>\r\n</ul>\r\n<p>注意：并不是所以的矩阵范数都与向量范数相容。只有满足该条件的矩阵范数才与向量范数是相容的。</p>\r\n<p>算子范数定义2： <img src=\"/img/矩阵论/算子范数定义2.png\" /></p>\r\n<p><strong>则称此矩阵范数为从属于向量范数 <span\r\nclass=\"math inline\">\\(||x||\\)</span>\r\n的算子范数</strong>。这里的x可是n维空间的任意取向。</p>\r\n<p><strong>算子范数表示</strong>：</p>\r\n<p><span class=\"math inline\">\\({||A||}_1=\\max\\limits_{1 \\le j \\le\r\nn}\\{\\sum\\limits^{s}_{j=1}|a_{ij}|\\}\\)</span>,\r\n列模和范数，即所有矩阵列向量绝对值之和的最大值</p>\r\n<p><span class=\"math inline\">\\(||A||_2=\\sqrt{\\rho(A^HA)}\\)</span>，\r\n谱范数</p>\r\n<p><span class=\"math inline\">\\(||A||_\\infty=\\max\\limits_{1 \\le i \\le\r\ns}\\{\\sum^n_{j=1}|a_{ij}|\\}\\)</span>,\r\n行模和范数,即所有矩阵行向量绝对值之和的最大值</p>\r\n<h3 id=\"算子范数性质\">算子范数性质</h3>\r\n<ul>\r\n<li><span class=\"math inline\">\\({||A||}_{1}\\)</span> 范数与向量范数\r\n<span class=\"math inline\">\\(||x||_1\\)</span> 相容</li>\r\n<li><span class=\"math inline\">\\({||A||}_{2}\\)</span> 范数与向量范数\r\n<span class=\"math inline\">\\(||x||_2\\)</span> 相容</li>\r\n<li><span class=\"math inline\">\\(||·||_a\\)</span>是算子范数 <span\r\nclass=\"math inline\">\\(\\Rightarrow ||E||_a = 1\\)</span></li>\r\n<li>设<span class=\"math inline\">\\(A \\in \\mathbb{C}^{n × n}，\r\n||A||\\)</span>是从属向量范数<span\r\nclass=\"math inline\">\\(||x||\\)</span>的算子范数，若<span\r\nclass=\"math inline\">\\(||A|| &lt; 1\\)</span>,则 <span\r\nclass=\"math inline\">\\(E \\pm A\\)</span> 可逆，且<span\r\nclass=\"math inline\">\\(||(E \\pm A)^{-1} \\le 1 - ||A||^{-1}\\)</span></li>\r\n</ul>\r\n<p><img src=\"/img/矩阵论/算子范数性质-定理3.png\" /></p>\r\n"},{"title":"胜者树与败者树","math":true,"_content":"\n胜者树与败者树是完全二叉树。就像是参加比赛一样，每个选手有不同的实力，两个选手PK,实力决定胜负，晋级下一轮，经过几轮之后，就能得到冠军。不同的是，胜者树的中间结点记录的是胜者的标号；而败者树的中间结点记录的败者的标号。 胜者树与败者树可以在log(n)的时间内找到最值。任何一个叶子结点的值改变后，利用中间结点的信息，还是能够快速地找到最值。在k路归并排序中经常用到。\n\n\n## 胜者树\n胜者树的一个优点是，如果一个选手的值改变了，可以很容易地修改这棵胜者树。只需要沿着从该结点到根结点的路径修改这棵二叉树，而不必改变其他比赛的结果。\n\n![fig1](/img/胜者树败者树/fig1.jpg)\n\n上图是一个胜者树的示例。规定数值小者胜。\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；\n2. b3 PK b0，b3胜b0负，内部结点ls[2]的值为3；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；\n4. b3 PK b1，b3胜b1负，内部结点ls[1]的值为3。\n\n取出胜者b3之后，叶子结点b3的值变为11时，重构的胜者树如下:\n\n![fig2](/img/胜者树败者树/fig2.jpg)\n\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；\n2. b3 PK b0，b0胜b3负，内部结点ls[2]的值为0；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；\n4. b0 PK b1，b1胜b0负，内部结点ls[1]的值为1。\n\n用胜者树对n个节点实现排序操作，构建胜者树和构建堆比较相似，区别在于胜者树只有叶子节点存放了数据，中间节点记录的是叶子节点间的关系。\n\n胜者树在每次重构时只需与其兄弟结点比较，一直到根节点选出胜者为止。\n\n## 败者树\n败者树是胜者树的一种变体。在败者树中，用父结点记录其左右子结点进行比赛的败者，而让胜者参加下一轮的比赛。败者树的根结点记录的是败者，需要加一个结点来记录整个比赛的胜利者。采用败者树可以简化重构的过程。\n\n![fig3](/img/胜者树败者树/fig3.jpg)\n\n上图是一棵败者树。规定数大者败。\n\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为4；\n2. b3 PK b0，b3胜b0负，内部结点ls[2]的值为0；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为2；\n4. b3 PK b1，b3胜b1负，内部结点ls[1]的值为1；\n\n败者树重构过程如下：\n- 将新进入选择树的结点与其父结点进行比赛：将败者存放在父结点中；而胜者再与上一级的父结点比较。\n- 比赛沿着到根结点的路径不断进行，直到ls[1]处。把败者存放在结点ls[1]中，胜者存放在ls[0]中。\n\n![fig4](/img/胜者树败者树/fig4.jpg)\n\n## 胜者树、败者树、堆比较\n### 相同点  \n这三者空间和时间复杂度都是一样的。调整一次的时间复杂度都是O(logN)的。\n\n### 不同点\n一开始就是只有堆来完成多路归并的，但是人们发现堆每次取出最小值之后，把最后一个数放到堆顶，**调整堆的时候，每次都要选出父结点的两个孩子节点的最小值，然后再用孩子结点的最小值和父节点进行比较，所以每调整一层需要比较两次**。\n\n这时人们想能否简化比较过程，这时就有了胜者树。这样**每次比较只用跟自己的兄弟结点进行比较就好**，所以用胜者树可以比堆少一半的比较次数。\n\n而**胜者树想要比较兄弟结点首先要获得其父结点，也就是说需要访存两次**，这时人们又想能否再次减少比较次数，于是就有了败者树。败者树每个新元素上升时，**只需要获得父节点并比较即可**。\n\n总的来说，败者树与胜者树相比减少了访存时间。**现在程序的主要瓶颈在于访存了，计算倒几乎可以忽略不计了**。\n\n## 参考\n1. [胜者树和败者树](https://www.cnblogs.com/qianye/archive/2012/11/25/2787923.html#:~:text=%E8%83%9C%E8%80%85%E6%A0%91%E5%92%8C%E8%B4%A5%E8%80%85%E6%A0%91%E9%83%BD%E6%98%AF%E5%AE%8C%E5%85%A8,%E6%97%B6%E9%97%B4%E5%86%85%E6%89%BE%E5%88%B0%E6%9C%80%E5%80%BC%E3%80%82)\n2. [堆，赢者树，败者树的区别与联系](https://blog.csdn.net/haolexiao/article/details/53488314)\n\n","source":"_posts/胜者树败者树.md","raw":"---\ntitle: 胜者树与败者树\ntags: 算法\nmath: true\n---\n\n胜者树与败者树是完全二叉树。就像是参加比赛一样，每个选手有不同的实力，两个选手PK,实力决定胜负，晋级下一轮，经过几轮之后，就能得到冠军。不同的是，胜者树的中间结点记录的是胜者的标号；而败者树的中间结点记录的败者的标号。 胜者树与败者树可以在log(n)的时间内找到最值。任何一个叶子结点的值改变后，利用中间结点的信息，还是能够快速地找到最值。在k路归并排序中经常用到。\n\n\n## 胜者树\n胜者树的一个优点是，如果一个选手的值改变了，可以很容易地修改这棵胜者树。只需要沿着从该结点到根结点的路径修改这棵二叉树，而不必改变其他比赛的结果。\n\n![fig1](/img/胜者树败者树/fig1.jpg)\n\n上图是一个胜者树的示例。规定数值小者胜。\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；\n2. b3 PK b0，b3胜b0负，内部结点ls[2]的值为3；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；\n4. b3 PK b1，b3胜b1负，内部结点ls[1]的值为3。\n\n取出胜者b3之后，叶子结点b3的值变为11时，重构的胜者树如下:\n\n![fig2](/img/胜者树败者树/fig2.jpg)\n\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；\n2. b3 PK b0，b0胜b3负，内部结点ls[2]的值为0；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；\n4. b0 PK b1，b1胜b0负，内部结点ls[1]的值为1。\n\n用胜者树对n个节点实现排序操作，构建胜者树和构建堆比较相似，区别在于胜者树只有叶子节点存放了数据，中间节点记录的是叶子节点间的关系。\n\n胜者树在每次重构时只需与其兄弟结点比较，一直到根节点选出胜者为止。\n\n## 败者树\n败者树是胜者树的一种变体。在败者树中，用父结点记录其左右子结点进行比赛的败者，而让胜者参加下一轮的比赛。败者树的根结点记录的是败者，需要加一个结点来记录整个比赛的胜利者。采用败者树可以简化重构的过程。\n\n![fig3](/img/胜者树败者树/fig3.jpg)\n\n上图是一棵败者树。规定数大者败。\n\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为4；\n2. b3 PK b0，b3胜b0负，内部结点ls[2]的值为0；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为2；\n4. b3 PK b1，b3胜b1负，内部结点ls[1]的值为1；\n\n败者树重构过程如下：\n- 将新进入选择树的结点与其父结点进行比赛：将败者存放在父结点中；而胜者再与上一级的父结点比较。\n- 比赛沿着到根结点的路径不断进行，直到ls[1]处。把败者存放在结点ls[1]中，胜者存放在ls[0]中。\n\n![fig4](/img/胜者树败者树/fig4.jpg)\n\n## 胜者树、败者树、堆比较\n### 相同点  \n这三者空间和时间复杂度都是一样的。调整一次的时间复杂度都是O(logN)的。\n\n### 不同点\n一开始就是只有堆来完成多路归并的，但是人们发现堆每次取出最小值之后，把最后一个数放到堆顶，**调整堆的时候，每次都要选出父结点的两个孩子节点的最小值，然后再用孩子结点的最小值和父节点进行比较，所以每调整一层需要比较两次**。\n\n这时人们想能否简化比较过程，这时就有了胜者树。这样**每次比较只用跟自己的兄弟结点进行比较就好**，所以用胜者树可以比堆少一半的比较次数。\n\n而**胜者树想要比较兄弟结点首先要获得其父结点，也就是说需要访存两次**，这时人们又想能否再次减少比较次数，于是就有了败者树。败者树每个新元素上升时，**只需要获得父节点并比较即可**。\n\n总的来说，败者树与胜者树相比减少了访存时间。**现在程序的主要瓶颈在于访存了，计算倒几乎可以忽略不计了**。\n\n## 参考\n1. [胜者树和败者树](https://www.cnblogs.com/qianye/archive/2012/11/25/2787923.html#:~:text=%E8%83%9C%E8%80%85%E6%A0%91%E5%92%8C%E8%B4%A5%E8%80%85%E6%A0%91%E9%83%BD%E6%98%AF%E5%AE%8C%E5%85%A8,%E6%97%B6%E9%97%B4%E5%86%85%E6%89%BE%E5%88%B0%E6%9C%80%E5%80%BC%E3%80%82)\n2. [堆，赢者树，败者树的区别与联系](https://blog.csdn.net/haolexiao/article/details/53488314)\n\n","slug":"胜者树败者树","published":1,"date":"2022-12-02T04:31:08.731Z","updated":"2022-12-05T14:50:52.767Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8oh000zr4sge1181zld","content":"<p>胜者树与败者树是完全二叉树。就像是参加比赛一样，每个选手有不同的实力，两个选手PK,实力决定胜负，晋级下一轮，经过几轮之后，就能得到冠军。不同的是，胜者树的中间结点记录的是胜者的标号；而败者树的中间结点记录的败者的标号。\r\n胜者树与败者树可以在log(n)的时间内找到最值。任何一个叶子结点的值改变后，利用中间结点的信息，还是能够快速地找到最值。在k路归并排序中经常用到。</p>\r\n<h2 id=\"胜者树\">胜者树</h2>\r\n<p>胜者树的一个优点是，如果一个选手的值改变了，可以很容易地修改这棵胜者树。只需要沿着从该结点到根结点的路径修改这棵二叉树，而不必改变其他比赛的结果。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig1.jpg\" alt=\"fig1\" />\r\n<figcaption aria-hidden=\"true\">fig1</figcaption>\r\n</figure>\r\n<p>上图是一个胜者树的示例。规定数值小者胜。 1. b3 PK\r\nb4，b3胜b4负，内部结点ls[4]的值为3； 2. b3 PK\r\nb0，b3胜b0负，内部结点ls[2]的值为3； 3. b1 PK\r\nb2，b1胜b2负，内部结点ls[3]的值为1； 4. b3 PK\r\nb1，b3胜b1负，内部结点ls[1]的值为3。</p>\r\n<p>取出胜者b3之后，叶子结点b3的值变为11时，重构的胜者树如下:</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig2.jpg\" alt=\"fig2\" />\r\n<figcaption aria-hidden=\"true\">fig2</figcaption>\r\n</figure>\r\n<ol type=\"1\">\r\n<li>b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；</li>\r\n<li>b3 PK b0，b0胜b3负，内部结点ls[2]的值为0；</li>\r\n<li>b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；</li>\r\n<li>b0 PK b1，b1胜b0负，内部结点ls[1]的值为1。</li>\r\n</ol>\r\n<p>用胜者树对n个节点实现排序操作，构建胜者树和构建堆比较相似，区别在于胜者树只有叶子节点存放了数据，中间节点记录的是叶子节点间的关系。</p>\r\n<p>胜者树在每次重构时只需与其兄弟结点比较，一直到根节点选出胜者为止。</p>\r\n<h2 id=\"败者树\">败者树</h2>\r\n<p>败者树是胜者树的一种变体。在败者树中，用父结点记录其左右子结点进行比赛的败者，而让胜者参加下一轮的比赛。败者树的根结点记录的是败者，需要加一个结点来记录整个比赛的胜利者。采用败者树可以简化重构的过程。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig3.jpg\" alt=\"fig3\" />\r\n<figcaption aria-hidden=\"true\">fig3</figcaption>\r\n</figure>\r\n<p>上图是一棵败者树。规定数大者败。</p>\r\n<ol type=\"1\">\r\n<li>b3 PK b4，b3胜b4负，内部结点ls[4]的值为4；</li>\r\n<li>b3 PK b0，b3胜b0负，内部结点ls[2]的值为0；</li>\r\n<li>b1 PK b2，b1胜b2负，内部结点ls[3]的值为2；</li>\r\n<li>b3 PK b1，b3胜b1负，内部结点ls[1]的值为1；</li>\r\n</ol>\r\n<p>败者树重构过程如下： -\r\n将新进入选择树的结点与其父结点进行比赛：将败者存放在父结点中；而胜者再与上一级的父结点比较。\r\n-\r\n比赛沿着到根结点的路径不断进行，直到ls[1]处。把败者存放在结点ls[1]中，胜者存放在ls[0]中。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig4.jpg\" alt=\"fig4\" />\r\n<figcaption aria-hidden=\"true\">fig4</figcaption>\r\n</figure>\r\n<h2 id=\"胜者树败者树堆比较\">胜者树、败者树、堆比较</h2>\r\n<h3 id=\"相同点\">相同点</h3>\r\n<p>这三者空间和时间复杂度都是一样的。调整一次的时间复杂度都是O(logN)的。</p>\r\n<h3 id=\"不同点\">不同点</h3>\r\n<p>一开始就是只有堆来完成多路归并的，但是人们发现堆每次取出最小值之后，把最后一个数放到堆顶，<strong>调整堆的时候，每次都要选出父结点的两个孩子节点的最小值，然后再用孩子结点的最小值和父节点进行比较，所以每调整一层需要比较两次</strong>。</p>\r\n<p>这时人们想能否简化比较过程，这时就有了胜者树。这样<strong>每次比较只用跟自己的兄弟结点进行比较就好</strong>，所以用胜者树可以比堆少一半的比较次数。</p>\r\n<p>而<strong>胜者树想要比较兄弟结点首先要获得其父结点，也就是说需要访存两次</strong>，这时人们又想能否再次减少比较次数，于是就有了败者树。败者树每个新元素上升时，<strong>只需要获得父节点并比较即可</strong>。</p>\r\n<p>总的来说，败者树与胜者树相比减少了访存时间。<strong>现在程序的主要瓶颈在于访存了，计算倒几乎可以忽略不计了</strong>。</p>\r\n<h2 id=\"参考\">参考</h2>\r\n<ol type=\"1\">\r\n<li><a\r\nhref=\"https://www.cnblogs.com/qianye/archive/2012/11/25/2787923.html#:~:text=%E8%83%9C%E8%80%85%E6%A0%91%E5%92%8C%E8%B4%A5%E8%80%85%E6%A0%91%E9%83%BD%E6%98%AF%E5%AE%8C%E5%85%A8,%E6%97%B6%E9%97%B4%E5%86%85%E6%89%BE%E5%88%B0%E6%9C%80%E5%80%BC%E3%80%82\">胜者树和败者树</a></li>\r\n<li><a\r\nhref=\"https://blog.csdn.net/haolexiao/article/details/53488314\">堆，赢者树，败者树的区别与联系</a></li>\r\n</ol>\r\n","site":{"data":{}},"excerpt":"","more":"<p>胜者树与败者树是完全二叉树。就像是参加比赛一样，每个选手有不同的实力，两个选手PK,实力决定胜负，晋级下一轮，经过几轮之后，就能得到冠军。不同的是，胜者树的中间结点记录的是胜者的标号；而败者树的中间结点记录的败者的标号。\r\n胜者树与败者树可以在log(n)的时间内找到最值。任何一个叶子结点的值改变后，利用中间结点的信息，还是能够快速地找到最值。在k路归并排序中经常用到。</p>\r\n<h2 id=\"胜者树\">胜者树</h2>\r\n<p>胜者树的一个优点是，如果一个选手的值改变了，可以很容易地修改这棵胜者树。只需要沿着从该结点到根结点的路径修改这棵二叉树，而不必改变其他比赛的结果。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig1.jpg\" alt=\"fig1\" />\r\n<figcaption aria-hidden=\"true\">fig1</figcaption>\r\n</figure>\r\n<p>上图是一个胜者树的示例。规定数值小者胜。 1. b3 PK\r\nb4，b3胜b4负，内部结点ls[4]的值为3； 2. b3 PK\r\nb0，b3胜b0负，内部结点ls[2]的值为3； 3. b1 PK\r\nb2，b1胜b2负，内部结点ls[3]的值为1； 4. b3 PK\r\nb1，b3胜b1负，内部结点ls[1]的值为3。</p>\r\n<p>取出胜者b3之后，叶子结点b3的值变为11时，重构的胜者树如下:</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig2.jpg\" alt=\"fig2\" />\r\n<figcaption aria-hidden=\"true\">fig2</figcaption>\r\n</figure>\r\n<ol type=\"1\">\r\n<li>b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；</li>\r\n<li>b3 PK b0，b0胜b3负，内部结点ls[2]的值为0；</li>\r\n<li>b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；</li>\r\n<li>b0 PK b1，b1胜b0负，内部结点ls[1]的值为1。</li>\r\n</ol>\r\n<p>用胜者树对n个节点实现排序操作，构建胜者树和构建堆比较相似，区别在于胜者树只有叶子节点存放了数据，中间节点记录的是叶子节点间的关系。</p>\r\n<p>胜者树在每次重构时只需与其兄弟结点比较，一直到根节点选出胜者为止。</p>\r\n<h2 id=\"败者树\">败者树</h2>\r\n<p>败者树是胜者树的一种变体。在败者树中，用父结点记录其左右子结点进行比赛的败者，而让胜者参加下一轮的比赛。败者树的根结点记录的是败者，需要加一个结点来记录整个比赛的胜利者。采用败者树可以简化重构的过程。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig3.jpg\" alt=\"fig3\" />\r\n<figcaption aria-hidden=\"true\">fig3</figcaption>\r\n</figure>\r\n<p>上图是一棵败者树。规定数大者败。</p>\r\n<ol type=\"1\">\r\n<li>b3 PK b4，b3胜b4负，内部结点ls[4]的值为4；</li>\r\n<li>b3 PK b0，b3胜b0负，内部结点ls[2]的值为0；</li>\r\n<li>b1 PK b2，b1胜b2负，内部结点ls[3]的值为2；</li>\r\n<li>b3 PK b1，b3胜b1负，内部结点ls[1]的值为1；</li>\r\n</ol>\r\n<p>败者树重构过程如下： -\r\n将新进入选择树的结点与其父结点进行比赛：将败者存放在父结点中；而胜者再与上一级的父结点比较。\r\n-\r\n比赛沿着到根结点的路径不断进行，直到ls[1]处。把败者存放在结点ls[1]中，胜者存放在ls[0]中。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig4.jpg\" alt=\"fig4\" />\r\n<figcaption aria-hidden=\"true\">fig4</figcaption>\r\n</figure>\r\n<h2 id=\"胜者树败者树堆比较\">胜者树、败者树、堆比较</h2>\r\n<h3 id=\"相同点\">相同点</h3>\r\n<p>这三者空间和时间复杂度都是一样的。调整一次的时间复杂度都是O(logN)的。</p>\r\n<h3 id=\"不同点\">不同点</h3>\r\n<p>一开始就是只有堆来完成多路归并的，但是人们发现堆每次取出最小值之后，把最后一个数放到堆顶，<strong>调整堆的时候，每次都要选出父结点的两个孩子节点的最小值，然后再用孩子结点的最小值和父节点进行比较，所以每调整一层需要比较两次</strong>。</p>\r\n<p>这时人们想能否简化比较过程，这时就有了胜者树。这样<strong>每次比较只用跟自己的兄弟结点进行比较就好</strong>，所以用胜者树可以比堆少一半的比较次数。</p>\r\n<p>而<strong>胜者树想要比较兄弟结点首先要获得其父结点，也就是说需要访存两次</strong>，这时人们又想能否再次减少比较次数，于是就有了败者树。败者树每个新元素上升时，<strong>只需要获得父节点并比较即可</strong>。</p>\r\n<p>总的来说，败者树与胜者树相比减少了访存时间。<strong>现在程序的主要瓶颈在于访存了，计算倒几乎可以忽略不计了</strong>。</p>\r\n<h2 id=\"参考\">参考</h2>\r\n<ol type=\"1\">\r\n<li><a\r\nhref=\"https://www.cnblogs.com/qianye/archive/2012/11/25/2787923.html#:~:text=%E8%83%9C%E8%80%85%E6%A0%91%E5%92%8C%E8%B4%A5%E8%80%85%E6%A0%91%E9%83%BD%E6%98%AF%E5%AE%8C%E5%85%A8,%E6%97%B6%E9%97%B4%E5%86%85%E6%89%BE%E5%88%B0%E6%9C%80%E5%80%BC%E3%80%82\">胜者树和败者树</a></li>\r\n<li><a\r\nhref=\"https://blog.csdn.net/haolexiao/article/details/53488314\">堆，赢者树，败者树的区别与联系</a></li>\r\n</ol>\r\n"},{"title":"近似算法","_content":" \n\n## 近似算法\n假设现在需要解决一个NP-Hard问题，但是又不太可能在多项式时间内求解，但是我们可以退而求其次，那么就必须要牺牲下面的其中一项：\n\n- 求得最优解\n- 在多项式时间内完成\n- 覆盖问题的所有例子\n\n\n而牺牲第二条是不能接受的，当我们选择满足后两者（也就是牺牲第一项），即对解的优越性放宽要求时，设计出的算法被称为**近似算法**。\n\n## Load Balancing问题\n给定$m$台相同的机器，$n$个任务，任务$j$需要的处理时间为$t_j$,且每个任务$j$必须在一台机器上连续完成。\n\n令$J(i)$为分配给机器$i$的任务子集，机器$i$的负载为$L_i=\\sum\\limits_{j \\in J(i)}t_j$,该问题的时间跨度(makespan)为所有机器上的结束时间最大值$L=\\max\\limits_i L_i$。\n\n**Load Balancing**：求上述问题中的任务分配使得时间跨度最小。\n\n### 贪心算法\n每次将任务$j$分配在当前负载最小的机器上：\n![](/img/近似算法/LoadBalancing贪心算法.png)\n\n\n\n**引理1**：最优解makespan$L^* \\ge \\max\\limits_j t_j$。\n\n用时最长的这个任务总需要分配到一个机器上完成.\n\n**引理2**:最优解makespan $L^* \\ge \\frac{1}{m} \\sum\\limits_j t_j$\n\n所有任务的总运行时间为$\\sum\\limits_j t_j$,那么$L^*$的时间跨度必然选自$m$个机器中的一个,而每个机器的最小时间跨度为$\\frac{1}{m}$的总运行时间.\n\n**定理:贪心算法是Load Balancing问题的二倍近似算法。**\n\n证明:\n\n假设负载$L_i$为问题的平静,令$j$为最后一个分配到该机器的任务,由贪心算法,在任务$j$分配之前,机器$i$的负载是最小的.$j$分配之前机器$i$的负载为$L_i - t_j$,也就是说在准备分配$j$的时候有$L_i - t_j$小于或等于所有机器上的负载$L_k, 1 \\le k \\le m$\n\n![](/img/近似算法/LoadBalancing贪心算法证明-1.png)\n\n分配任务$j$之前,由引理1:\n$$  \\begin{aligned}\n    L_i - t_j &\\le \\frac{1}{m}\\sum\\limits_k L_k \\\\\n        &=  \\frac{1}{m} \\sum\\limits_k t_k \\\\\n        &\\le L^*\n    \\end{aligned}$$\n\n分配任务$j$后,由上式以及引理2:\n$$L_i = (L_i -t_i) + t_j \\le L^* + \\max\\limits_j t_j \\le L^* + L^* = 2L^*$$\n\n那么贪心算法是Load Balancing的紧2倍近似算法吗?所谓紧的是指该算法可以相比于最优解更低的倍率吗(如1.5倍)?若可以则说明贪心算法并不是Load Balancing的紧2倍近似算法.\n\n答:大致是的,考虑下面的一个Load Balancing的实例,有$m$个机器,$m^2$个任务,其中有$m(m-1)$个任务运行时间为1,一个任务的运行时间为$m$.贪心算法的结果如下图所示:\n\n![](/img/近似算法/LoadBalancing实例-贪心算法.png)\n\n而最优解的结果为:\n\n![](/img/近似算法/LoadBalancing实例-最优解.png)\n\n这个实例里贪心算法的时间跨度为19,而最优解的时间跨度为10.\n\n### LPT(longest Processing Time)算法\nLPT算法是在上面的贪心算法基础之上,先对$n$个任务按时间降序排序,然后再按照上面的贪心算法执行.\n\n![](/img/近似算法/LoadBalancingLPT算法.png)\n\n通过观察可以得出,当任务数小于或等于机器数的时候,LRT算法就是最优解.这时候只需要把任务$i$分配给机器$i$.\n\n**引理3**:如果任务数多于机器数$m$,有$L^* \\ge 2t_{m+1}$.\n\n设前$m+1$个任务的运行时间分别为$t_1,\\dots,t_{m+1}$,由于运行时间$t_i$是按照降序排列,所以前$m+1$个任务的运行时间都不小于$t_{m\n+1}$,且由于鸽笼原则,至少有一个机器会被分配两个任务.\n\n**定理:LPT算法是Load Balancing的一个$\\frac{3}{2}$近似算法.**\n\n证明:与证明贪心算法相同的方法\n$$L_i=(L_i - t_j) + t_j \\le L^* + \\frac{1}{2}L^* = \\frac{3}{2}L$$\n\n那么LPT算法是Load Balancing的紧$\\frac{3}{2}$倍近似算法吗?不是;LPT算法是Load Balancing的紧$\\frac{4}{3}$倍近似算法吗?很可能是.\n\n\n## Centrer Selection Problem(中心选址问题)\n定义:给定一个大小为$n$个地址集合$s_1,s_2,\\dots,s_n$以及一个整数$k>0$,选择$k$个中心使所有地址到离它最近的中心距离的最大值最短.\n\n![](/img/近似算法/CentrerSelectionProblem.png)\n\n几个概念:\n\n- $dist(x, y)$:$x,y$的距离.\n- $dist(s_i, C)=\\min\\limits_{c \\in C}$:$s_i$到离它最近的中心的距离,这里采用欧式距离.\n- $r(C)=\\max\\limits_{i} dist(s_i,C)$:最小的覆盖半径.\n\n中心选址问题的目标便是找到一个中心集合$C$使覆盖半径$r(C)$最小,其中中心的数量等于$k$.\n\n距离的一些性质:\n$$dist(x,x)=0 \\tag{同一性}$$\n$$dist(x,y)=dist(y,x) \\tag{对称性}$$\n$$dist(x,y) \\le dist(x,z) + dist(z,y) \\tag{三角不等式}$$\n\n\n### 贪心算法\n开始时我们任意选取一个地址作为中心，接着选择离第一个中心最远的那个地址作为第二个中心，如此的重复进行,直到选了$k$个中心为止。\n\n![](/img/近似算法/CentrerSelectionProblem贪心算法.png)\n\n**定理：贪心算法是中心选址问题的2倍近似解**\n\n证明(反证法)：\n\n\n假设$r(C^*)<\\frac{1}{2}r(C)$\n\n- 对近似解集合$C$的中心$c_i$，总有一个最优解的中心$c_i^*$在$c_i$的圆中(任意一个最优解的中心$c_i^*$的圆里最少有一个地址$s$,而贪心算法选址都是在地址集合中选的，并且$c_i$的半径 $>$ $c_i^*$的半径，所以$c_i^*$必然在某一个中心$c_i$的圆里)\n- 令$c_i$是与$c_i^*$对应的中心\n- 对于任意一个离最优解$c_i^*$最近的地址$s$,有\n\n$$dist(s,C) \\le dist(s, c_i) \\le dist(s, c_i^*) + dist(c_i^*, c_i) \\le r(C^*) + r(C^*) = 2r(C^*)$$\n\n上式与假设$r(C^*)<\\frac{1}{2}r(C)$相违背，故有$r(C^*) \\ge \\frac{1}{2}r(C)$,即贪心算法是中心选址问题的2倍近似解。\n\n中心选址问题有没有$\\frac{3}{2}$倍近似解或者$\\frac{4}{3}$倍近似解？\n\n答：没有，除非P＝NP，否则中心选址问题没有倍率比2小的近似算法。\n\n## Weighted Vertex Cover\n带权值的顶点覆盖：对于给出的一个顶点带权值的图$G$，找到一个顶点覆盖，使它们的权值之和最小。 （这里我们主要解决的是：求图$G=(V,E)$的顶点覆盖$S$，要使顶点集合$S$中所有顶点的权值之和最小。\n\n![](/img/近似算法/WeightedVertexCover.png)\n\n### Pricing Method\n**定价法**：因为顶点覆盖要求每条边至少有一个顶点在集合$S$里,每条边必须被一些顶点所覆盖，根据顶点$i$和$j$，给边$e = (i, j)$ 标上价格$P_e$。\n\n公平性：与顶点$i$所连接的所有边的价格（权值）之和必须小于顶点$i$的权值。\n\n引理：：图$G$的所有边的价格（权值）之和 $\\le$ 顶点覆盖$S$中所有顶点的权值之和（两个简单的缩放）。\n\n![](/img/近似算法/WeightedVertexCover-不等式放缩.png)\n\n(上面第一个 $\\le$ 好像可以写成等号？)\n\n求解过程：边的价格设置与找寻顶点覆盖同时进行\n\n![](/img/近似算法/WeightedVertexCover-PricingMethod-求解过程.png)\n\n例子：\n\n![](/img/近似算法/WeightedVertexCover-PricingMethod-例子.png)\n\n\n**Pricing Method是Weighted Vertex Cover**的一个2倍近似算法。\n\n证明：\n\n首先证明$S$是一个点覆盖：\n\n算法结束条件：在while循环的每次迭代结束之后，至少有一个顶点会是紧致的（除非图没有边），所以在算法结束的时候每条边的两个顶点中至少有一个是紧的，即每条边至少有一个顶点在$S$中，而Vertex Cover要求每条边至少有一个顶点在$S$中，所以$S$必然是一个点覆盖，否则循环就不会停止。\n\n然后再证明$S$是最优解的一个2倍近似解：\n\n![](/img/近似算法/证明PricingMethod2倍近似解.png)\n\n第一处放缩很容易得出，$S$肯定为顶点集$V$的一个子集；$\\sum\\limits_{i \\in V} \\sum\\limits_{e=(i,j)} p_e = 2 \\sum\\limits_{e \\in E} p_e$是因为算与$V$中所有顶点相连的边时，每条边会被计算两次；最右边一个放缩为引理的结论。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/近似算法.md","raw":"---\ntitle: 近似算法\ntags: \n    - 算法\n    - 高级算法设计与分析\ncategories: \n    - 算法\n--- \n\n## 近似算法\n假设现在需要解决一个NP-Hard问题，但是又不太可能在多项式时间内求解，但是我们可以退而求其次，那么就必须要牺牲下面的其中一项：\n\n- 求得最优解\n- 在多项式时间内完成\n- 覆盖问题的所有例子\n\n\n而牺牲第二条是不能接受的，当我们选择满足后两者（也就是牺牲第一项），即对解的优越性放宽要求时，设计出的算法被称为**近似算法**。\n\n## Load Balancing问题\n给定$m$台相同的机器，$n$个任务，任务$j$需要的处理时间为$t_j$,且每个任务$j$必须在一台机器上连续完成。\n\n令$J(i)$为分配给机器$i$的任务子集，机器$i$的负载为$L_i=\\sum\\limits_{j \\in J(i)}t_j$,该问题的时间跨度(makespan)为所有机器上的结束时间最大值$L=\\max\\limits_i L_i$。\n\n**Load Balancing**：求上述问题中的任务分配使得时间跨度最小。\n\n### 贪心算法\n每次将任务$j$分配在当前负载最小的机器上：\n![](/img/近似算法/LoadBalancing贪心算法.png)\n\n\n\n**引理1**：最优解makespan$L^* \\ge \\max\\limits_j t_j$。\n\n用时最长的这个任务总需要分配到一个机器上完成.\n\n**引理2**:最优解makespan $L^* \\ge \\frac{1}{m} \\sum\\limits_j t_j$\n\n所有任务的总运行时间为$\\sum\\limits_j t_j$,那么$L^*$的时间跨度必然选自$m$个机器中的一个,而每个机器的最小时间跨度为$\\frac{1}{m}$的总运行时间.\n\n**定理:贪心算法是Load Balancing问题的二倍近似算法。**\n\n证明:\n\n假设负载$L_i$为问题的平静,令$j$为最后一个分配到该机器的任务,由贪心算法,在任务$j$分配之前,机器$i$的负载是最小的.$j$分配之前机器$i$的负载为$L_i - t_j$,也就是说在准备分配$j$的时候有$L_i - t_j$小于或等于所有机器上的负载$L_k, 1 \\le k \\le m$\n\n![](/img/近似算法/LoadBalancing贪心算法证明-1.png)\n\n分配任务$j$之前,由引理1:\n$$  \\begin{aligned}\n    L_i - t_j &\\le \\frac{1}{m}\\sum\\limits_k L_k \\\\\n        &=  \\frac{1}{m} \\sum\\limits_k t_k \\\\\n        &\\le L^*\n    \\end{aligned}$$\n\n分配任务$j$后,由上式以及引理2:\n$$L_i = (L_i -t_i) + t_j \\le L^* + \\max\\limits_j t_j \\le L^* + L^* = 2L^*$$\n\n那么贪心算法是Load Balancing的紧2倍近似算法吗?所谓紧的是指该算法可以相比于最优解更低的倍率吗(如1.5倍)?若可以则说明贪心算法并不是Load Balancing的紧2倍近似算法.\n\n答:大致是的,考虑下面的一个Load Balancing的实例,有$m$个机器,$m^2$个任务,其中有$m(m-1)$个任务运行时间为1,一个任务的运行时间为$m$.贪心算法的结果如下图所示:\n\n![](/img/近似算法/LoadBalancing实例-贪心算法.png)\n\n而最优解的结果为:\n\n![](/img/近似算法/LoadBalancing实例-最优解.png)\n\n这个实例里贪心算法的时间跨度为19,而最优解的时间跨度为10.\n\n### LPT(longest Processing Time)算法\nLPT算法是在上面的贪心算法基础之上,先对$n$个任务按时间降序排序,然后再按照上面的贪心算法执行.\n\n![](/img/近似算法/LoadBalancingLPT算法.png)\n\n通过观察可以得出,当任务数小于或等于机器数的时候,LRT算法就是最优解.这时候只需要把任务$i$分配给机器$i$.\n\n**引理3**:如果任务数多于机器数$m$,有$L^* \\ge 2t_{m+1}$.\n\n设前$m+1$个任务的运行时间分别为$t_1,\\dots,t_{m+1}$,由于运行时间$t_i$是按照降序排列,所以前$m+1$个任务的运行时间都不小于$t_{m\n+1}$,且由于鸽笼原则,至少有一个机器会被分配两个任务.\n\n**定理:LPT算法是Load Balancing的一个$\\frac{3}{2}$近似算法.**\n\n证明:与证明贪心算法相同的方法\n$$L_i=(L_i - t_j) + t_j \\le L^* + \\frac{1}{2}L^* = \\frac{3}{2}L$$\n\n那么LPT算法是Load Balancing的紧$\\frac{3}{2}$倍近似算法吗?不是;LPT算法是Load Balancing的紧$\\frac{4}{3}$倍近似算法吗?很可能是.\n\n\n## Centrer Selection Problem(中心选址问题)\n定义:给定一个大小为$n$个地址集合$s_1,s_2,\\dots,s_n$以及一个整数$k>0$,选择$k$个中心使所有地址到离它最近的中心距离的最大值最短.\n\n![](/img/近似算法/CentrerSelectionProblem.png)\n\n几个概念:\n\n- $dist(x, y)$:$x,y$的距离.\n- $dist(s_i, C)=\\min\\limits_{c \\in C}$:$s_i$到离它最近的中心的距离,这里采用欧式距离.\n- $r(C)=\\max\\limits_{i} dist(s_i,C)$:最小的覆盖半径.\n\n中心选址问题的目标便是找到一个中心集合$C$使覆盖半径$r(C)$最小,其中中心的数量等于$k$.\n\n距离的一些性质:\n$$dist(x,x)=0 \\tag{同一性}$$\n$$dist(x,y)=dist(y,x) \\tag{对称性}$$\n$$dist(x,y) \\le dist(x,z) + dist(z,y) \\tag{三角不等式}$$\n\n\n### 贪心算法\n开始时我们任意选取一个地址作为中心，接着选择离第一个中心最远的那个地址作为第二个中心，如此的重复进行,直到选了$k$个中心为止。\n\n![](/img/近似算法/CentrerSelectionProblem贪心算法.png)\n\n**定理：贪心算法是中心选址问题的2倍近似解**\n\n证明(反证法)：\n\n\n假设$r(C^*)<\\frac{1}{2}r(C)$\n\n- 对近似解集合$C$的中心$c_i$，总有一个最优解的中心$c_i^*$在$c_i$的圆中(任意一个最优解的中心$c_i^*$的圆里最少有一个地址$s$,而贪心算法选址都是在地址集合中选的，并且$c_i$的半径 $>$ $c_i^*$的半径，所以$c_i^*$必然在某一个中心$c_i$的圆里)\n- 令$c_i$是与$c_i^*$对应的中心\n- 对于任意一个离最优解$c_i^*$最近的地址$s$,有\n\n$$dist(s,C) \\le dist(s, c_i) \\le dist(s, c_i^*) + dist(c_i^*, c_i) \\le r(C^*) + r(C^*) = 2r(C^*)$$\n\n上式与假设$r(C^*)<\\frac{1}{2}r(C)$相违背，故有$r(C^*) \\ge \\frac{1}{2}r(C)$,即贪心算法是中心选址问题的2倍近似解。\n\n中心选址问题有没有$\\frac{3}{2}$倍近似解或者$\\frac{4}{3}$倍近似解？\n\n答：没有，除非P＝NP，否则中心选址问题没有倍率比2小的近似算法。\n\n## Weighted Vertex Cover\n带权值的顶点覆盖：对于给出的一个顶点带权值的图$G$，找到一个顶点覆盖，使它们的权值之和最小。 （这里我们主要解决的是：求图$G=(V,E)$的顶点覆盖$S$，要使顶点集合$S$中所有顶点的权值之和最小。\n\n![](/img/近似算法/WeightedVertexCover.png)\n\n### Pricing Method\n**定价法**：因为顶点覆盖要求每条边至少有一个顶点在集合$S$里,每条边必须被一些顶点所覆盖，根据顶点$i$和$j$，给边$e = (i, j)$ 标上价格$P_e$。\n\n公平性：与顶点$i$所连接的所有边的价格（权值）之和必须小于顶点$i$的权值。\n\n引理：：图$G$的所有边的价格（权值）之和 $\\le$ 顶点覆盖$S$中所有顶点的权值之和（两个简单的缩放）。\n\n![](/img/近似算法/WeightedVertexCover-不等式放缩.png)\n\n(上面第一个 $\\le$ 好像可以写成等号？)\n\n求解过程：边的价格设置与找寻顶点覆盖同时进行\n\n![](/img/近似算法/WeightedVertexCover-PricingMethod-求解过程.png)\n\n例子：\n\n![](/img/近似算法/WeightedVertexCover-PricingMethod-例子.png)\n\n\n**Pricing Method是Weighted Vertex Cover**的一个2倍近似算法。\n\n证明：\n\n首先证明$S$是一个点覆盖：\n\n算法结束条件：在while循环的每次迭代结束之后，至少有一个顶点会是紧致的（除非图没有边），所以在算法结束的时候每条边的两个顶点中至少有一个是紧的，即每条边至少有一个顶点在$S$中，而Vertex Cover要求每条边至少有一个顶点在$S$中，所以$S$必然是一个点覆盖，否则循环就不会停止。\n\n然后再证明$S$是最优解的一个2倍近似解：\n\n![](/img/近似算法/证明PricingMethod2倍近似解.png)\n\n第一处放缩很容易得出，$S$肯定为顶点集$V$的一个子集；$\\sum\\limits_{i \\in V} \\sum\\limits_{e=(i,j)} p_e = 2 \\sum\\limits_{e \\in E} p_e$是因为算与$V$中所有顶点相连的边时，每条边会被计算两次；最右边一个放缩为引理的结论。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"近似算法","published":1,"date":"2022-12-08T07:41:52.704Z","updated":"2022-12-08T13:41:53.495Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8oi0013r4sg16kb6u8s","content":"<h2 id=\"近似算法\">近似算法</h2>\r\n<p>假设现在需要解决一个NP-Hard问题，但是又不太可能在多项式时间内求解，但是我们可以退而求其次，那么就必须要牺牲下面的其中一项：</p>\r\n<ul>\r\n<li>求得最优解</li>\r\n<li>在多项式时间内完成</li>\r\n<li>覆盖问题的所有例子</li>\r\n</ul>\r\n<p>而牺牲第二条是不能接受的，当我们选择满足后两者（也就是牺牲第一项），即对解的优越性放宽要求时，设计出的算法被称为<strong>近似算法</strong>。</p>\r\n<h2 id=\"load-balancing问题\">Load Balancing问题</h2>\r\n<p>给定<span class=\"math inline\">\\(m\\)</span>台相同的机器，<span\r\nclass=\"math inline\">\\(n\\)</span>个任务，任务<span\r\nclass=\"math inline\">\\(j\\)</span>需要的处理时间为<span\r\nclass=\"math inline\">\\(t_j\\)</span>,且每个任务<span\r\nclass=\"math inline\">\\(j\\)</span>必须在一台机器上连续完成。</p>\r\n<p>令<span class=\"math inline\">\\(J(i)\\)</span>为分配给机器<span\r\nclass=\"math inline\">\\(i\\)</span>的任务子集，机器<span\r\nclass=\"math inline\">\\(i\\)</span>的负载为<span\r\nclass=\"math inline\">\\(L_i=\\sum\\limits_{j \\in\r\nJ(i)}t_j\\)</span>,该问题的时间跨度(makespan)为所有机器上的结束时间最大值<span\r\nclass=\"math inline\">\\(L=\\max\\limits_i L_i\\)</span>。</p>\r\n<p><strong>Load\r\nBalancing</strong>：求上述问题中的任务分配使得时间跨度最小。</p>\r\n<h3 id=\"贪心算法\">贪心算法</h3>\r\n<p>每次将任务<span\r\nclass=\"math inline\">\\(j\\)</span>分配在当前负载最小的机器上： <img\r\nsrc=\"/img/近似算法/LoadBalancing贪心算法.png\" /></p>\r\n<p><strong>引理1</strong>：最优解makespan<span class=\"math inline\">\\(L^*\r\n\\ge \\max\\limits_j t_j\\)</span>。</p>\r\n<p>用时最长的这个任务总需要分配到一个机器上完成.</p>\r\n<p><strong>引理2</strong>:最优解makespan <span class=\"math inline\">\\(L^*\r\n\\ge \\frac{1}{m} \\sum\\limits_j t_j\\)</span></p>\r\n<p>所有任务的总运行时间为<span class=\"math inline\">\\(\\sum\\limits_j\r\nt_j\\)</span>,那么<span\r\nclass=\"math inline\">\\(L^*\\)</span>的时间跨度必然选自<span\r\nclass=\"math inline\">\\(m\\)</span>个机器中的一个,而每个机器的最小时间跨度为<span\r\nclass=\"math inline\">\\(\\frac{1}{m}\\)</span>的总运行时间.</p>\r\n<p><strong>定理:贪心算法是Load\r\nBalancing问题的二倍近似算法。</strong></p>\r\n<p>证明:</p>\r\n<p>假设负载<span class=\"math inline\">\\(L_i\\)</span>为问题的平静,令<span\r\nclass=\"math inline\">\\(j\\)</span>为最后一个分配到该机器的任务,由贪心算法,在任务<span\r\nclass=\"math inline\">\\(j\\)</span>分配之前,机器<span\r\nclass=\"math inline\">\\(i\\)</span>的负载是最小的.<span\r\nclass=\"math inline\">\\(j\\)</span>分配之前机器<span\r\nclass=\"math inline\">\\(i\\)</span>的负载为<span class=\"math inline\">\\(L_i\r\n- t_j\\)</span>,也就是说在准备分配<span\r\nclass=\"math inline\">\\(j\\)</span>的时候有<span class=\"math inline\">\\(L_i\r\n- t_j\\)</span>小于或等于所有机器上的负载<span class=\"math inline\">\\(L_k,\r\n1 \\le k \\le m\\)</span></p>\r\n<p><img src=\"/img/近似算法/LoadBalancing贪心算法证明-1.png\" /></p>\r\n<p>分配任务<span class=\"math inline\">\\(j\\)</span>之前,由引理1: <span\r\nclass=\"math display\">\\[  \\begin{aligned}\r\n    L_i - t_j &amp;\\le \\frac{1}{m}\\sum\\limits_k L_k \\\\\r\n        &amp;=  \\frac{1}{m} \\sum\\limits_k t_k \\\\\r\n        &amp;\\le L^*\r\n    \\end{aligned}\\]</span></p>\r\n<p>分配任务<span class=\"math inline\">\\(j\\)</span>后,由上式以及引理2:\r\n<span class=\"math display\">\\[L_i = (L_i -t_i) + t_j \\le L^* +\r\n\\max\\limits_j t_j \\le L^* + L^* = 2L^*\\]</span></p>\r\n<p>那么贪心算法是Load\r\nBalancing的紧2倍近似算法吗?所谓紧的是指该算法可以相比于最优解更低的倍率吗(如1.5倍)?若可以则说明贪心算法并不是Load\r\nBalancing的紧2倍近似算法.</p>\r\n<p>答:大致是的,考虑下面的一个Load Balancing的实例,有<span\r\nclass=\"math inline\">\\(m\\)</span>个机器,<span\r\nclass=\"math inline\">\\(m^2\\)</span>个任务,其中有<span\r\nclass=\"math inline\">\\(m(m-1)\\)</span>个任务运行时间为1,一个任务的运行时间为<span\r\nclass=\"math inline\">\\(m\\)</span>.贪心算法的结果如下图所示:</p>\r\n<p><img src=\"/img/近似算法/LoadBalancing实例-贪心算法.png\" /></p>\r\n<p>而最优解的结果为:</p>\r\n<p><img src=\"/img/近似算法/LoadBalancing实例-最优解.png\" /></p>\r\n<p>这个实例里贪心算法的时间跨度为19,而最优解的时间跨度为10.</p>\r\n<h3 id=\"lptlongest-processing-time算法\">LPT(longest Processing\r\nTime)算法</h3>\r\n<p>LPT算法是在上面的贪心算法基础之上,先对<span\r\nclass=\"math inline\">\\(n\\)</span>个任务按时间降序排序,然后再按照上面的贪心算法执行.</p>\r\n<p><img src=\"/img/近似算法/LoadBalancingLPT算法.png\" /></p>\r\n<p>通过观察可以得出,当任务数小于或等于机器数的时候,LRT算法就是最优解.这时候只需要把任务<span\r\nclass=\"math inline\">\\(i\\)</span>分配给机器<span\r\nclass=\"math inline\">\\(i\\)</span>.</p>\r\n<p><strong>引理3</strong>:如果任务数多于机器数<span\r\nclass=\"math inline\">\\(m\\)</span>,有<span class=\"math inline\">\\(L^* \\ge\r\n2t_{m+1}\\)</span>.</p>\r\n<p>设前<span\r\nclass=\"math inline\">\\(m+1\\)</span>个任务的运行时间分别为<span\r\nclass=\"math inline\">\\(t_1,\\dots,t_{m+1}\\)</span>,由于运行时间<span\r\nclass=\"math inline\">\\(t_i\\)</span>是按照降序排列,所以前<span\r\nclass=\"math inline\">\\(m+1\\)</span>个任务的运行时间都不小于<span\r\nclass=\"math inline\">\\(t_{m\r\n+1}\\)</span>,且由于鸽笼原则,至少有一个机器会被分配两个任务.</p>\r\n<p><strong>定理:LPT算法是Load Balancing的一个<span\r\nclass=\"math inline\">\\(\\frac{3}{2}\\)</span>近似算法.</strong></p>\r\n<p>证明:与证明贪心算法相同的方法 <span class=\"math display\">\\[L_i=(L_i -\r\nt_j) + t_j \\le L^* + \\frac{1}{2}L^* = \\frac{3}{2}L\\]</span></p>\r\n<p>那么LPT算法是Load Balancing的紧<span\r\nclass=\"math inline\">\\(\\frac{3}{2}\\)</span>倍近似算法吗?不是;LPT算法是Load\r\nBalancing的紧<span\r\nclass=\"math inline\">\\(\\frac{4}{3}\\)</span>倍近似算法吗?很可能是.</p>\r\n<h2 id=\"centrer-selection-problem中心选址问题\">Centrer Selection\r\nProblem(中心选址问题)</h2>\r\n<p>定义:给定一个大小为<span\r\nclass=\"math inline\">\\(n\\)</span>个地址集合<span\r\nclass=\"math inline\">\\(s_1,s_2,\\dots,s_n\\)</span>以及一个整数<span\r\nclass=\"math inline\">\\(k&gt;0\\)</span>,选择<span\r\nclass=\"math inline\">\\(k\\)</span>个中心使所有地址到离它最近的中心距离的最大值最短.</p>\r\n<p><img src=\"/img/近似算法/CentrerSelectionProblem.png\" /></p>\r\n<p>几个概念:</p>\r\n<ul>\r\n<li><span class=\"math inline\">\\(dist(x, y)\\)</span>:<span\r\nclass=\"math inline\">\\(x,y\\)</span>的距离.</li>\r\n<li><span class=\"math inline\">\\(dist(s_i, C)=\\min\\limits_{c \\in\r\nC}\\)</span>:<span\r\nclass=\"math inline\">\\(s_i\\)</span>到离它最近的中心的距离,这里采用欧式距离.</li>\r\n<li><span class=\"math inline\">\\(r(C)=\\max\\limits_{i}\r\ndist(s_i,C)\\)</span>:最小的覆盖半径.</li>\r\n</ul>\r\n<p>中心选址问题的目标便是找到一个中心集合<span\r\nclass=\"math inline\">\\(C\\)</span>使覆盖半径<span\r\nclass=\"math inline\">\\(r(C)\\)</span>最小,其中中心的数量等于<span\r\nclass=\"math inline\">\\(k\\)</span>.</p>\r\n<p>距离的一些性质: <span class=\"math display\">\\[dist(x,x)=0\r\n\\tag{同一性}\\]</span> <span class=\"math display\">\\[dist(x,y)=dist(y,x)\r\n\\tag{对称性}\\]</span> <span class=\"math display\">\\[dist(x,y) \\le\r\ndist(x,z) + dist(z,y) \\tag{三角不等式}\\]</span></p>\r\n<h3 id=\"贪心算法-1\">贪心算法</h3>\r\n<p>开始时我们任意选取一个地址作为中心，接着选择离第一个中心最远的那个地址作为第二个中心，如此的重复进行,直到选了<span\r\nclass=\"math inline\">\\(k\\)</span>个中心为止。</p>\r\n<p><img src=\"/img/近似算法/CentrerSelectionProblem贪心算法.png\" /></p>\r\n<p><strong>定理：贪心算法是中心选址问题的2倍近似解</strong></p>\r\n<p>证明(反证法)：</p>\r\n<p>假设<span\r\nclass=\"math inline\">\\(r(C^*)&lt;\\frac{1}{2}r(C)\\)</span></p>\r\n<ul>\r\n<li>对近似解集合<span class=\"math inline\">\\(C\\)</span>的中心<span\r\nclass=\"math inline\">\\(c_i\\)</span>，总有一个最优解的中心<span\r\nclass=\"math inline\">\\(c_i^*\\)</span>在<span\r\nclass=\"math inline\">\\(c_i\\)</span>的圆中(任意一个最优解的中心<span\r\nclass=\"math inline\">\\(c_i^*\\)</span>的圆里最少有一个地址<span\r\nclass=\"math inline\">\\(s\\)</span>,而贪心算法选址都是在地址集合中选的，并且<span\r\nclass=\"math inline\">\\(c_i\\)</span>的半径 <span\r\nclass=\"math inline\">\\(&gt;\\)</span> <span\r\nclass=\"math inline\">\\(c_i^*\\)</span>的半径，所以<span\r\nclass=\"math inline\">\\(c_i^*\\)</span>必然在某一个中心<span\r\nclass=\"math inline\">\\(c_i\\)</span>的圆里)</li>\r\n<li>令<span class=\"math inline\">\\(c_i\\)</span>是与<span\r\nclass=\"math inline\">\\(c_i^*\\)</span>对应的中心</li>\r\n<li>对于任意一个离最优解<span\r\nclass=\"math inline\">\\(c_i^*\\)</span>最近的地址<span\r\nclass=\"math inline\">\\(s\\)</span>,有</li>\r\n</ul>\r\n<p><span class=\"math display\">\\[dist(s,C) \\le dist(s, c_i) \\le dist(s,\r\nc_i^*) + dist(c_i^*, c_i) \\le r(C^*) + r(C^*) = 2r(C^*)\\]</span></p>\r\n<p>上式与假设<span\r\nclass=\"math inline\">\\(r(C^*)&lt;\\frac{1}{2}r(C)\\)</span>相违背，故有<span\r\nclass=\"math inline\">\\(r(C^*) \\ge\r\n\\frac{1}{2}r(C)\\)</span>,即贪心算法是中心选址问题的2倍近似解。</p>\r\n<p>中心选址问题有没有<span\r\nclass=\"math inline\">\\(\\frac{3}{2}\\)</span>倍近似解或者<span\r\nclass=\"math inline\">\\(\\frac{4}{3}\\)</span>倍近似解？</p>\r\n<p>答：没有，除非P＝NP，否则中心选址问题没有倍率比2小的近似算法。</p>\r\n<h2 id=\"weighted-vertex-cover\">Weighted Vertex Cover</h2>\r\n<p>带权值的顶点覆盖：对于给出的一个顶点带权值的图<span\r\nclass=\"math inline\">\\(G\\)</span>，找到一个顶点覆盖，使它们的权值之和最小。\r\n（这里我们主要解决的是：求图<span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>的顶点覆盖<span\r\nclass=\"math inline\">\\(S\\)</span>，要使顶点集合<span\r\nclass=\"math inline\">\\(S\\)</span>中所有顶点的权值之和最小。</p>\r\n<p><img src=\"/img/近似算法/WeightedVertexCover.png\" /></p>\r\n<h3 id=\"pricing-method\">Pricing Method</h3>\r\n<p><strong>定价法</strong>：因为顶点覆盖要求每条边至少有一个顶点在集合<span\r\nclass=\"math inline\">\\(S\\)</span>里,每条边必须被一些顶点所覆盖，根据顶点<span\r\nclass=\"math inline\">\\(i\\)</span>和<span\r\nclass=\"math inline\">\\(j\\)</span>，给边<span class=\"math inline\">\\(e =\r\n(i, j)\\)</span> 标上价格<span class=\"math inline\">\\(P_e\\)</span>。</p>\r\n<p>公平性：与顶点<span\r\nclass=\"math inline\">\\(i\\)</span>所连接的所有边的价格（权值）之和必须小于顶点<span\r\nclass=\"math inline\">\\(i\\)</span>的权值。</p>\r\n<p>引理：：图<span\r\nclass=\"math inline\">\\(G\\)</span>的所有边的价格（权值）之和 <span\r\nclass=\"math inline\">\\(\\le\\)</span> 顶点覆盖<span\r\nclass=\"math inline\">\\(S\\)</span>中所有顶点的权值之和（两个简单的缩放）。</p>\r\n<p><img src=\"/img/近似算法/WeightedVertexCover-不等式放缩.png\" /></p>\r\n<p>(上面第一个 <span class=\"math inline\">\\(\\le\\)</span>\r\n好像可以写成等号？)</p>\r\n<p>求解过程：边的价格设置与找寻顶点覆盖同时进行</p>\r\n<p><img\r\nsrc=\"/img/近似算法/WeightedVertexCover-PricingMethod-求解过程.png\" /></p>\r\n<p>例子：</p>\r\n<p><img\r\nsrc=\"/img/近似算法/WeightedVertexCover-PricingMethod-例子.png\" /></p>\r\n<p><strong>Pricing Method是Weighted Vertex\r\nCover</strong>的一个2倍近似算法。</p>\r\n<p>证明：</p>\r\n<p>首先证明<span class=\"math inline\">\\(S\\)</span>是一个点覆盖：</p>\r\n<p>算法结束条件：在while循环的每次迭代结束之后，至少有一个顶点会是紧致的（除非图没有边），所以在算法结束的时候每条边的两个顶点中至少有一个是紧的，即每条边至少有一个顶点在<span\r\nclass=\"math inline\">\\(S\\)</span>中，而Vertex\r\nCover要求每条边至少有一个顶点在<span\r\nclass=\"math inline\">\\(S\\)</span>中，所以<span\r\nclass=\"math inline\">\\(S\\)</span>必然是一个点覆盖，否则循环就不会停止。</p>\r\n<p>然后再证明<span\r\nclass=\"math inline\">\\(S\\)</span>是最优解的一个2倍近似解：</p>\r\n<p><img src=\"/img/近似算法/证明PricingMethod2倍近似解.png\" /></p>\r\n<p>第一处放缩很容易得出，<span\r\nclass=\"math inline\">\\(S\\)</span>肯定为顶点集<span\r\nclass=\"math inline\">\\(V\\)</span>的一个子集；<span\r\nclass=\"math inline\">\\(\\sum\\limits_{i \\in V} \\sum\\limits_{e=(i,j)} p_e =\r\n2 \\sum\\limits_{e \\in E} p_e\\)</span>是因为算与<span\r\nclass=\"math inline\">\\(V\\)</span>中所有顶点相连的边时，每条边会被计算两次；最右边一个放缩为引理的结论。</p>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"近似算法\">近似算法</h2>\r\n<p>假设现在需要解决一个NP-Hard问题，但是又不太可能在多项式时间内求解，但是我们可以退而求其次，那么就必须要牺牲下面的其中一项：</p>\r\n<ul>\r\n<li>求得最优解</li>\r\n<li>在多项式时间内完成</li>\r\n<li>覆盖问题的所有例子</li>\r\n</ul>\r\n<p>而牺牲第二条是不能接受的，当我们选择满足后两者（也就是牺牲第一项），即对解的优越性放宽要求时，设计出的算法被称为<strong>近似算法</strong>。</p>\r\n<h2 id=\"load-balancing问题\">Load Balancing问题</h2>\r\n<p>给定<span class=\"math inline\">\\(m\\)</span>台相同的机器，<span\r\nclass=\"math inline\">\\(n\\)</span>个任务，任务<span\r\nclass=\"math inline\">\\(j\\)</span>需要的处理时间为<span\r\nclass=\"math inline\">\\(t_j\\)</span>,且每个任务<span\r\nclass=\"math inline\">\\(j\\)</span>必须在一台机器上连续完成。</p>\r\n<p>令<span class=\"math inline\">\\(J(i)\\)</span>为分配给机器<span\r\nclass=\"math inline\">\\(i\\)</span>的任务子集，机器<span\r\nclass=\"math inline\">\\(i\\)</span>的负载为<span\r\nclass=\"math inline\">\\(L_i=\\sum\\limits_{j \\in\r\nJ(i)}t_j\\)</span>,该问题的时间跨度(makespan)为所有机器上的结束时间最大值<span\r\nclass=\"math inline\">\\(L=\\max\\limits_i L_i\\)</span>。</p>\r\n<p><strong>Load\r\nBalancing</strong>：求上述问题中的任务分配使得时间跨度最小。</p>\r\n<h3 id=\"贪心算法\">贪心算法</h3>\r\n<p>每次将任务<span\r\nclass=\"math inline\">\\(j\\)</span>分配在当前负载最小的机器上： <img\r\nsrc=\"/img/近似算法/LoadBalancing贪心算法.png\" /></p>\r\n<p><strong>引理1</strong>：最优解makespan<span class=\"math inline\">\\(L^*\r\n\\ge \\max\\limits_j t_j\\)</span>。</p>\r\n<p>用时最长的这个任务总需要分配到一个机器上完成.</p>\r\n<p><strong>引理2</strong>:最优解makespan <span class=\"math inline\">\\(L^*\r\n\\ge \\frac{1}{m} \\sum\\limits_j t_j\\)</span></p>\r\n<p>所有任务的总运行时间为<span class=\"math inline\">\\(\\sum\\limits_j\r\nt_j\\)</span>,那么<span\r\nclass=\"math inline\">\\(L^*\\)</span>的时间跨度必然选自<span\r\nclass=\"math inline\">\\(m\\)</span>个机器中的一个,而每个机器的最小时间跨度为<span\r\nclass=\"math inline\">\\(\\frac{1}{m}\\)</span>的总运行时间.</p>\r\n<p><strong>定理:贪心算法是Load\r\nBalancing问题的二倍近似算法。</strong></p>\r\n<p>证明:</p>\r\n<p>假设负载<span class=\"math inline\">\\(L_i\\)</span>为问题的平静,令<span\r\nclass=\"math inline\">\\(j\\)</span>为最后一个分配到该机器的任务,由贪心算法,在任务<span\r\nclass=\"math inline\">\\(j\\)</span>分配之前,机器<span\r\nclass=\"math inline\">\\(i\\)</span>的负载是最小的.<span\r\nclass=\"math inline\">\\(j\\)</span>分配之前机器<span\r\nclass=\"math inline\">\\(i\\)</span>的负载为<span class=\"math inline\">\\(L_i\r\n- t_j\\)</span>,也就是说在准备分配<span\r\nclass=\"math inline\">\\(j\\)</span>的时候有<span class=\"math inline\">\\(L_i\r\n- t_j\\)</span>小于或等于所有机器上的负载<span class=\"math inline\">\\(L_k,\r\n1 \\le k \\le m\\)</span></p>\r\n<p><img src=\"/img/近似算法/LoadBalancing贪心算法证明-1.png\" /></p>\r\n<p>分配任务<span class=\"math inline\">\\(j\\)</span>之前,由引理1: <span\r\nclass=\"math display\">\\[  \\begin{aligned}\r\n    L_i - t_j &amp;\\le \\frac{1}{m}\\sum\\limits_k L_k \\\\\r\n        &amp;=  \\frac{1}{m} \\sum\\limits_k t_k \\\\\r\n        &amp;\\le L^*\r\n    \\end{aligned}\\]</span></p>\r\n<p>分配任务<span class=\"math inline\">\\(j\\)</span>后,由上式以及引理2:\r\n<span class=\"math display\">\\[L_i = (L_i -t_i) + t_j \\le L^* +\r\n\\max\\limits_j t_j \\le L^* + L^* = 2L^*\\]</span></p>\r\n<p>那么贪心算法是Load\r\nBalancing的紧2倍近似算法吗?所谓紧的是指该算法可以相比于最优解更低的倍率吗(如1.5倍)?若可以则说明贪心算法并不是Load\r\nBalancing的紧2倍近似算法.</p>\r\n<p>答:大致是的,考虑下面的一个Load Balancing的实例,有<span\r\nclass=\"math inline\">\\(m\\)</span>个机器,<span\r\nclass=\"math inline\">\\(m^2\\)</span>个任务,其中有<span\r\nclass=\"math inline\">\\(m(m-1)\\)</span>个任务运行时间为1,一个任务的运行时间为<span\r\nclass=\"math inline\">\\(m\\)</span>.贪心算法的结果如下图所示:</p>\r\n<p><img src=\"/img/近似算法/LoadBalancing实例-贪心算法.png\" /></p>\r\n<p>而最优解的结果为:</p>\r\n<p><img src=\"/img/近似算法/LoadBalancing实例-最优解.png\" /></p>\r\n<p>这个实例里贪心算法的时间跨度为19,而最优解的时间跨度为10.</p>\r\n<h3 id=\"lptlongest-processing-time算法\">LPT(longest Processing\r\nTime)算法</h3>\r\n<p>LPT算法是在上面的贪心算法基础之上,先对<span\r\nclass=\"math inline\">\\(n\\)</span>个任务按时间降序排序,然后再按照上面的贪心算法执行.</p>\r\n<p><img src=\"/img/近似算法/LoadBalancingLPT算法.png\" /></p>\r\n<p>通过观察可以得出,当任务数小于或等于机器数的时候,LRT算法就是最优解.这时候只需要把任务<span\r\nclass=\"math inline\">\\(i\\)</span>分配给机器<span\r\nclass=\"math inline\">\\(i\\)</span>.</p>\r\n<p><strong>引理3</strong>:如果任务数多于机器数<span\r\nclass=\"math inline\">\\(m\\)</span>,有<span class=\"math inline\">\\(L^* \\ge\r\n2t_{m+1}\\)</span>.</p>\r\n<p>设前<span\r\nclass=\"math inline\">\\(m+1\\)</span>个任务的运行时间分别为<span\r\nclass=\"math inline\">\\(t_1,\\dots,t_{m+1}\\)</span>,由于运行时间<span\r\nclass=\"math inline\">\\(t_i\\)</span>是按照降序排列,所以前<span\r\nclass=\"math inline\">\\(m+1\\)</span>个任务的运行时间都不小于<span\r\nclass=\"math inline\">\\(t_{m\r\n+1}\\)</span>,且由于鸽笼原则,至少有一个机器会被分配两个任务.</p>\r\n<p><strong>定理:LPT算法是Load Balancing的一个<span\r\nclass=\"math inline\">\\(\\frac{3}{2}\\)</span>近似算法.</strong></p>\r\n<p>证明:与证明贪心算法相同的方法 <span class=\"math display\">\\[L_i=(L_i -\r\nt_j) + t_j \\le L^* + \\frac{1}{2}L^* = \\frac{3}{2}L\\]</span></p>\r\n<p>那么LPT算法是Load Balancing的紧<span\r\nclass=\"math inline\">\\(\\frac{3}{2}\\)</span>倍近似算法吗?不是;LPT算法是Load\r\nBalancing的紧<span\r\nclass=\"math inline\">\\(\\frac{4}{3}\\)</span>倍近似算法吗?很可能是.</p>\r\n<h2 id=\"centrer-selection-problem中心选址问题\">Centrer Selection\r\nProblem(中心选址问题)</h2>\r\n<p>定义:给定一个大小为<span\r\nclass=\"math inline\">\\(n\\)</span>个地址集合<span\r\nclass=\"math inline\">\\(s_1,s_2,\\dots,s_n\\)</span>以及一个整数<span\r\nclass=\"math inline\">\\(k&gt;0\\)</span>,选择<span\r\nclass=\"math inline\">\\(k\\)</span>个中心使所有地址到离它最近的中心距离的最大值最短.</p>\r\n<p><img src=\"/img/近似算法/CentrerSelectionProblem.png\" /></p>\r\n<p>几个概念:</p>\r\n<ul>\r\n<li><span class=\"math inline\">\\(dist(x, y)\\)</span>:<span\r\nclass=\"math inline\">\\(x,y\\)</span>的距离.</li>\r\n<li><span class=\"math inline\">\\(dist(s_i, C)=\\min\\limits_{c \\in\r\nC}\\)</span>:<span\r\nclass=\"math inline\">\\(s_i\\)</span>到离它最近的中心的距离,这里采用欧式距离.</li>\r\n<li><span class=\"math inline\">\\(r(C)=\\max\\limits_{i}\r\ndist(s_i,C)\\)</span>:最小的覆盖半径.</li>\r\n</ul>\r\n<p>中心选址问题的目标便是找到一个中心集合<span\r\nclass=\"math inline\">\\(C\\)</span>使覆盖半径<span\r\nclass=\"math inline\">\\(r(C)\\)</span>最小,其中中心的数量等于<span\r\nclass=\"math inline\">\\(k\\)</span>.</p>\r\n<p>距离的一些性质: <span class=\"math display\">\\[dist(x,x)=0\r\n\\tag{同一性}\\]</span> <span class=\"math display\">\\[dist(x,y)=dist(y,x)\r\n\\tag{对称性}\\]</span> <span class=\"math display\">\\[dist(x,y) \\le\r\ndist(x,z) + dist(z,y) \\tag{三角不等式}\\]</span></p>\r\n<h3 id=\"贪心算法-1\">贪心算法</h3>\r\n<p>开始时我们任意选取一个地址作为中心，接着选择离第一个中心最远的那个地址作为第二个中心，如此的重复进行,直到选了<span\r\nclass=\"math inline\">\\(k\\)</span>个中心为止。</p>\r\n<p><img src=\"/img/近似算法/CentrerSelectionProblem贪心算法.png\" /></p>\r\n<p><strong>定理：贪心算法是中心选址问题的2倍近似解</strong></p>\r\n<p>证明(反证法)：</p>\r\n<p>假设<span\r\nclass=\"math inline\">\\(r(C^*)&lt;\\frac{1}{2}r(C)\\)</span></p>\r\n<ul>\r\n<li>对近似解集合<span class=\"math inline\">\\(C\\)</span>的中心<span\r\nclass=\"math inline\">\\(c_i\\)</span>，总有一个最优解的中心<span\r\nclass=\"math inline\">\\(c_i^*\\)</span>在<span\r\nclass=\"math inline\">\\(c_i\\)</span>的圆中(任意一个最优解的中心<span\r\nclass=\"math inline\">\\(c_i^*\\)</span>的圆里最少有一个地址<span\r\nclass=\"math inline\">\\(s\\)</span>,而贪心算法选址都是在地址集合中选的，并且<span\r\nclass=\"math inline\">\\(c_i\\)</span>的半径 <span\r\nclass=\"math inline\">\\(&gt;\\)</span> <span\r\nclass=\"math inline\">\\(c_i^*\\)</span>的半径，所以<span\r\nclass=\"math inline\">\\(c_i^*\\)</span>必然在某一个中心<span\r\nclass=\"math inline\">\\(c_i\\)</span>的圆里)</li>\r\n<li>令<span class=\"math inline\">\\(c_i\\)</span>是与<span\r\nclass=\"math inline\">\\(c_i^*\\)</span>对应的中心</li>\r\n<li>对于任意一个离最优解<span\r\nclass=\"math inline\">\\(c_i^*\\)</span>最近的地址<span\r\nclass=\"math inline\">\\(s\\)</span>,有</li>\r\n</ul>\r\n<p><span class=\"math display\">\\[dist(s,C) \\le dist(s, c_i) \\le dist(s,\r\nc_i^*) + dist(c_i^*, c_i) \\le r(C^*) + r(C^*) = 2r(C^*)\\]</span></p>\r\n<p>上式与假设<span\r\nclass=\"math inline\">\\(r(C^*)&lt;\\frac{1}{2}r(C)\\)</span>相违背，故有<span\r\nclass=\"math inline\">\\(r(C^*) \\ge\r\n\\frac{1}{2}r(C)\\)</span>,即贪心算法是中心选址问题的2倍近似解。</p>\r\n<p>中心选址问题有没有<span\r\nclass=\"math inline\">\\(\\frac{3}{2}\\)</span>倍近似解或者<span\r\nclass=\"math inline\">\\(\\frac{4}{3}\\)</span>倍近似解？</p>\r\n<p>答：没有，除非P＝NP，否则中心选址问题没有倍率比2小的近似算法。</p>\r\n<h2 id=\"weighted-vertex-cover\">Weighted Vertex Cover</h2>\r\n<p>带权值的顶点覆盖：对于给出的一个顶点带权值的图<span\r\nclass=\"math inline\">\\(G\\)</span>，找到一个顶点覆盖，使它们的权值之和最小。\r\n（这里我们主要解决的是：求图<span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>的顶点覆盖<span\r\nclass=\"math inline\">\\(S\\)</span>，要使顶点集合<span\r\nclass=\"math inline\">\\(S\\)</span>中所有顶点的权值之和最小。</p>\r\n<p><img src=\"/img/近似算法/WeightedVertexCover.png\" /></p>\r\n<h3 id=\"pricing-method\">Pricing Method</h3>\r\n<p><strong>定价法</strong>：因为顶点覆盖要求每条边至少有一个顶点在集合<span\r\nclass=\"math inline\">\\(S\\)</span>里,每条边必须被一些顶点所覆盖，根据顶点<span\r\nclass=\"math inline\">\\(i\\)</span>和<span\r\nclass=\"math inline\">\\(j\\)</span>，给边<span class=\"math inline\">\\(e =\r\n(i, j)\\)</span> 标上价格<span class=\"math inline\">\\(P_e\\)</span>。</p>\r\n<p>公平性：与顶点<span\r\nclass=\"math inline\">\\(i\\)</span>所连接的所有边的价格（权值）之和必须小于顶点<span\r\nclass=\"math inline\">\\(i\\)</span>的权值。</p>\r\n<p>引理：：图<span\r\nclass=\"math inline\">\\(G\\)</span>的所有边的价格（权值）之和 <span\r\nclass=\"math inline\">\\(\\le\\)</span> 顶点覆盖<span\r\nclass=\"math inline\">\\(S\\)</span>中所有顶点的权值之和（两个简单的缩放）。</p>\r\n<p><img src=\"/img/近似算法/WeightedVertexCover-不等式放缩.png\" /></p>\r\n<p>(上面第一个 <span class=\"math inline\">\\(\\le\\)</span>\r\n好像可以写成等号？)</p>\r\n<p>求解过程：边的价格设置与找寻顶点覆盖同时进行</p>\r\n<p><img\r\nsrc=\"/img/近似算法/WeightedVertexCover-PricingMethod-求解过程.png\" /></p>\r\n<p>例子：</p>\r\n<p><img\r\nsrc=\"/img/近似算法/WeightedVertexCover-PricingMethod-例子.png\" /></p>\r\n<p><strong>Pricing Method是Weighted Vertex\r\nCover</strong>的一个2倍近似算法。</p>\r\n<p>证明：</p>\r\n<p>首先证明<span class=\"math inline\">\\(S\\)</span>是一个点覆盖：</p>\r\n<p>算法结束条件：在while循环的每次迭代结束之后，至少有一个顶点会是紧致的（除非图没有边），所以在算法结束的时候每条边的两个顶点中至少有一个是紧的，即每条边至少有一个顶点在<span\r\nclass=\"math inline\">\\(S\\)</span>中，而Vertex\r\nCover要求每条边至少有一个顶点在<span\r\nclass=\"math inline\">\\(S\\)</span>中，所以<span\r\nclass=\"math inline\">\\(S\\)</span>必然是一个点覆盖，否则循环就不会停止。</p>\r\n<p>然后再证明<span\r\nclass=\"math inline\">\\(S\\)</span>是最优解的一个2倍近似解：</p>\r\n<p><img src=\"/img/近似算法/证明PricingMethod2倍近似解.png\" /></p>\r\n<p>第一处放缩很容易得出，<span\r\nclass=\"math inline\">\\(S\\)</span>肯定为顶点集<span\r\nclass=\"math inline\">\\(V\\)</span>的一个子集；<span\r\nclass=\"math inline\">\\(\\sum\\limits_{i \\in V} \\sum\\limits_{e=(i,j)} p_e =\r\n2 \\sum\\limits_{e \\in E} p_e\\)</span>是因为算与<span\r\nclass=\"math inline\">\\(V\\)</span>中所有顶点相连的边时，每条边会被计算两次；最右边一个放缩为引理的结论。</p>\r\n"},{"title":"矩阵级数和矩阵函数","_content":"\n## 矩阵序列\n","source":"_posts/矩阵级数和矩阵函数.md","raw":"---\ntitle: 矩阵级数和矩阵函数\ntags: 矩阵论\ncategories:\n    - 数学\n    - 矩阵论\n---\n\n## 矩阵序列\n","slug":"矩阵级数和矩阵函数","published":1,"date":"2022-12-05T07:20:39.771Z","updated":"2022-12-05T07:21:18.690Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clbf4q8oi0016r4sgayi31g2a","content":"<h2 id=\"矩阵序列\">矩阵序列</h2>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"矩阵序列\">矩阵序列</h2>\r\n"}],"PostAsset":[],"PostCategory":[{"post_id":"clbf4q8ob000cr4sgdala6ml9","category_id":"clbf4q8oa0009r4sg2nz2h93r","_id":"clbf4q8od000kr4sg5jza778q"},{"post_id":"clbf4q8o90006r4sg9zweajzy","category_id":"clbf4q8oa0009r4sg2nz2h93r","_id":"clbf4q8of000or4sg3ydj9nm8"},{"post_id":"clbf4q8o30001r4sg2b5jfcc7","category_id":"clbf4q8o70003r4sghiqp7wng","_id":"clbf4q8og000tr4sg2zm2gdwp"},{"post_id":"clbf4q8o30001r4sg2b5jfcc7","category_id":"clbf4q8oc000fr4sg9jtqavfk","_id":"clbf4q8oh000wr4sg66vi1ixx"},{"post_id":"clbf4q8od000jr4sg411me7kn","category_id":"clbf4q8o70003r4sghiqp7wng","_id":"clbf4q8oh0011r4sgh7u0hdgf"},{"post_id":"clbf4q8od000jr4sg411me7kn","category_id":"clbf4q8oc000fr4sg9jtqavfk","_id":"clbf4q8oi0014r4sg0o31ebpg"},{"post_id":"clbf4q8oe000nr4sghcmtbwke","category_id":"clbf4q8o70003r4sghiqp7wng","_id":"clbf4q8oj0019r4sg845ffald"},{"post_id":"clbf4q8oe000nr4sghcmtbwke","category_id":"clbf4q8oc000fr4sg9jtqavfk","_id":"clbf4q8oj001br4sggg88fs38"},{"post_id":"clbf4q8o90007r4sg6at64sdw","category_id":"clbf4q8oa0009r4sg2nz2h93r","_id":"clbf4q8oj001er4sg0kjj7gb0"},{"post_id":"clbf4q8og000vr4sgbghm1yxq","category_id":"clbf4q8o70003r4sghiqp7wng","_id":"clbf4q8oj001gr4sg0ssf3rj4"},{"post_id":"clbf4q8og000vr4sgbghm1yxq","category_id":"clbf4q8oc000fr4sg9jtqavfk","_id":"clbf4q8oj001ir4sg5ew11xom"},{"post_id":"clbf4q8oa000br4sgdl5l609u","category_id":"clbf4q8oa0009r4sg2nz2h93r","_id":"clbf4q8ok001lr4sgdivodlsp"},{"post_id":"clbf4q8oi0013r4sg16kb6u8s","category_id":"clbf4q8oa0009r4sg2nz2h93r","_id":"clbf4q8ol001nr4sg5zsoe1f1"},{"post_id":"clbf4q8ob000er4sg0etwcx1o","category_id":"clbf4q8o70003r4sghiqp7wng","_id":"clbf4q8ol001qr4sgh8nvgtci"},{"post_id":"clbf4q8ob000er4sg0etwcx1o","category_id":"clbf4q8oc000fr4sg9jtqavfk","_id":"clbf4q8ol001rr4sg74fr7ojm"},{"post_id":"clbf4q8oi0016r4sgayi31g2a","category_id":"clbf4q8o70003r4sghiqp7wng","_id":"clbf4q8ol001ur4sgh4q7ean0"},{"post_id":"clbf4q8oi0016r4sgayi31g2a","category_id":"clbf4q8oc000fr4sg9jtqavfk","_id":"clbf4q8ol001wr4sg4ojibons"},{"post_id":"clbf4q8oc000gr4sg66je50y1","category_id":"clbf4q8o70003r4sghiqp7wng","_id":"clbf4q8ol001yr4sg8blm7k26"},{"post_id":"clbf4q8oc000gr4sg66je50y1","category_id":"clbf4q8oi0018r4sg38j47o8i","_id":"clbf4q8ol0020r4sg592pbx8c"}],"PostTag":[{"post_id":"clbf4q8o30001r4sg2b5jfcc7","tag_id":"clbf4q8o70004r4sg3pkd7w2n","_id":"clbf4q8oa000ar4sg3aok0ooj"},{"post_id":"clbf4q8ob000er4sg0etwcx1o","tag_id":"clbf4q8o70004r4sg3pkd7w2n","_id":"clbf4q8od000ir4sg709hhtvz"},{"post_id":"clbf4q8o80005r4sgchpq6n4s","tag_id":"clbf4q8oa0008r4sg4n576xpp","_id":"clbf4q8oe000mr4sg3mxieuqn"},{"post_id":"clbf4q8o80005r4sgchpq6n4s","tag_id":"clbf4q8ob000dr4sg9n826egw","_id":"clbf4q8of000pr4sggmaph6ly"},{"post_id":"clbf4q8od000jr4sg411me7kn","tag_id":"clbf4q8o70004r4sg3pkd7w2n","_id":"clbf4q8og000ur4sg6nf4722e"},{"post_id":"clbf4q8o90006r4sg9zweajzy","tag_id":"clbf4q8od000hr4sg3g772oxa","_id":"clbf4q8oh000xr4sgg1s2essn"},{"post_id":"clbf4q8oe000nr4sghcmtbwke","tag_id":"clbf4q8o70004r4sg3pkd7w2n","_id":"clbf4q8oi0012r4sgdr221jre"},{"post_id":"clbf4q8of000rr4sg2z6c8zza","tag_id":"clbf4q8od000hr4sg3g772oxa","_id":"clbf4q8oi0015r4sgf8ib5e4w"},{"post_id":"clbf4q8og000vr4sgbghm1yxq","tag_id":"clbf4q8o70004r4sg3pkd7w2n","_id":"clbf4q8oj001ar4sg7izo5jzm"},{"post_id":"clbf4q8oh000zr4sge1181zld","tag_id":"clbf4q8od000hr4sg3g772oxa","_id":"clbf4q8oj001cr4sg4fba77id"},{"post_id":"clbf4q8o90007r4sg6at64sdw","tag_id":"clbf4q8od000hr4sg3g772oxa","_id":"clbf4q8oj001fr4sgabse9trq"},{"post_id":"clbf4q8o90007r4sg6at64sdw","tag_id":"clbf4q8oh000yr4sg6pzjey4d","_id":"clbf4q8oj001hr4sg5tex880x"},{"post_id":"clbf4q8oi0016r4sgayi31g2a","tag_id":"clbf4q8o70004r4sg3pkd7w2n","_id":"clbf4q8ok001kr4sg8btaaq77"},{"post_id":"clbf4q8oa000br4sgdl5l609u","tag_id":"clbf4q8od000hr4sg3g772oxa","_id":"clbf4q8ok001mr4sgg49ocrlt"},{"post_id":"clbf4q8oa000br4sgdl5l609u","tag_id":"clbf4q8oj001dr4sghm6x7abi","_id":"clbf4q8ol001pr4sgcbq279gt"},{"post_id":"clbf4q8ob000cr4sgdala6ml9","tag_id":"clbf4q8od000hr4sg3g772oxa","_id":"clbf4q8ol001tr4sg0bj749fm"},{"post_id":"clbf4q8ob000cr4sgdala6ml9","tag_id":"clbf4q8oj001dr4sghm6x7abi","_id":"clbf4q8ol001vr4sgdr70061z"},{"post_id":"clbf4q8oc000gr4sg66je50y1","tag_id":"clbf4q8ol001sr4sgfhvl4qpe","_id":"clbf4q8ol001zr4sgdsc165nj"},{"post_id":"clbf4q8oi0013r4sg16kb6u8s","tag_id":"clbf4q8od000hr4sg3g772oxa","_id":"clbf4q8om0021r4sgdk8i58sr"},{"post_id":"clbf4q8oi0013r4sg16kb6u8s","tag_id":"clbf4q8oj001dr4sghm6x7abi","_id":"clbf4q8om0022r4sg7y9q8wqk"}],"Tag":[{"name":"矩阵论","_id":"clbf4q8o70004r4sg3pkd7w2n"},{"name":"latex","_id":"clbf4q8oa0008r4sg4n576xpp"},{"name":"杂","_id":"clbf4q8ob000dr4sg9n826egw"},{"name":"算法","_id":"clbf4q8od000hr4sg3g772oxa"},{"name":"算法设计与分析","_id":"clbf4q8oh000yr4sg6pzjey4d"},{"name":"高级算法设计与分析","_id":"clbf4q8oj001dr4sghm6x7abi"},{"name":"随机过程","_id":"clbf4q8ol001sr4sgfhvl4qpe"}]}}