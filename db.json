{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"source/img/动态规划/最短路径.png","path":"img/动态规划/最短路径.png","modified":1,"renderable":0},{"_id":"source/img/动态规划/状态转移方程.svg","path":"img/动态规划/状态转移方程.svg","modified":1,"renderable":0},{"_id":"source/img/动态规划/解决方案.jpg","path":"img/动态规划/解决方案.jpg","modified":1,"renderable":0},{"_id":"source/img/多项式规约/独立集.png","path":"img/多项式规约/独立集.png","modified":1,"renderable":0},{"_id":"source/img/多项式规约/点覆盖.png","path":"img/多项式规约/点覆盖.png","modified":1,"renderable":0},{"_id":"source/img/动态规划/最长上升子序列代码.jpg","path":"img/动态规划/最长上升子序列代码.jpg","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子1.png","path":"img/最大流最小割/Ford-Fulkerson例子1.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子2.png","path":"img/最大流最小割/Ford-Fulkerson例子2.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子3.png","path":"img/最大流最小割/Ford-Fulkerson例子3.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子6.png","path":"img/最大流最小割/Ford-Fulkerson例子6.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子4.png","path":"img/最大流最小割/Ford-Fulkerson例子4.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子5.png","path":"img/最大流最小割/Ford-Fulkerson例子5.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子7.png","path":"img/最大流最小割/Ford-Fulkerson例子7.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/iii到i.png","path":"img/最大流最小割/iii到i.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/一个割例子.png","path":"img/最大流最小割/一个割例子.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/最大流.png","path":"img/最大流最小割/最大流.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/最大流最小割定理.png","path":"img/最大流最小割/最大流最小割定理.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/残余图.png","path":"img/最大流最小割/残余图.png","modified":1,"renderable":0},{"_id":"source/img/最大流最小割/最小割定义.png","path":"img/最大流最小割/最小割定义.png","modified":1,"renderable":0},{"_id":"source/img/胜者树败者树/fig1.jpg","path":"img/胜者树败者树/fig1.jpg","modified":1,"renderable":0},{"_id":"source/img/胜者树败者树/fig3.jpg","path":"img/胜者树败者树/fig3.jpg","modified":1,"renderable":0},{"_id":"source/img/胜者树败者树/fig2.jpg","path":"img/胜者树败者树/fig2.jpg","modified":1,"renderable":0},{"_id":"source/img/胜者树败者树/fig4.jpg","path":"img/胜者树败者树/fig4.jpg","modified":1,"renderable":0},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","path":"img/default.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","path":"img/fluid.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","path":"img/loading.gif","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","path":"css/highlight-dark.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","path":"css/highlight.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","path":"js/boot.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","path":"js/events.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","path":"js/plugins.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":1,"renderable":1}],"Cache":[{"_id":"source/_posts/Git常用命令.md","hash":"7bb310ecc4d3ede1a0d87821108f9c87e5726a69","modified":1670054969350},{"_id":"source/_posts/动态规划.md","hash":"4c6ee63bddf07404e015cba4966f83b8998f7a6b","modified":1670083911193},{"_id":"source/about/index.md","hash":"9aefab0ac381b3378b472ea3ff97de5a58274e89","modified":1669955882134},{"_id":"source/_posts/最大流最小割.md","hash":"8fdebc80b145a21763c2ccd3cb287a94cefe3dc3","modified":1670083584584},{"_id":"source/_posts/多项式规约.md","hash":"7ecfa79ea2d8cca1dec418c19c3903f1425239d5","modified":1670083252653},{"_id":"source/_posts/红黑树.md","hash":"4130f9bea7213a08ba72317646859b570520c3c9","modified":1670055048915},{"_id":"source/_posts/矩阵分解.md","hash":"913e34c6600c739cd3442f5d32ecc5b8256468a2","modified":1670118340614},{"_id":"source/_posts/胜者树败者树.md","hash":"91285e6a406007db9055cc61b67a870f420ca4ec","modified":1670083056104},{"_id":"source/img/动态规划/状态转移方程.svg","hash":"8b5734d7212db7f4d24e95f2d422d7f1c6defb1d","modified":1646918590917},{"_id":"source/img/动态规划/最短路径.png","hash":"0ba147ab707a0e36e3051bff42d30cbaa6759c63","modified":1646917567601},{"_id":"source/img/多项式规约/独立集.png","hash":"c41df5652e2b1ec4fc4c0afa8960ca8db7e7f252","modified":1670070305476},{"_id":"source/img/动态规划/解决方案.jpg","hash":"8500d51aa92b8cf3e1a4faa475de9524d179f978","modified":1646917030251},{"_id":"source/img/多项式规约/点覆盖.png","hash":"021805ebf776c01cd678d4c26f21f8a0672e1902","modified":1670070318643},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子1.png","hash":"67e5f7b1db79d46598fe41b1b57fff2c84dc6d32","modified":1670052565578},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子2.png","hash":"df88bf8af91a2073fbaaba71def9ebebe949b645","modified":1670052706600},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子3.png","hash":"757c7bb6ff26a30ea9e46deb7777740516f225cc","modified":1670052873685},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子6.png","hash":"6a815e321d3abd5d260709d42b921d4cf35f5bf5","modified":1670052929316},{"_id":"source/img/动态规划/最长上升子序列代码.jpg","hash":"d0c1dbb9c49b2b4264b9e6eca7971f38d06e5455","modified":1646918693344},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子4.png","hash":"e08eea19af73ad0bcc8c8c0181173e5db30e19df","modified":1670052896438},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子5.png","hash":"19e85b264deafb8926b70ed397a59cd495e224f6","modified":1670052912631},{"_id":"source/img/最大流最小割/iii到i.png","hash":"eb6738e99b57447dcd63fdf8aa241fb8f5c2b321","modified":1670053933038},{"_id":"source/img/最大流最小割/Ford-Fulkerson例子7.png","hash":"1a935d7a67c1cd2241cdeb2c4a61ca437e65a756","modified":1670052947803},{"_id":"source/img/最大流最小割/一个割例子.png","hash":"79f139ef1f807758efb8dd0614723b008117597d","modified":1670044400309},{"_id":"source/img/最大流最小割/最大流.png","hash":"f4671c1a200b41a3ac6608cd4ad0c03b14da6596","modified":1670049218424},{"_id":"source/img/最大流最小割/最小割定义.png","hash":"f3d62ba163797d84ab99a6113baea85c67152a94","modified":1670044091900},{"_id":"source/img/胜者树败者树/fig1.jpg","hash":"97867bf0b5eeedc2a763d42b0ddf3a489ee2a08d","modified":1647227120629},{"_id":"source/img/胜者树败者树/fig2.jpg","hash":"daaf81658569b19710523c650f4a1c95fa46db4b","modified":1647227127787},{"_id":"source/img/胜者树败者树/fig4.jpg","hash":"8f104f440e15af2f0fa833339e76b58e1c0fc1ee","modified":1647227141329},{"_id":"source/img/胜者树败者树/fig3.jpg","hash":"f65abc86102943457c2fd7f4de3bc2ca6e9ff8ff","modified":1647227136005},{"_id":"source/img/最大流最小割/最大流最小割定理.png","hash":"46e2700778a75dc5e59e5d73de4705013dadc97b","modified":1670053289831},{"_id":"source/img/最大流最小割/残余图.png","hash":"32b9449b7cec2790927c7b5c0a679064e7b9e488","modified":1670050457590},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1669908961622},{"_id":"node_modules/hexo-theme-fluid/README.md","hash":"6d752df6f2278033dc2512a7d5be22c8a8eb665a","modified":1669908959661},{"_id":"node_modules/hexo-theme-fluid/languages/de.yml","hash":"0e7d455d9e004ff15d8924b7a0c35cea25ee5b1d","modified":1669908961627},{"_id":"node_modules/hexo-theme-fluid/languages/en.yml","hash":"cb11b39f44ea069652c9647179606b6cecc98d50","modified":1669908961628},{"_id":"node_modules/hexo-theme-fluid/package.json","hash":"167c6a0729a9286a7f508c1dd6a9c689e8799008","modified":1669908959661},{"_id":"node_modules/hexo-theme-fluid/_config.yml","hash":"39baa882da9b0af5178c7767306be14bcf992a55","modified":1669908961627},{"_id":"node_modules/hexo-theme-fluid/LICENSE","hash":"26f9356fd6e84b5a88df6d9014378f41b65ba209","modified":1669908959152},{"_id":"node_modules/hexo-theme-fluid/languages/es.yml","hash":"7112594259c88c04714be152af7fd377687dad40","modified":1669908961628},{"_id":"node_modules/hexo-theme-fluid/languages/eo.yml","hash":"a556251cc50a5680578c03f1efbf252b1f4ab860","modified":1669908961628},{"_id":"node_modules/hexo-theme-fluid/languages/ru.yml","hash":"7dc78f22696649a4c68dc65a9b52d9a992fa82a0","modified":1669908961629},{"_id":"node_modules/hexo-theme-fluid/languages/ja.yml","hash":"3dd6d20f8d26585a7c154a8e59fe8d5d902f4c6a","modified":1669908961629},{"_id":"node_modules/hexo-theme-fluid/layout/404.ejs","hash":"9569c5c8f67d2783f372f671c57b93a00dc63c2f","modified":1669908959159},{"_id":"node_modules/hexo-theme-fluid/layout/archive.ejs","hash":"7c1f44005849791feae4abaa10fae4cb983d3277","modified":1669908959166},{"_id":"node_modules/hexo-theme-fluid/layout/about.ejs","hash":"163bee643e6a38912d3ae70923c83c48d57222e7","modified":1669908959160},{"_id":"node_modules/hexo-theme-fluid/layout/layout.ejs","hash":"7e0023474128fbe4d68c467704c41f1712432415","modified":1669908959459},{"_id":"node_modules/hexo-theme-fluid/layout/index.ejs","hash":"db000a6a0cec19d32a6e7e94cd4c478500d9c5ac","modified":1669908959459},{"_id":"node_modules/hexo-theme-fluid/layout/categories.ejs","hash":"13859726c27b6c79b5876ec174176d0f9c1ee164","modified":1669908959170},{"_id":"node_modules/hexo-theme-fluid/layout/category.ejs","hash":"f099161b738a16a32253f42085b5444f902018ed","modified":1669908959439},{"_id":"node_modules/hexo-theme-fluid/languages/zh-CN.yml","hash":"f96a22f989897ecddc69d5867a206e1cf6b8f610","modified":1669908961632},{"_id":"node_modules/hexo-theme-fluid/layout/links.ejs","hash":"1cac32ec4579aaf7b9fa39d317497331d4c5e1dd","modified":1669908959460},{"_id":"node_modules/hexo-theme-fluid/layout/page.ejs","hash":"ed5007a3feb8f14d3d2843271bfb298eb0c56219","modified":1669908959465},{"_id":"node_modules/hexo-theme-fluid/layout/post.ejs","hash":"505bcc06e55066b7cc5551d9ac0694e7713bfab5","modified":1669908959465},{"_id":"node_modules/hexo-theme-fluid/layout/tag.ejs","hash":"9d686364c4d16a1a9219471623af452035c5b966","modified":1669908959468},{"_id":"node_modules/hexo-theme-fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":1669908959469},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/archive-list.ejs","hash":"7520fbf91f762207c2ab06b2c293235cd5b23905","modified":1669908959166},{"_id":"node_modules/hexo-theme-fluid/languages/zh-HK.yml","hash":"80ed400a7adaa92ea54fc7f5d534c9af795bed00","modified":1669908961633},{"_id":"node_modules/hexo-theme-fluid/languages/zh-TW.yml","hash":"596d031dff3826ae8e4ffc8931fff28977b73247","modified":1669908961634},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-chains.ejs","hash":"18309584aab83bc4deb20723ebad832149dd2e24","modified":1669908959433},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-list.ejs","hash":"f8d2f1907450e61968e6d54443e9be8138196a77","modified":1669908959437},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments.ejs","hash":"24ef242aa01e5f5bc397cf3f83ae48b1e8353dab","modified":1669908959447},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/markdown-plugins.ejs","hash":"fc4bdf7de0cf1a66d0e5e4fba1b31d6f7ed49468","modified":1669908959461},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/css.ejs","hash":"85f6e051550907681ab4ed2e268ac8f6e9ebf931","modified":1669908959449},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer.ejs","hash":"10ccfb8eef4e16182183c9a3e175c90d5b6397d3","modified":1669908959456},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/paginator.ejs","hash":"0f38a2c238169edcb63fc46c23bfc529ff3859b7","modified":1669908959465},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/head.ejs","hash":"7b7b1d098726e86687a15fe3d520d178577ffcae","modified":1669908959457},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header.ejs","hash":"0d5e397d30051e5fbabe7b47cfd1f1e6a5820af1","modified":1669908959458},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/scripts.ejs","hash":"da5810785105e5075861593c7ac22c7aa9665a72","modified":1669908959466},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/search.ejs","hash":"70e1c929e084ca8a2648cedabf29b372511ea2b8","modified":1669908959467},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1669908961299},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1669908959663},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1669908959626},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":1669908959653},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1669908961589},{"_id":"node_modules/hexo-theme-fluid/scripts/events/index.js","hash":"79de5a379b28cad759a49048351c7f6b8915bd7d","modified":1669908959649},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/default-injects.js","hash":"b2013ae8e189cd07ebc8a2ff48a78e153345210f","modified":1669908959645},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","hash":"45695ef75c31a4aa57324dd408b7e2327a337018","modified":1669908961612},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1669908959157},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/post-filter.js","hash":"d516b9db63067f9ea9c72cc75ae4ff358417e77d","modified":1669908959658},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/engine.js","hash":"d3a231d106795ce99cb0bc77eb65f9ae44515933","modified":1669908959645},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","hash":"a9efc52a646a9e585439c768557e3e3c9e3326dc","modified":1669908961613},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/date.js","hash":"9bda6382f61b40a20c24af466fe10c8366ebb74c","modified":1669908959643},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","hash":"855ae5fe229c51afa57f7645f6997a27a705d7e4","modified":1669908961617},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/export-config.js","hash":"47e6dba7652a621a54067413490a11c8a89e3d7b","modified":1669908959646},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/injects.js","hash":"1ad2ae6b11bd8806ee7dd6eb7140d8b54a95d613","modified":1669908959650},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":1669908959657},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/scope.js","hash":"d41d9d658fcb54964b388598e996747aadb85b0f","modified":1669908959659},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/import.js","hash":"ca53e8dbf7d44cfd372cfa79ac60f35a7d5b0076","modified":1669908959649},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/local-search.js","hash":"fc2c50405b771b06b7f6cfc4e9de97b992691555","modified":1669908959653},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/pages.js","hash":"d9971f15fbb6b775e3d31a1b9b45011959395010","modified":1669908959657},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","hash":"ba63f7c3324bc1fdd050a90add9d8faaffc27e07","modified":1669908959638},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","hash":"89e3561488a618ed0caeb9edf18e441978e29c25","modified":1669908959646},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1669908959634},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/utils.js","hash":"226f99b465ff513de075a8e78b321d6cb62592ca","modified":1669908959660},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/url.js","hash":"2a6a8288176d0e0f6ec008056bf2745a86e8943e","modified":1669908959659},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/wordcount.js","hash":"4543b8954c5c2ca91191cc0d53cf071b3f26faaa","modified":1669908959661},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":1669908959636},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1669908959652},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1669908959648},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","hash":"45cc86f099db0a2c36ad49711ce66c2d598a2ab1","modified":1669908959660},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","hash":"cebcda5991b6a9ab9307c69542389ce9013f04f7","modified":1669908959653},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","hash":"2333494add51e5e1374602a4e81f0be36a05d4c2","modified":1669908959658},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":1669908959650},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/checkbox.js","hash":"4938610c3543a921a341bc074626d511cb1a4b45","modified":1669908959636},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/mermaid.js","hash":"75160561e1ef3603b6d2ad2938464ab1cb77fd38","modified":1669908959655},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/compare-versions.js","hash":"dbbc928c914fc2bd242cd66aa0c45971aec13a5d","modified":1669908959640},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/object.js","hash":"33b57e4decdc5e75c518859f168c8ba80b2c665b","modified":1669908959657},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":1669908959647},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/resolve.js","hash":"8c4a8b62aa8608f12f1e9046231dff04859dc3e9","modified":1669908959659},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/note.js","hash":"f52f3a005b41f48b4da274ac64710177c8d4502f","modified":1669908959656},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1669908961625},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/url-join.js","hash":"718aab5e7b2059a06b093ca738de420d9afa44ba","modified":1669908959659},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/disqus.ejs","hash":"aab4a4d24c55231a37db308ae94414319cecdd9b","modified":1669908959453},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/changyan.ejs","hash":"c9b2d68ed3d375f1953e7007307d2a3f75ed6249","modified":1669908959441},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/gitalk.ejs","hash":"843bc141a4545eb20d1c92fb63c85d459b4271ec","modified":1669908959457},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/cusdis.ejs","hash":"5f9dc012be27040bbe874d0c093c0d53958cc987","modified":1669908959451},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/livere.ejs","hash":"2264758fed57542a7389c7aa9f00f1aefa17eb87","modified":1669908959461},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/remark42.ejs","hash":"d4e9532feeb02aed61bd15eda536b5b631454dac","modified":1669908959466},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/giscus.ejs","hash":"95f8b866b158eff9352c381c243b332a155a5110","modified":1669908959456},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/twikoo.ejs","hash":"e6820fb7f13662c42f8433ec95404238f4c1860c","modified":1669908959471},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/valine.ejs","hash":"19ba937553dddd317f827d682661a1066a7b1f30","modified":1669908959472},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/waline.ejs","hash":"12727da7cf3ac83443270f550be4d1c06135b52b","modified":1669908959472},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/beian.ejs","hash":"4fb9b5dd3f3e41a586d6af44e5069afe7c81fff2","modified":1669908959169},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/utterances.ejs","hash":"c7ccf7f28308334a6da6f5425b141a24b5eca0e2","modified":1669908959471},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/analytics.ejs","hash":"1327395a4dde1ea06c476b047fb110bcd269149f","modified":1669908959162},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/statistics.ejs","hash":"454d8dd4c39f9494ebeb03ca0746f5bc122af76a","modified":1669908959468},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/banner.ejs","hash":"e07757b59e7b89eea213d0e595cb5932f812fd32","modified":1669908959168},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/navigation.ejs","hash":"38990ed9dbccd88342ee4b4cb5e60818e9eb8e8a","modified":1669908959464},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/anchorjs.ejs","hash":"40181442d3a2b8734783a0ad7caf2d2522e3f2ab","modified":1669908959164},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/encrypt.ejs","hash":"e3713fa78e0fc14a239360b020068d8513573ae4","modified":1669908959455},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/code-widget.ejs","hash":"3a505cba37942badf62a56bbb8b605b72af330aa","modified":1669908959444},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/fancybox.ejs","hash":"9d1ea2a46b8c8ad8c168594d578f40764818ef13","modified":1669908959455},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/highlight.ejs","hash":"7529dd215b09d3557804333942377b9e20fa554e","modified":1669908959459},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/math.ejs","hash":"dcbf9a381ee76f2f1f75fcbc22c50a502ec85023","modified":1669908959462},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/nprogress.ejs","hash":"4c2d39ce816b8a6dcd6b53113c8695f8bd650a23","modified":1669908959464},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/category-bar.ejs","hash":"8772bce97ed297e7a88523f4e939ed6436c22f87","modified":1669908959173},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/mermaid.ejs","hash":"e49506e9895e255e0e53f34a11d325f83109c1b0","modified":1669908959462},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/copyright.ejs","hash":"9d13392cea94b66d86422ad17c66e5ae67ce1d32","modified":1669908959448},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-bottom.ejs","hash":"7079b27a7bc15a7dfa9209f6be6051bdec49ebad","modified":1669908959462},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-top.ejs","hash":"ce6e9f578f4faa45840abddf8f46af3f4b69c177","modified":1669908959464},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/typed.ejs","hash":"51faef29f8e464bcb2e73049b428b88c8dd8b40a","modified":1669908959471},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/footnote.js","hash":"2ec2ae03c79bb1ae7ac3fcf7e00fb52d1af2898d","modified":1669908959647},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/compatible-configs.js","hash":"ef474d1fa5bbafc52619ced0f9dc7eaf2affb363","modified":1669908959642},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-right.ejs","hash":"d5fcc9b60e02f869a29a8c17a16a6028ecc1e6d8","modified":1669908959468},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/highlight.js","hash":"0f02df2244e275595e72163498d42f42bcf0de5e","modified":1669908959648},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-left.ejs","hash":"9992c99b3eb728ad195970e1b84d665f2c8691c4","modified":1669908959468},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/toc.ejs","hash":"97e003371b76911522fb93c5180c9fdceed29488","modified":1669908959470},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/injects.js","hash":"5ae4b07204683e54b5a1b74e931702bbce2ac23e","modified":1669908959649},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/lazyload.js","hash":"9ba0d4bc224e22af8a5a48d6ff13e5a0fcfee2a4","modified":1669908959652},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/merge-configs.js","hash":"7c944c43b2ece5dd84859bd9d1fe955d13427387","modified":1669908959654},{"_id":"node_modules/hexo-theme-fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":1669908961601},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/hello.js","hash":"44c5eb97b98813a07c659d6afedd17fad63b1821","modified":1669908959648},{"_id":"node_modules/hexo-theme-fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":1669908961602},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":1669908961620},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_archive/archive.styl","hash":"c475e6681546d30350eaed11f23081ecae80c375","modified":1669908961598},{"_id":"node_modules/hexo-theme-fluid/source/css/_variables/base.styl","hash":"4ed5f0ae105ef4c7dd92eaf652ceda176c38e502","modified":1669908961604},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/color-schema.styl","hash":"61279540c2623ea4bf93e40613d41380839b92d3","modified":1669908961608},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_about/about.styl","hash":"97fe42516ea531fdad771489b68aa8b2a7f6ae46","modified":1669908961592},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":1669908961615},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-bar.styl","hash":"cc6df43fef6bb3efecbfdd8b9e467424a1dea581","modified":1669908961606},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/base.styl","hash":"643284c567665f96915f0b64e59934dda315f74d","modified":1669908961603},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-chain.styl","hash":"0cdf7ef50dfd0669d3b257821384ff31cd81b7c9","modified":1669908961606},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/inline.styl","hash":"411a3fa3f924a87e00ff04d18b5c83283b049a4d","modified":1669908961615},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-list.styl","hash":"7edfe1b571ecca7d08f5f4dbcf76f4ffdcfbf0b5","modified":1669908961607},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_index/index.styl","hash":"0acbd71633bcc7191672ea4e1b2277bea350d73b","modified":1669908961614},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/highlight.styl","hash":"4df764d298fe556e501db4afc2b05686fe6ebcfb","modified":1669908961613},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/comment.styl","hash":"780f3788e7357bcd3f3262d781cb91bb53976a93","modified":1669908961609},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-page.styl","hash":"127bb5391370afe7fef2a297084d76406bc5e902","modified":1669908961620},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/markdown.styl","hash":"1e3d3a82721e7c10bcfcecec6d81cf2979039452","modified":1669908961617},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_links/links.styl","hash":"5c7f2044e3f1da05a3229537c06bd879836f8d6e","modified":1669908961616},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-tag.styl","hash":"27f70062415ccf66a9b6f4952db124fc1471fda5","modified":1669908961621},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/banner.styl","hash":"7a0bd629bc234fc75e3cc8e3715ffada92f09e73","modified":1669908961600},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":1669908961624},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/anchorjs.styl","hash":"e0cebda4a6f499aff75e71417d88caa7ceb13b94","modified":1669908961596},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/code-widget.styl","hash":"b66ab013f0f37d724a149b85b3c7432afcf460ad","modified":1669908961607},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/copyright.styl","hash":"26f71a9cd60d96bb0cb5bbdf58150b8e524d9707","modified":1669908961610},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":1669908961610},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/board.styl","hash":"4397037fc3f0033dbe546c33cd9dbdabd8cb1632","modified":1669908961605},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/header.styl","hash":"0aa512c21a4b74ef2e70009786a1858d7c2fae9c","modified":1669908961611},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/modal.styl","hash":"adf6c1e5c8e1fb41c77ce6e2258001df61245aa2","modified":1669908961618},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footer.styl","hash":"2caaca71dd1ff63d583099ed817677dd267b457e","modified":1669908961610},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/noscript.styl","hash":"0cf2f2bb44f456150d428016675d5876a9d2e2aa","modified":1669908961619},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"78704a94c0436097abfb0e0a57abeb3429c749b7","modified":1669908961621},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/ngrogress.styl","hash":"5d225357b4a58d46118e6616377168336ed44cb2","modified":1669908961618},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/pagination.styl","hash":"8bb1b68e5f3552cb48c2ffa31edbc53646a8fb4c","modified":1669908961620},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/toc.styl","hash":"9e7452aa2372153f25d7a4675c9d36d281a65d24","modified":1669908961624},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"f0e429a27fa8a7658fcbddbb4d4dbe4afa12499a","modified":1669908961622},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":1669908961622},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1669908961297},{"_id":"public/local-search.xml","hash":"94e2ec1fb7a5b4585e405d063411e36906432694","modified":1670119249708},{"_id":"public/about/index.html","hash":"58587ac2ec1b6d098c760cc069afdd0699625cd2","modified":1670119249708},{"_id":"public/archives/index.html","hash":"817ecb0ab46072e316389269a83da88d4c50456f","modified":1670119249708},{"_id":"public/archives/2022/index.html","hash":"a417ab2cf7ab5448f55e290d733b2811e49595c8","modified":1670119249708},{"_id":"public/archives/2022/12/index.html","hash":"9904f7d1ad95042e94b10191cef1be0a70e0e4e1","modified":1670119249708},{"_id":"public/tags/算法/index.html","hash":"7fc5dcee3d9d2487fe1fad02da9c51e82957e61c","modified":1670119249708},{"_id":"public/tags/高级算法设计与分析/index.html","hash":"9c5223be42875d9fe54018548764923cda5fd3fe","modified":1670119249708},{"_id":"public/tags/矩阵论/index.html","hash":"6b6b42cae362e33f2566a8ffdd64b2e14843d9aa","modified":1670119249708},{"_id":"public/categories/算法/index.html","hash":"1520d42bf5a3d8958105d0bdabc80224a977316f","modified":1670119249708},{"_id":"public/categories/数学，-矩阵论/index.html","hash":"2a6142af501507ea4baf0a254273c2653dcd5d38","modified":1670119249708},{"_id":"public/404.html","hash":"6502d5e0d37de0252b9b917b098e613fa75a5053","modified":1670119249708},{"_id":"public/tags/index.html","hash":"8629c845d3523dda969f552520706f2af45d1e22","modified":1670119249708},{"_id":"public/categories/index.html","hash":"c2079df403b74b11692070661641138204a63000","modified":1670119249708},{"_id":"public/links/index.html","hash":"df8b33302188c76095b69a86e997befa2a2b0d52","modified":1670119249708},{"_id":"public/2022/12/03/矩阵分解/index.html","hash":"04b010499fd264cae34d5bc5c62fc8dd2d78a4ca","modified":1670119249708},{"_id":"public/2022/12/03/多项式规约/index.html","hash":"6d77054e1bddafc3c2b3d2c334089c1e2ec06f52","modified":1670119249708},{"_id":"public/2022/12/03/最大流最小割/index.html","hash":"fcc8db5c518b625486e0ef1dd07a24e37d0e1eeb","modified":1670119249708},{"_id":"public/2022/12/02/动态规划/index.html","hash":"c6b358f1a4dfeec01e3ea83f0bf692017f6bb772","modified":1670119249708},{"_id":"public/2022/12/02/胜者树败者树/index.html","hash":"5914629834ccb74dccc651b4b7e3168e0e01a722","modified":1670119249708},{"_id":"public/2022/12/02/红黑树/index.html","hash":"5699c2f5bbb8359989a19677314fb3bfb82efdc0","modified":1670119249708},{"_id":"public/2022/12/02/Git常用命令/index.html","hash":"cc1b11a51867a31fb6f7c090bddf3c92f39c2b5f","modified":1670119249708},{"_id":"public/index.html","hash":"bed966c7656df22791b0d3ef3e35eb5cb24b9238","modified":1670119249708},{"_id":"public/img/动态规划/最短路径.png","hash":"0ba147ab707a0e36e3051bff42d30cbaa6759c63","modified":1670119249708},{"_id":"public/img/多项式规约/独立集.png","hash":"c41df5652e2b1ec4fc4c0afa8960ca8db7e7f252","modified":1670119249708},{"_id":"public/img/多项式规约/点覆盖.png","hash":"021805ebf776c01cd678d4c26f21f8a0672e1902","modified":1670119249708},{"_id":"public/img/动态规划/最长上升子序列代码.jpg","hash":"d0c1dbb9c49b2b4264b9e6eca7971f38d06e5455","modified":1670119249708},{"_id":"public/img/动态规划/状态转移方程.svg","hash":"8b5734d7212db7f4d24e95f2d422d7f1c6defb1d","modified":1670119249708},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子1.png","hash":"67e5f7b1db79d46598fe41b1b57fff2c84dc6d32","modified":1670119249708},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子2.png","hash":"df88bf8af91a2073fbaaba71def9ebebe949b645","modified":1670119249708},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子3.png","hash":"757c7bb6ff26a30ea9e46deb7777740516f225cc","modified":1670119249708},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子4.png","hash":"e08eea19af73ad0bcc8c8c0181173e5db30e19df","modified":1670119249708},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子6.png","hash":"6a815e321d3abd5d260709d42b921d4cf35f5bf5","modified":1670119249708},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子7.png","hash":"1a935d7a67c1cd2241cdeb2c4a61ca437e65a756","modified":1670119249708},{"_id":"public/img/最大流最小割/Ford-Fulkerson例子5.png","hash":"19e85b264deafb8926b70ed397a59cd495e224f6","modified":1670119249708},{"_id":"public/img/最大流最小割/iii到i.png","hash":"eb6738e99b57447dcd63fdf8aa241fb8f5c2b321","modified":1670119249708},{"_id":"public/img/动态规划/解决方案.jpg","hash":"8500d51aa92b8cf3e1a4faa475de9524d179f978","modified":1670119249708},{"_id":"public/img/最大流最小割/最小割定义.png","hash":"f3d62ba163797d84ab99a6113baea85c67152a94","modified":1670119249708},{"_id":"public/img/最大流最小割/一个割例子.png","hash":"79f139ef1f807758efb8dd0614723b008117597d","modified":1670119249708},{"_id":"public/img/胜者树败者树/fig1.jpg","hash":"97867bf0b5eeedc2a763d42b0ddf3a489ee2a08d","modified":1670119249708},{"_id":"public/img/最大流最小割/最大流.png","hash":"f4671c1a200b41a3ac6608cd4ad0c03b14da6596","modified":1670119249708},{"_id":"public/img/胜者树败者树/fig4.jpg","hash":"8f104f440e15af2f0fa833339e76b58e1c0fc1ee","modified":1670119249708},{"_id":"public/img/胜者树败者树/fig3.jpg","hash":"f65abc86102943457c2fd7f4de3bc2ca6e9ff8ff","modified":1670119249708},{"_id":"public/img/胜者树败者树/fig2.jpg","hash":"daaf81658569b19710523c650f4a1c95fa46db4b","modified":1670119249708},{"_id":"public/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1670119249708},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1670119249708},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1670119249708},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1670119249708},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1670119249708},{"_id":"public/img/最大流最小割/残余图.png","hash":"32b9449b7cec2790927c7b5c0a679064e7b9e488","modified":1670119249708},{"_id":"public/img/最大流最小割/最大流最小割定理.png","hash":"46e2700778a75dc5e59e5d73de4705013dadc97b","modified":1670119249708},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1670119249708},{"_id":"public/css/highlight.css","hash":"0f9a477d33d3b15ebe7e163e756fb7c54c7ded6b","modified":1670119249708},{"_id":"public/css/highlight-dark.css","hash":"2b0daa6e5343da9dbb26d617d224b8397e48556b","modified":1670119249708},{"_id":"public/js/events.js","hash":"89e3561488a618ed0caeb9edf18e441978e29c25","modified":1670119249708},{"_id":"public/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1670119249708},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1670119249708},{"_id":"public/js/color-schema.js","hash":"ba63f7c3324bc1fdd050a90add9d8faaffc27e07","modified":1670119249708},{"_id":"public/js/local-search.js","hash":"cebcda5991b6a9ab9307c69542389ce9013f04f7","modified":1670119249708},{"_id":"public/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1670119249708},{"_id":"public/js/plugins.js","hash":"2333494add51e5e1374602a4e81f0be36a05d4c2","modified":1670119249708},{"_id":"public/js/utils.js","hash":"45cc86f099db0a2c36ad49711ce66c2d598a2ab1","modified":1670119249708},{"_id":"public/css/main.css","hash":"d3b6eb3ef0e222271f1453d3d1214f3ba053792d","modified":1670119249708},{"_id":"public/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1670119249708}],"Category":[{"name":"算法","_id":"clb8pvosx0004zgsgfrip20v4"},{"name":"数学， 矩阵论","_id":"clb8pvot1000hzgsg76poawec"}],"Data":[],"Page":[{"title":"about","layout":"about","_content":"\n","source":"about/index.md","raw":"---\ntitle: about\nlayout: about\n---\n\n","date":"2022-12-02T04:38:02.134Z","updated":"2022-12-02T04:38:02.134Z","path":"about/index.html","comments":1,"_id":"clb8pvosq0000zgsgfvtsbuxs","content":"\r\n","site":{"data":{}},"excerpt":"","more":"\r\n"}],"Post":[{"title":"Git常用命令","math":true,"_content":"\n\n## Git撤销commit命令\n当要撤销的提交不是最开始的提交时\n```\ngit reset HEAD~\n```\n当要撤销的提交时最开始的提交时\n```\ngit update -ref -d HEAD\n```\n## Git连接远程仓库\n```\ngit remote add origin url\n```\n注：url为github仓库链接\n## Git删除已经add的文件\n1.要删除的文件少时\n\t一种是 `git rm --cached` \"文件路径\"，不删除物理文件，仅将该文件从缓存中删除；\n\t一种是 `git rm --f`  \"文件路径\"，不仅将该文件从缓存中删除，还会将物理文件删除（不会回收到垃圾桶）。\n\n\n2.要删除的文件多时\n\t`git rm -r --cached` .  清空缓存区\n\t然后将本地文件删除，再次`add`\n\t\n\n## Git创建远程新分支\ngit无法直接通过命令方式创建远程新分支，需要间接来创建,这里我创建的远程新分支名叫 vedio\n\n\n首先 \n\n`git checkout --orphan 分支名`\n![](https://img-blog.csdnimg.cn/20210403164118752.png)\n**git rm -rf .** （这一步很关键）\n然后创建一个文件readme.md（其实任何文件都可以），add并commit，然后\n\n`git push origin 分支名` \n\n就可以啦~如下图红框圈注的命令\n![](https://img-blog.csdnimg.cn/20210403164816128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzOTQyMQ==,size_16,color_FFFFFF,t_70)\n## git强制提交本地分支覆盖远程分支\n```\ngit push origin localBranchName:remoteBranchName --force\n```\n## Git从远程仓库拉取\n`git pull origin main`\n## Git创建与切换分支\n创建分支 `git branch branch_name`\n切换分支 `git checkout branch_name`\n\n\n\n\n\n\n\n\n","source":"_posts/Git常用命令.md","raw":"---\ntitle: Git常用命令\nmath: true\n---\n\n\n## Git撤销commit命令\n当要撤销的提交不是最开始的提交时\n```\ngit reset HEAD~\n```\n当要撤销的提交时最开始的提交时\n```\ngit update -ref -d HEAD\n```\n## Git连接远程仓库\n```\ngit remote add origin url\n```\n注：url为github仓库链接\n## Git删除已经add的文件\n1.要删除的文件少时\n\t一种是 `git rm --cached` \"文件路径\"，不删除物理文件，仅将该文件从缓存中删除；\n\t一种是 `git rm --f`  \"文件路径\"，不仅将该文件从缓存中删除，还会将物理文件删除（不会回收到垃圾桶）。\n\n\n2.要删除的文件多时\n\t`git rm -r --cached` .  清空缓存区\n\t然后将本地文件删除，再次`add`\n\t\n\n## Git创建远程新分支\ngit无法直接通过命令方式创建远程新分支，需要间接来创建,这里我创建的远程新分支名叫 vedio\n\n\n首先 \n\n`git checkout --orphan 分支名`\n![](https://img-blog.csdnimg.cn/20210403164118752.png)\n**git rm -rf .** （这一步很关键）\n然后创建一个文件readme.md（其实任何文件都可以），add并commit，然后\n\n`git push origin 分支名` \n\n就可以啦~如下图红框圈注的命令\n![](https://img-blog.csdnimg.cn/20210403164816128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzOTQyMQ==,size_16,color_FFFFFF,t_70)\n## git强制提交本地分支覆盖远程分支\n```\ngit push origin localBranchName:remoteBranchName --force\n```\n## Git从远程仓库拉取\n`git pull origin main`\n## Git创建与切换分支\n创建分支 `git branch branch_name`\n切换分支 `git checkout branch_name`\n\n\n\n\n\n\n\n\n","slug":"Git常用命令","published":1,"date":"2022-12-02T04:17:50.606Z","updated":"2022-12-03T08:09:29.350Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clb8pvoss0001zgsgem0w7dy0","content":"<h2 id=\"git撤销commit命令\">Git撤销commit命令</h2>\r\n<p>当要撤销的提交不是最开始的提交时 <figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">git <span class=\"hljs-built_in\">reset</span> HEAD~<br></code></pre></td></tr></table></figure>\r\n当要撤销的提交时最开始的提交时 <figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">git <span class=\"hljs-keyword\">update</span> <span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">ref</span> <span class=\"hljs-operator\">-</span>d HEAD<br></code></pre></td></tr></table></figure> ## Git连接远程仓库\r\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">git remote <span class=\"hljs-keyword\">add </span><span class=\"hljs-keyword\">origin </span>url<br></code></pre></td></tr></table></figure> 注：url为github仓库链接 ## Git删除已经add的文件\r\n1.要删除的文件少时 一种是 <code>git rm --cached</code>\r\n\"文件路径\"，不删除物理文件，仅将该文件从缓存中删除； 一种是\r\n<code>git rm --f</code>\r\n\"文件路径\"，不仅将该文件从缓存中删除，还会将物理文件删除（不会回收到垃圾桶）。</p>\r\n<p>2.要删除的文件多时 <code>git rm -r --cached</code> . 清空缓存区\r\n然后将本地文件删除，再次<code>add</code></p>\r\n<h2 id=\"git创建远程新分支\">Git创建远程新分支</h2>\r\n<p>git无法直接通过命令方式创建远程新分支，需要间接来创建,这里我创建的远程新分支名叫\r\nvedio</p>\r\n<p>首先</p>\r\n<p><code>git checkout --orphan 分支名</code> <img\r\nsrc=\"https://img-blog.csdnimg.cn/20210403164118752.png\" /> <strong>git\r\nrm -rf .</strong> （这一步很关键）\r\n然后创建一个文件readme.md（其实任何文件都可以），add并commit，然后</p>\r\n<p><code>git push origin 分支名</code></p>\r\n<p>就可以啦~如下图红框圈注的命令 <img\r\nsrc=\"https://img-blog.csdnimg.cn/20210403164816128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzOTQyMQ==,size_16,color_FFFFFF,t_70\" />\r\n## git强制提交本地分支覆盖远程分支 <figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">git <span class=\"hljs-built_in\">push</span> <span class=\"hljs-built_in\">origin</span> localBranchName:remoteBranchName --force<br></code></pre></td></tr></table></figure> ## Git从远程仓库拉取\r\n<code>git pull origin main</code> ## Git创建与切换分支 创建分支\r\n<code>git branch branch_name</code> 切换分支\r\n<code>git checkout branch_name</code></p>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"git撤销commit命令\">Git撤销commit命令</h2>\r\n<p>当要撤销的提交不是最开始的提交时 <figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">git <span class=\"hljs-built_in\">reset</span> HEAD~<br></code></pre></td></tr></table></figure>\r\n当要撤销的提交时最开始的提交时 <figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\">git <span class=\"hljs-keyword\">update</span> <span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">ref</span> <span class=\"hljs-operator\">-</span>d HEAD<br></code></pre></td></tr></table></figure> ## Git连接远程仓库\r\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">git remote <span class=\"hljs-keyword\">add </span><span class=\"hljs-keyword\">origin </span>url<br></code></pre></td></tr></table></figure> 注：url为github仓库链接 ## Git删除已经add的文件\r\n1.要删除的文件少时 一种是 <code>git rm --cached</code>\r\n\"文件路径\"，不删除物理文件，仅将该文件从缓存中删除； 一种是\r\n<code>git rm --f</code>\r\n\"文件路径\"，不仅将该文件从缓存中删除，还会将物理文件删除（不会回收到垃圾桶）。</p>\r\n<p>2.要删除的文件多时 <code>git rm -r --cached</code> . 清空缓存区\r\n然后将本地文件删除，再次<code>add</code></p>\r\n<h2 id=\"git创建远程新分支\">Git创建远程新分支</h2>\r\n<p>git无法直接通过命令方式创建远程新分支，需要间接来创建,这里我创建的远程新分支名叫\r\nvedio</p>\r\n<p>首先</p>\r\n<p><code>git checkout --orphan 分支名</code> <img\r\nsrc=\"https://img-blog.csdnimg.cn/20210403164118752.png\" /> <strong>git\r\nrm -rf .</strong> （这一步很关键）\r\n然后创建一个文件readme.md（其实任何文件都可以），add并commit，然后</p>\r\n<p><code>git push origin 分支名</code></p>\r\n<p>就可以啦~如下图红框圈注的命令 <img\r\nsrc=\"https://img-blog.csdnimg.cn/20210403164816128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzOTQyMQ==,size_16,color_FFFFFF,t_70\" />\r\n## git强制提交本地分支覆盖远程分支 <figure class=\"highlight maxima\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs maxima\">git <span class=\"hljs-built_in\">push</span> <span class=\"hljs-built_in\">origin</span> localBranchName:remoteBranchName --force<br></code></pre></td></tr></table></figure> ## Git从远程仓库拉取\r\n<code>git pull origin main</code> ## Git创建与切换分支 创建分支\r\n<code>git branch branch_name</code> 切换分支\r\n<code>git checkout branch_name</code></p>\r\n"},{"title":"动态规划","math":true,"_content":"\n本文大部分转载自知乎[@阮行止](https://www.zhihu.com/people/ruan-xing-zhi)，后添加了自己的一些思考。\n\n## 1. 从一个生活问题谈起\n先来看看生活中经常遇到的事吧——假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，**需要用到尽量少的钞票**。\n\n依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。\n\n这种策略称为“**贪心**”：假设我们面对的局面是“需要凑出w”，贪心策略会**尽快**让w变得更小。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。\n\n但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：  \n　　15=1×11+4×1 （贪心策略使用了5张钞票）  \n　　15=3×5 （正确的策略，只用3张钞票）  \n　　为什么会这样呢？贪心策略错在了哪里？  \n\n**鼠目寸光**。\n\n刚刚已经说过，贪心策略的纲领是：“尽量使接下来面对的w更小”。这样，贪心策略在w=15的局面时，会优先使用11来把w降到4；但是在这个问题中，凑出4的代价是很高的，必须使用4×1。如果使用了5，w会降为10，虽然没有4那么小，但是凑出10只需要两张5元。 \n\n在这里我们发现，贪心是一种**只考虑眼前情况**的策略。\n\n那么，现在我们怎样才能避免鼠目寸光呢？\n\n如果直接暴力枚举凑出w的方案，明显复杂度过高。太多种方法可以凑出w了，枚举它们的时间是不可承受的。我们现在来尝试找一下性质。\n\n重新分析刚刚的例子。w=15时，我们如果取11，接下来就面对w=4的情况；如果取5，则接下来面对w=10的情况。我们发现这些问题都有相同的形式：“给定w，凑出w所用的最少钞票是多少张？”接下来，我们用f(n)来表示“凑出n所需的最少钞票数量”。\n\n那么，如果我们取了11，最后的代价（用掉的钞票总数）是多少呢？  \n\n明显**cost=f(4)+1=4+1=5** ，它的意义是：利用11来凑出15，付出的代价等于f(4)加上自己这一张钞票。现在我们暂时不管f(4)怎么求出来。  \n\n依次类推，马上可以知道：如果我们用5来凑出15，cost就是**f(10)+1=2+1=3** 。\n\n那么，现在w=15的时候，我们该取那种钞票呢？**当然是各种方案中，cost值最低的那一个！**\n\n- 取11：cost=f(4)+1=4+1=5\n- 取5:cost=f(10)+1=2+1=3\n- 取1:cost=f(14)+1=4+1=5\n\n显而易见，cost值最低的是取5的方案。**我们通过上面三个式子，做出了正确的决策！**\n\n这给了我们一个**至关重要**的启示—— f(n)只与f(n-1),f(n-5),f(n-11) 相关；更确切地说：\n\n> f(n)=min{f(n-1),f(n-5),f(n-11)}+1\n\n这个式子是非常激动人心的。我们要求出f(n)，只需要求出几个更小的f值；既然如此，我们从小到大把所有的f(i)求出来不就好了？注意一下边界情况即可。代码如下：\n\n![pic1](/img/动态规划/解决方案.jpg)\n\n我们以O(n)的复杂度解决了这个问题。现在回过头来，我们看看它的原理：\n\n- f(n)只与f(n-1),f(n-5),f(n-11)的值有关。\n- 我们只关心f(w)的值，不关心是怎么凑出w的。\n\n这两个事实，保证了我们做法的正确性。它比起贪心策略，会分别算出取1、5、11的代价，从而做出一个正确决策，这样就避免掉了“鼠目寸光”！\n\n它与暴力的区别在哪里？我们的暴力枚举了“使用的硬币”，然而这属于冗余信息。我们要的是答案，根本不关心这个答案是怎么凑出来的。譬如，要求出f(15)，只需要知道f(14),f(10),f(4)的值。**其他信息并不需要**。我们舍弃了冗余信息。我们只记录了对解决问题有帮助的信息——f(n).\n\n我们能这样干，取决于问题的性质：求出f(n)，只需要知道几个更小的f(c)。**我们将求解f(c)称作求解f(n)的“子问题”**。\n\n**这就是DP（动态规划，dynamic programming）**.\n\n**将一个问题拆成几个子问题，分别求解这些子问题，即可推断出大问题的解。**\n\n## 2. 几个简单的概念\n- **无后效性**  \n    一旦f(n)确定，“我们如何凑出f(n)”就再也用不着了。  \n\n要求出f(15)，只需要知道f(14),f(10),f(4)的值，而f(14),f(10),f(4)是如何算出来的，对之后的问题没有影响。\n\n“**未来与过去无关**”，这就是**无后效性**。\n\n（严格定义：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响。）\n\n- 最优子结构\n\n回顾我们对f(n)的定义：我们记“凑出n所需的最少钞票数量”为f(n).\n\nf(n)的定义就已经蕴含了“最优”。利用w=14,10,4的最优解，我们即可算出w=15的最优解。\n\n大问题的**最优解**可以由小问题的**最优解**推出，这个性质叫做“最优子结构性质”。\n\n引入这两个概念之后，我们如何判断一个问题能否使用DP解决呢？\n\n**能将大问题拆成几个小问题，且满足无后效性、最优子结构性质**。\n\n## 3. DP的典型应用：DAG最短路\n\n问题很简单：给定一个城市的地图，所有的道路都是单行道，而且不会构成环。每条道路都有过路费，问您从S点到T点花费的最少费用。\n\n![最短路径](/img/动态规划/最短路径.png)\n\n这个问题能用DP解决吗？我们先试着记从S到P的最少费用为f(P).\n\n想要到T，要么经过C，要么经过D。从而$f(T)=min\\{f(C)+20,f(D)+10\\}$.\n\n好像看起来可以DP。现在我们检验刚刚那两个性质：\n\n- 无后效性：对于点P，一旦f(P)确定，以后就只关心f(P)的值，不关心怎么去的。\n- 最优子结构：对于P，我们当然只关心到P的最小费用，即f(P)。如果我们从S走到T是$S \\rightarrow P\\rightarrow Q \\rightarrow T$,那肯定S走到Q的最优路径是$S \\rightarrow P\\rightarrow Q$。对一条最优的路径而言，从S走到**沿途上所有的点（子问题）**的最优路径，都是这条大路的一部分。这个问题的最优子结构性质是显然的。\n\n既然这两个性质都满足，那么本题可以DP。式子明显为：\n\n> f(P)=min\\{f(R)+W<sub>$R \\rightarrow P$</sub>\\}\n\n其中R为有路通到P的所有的点， [公式] 为R到P的过路费。\n\n代码实现也很简单，拓扑排序即可。\n\n## 4. 对DP原理的一点讨论\n\n- DP的核心思想\n\nDP为什么会快？\n\n无论是DP还是暴力，我们的算法都是在**可能解空间**内，寻找**最优解**。\n\n来看钞票问题。暴力做法是枚举所有的可能解，这是最大的可能解空间。\n\nDP是枚举**有希望成为答案的解**。这个空间比暴力的小得多。\n\n也就是说：**DP自带剪枝**。\n\nDP舍弃了一大堆不可能成为最优解的答案。譬如：  \n　　15 = 5+5+5 被考虑了。  \n　　15 = 5+5+1+1+1+1+1 从来没有考虑过，因为这不可能成为最优解。\n\n在暴力算法中，可能解空间往往是指数级的大小；如果我们采用DP，那么有可能把解空间的大小降到多项式级。\n\n一般来说，解空间越小，寻找解就越快。这样就完成了优化。\n\n- DP的操作过程\n\n一言以蔽之：**大事化小，小事化了**。\n\n将一个大问题转化成几个小问题；  \n　　求解小问题；  \n　　推出大问题的解。\n\n- 如何设计DP算法\n\n下面介绍比较通用的设计DP算法的步骤。\n\n首先，把我们面对的局面表示为x。这一步称为设计状态。\n\n对于状态x，记我们要求出的答案(e.g. 最小费用)为f(x).我们的目标是求出f(T).\n**找出f(x)与哪些局面有关（记为p）**，写出一个式子（称为状态转移方程），通过f(p)来推出f(x).\n\n- DP三连\n\n设计DP算法，往往可以遵循DP三连：\n\n我是谁？ ——设计状态，表示局面\n\n我从哪里来？\n\n我要到哪里去？ ——设计转移\n\n设计状态是DP的基础。接下来的设计转移，有两种方式：一种是考虑我从哪里来（本文之前提到的两个例子，都是在考虑“我从哪里来”）；另一种是考虑我到哪里去，这常见于求出f(x)之后，**更新能从x走到的一些解**。这种DP也是不少的，我们以后会遇到。\n\n总而言之，“我从哪里来”和“我要到哪里去”只需要考虑清楚其中一个，就能设计出状态转移方程，从而写代码求解问题。前者又称pull型的转移，后者又称push型的转移。\n\n> 思考题：如何把钞票问题的代码改写成“我到哪里去”的形式？  \n> 提示：求出f(x)之后，更新f(x+1),f(x+5),f(x+11).\n\n## 5. 例题：最长上升子序列\n\n扯了这么多形而上的内容，还是做一道例题吧。\n\n最长上升子序列（LIS）问题：给定长度为n的序列a，从a中抽取出一个子序列，这个子序列需要单调递增。问最长的上升子序列（LIS）的长度。  \n　　e.g. 1,5,3,4,6,9,7,8的LIS为1,3,4,6,7,8，长度为6。\n\n如何设计状态（我是谁）？\n\n我们记$f(x)$为以a<sub>x</sub>结尾的LIS长度，那么答案就是 $max\\{f(x)\\}$\n\n状态x从哪里推过来（我从哪里来）？\n\n考虑比x小的每一个p：如果 a<sub>x</sub> > a<sub>p</sub>，那么$f(x)$可以取$f(p)+1$.\n\n解释：我们把 a<sub>x</sub> 接在 a<sub>p</sub> 的后面，肯定能构造一个以 a<sub>x</sub> 结尾的上升子序列，长度比以 a<sub>p</sub> 结尾的LIS大1.那么，我们可以写出状态转移方程了：\n\n![状态转移方程](/img/动态规划/状态转移方程.svg)\n\n至此解决问题。两层for循环，复杂度O(n<sup>2</sup>) 。\n\n![最长上升子序列代码](/img/动态规划/最长上升子序列代码.jpg)\n\n从这三个例题中可以看出，DP是一种思想，一种“大事化小，小事化了”的思想。带着这种思想，DP将会成为我们解决问题的利器。\n\n## 6. 习题\n\n如果读者有兴趣，可以试着完成下面几个习题：\n\n1. 请采取一些优化手段，以 O(n log<sub>2</sub> n) 的复杂度解决LIS问题。\n\n提示：可以参考这篇博客 [Junior Dynamic Programming--动态规划初步·各种子序列问题](https://www.luogu.com.cn/blog/pks-LOVING/junior-dynamic-programming-dong-tai-gui-hua-chu-bu-ge-zhong-zi-xu-lie)\n\n2. “按顺序递推”和“记忆化搜索”是实现DP的两种方式。请查阅资料，简单描述“记忆化搜索”是什么。并采用记忆化搜索写出钞票问题的代码，然后完成[P1541 乌龟棋 - 洛谷](https://www.luogu.com.cn/problem/P1541) 。\n3. 01背包问题是一种常见的DP模型。请完成[P1048 采药 - 洛谷](https://www.luogu.com.cn/problem/P1048)。\n\n## 7. 读后思考：动态规划和分治法的区别与共同点？\n\n### 1. 分治法\n\n分治法(Divide-and-Conquer) : 将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。\n\n分治模式在每一层递归上都有三个步骤：\n\n- 分解(Divide)：将原问题分解成一系列子问题；\n- 解决(Conquer)：递归地解决各个子问题。若子问题足够小，则直接求解。\n- 合并(Combine)：将子问题的结果合并成原问题的解。\n\n合并排序(Merge Sort)是一个典型分治法的例子。其对应的直观的操作如下:\n\n分解： 将n个元素分成各含n/2个元素的子序列；\n\n解决：用合并排序法对两个子序列递归地排序；\n\n合并：合并两个已排序的子序列以得到排序结果。\n\n### 2. 动态规划法\n\n动态规划算法的设计可以分为如下4个步骤：\n\n- 描述最优解的结构\n- 递归定义最优解的值\n- 按自底向上的方式计算最优解的值\n- 由计算出的结果构造一个最优解\n\n**分治法是指将问题划分成一些独立的子问题，递归的求解各子问题，然后合并子问题的解而得到原问题的解。与此不同，动态规划适用于子问题独立且重叠的情况，也就是各子问题包含公共的子子问题。在这种情况下，若用分治法则会做许多不必要的工作，即重复地求解公共的子问题。动态规划算法对每个子子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。**\n\n适合采用动态规划方法的最优化问题中的两个要素：**最优子结构**和**重叠子问题**。\n\n最优子结构：如果问题的一个最优解中包含了子问题的最优解，则该问题具有最优子结构。\n\n重叠子问题：适用于动态规划求解的最优化问题必须具有的第二个要素是子问题的空间要很小，也就是用来求解原问题的递归算法反复地解同样的子问题，而不是总是在产生新的子问题。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则它们是重叠的。\n\nIn a word, **分治法 —— 各子问题独立；动态规划 —— 各子问题重叠**。\n\n算法导论： **动态规划要求其子问题既要独立又要重叠，这看上去似乎有些奇怪。虽然这两点要求听起来可能矛盾的，但它们描述了两种不同的概念，而不是同一个问题的两个方面。如果同一个问题的两个子问题不共享资源，则它们就是独立的。对两个子问题俩说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，是重叠的，则它们是重叠**。","source":"_posts/动态规划.md","raw":"---\ntitle: 动态规划\ncategories: 算法\ntags: 算法\nmath: true\n---\n\n本文大部分转载自知乎[@阮行止](https://www.zhihu.com/people/ruan-xing-zhi)，后添加了自己的一些思考。\n\n## 1. 从一个生活问题谈起\n先来看看生活中经常遇到的事吧——假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，**需要用到尽量少的钞票**。\n\n依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。\n\n这种策略称为“**贪心**”：假设我们面对的局面是“需要凑出w”，贪心策略会**尽快**让w变得更小。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。\n\n但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：  \n　　15=1×11+4×1 （贪心策略使用了5张钞票）  \n　　15=3×5 （正确的策略，只用3张钞票）  \n　　为什么会这样呢？贪心策略错在了哪里？  \n\n**鼠目寸光**。\n\n刚刚已经说过，贪心策略的纲领是：“尽量使接下来面对的w更小”。这样，贪心策略在w=15的局面时，会优先使用11来把w降到4；但是在这个问题中，凑出4的代价是很高的，必须使用4×1。如果使用了5，w会降为10，虽然没有4那么小，但是凑出10只需要两张5元。 \n\n在这里我们发现，贪心是一种**只考虑眼前情况**的策略。\n\n那么，现在我们怎样才能避免鼠目寸光呢？\n\n如果直接暴力枚举凑出w的方案，明显复杂度过高。太多种方法可以凑出w了，枚举它们的时间是不可承受的。我们现在来尝试找一下性质。\n\n重新分析刚刚的例子。w=15时，我们如果取11，接下来就面对w=4的情况；如果取5，则接下来面对w=10的情况。我们发现这些问题都有相同的形式：“给定w，凑出w所用的最少钞票是多少张？”接下来，我们用f(n)来表示“凑出n所需的最少钞票数量”。\n\n那么，如果我们取了11，最后的代价（用掉的钞票总数）是多少呢？  \n\n明显**cost=f(4)+1=4+1=5** ，它的意义是：利用11来凑出15，付出的代价等于f(4)加上自己这一张钞票。现在我们暂时不管f(4)怎么求出来。  \n\n依次类推，马上可以知道：如果我们用5来凑出15，cost就是**f(10)+1=2+1=3** 。\n\n那么，现在w=15的时候，我们该取那种钞票呢？**当然是各种方案中，cost值最低的那一个！**\n\n- 取11：cost=f(4)+1=4+1=5\n- 取5:cost=f(10)+1=2+1=3\n- 取1:cost=f(14)+1=4+1=5\n\n显而易见，cost值最低的是取5的方案。**我们通过上面三个式子，做出了正确的决策！**\n\n这给了我们一个**至关重要**的启示—— f(n)只与f(n-1),f(n-5),f(n-11) 相关；更确切地说：\n\n> f(n)=min{f(n-1),f(n-5),f(n-11)}+1\n\n这个式子是非常激动人心的。我们要求出f(n)，只需要求出几个更小的f值；既然如此，我们从小到大把所有的f(i)求出来不就好了？注意一下边界情况即可。代码如下：\n\n![pic1](/img/动态规划/解决方案.jpg)\n\n我们以O(n)的复杂度解决了这个问题。现在回过头来，我们看看它的原理：\n\n- f(n)只与f(n-1),f(n-5),f(n-11)的值有关。\n- 我们只关心f(w)的值，不关心是怎么凑出w的。\n\n这两个事实，保证了我们做法的正确性。它比起贪心策略，会分别算出取1、5、11的代价，从而做出一个正确决策，这样就避免掉了“鼠目寸光”！\n\n它与暴力的区别在哪里？我们的暴力枚举了“使用的硬币”，然而这属于冗余信息。我们要的是答案，根本不关心这个答案是怎么凑出来的。譬如，要求出f(15)，只需要知道f(14),f(10),f(4)的值。**其他信息并不需要**。我们舍弃了冗余信息。我们只记录了对解决问题有帮助的信息——f(n).\n\n我们能这样干，取决于问题的性质：求出f(n)，只需要知道几个更小的f(c)。**我们将求解f(c)称作求解f(n)的“子问题”**。\n\n**这就是DP（动态规划，dynamic programming）**.\n\n**将一个问题拆成几个子问题，分别求解这些子问题，即可推断出大问题的解。**\n\n## 2. 几个简单的概念\n- **无后效性**  \n    一旦f(n)确定，“我们如何凑出f(n)”就再也用不着了。  \n\n要求出f(15)，只需要知道f(14),f(10),f(4)的值，而f(14),f(10),f(4)是如何算出来的，对之后的问题没有影响。\n\n“**未来与过去无关**”，这就是**无后效性**。\n\n（严格定义：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响。）\n\n- 最优子结构\n\n回顾我们对f(n)的定义：我们记“凑出n所需的最少钞票数量”为f(n).\n\nf(n)的定义就已经蕴含了“最优”。利用w=14,10,4的最优解，我们即可算出w=15的最优解。\n\n大问题的**最优解**可以由小问题的**最优解**推出，这个性质叫做“最优子结构性质”。\n\n引入这两个概念之后，我们如何判断一个问题能否使用DP解决呢？\n\n**能将大问题拆成几个小问题，且满足无后效性、最优子结构性质**。\n\n## 3. DP的典型应用：DAG最短路\n\n问题很简单：给定一个城市的地图，所有的道路都是单行道，而且不会构成环。每条道路都有过路费，问您从S点到T点花费的最少费用。\n\n![最短路径](/img/动态规划/最短路径.png)\n\n这个问题能用DP解决吗？我们先试着记从S到P的最少费用为f(P).\n\n想要到T，要么经过C，要么经过D。从而$f(T)=min\\{f(C)+20,f(D)+10\\}$.\n\n好像看起来可以DP。现在我们检验刚刚那两个性质：\n\n- 无后效性：对于点P，一旦f(P)确定，以后就只关心f(P)的值，不关心怎么去的。\n- 最优子结构：对于P，我们当然只关心到P的最小费用，即f(P)。如果我们从S走到T是$S \\rightarrow P\\rightarrow Q \\rightarrow T$,那肯定S走到Q的最优路径是$S \\rightarrow P\\rightarrow Q$。对一条最优的路径而言，从S走到**沿途上所有的点（子问题）**的最优路径，都是这条大路的一部分。这个问题的最优子结构性质是显然的。\n\n既然这两个性质都满足，那么本题可以DP。式子明显为：\n\n> f(P)=min\\{f(R)+W<sub>$R \\rightarrow P$</sub>\\}\n\n其中R为有路通到P的所有的点， [公式] 为R到P的过路费。\n\n代码实现也很简单，拓扑排序即可。\n\n## 4. 对DP原理的一点讨论\n\n- DP的核心思想\n\nDP为什么会快？\n\n无论是DP还是暴力，我们的算法都是在**可能解空间**内，寻找**最优解**。\n\n来看钞票问题。暴力做法是枚举所有的可能解，这是最大的可能解空间。\n\nDP是枚举**有希望成为答案的解**。这个空间比暴力的小得多。\n\n也就是说：**DP自带剪枝**。\n\nDP舍弃了一大堆不可能成为最优解的答案。譬如：  \n　　15 = 5+5+5 被考虑了。  \n　　15 = 5+5+1+1+1+1+1 从来没有考虑过，因为这不可能成为最优解。\n\n在暴力算法中，可能解空间往往是指数级的大小；如果我们采用DP，那么有可能把解空间的大小降到多项式级。\n\n一般来说，解空间越小，寻找解就越快。这样就完成了优化。\n\n- DP的操作过程\n\n一言以蔽之：**大事化小，小事化了**。\n\n将一个大问题转化成几个小问题；  \n　　求解小问题；  \n　　推出大问题的解。\n\n- 如何设计DP算法\n\n下面介绍比较通用的设计DP算法的步骤。\n\n首先，把我们面对的局面表示为x。这一步称为设计状态。\n\n对于状态x，记我们要求出的答案(e.g. 最小费用)为f(x).我们的目标是求出f(T).\n**找出f(x)与哪些局面有关（记为p）**，写出一个式子（称为状态转移方程），通过f(p)来推出f(x).\n\n- DP三连\n\n设计DP算法，往往可以遵循DP三连：\n\n我是谁？ ——设计状态，表示局面\n\n我从哪里来？\n\n我要到哪里去？ ——设计转移\n\n设计状态是DP的基础。接下来的设计转移，有两种方式：一种是考虑我从哪里来（本文之前提到的两个例子，都是在考虑“我从哪里来”）；另一种是考虑我到哪里去，这常见于求出f(x)之后，**更新能从x走到的一些解**。这种DP也是不少的，我们以后会遇到。\n\n总而言之，“我从哪里来”和“我要到哪里去”只需要考虑清楚其中一个，就能设计出状态转移方程，从而写代码求解问题。前者又称pull型的转移，后者又称push型的转移。\n\n> 思考题：如何把钞票问题的代码改写成“我到哪里去”的形式？  \n> 提示：求出f(x)之后，更新f(x+1),f(x+5),f(x+11).\n\n## 5. 例题：最长上升子序列\n\n扯了这么多形而上的内容，还是做一道例题吧。\n\n最长上升子序列（LIS）问题：给定长度为n的序列a，从a中抽取出一个子序列，这个子序列需要单调递增。问最长的上升子序列（LIS）的长度。  \n　　e.g. 1,5,3,4,6,9,7,8的LIS为1,3,4,6,7,8，长度为6。\n\n如何设计状态（我是谁）？\n\n我们记$f(x)$为以a<sub>x</sub>结尾的LIS长度，那么答案就是 $max\\{f(x)\\}$\n\n状态x从哪里推过来（我从哪里来）？\n\n考虑比x小的每一个p：如果 a<sub>x</sub> > a<sub>p</sub>，那么$f(x)$可以取$f(p)+1$.\n\n解释：我们把 a<sub>x</sub> 接在 a<sub>p</sub> 的后面，肯定能构造一个以 a<sub>x</sub> 结尾的上升子序列，长度比以 a<sub>p</sub> 结尾的LIS大1.那么，我们可以写出状态转移方程了：\n\n![状态转移方程](/img/动态规划/状态转移方程.svg)\n\n至此解决问题。两层for循环，复杂度O(n<sup>2</sup>) 。\n\n![最长上升子序列代码](/img/动态规划/最长上升子序列代码.jpg)\n\n从这三个例题中可以看出，DP是一种思想，一种“大事化小，小事化了”的思想。带着这种思想，DP将会成为我们解决问题的利器。\n\n## 6. 习题\n\n如果读者有兴趣，可以试着完成下面几个习题：\n\n1. 请采取一些优化手段，以 O(n log<sub>2</sub> n) 的复杂度解决LIS问题。\n\n提示：可以参考这篇博客 [Junior Dynamic Programming--动态规划初步·各种子序列问题](https://www.luogu.com.cn/blog/pks-LOVING/junior-dynamic-programming-dong-tai-gui-hua-chu-bu-ge-zhong-zi-xu-lie)\n\n2. “按顺序递推”和“记忆化搜索”是实现DP的两种方式。请查阅资料，简单描述“记忆化搜索”是什么。并采用记忆化搜索写出钞票问题的代码，然后完成[P1541 乌龟棋 - 洛谷](https://www.luogu.com.cn/problem/P1541) 。\n3. 01背包问题是一种常见的DP模型。请完成[P1048 采药 - 洛谷](https://www.luogu.com.cn/problem/P1048)。\n\n## 7. 读后思考：动态规划和分治法的区别与共同点？\n\n### 1. 分治法\n\n分治法(Divide-and-Conquer) : 将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。\n\n分治模式在每一层递归上都有三个步骤：\n\n- 分解(Divide)：将原问题分解成一系列子问题；\n- 解决(Conquer)：递归地解决各个子问题。若子问题足够小，则直接求解。\n- 合并(Combine)：将子问题的结果合并成原问题的解。\n\n合并排序(Merge Sort)是一个典型分治法的例子。其对应的直观的操作如下:\n\n分解： 将n个元素分成各含n/2个元素的子序列；\n\n解决：用合并排序法对两个子序列递归地排序；\n\n合并：合并两个已排序的子序列以得到排序结果。\n\n### 2. 动态规划法\n\n动态规划算法的设计可以分为如下4个步骤：\n\n- 描述最优解的结构\n- 递归定义最优解的值\n- 按自底向上的方式计算最优解的值\n- 由计算出的结果构造一个最优解\n\n**分治法是指将问题划分成一些独立的子问题，递归的求解各子问题，然后合并子问题的解而得到原问题的解。与此不同，动态规划适用于子问题独立且重叠的情况，也就是各子问题包含公共的子子问题。在这种情况下，若用分治法则会做许多不必要的工作，即重复地求解公共的子问题。动态规划算法对每个子子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。**\n\n适合采用动态规划方法的最优化问题中的两个要素：**最优子结构**和**重叠子问题**。\n\n最优子结构：如果问题的一个最优解中包含了子问题的最优解，则该问题具有最优子结构。\n\n重叠子问题：适用于动态规划求解的最优化问题必须具有的第二个要素是子问题的空间要很小，也就是用来求解原问题的递归算法反复地解同样的子问题，而不是总是在产生新的子问题。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则它们是重叠的。\n\nIn a word, **分治法 —— 各子问题独立；动态规划 —— 各子问题重叠**。\n\n算法导论： **动态规划要求其子问题既要独立又要重叠，这看上去似乎有些奇怪。虽然这两点要求听起来可能矛盾的，但它们描述了两种不同的概念，而不是同一个问题的两个方面。如果同一个问题的两个子问题不共享资源，则它们就是独立的。对两个子问题俩说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，是重叠的，则它们是重叠**。","slug":"动态规划","published":1,"date":"2022-12-02T04:31:12.142Z","updated":"2022-12-03T16:11:51.193Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clb8pvosu0002zgsgbj5p58hw","content":"<p>本文大部分转载自知乎<a\r\nhref=\"https://www.zhihu.com/people/ruan-xing-zhi\"><span class=\"citation\"\r\ndata-cites=\"阮行止\">@阮行止</span></a>，后添加了自己的一些思考。</p>\r\n<h2 id=\"从一个生活问题谈起\">1. 从一个生活问题谈起</h2>\r\n<p>先来看看生活中经常遇到的事吧——假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，<strong>需要用到尽量少的钞票</strong>。</p>\r\n<p>依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。</p>\r\n<p>这种策略称为“<strong>贪心</strong>”：假设我们面对的局面是“需要凑出w”，贪心策略会<strong>尽快</strong>让w变得更小。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。</p>\r\n<p>但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：<br />\r\n　　15=1×11+4×1 （贪心策略使用了5张钞票）<br />\r\n　　15=3×5 （正确的策略，只用3张钞票）<br />\r\n　　为什么会这样呢？贪心策略错在了哪里？</p>\r\n<p><strong>鼠目寸光</strong>。</p>\r\n<p>刚刚已经说过，贪心策略的纲领是：“尽量使接下来面对的w更小”。这样，贪心策略在w=15的局面时，会优先使用11来把w降到4；但是在这个问题中，凑出4的代价是很高的，必须使用4×1。如果使用了5，w会降为10，虽然没有4那么小，但是凑出10只需要两张5元。</p>\r\n<p>在这里我们发现，贪心是一种<strong>只考虑眼前情况</strong>的策略。</p>\r\n<p>那么，现在我们怎样才能避免鼠目寸光呢？</p>\r\n<p>如果直接暴力枚举凑出w的方案，明显复杂度过高。太多种方法可以凑出w了，枚举它们的时间是不可承受的。我们现在来尝试找一下性质。</p>\r\n<p>重新分析刚刚的例子。w=15时，我们如果取11，接下来就面对w=4的情况；如果取5，则接下来面对w=10的情况。我们发现这些问题都有相同的形式：“给定w，凑出w所用的最少钞票是多少张？”接下来，我们用f(n)来表示“凑出n所需的最少钞票数量”。</p>\r\n<p>那么，如果我们取了11，最后的代价（用掉的钞票总数）是多少呢？</p>\r\n<p>明显<strong>cost=f(4)+1=4+1=5</strong>\r\n，它的意义是：利用11来凑出15，付出的代价等于f(4)加上自己这一张钞票。现在我们暂时不管f(4)怎么求出来。</p>\r\n<p>依次类推，马上可以知道：如果我们用5来凑出15，cost就是<strong>f(10)+1=2+1=3</strong>\r\n。</p>\r\n<p>那么，现在w=15的时候，我们该取那种钞票呢？<strong>当然是各种方案中，cost值最低的那一个！</strong></p>\r\n<ul>\r\n<li>取11：cost=f(4)+1=4+1=5</li>\r\n<li>取5:cost=f(10)+1=2+1=3</li>\r\n<li>取1:cost=f(14)+1=4+1=5</li>\r\n</ul>\r\n<p>显而易见，cost值最低的是取5的方案。<strong>我们通过上面三个式子，做出了正确的决策！</strong></p>\r\n<p>这给了我们一个<strong>至关重要</strong>的启示——\r\nf(n)只与f(n-1),f(n-5),f(n-11) 相关；更确切地说：</p>\r\n<blockquote>\r\n<p>f(n)=min{f(n-1),f(n-5),f(n-11)}+1</p>\r\n</blockquote>\r\n<p>这个式子是非常激动人心的。我们要求出f(n)，只需要求出几个更小的f值；既然如此，我们从小到大把所有的f(i)求出来不就好了？注意一下边界情况即可。代码如下：</p>\r\n<figure>\r\n<img src=\"/img/动态规划/解决方案.jpg\" alt=\"pic1\" />\r\n<figcaption aria-hidden=\"true\">pic1</figcaption>\r\n</figure>\r\n<p>我们以O(n)的复杂度解决了这个问题。现在回过头来，我们看看它的原理：</p>\r\n<ul>\r\n<li>f(n)只与f(n-1),f(n-5),f(n-11)的值有关。</li>\r\n<li>我们只关心f(w)的值，不关心是怎么凑出w的。</li>\r\n</ul>\r\n<p>这两个事实，保证了我们做法的正确性。它比起贪心策略，会分别算出取1、5、11的代价，从而做出一个正确决策，这样就避免掉了“鼠目寸光”！</p>\r\n<p>它与暴力的区别在哪里？我们的暴力枚举了“使用的硬币”，然而这属于冗余信息。我们要的是答案，根本不关心这个答案是怎么凑出来的。譬如，要求出f(15)，只需要知道f(14),f(10),f(4)的值。<strong>其他信息并不需要</strong>。我们舍弃了冗余信息。我们只记录了对解决问题有帮助的信息——f(n).</p>\r\n<p>我们能这样干，取决于问题的性质：求出f(n)，只需要知道几个更小的f(c)。<strong>我们将求解f(c)称作求解f(n)的“子问题”</strong>。</p>\r\n<p><strong>这就是DP（动态规划，dynamic programming）</strong>.</p>\r\n<p><strong>将一个问题拆成几个子问题，分别求解这些子问题，即可推断出大问题的解。</strong></p>\r\n<h2 id=\"几个简单的概念\">2. 几个简单的概念</h2>\r\n<ul>\r\n<li><strong>无后效性</strong><br />\r\n一旦f(n)确定，“我们如何凑出f(n)”就再也用不着了。</li>\r\n</ul>\r\n<p>要求出f(15)，只需要知道f(14),f(10),f(4)的值，而f(14),f(10),f(4)是如何算出来的，对之后的问题没有影响。</p>\r\n<p>“<strong>未来与过去无关</strong>”，这就是<strong>无后效性</strong>。</p>\r\n<p>（严格定义：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响。）</p>\r\n<ul>\r\n<li>最优子结构</li>\r\n</ul>\r\n<p>回顾我们对f(n)的定义：我们记“凑出n所需的最少钞票数量”为f(n).</p>\r\n<p>f(n)的定义就已经蕴含了“最优”。利用w=14,10,4的最优解，我们即可算出w=15的最优解。</p>\r\n<p>大问题的<strong>最优解</strong>可以由小问题的<strong>最优解</strong>推出，这个性质叫做“最优子结构性质”。</p>\r\n<p>引入这两个概念之后，我们如何判断一个问题能否使用DP解决呢？</p>\r\n<p><strong>能将大问题拆成几个小问题，且满足无后效性、最优子结构性质</strong>。</p>\r\n<h2 id=\"dp的典型应用dag最短路\">3. DP的典型应用：DAG最短路</h2>\r\n<p>问题很简单：给定一个城市的地图，所有的道路都是单行道，而且不会构成环。每条道路都有过路费，问您从S点到T点花费的最少费用。</p>\r\n<figure>\r\n<img src=\"/img/动态规划/最短路径.png\" alt=\"最短路径\" />\r\n<figcaption aria-hidden=\"true\">最短路径</figcaption>\r\n</figure>\r\n<p>这个问题能用DP解决吗？我们先试着记从S到P的最少费用为f(P).</p>\r\n<p>想要到T，要么经过C，要么经过D。从而<span\r\nclass=\"math inline\">\\(f(T)=min\\{f(C)+20,f(D)+10\\}\\)</span>.</p>\r\n<p>好像看起来可以DP。现在我们检验刚刚那两个性质：</p>\r\n<ul>\r\n<li>无后效性：对于点P，一旦f(P)确定，以后就只关心f(P)的值，不关心怎么去的。</li>\r\n<li>最优子结构：对于P，我们当然只关心到P的最小费用，即f(P)。如果我们从S走到T是<span\r\nclass=\"math inline\">\\(S \\rightarrow P\\rightarrow Q \\rightarrow\r\nT\\)</span>,那肯定S走到Q的最优路径是<span class=\"math inline\">\\(S\r\n\\rightarrow P\\rightarrow\r\nQ\\)</span>。对一条最优的路径而言，从S走到<strong>沿途上所有的点（子问题）</strong>的最优路径，都是这条大路的一部分。这个问题的最优子结构性质是显然的。</li>\r\n</ul>\r\n<p>既然这两个性质都满足，那么本题可以DP。式子明显为：</p>\r\n<blockquote>\r\n<p>f(P)=min{f(R)+W<sub><span class=\"math inline\">\\(R \\rightarrow\r\nP\\)</span></sub>}</p>\r\n</blockquote>\r\n<p>其中R为有路通到P的所有的点， [公式] 为R到P的过路费。</p>\r\n<p>代码实现也很简单，拓扑排序即可。</p>\r\n<h2 id=\"对dp原理的一点讨论\">4. 对DP原理的一点讨论</h2>\r\n<ul>\r\n<li>DP的核心思想</li>\r\n</ul>\r\n<p>DP为什么会快？</p>\r\n<p>无论是DP还是暴力，我们的算法都是在<strong>可能解空间</strong>内，寻找<strong>最优解</strong>。</p>\r\n<p>来看钞票问题。暴力做法是枚举所有的可能解，这是最大的可能解空间。</p>\r\n<p>DP是枚举<strong>有希望成为答案的解</strong>。这个空间比暴力的小得多。</p>\r\n<p>也就是说：<strong>DP自带剪枝</strong>。</p>\r\n<p>DP舍弃了一大堆不可能成为最优解的答案。譬如：<br />\r\n　　15 = 5+5+5 被考虑了。<br />\r\n　　15 = 5+5+1+1+1+1+1 从来没有考虑过，因为这不可能成为最优解。</p>\r\n<p>在暴力算法中，可能解空间往往是指数级的大小；如果我们采用DP，那么有可能把解空间的大小降到多项式级。</p>\r\n<p>一般来说，解空间越小，寻找解就越快。这样就完成了优化。</p>\r\n<ul>\r\n<li>DP的操作过程</li>\r\n</ul>\r\n<p>一言以蔽之：<strong>大事化小，小事化了</strong>。</p>\r\n<p>将一个大问题转化成几个小问题；<br />\r\n　　求解小问题；<br />\r\n　　推出大问题的解。</p>\r\n<ul>\r\n<li>如何设计DP算法</li>\r\n</ul>\r\n<p>下面介绍比较通用的设计DP算法的步骤。</p>\r\n<p>首先，把我们面对的局面表示为x。这一步称为设计状态。</p>\r\n<p>对于状态x，记我们要求出的答案(e.g.\r\n最小费用)为f(x).我们的目标是求出f(T).\r\n<strong>找出f(x)与哪些局面有关（记为p）</strong>，写出一个式子（称为状态转移方程），通过f(p)来推出f(x).</p>\r\n<ul>\r\n<li>DP三连</li>\r\n</ul>\r\n<p>设计DP算法，往往可以遵循DP三连：</p>\r\n<p>我是谁？ ——设计状态，表示局面</p>\r\n<p>我从哪里来？</p>\r\n<p>我要到哪里去？ ——设计转移</p>\r\n<p>设计状态是DP的基础。接下来的设计转移，有两种方式：一种是考虑我从哪里来（本文之前提到的两个例子，都是在考虑“我从哪里来”）；另一种是考虑我到哪里去，这常见于求出f(x)之后，<strong>更新能从x走到的一些解</strong>。这种DP也是不少的，我们以后会遇到。</p>\r\n<p>总而言之，“我从哪里来”和“我要到哪里去”只需要考虑清楚其中一个，就能设计出状态转移方程，从而写代码求解问题。前者又称pull型的转移，后者又称push型的转移。</p>\r\n<blockquote>\r\n<p>思考题：如何把钞票问题的代码改写成“我到哪里去”的形式？<br />\r\n提示：求出f(x)之后，更新f(x+1),f(x+5),f(x+11).</p>\r\n</blockquote>\r\n<h2 id=\"例题最长上升子序列\">5. 例题：最长上升子序列</h2>\r\n<p>扯了这么多形而上的内容，还是做一道例题吧。</p>\r\n<p>最长上升子序列（LIS）问题：给定长度为n的序列a，从a中抽取出一个子序列，这个子序列需要单调递增。问最长的上升子序列（LIS）的长度。<br />\r\n　　e.g. 1,5,3,4,6,9,7,8的LIS为1,3,4,6,7,8，长度为6。</p>\r\n<p>如何设计状态（我是谁）？</p>\r\n<p>我们记<span\r\nclass=\"math inline\">\\(f(x)\\)</span>为以a<sub>x</sub>结尾的LIS长度，那么答案就是\r\n<span class=\"math inline\">\\(max\\{f(x)\\}\\)</span></p>\r\n<p>状态x从哪里推过来（我从哪里来）？</p>\r\n<p>考虑比x小的每一个p：如果 a<sub>x</sub> &gt; a<sub>p</sub>，那么<span\r\nclass=\"math inline\">\\(f(x)\\)</span>可以取<span\r\nclass=\"math inline\">\\(f(p)+1\\)</span>.</p>\r\n<p>解释：我们把 a<sub>x</sub> 接在 a<sub>p</sub>\r\n的后面，肯定能构造一个以 a<sub>x</sub> 结尾的上升子序列，长度比以\r\na<sub>p</sub> 结尾的LIS大1.那么，我们可以写出状态转移方程了：</p>\r\n<figure>\r\n<img src=\"/img/动态规划/状态转移方程.svg\" alt=\"状态转移方程\" />\r\n<figcaption aria-hidden=\"true\">状态转移方程</figcaption>\r\n</figure>\r\n<p>至此解决问题。两层for循环，复杂度O(n<sup>2</sup>) 。</p>\r\n<figure>\r\n<img src=\"/img/动态规划/最长上升子序列代码.jpg\"\r\nalt=\"最长上升子序列代码\" />\r\n<figcaption aria-hidden=\"true\">最长上升子序列代码</figcaption>\r\n</figure>\r\n<p>从这三个例题中可以看出，DP是一种思想，一种“大事化小，小事化了”的思想。带着这种思想，DP将会成为我们解决问题的利器。</p>\r\n<h2 id=\"习题\">6. 习题</h2>\r\n<p>如果读者有兴趣，可以试着完成下面几个习题：</p>\r\n<ol type=\"1\">\r\n<li>请采取一些优化手段，以 O(n log<sub>2</sub> n)\r\n的复杂度解决LIS问题。</li>\r\n</ol>\r\n<p>提示：可以参考这篇博客 <a\r\nhref=\"https://www.luogu.com.cn/blog/pks-LOVING/junior-dynamic-programming-dong-tai-gui-hua-chu-bu-ge-zhong-zi-xu-lie\">Junior\r\nDynamic Programming--动态规划初步·各种子序列问题</a></p>\r\n<ol start=\"2\" type=\"1\">\r\n<li>“按顺序递推”和“记忆化搜索”是实现DP的两种方式。请查阅资料，简单描述“记忆化搜索”是什么。并采用记忆化搜索写出钞票问题的代码，然后完成<a\r\nhref=\"https://www.luogu.com.cn/problem/P1541\">P1541 乌龟棋 - 洛谷</a>\r\n。</li>\r\n<li>01背包问题是一种常见的DP模型。请完成<a\r\nhref=\"https://www.luogu.com.cn/problem/P1048\">P1048 采药 -\r\n洛谷</a>。</li>\r\n</ol>\r\n<h2 id=\"读后思考动态规划和分治法的区别与共同点\">7.\r\n读后思考：动态规划和分治法的区别与共同点？</h2>\r\n<h3 id=\"分治法\">1. 分治法</h3>\r\n<p>分治法(Divide-and-Conquer) :\r\n将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。</p>\r\n<p>分治模式在每一层递归上都有三个步骤：</p>\r\n<ul>\r\n<li>分解(Divide)：将原问题分解成一系列子问题；</li>\r\n<li>解决(Conquer)：递归地解决各个子问题。若子问题足够小，则直接求解。</li>\r\n<li>合并(Combine)：将子问题的结果合并成原问题的解。</li>\r\n</ul>\r\n<p>合并排序(Merge\r\nSort)是一个典型分治法的例子。其对应的直观的操作如下:</p>\r\n<p>分解： 将n个元素分成各含n/2个元素的子序列；</p>\r\n<p>解决：用合并排序法对两个子序列递归地排序；</p>\r\n<p>合并：合并两个已排序的子序列以得到排序结果。</p>\r\n<h3 id=\"动态规划法\">2. 动态规划法</h3>\r\n<p>动态规划算法的设计可以分为如下4个步骤：</p>\r\n<ul>\r\n<li>描述最优解的结构</li>\r\n<li>递归定义最优解的值</li>\r\n<li>按自底向上的方式计算最优解的值</li>\r\n<li>由计算出的结果构造一个最优解</li>\r\n</ul>\r\n<p><strong>分治法是指将问题划分成一些独立的子问题，递归的求解各子问题，然后合并子问题的解而得到原问题的解。与此不同，动态规划适用于子问题独立且重叠的情况，也就是各子问题包含公共的子子问题。在这种情况下，若用分治法则会做许多不必要的工作，即重复地求解公共的子问题。动态规划算法对每个子子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。</strong></p>\r\n<p>适合采用动态规划方法的最优化问题中的两个要素：<strong>最优子结构</strong>和<strong>重叠子问题</strong>。</p>\r\n<p>最优子结构：如果问题的一个最优解中包含了子问题的最优解，则该问题具有最优子结构。</p>\r\n<p>重叠子问题：适用于动态规划求解的最优化问题必须具有的第二个要素是子问题的空间要很小，也就是用来求解原问题的递归算法反复地解同样的子问题，而不是总是在产生新的子问题。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则它们是重叠的。</p>\r\n<p>In a word, <strong>分治法 —— 各子问题独立；动态规划 ——\r\n各子问题重叠</strong>。</p>\r\n<p>算法导论：\r\n<strong>动态规划要求其子问题既要独立又要重叠，这看上去似乎有些奇怪。虽然这两点要求听起来可能矛盾的，但它们描述了两种不同的概念，而不是同一个问题的两个方面。如果同一个问题的两个子问题不共享资源，则它们就是独立的。对两个子问题俩说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，是重叠的，则它们是重叠</strong>。</p>\r\n","site":{"data":{}},"excerpt":"","more":"<p>本文大部分转载自知乎<a\r\nhref=\"https://www.zhihu.com/people/ruan-xing-zhi\"><span class=\"citation\"\r\ndata-cites=\"阮行止\">@阮行止</span></a>，后添加了自己的一些思考。</p>\r\n<h2 id=\"从一个生活问题谈起\">1. 从一个生活问题谈起</h2>\r\n<p>先来看看生活中经常遇到的事吧——假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，<strong>需要用到尽量少的钞票</strong>。</p>\r\n<p>依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。</p>\r\n<p>这种策略称为“<strong>贪心</strong>”：假设我们面对的局面是“需要凑出w”，贪心策略会<strong>尽快</strong>让w变得更小。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。</p>\r\n<p>但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：<br />\r\n　　15=1×11+4×1 （贪心策略使用了5张钞票）<br />\r\n　　15=3×5 （正确的策略，只用3张钞票）<br />\r\n　　为什么会这样呢？贪心策略错在了哪里？</p>\r\n<p><strong>鼠目寸光</strong>。</p>\r\n<p>刚刚已经说过，贪心策略的纲领是：“尽量使接下来面对的w更小”。这样，贪心策略在w=15的局面时，会优先使用11来把w降到4；但是在这个问题中，凑出4的代价是很高的，必须使用4×1。如果使用了5，w会降为10，虽然没有4那么小，但是凑出10只需要两张5元。</p>\r\n<p>在这里我们发现，贪心是一种<strong>只考虑眼前情况</strong>的策略。</p>\r\n<p>那么，现在我们怎样才能避免鼠目寸光呢？</p>\r\n<p>如果直接暴力枚举凑出w的方案，明显复杂度过高。太多种方法可以凑出w了，枚举它们的时间是不可承受的。我们现在来尝试找一下性质。</p>\r\n<p>重新分析刚刚的例子。w=15时，我们如果取11，接下来就面对w=4的情况；如果取5，则接下来面对w=10的情况。我们发现这些问题都有相同的形式：“给定w，凑出w所用的最少钞票是多少张？”接下来，我们用f(n)来表示“凑出n所需的最少钞票数量”。</p>\r\n<p>那么，如果我们取了11，最后的代价（用掉的钞票总数）是多少呢？</p>\r\n<p>明显<strong>cost=f(4)+1=4+1=5</strong>\r\n，它的意义是：利用11来凑出15，付出的代价等于f(4)加上自己这一张钞票。现在我们暂时不管f(4)怎么求出来。</p>\r\n<p>依次类推，马上可以知道：如果我们用5来凑出15，cost就是<strong>f(10)+1=2+1=3</strong>\r\n。</p>\r\n<p>那么，现在w=15的时候，我们该取那种钞票呢？<strong>当然是各种方案中，cost值最低的那一个！</strong></p>\r\n<ul>\r\n<li>取11：cost=f(4)+1=4+1=5</li>\r\n<li>取5:cost=f(10)+1=2+1=3</li>\r\n<li>取1:cost=f(14)+1=4+1=5</li>\r\n</ul>\r\n<p>显而易见，cost值最低的是取5的方案。<strong>我们通过上面三个式子，做出了正确的决策！</strong></p>\r\n<p>这给了我们一个<strong>至关重要</strong>的启示——\r\nf(n)只与f(n-1),f(n-5),f(n-11) 相关；更确切地说：</p>\r\n<blockquote>\r\n<p>f(n)=min{f(n-1),f(n-5),f(n-11)}+1</p>\r\n</blockquote>\r\n<p>这个式子是非常激动人心的。我们要求出f(n)，只需要求出几个更小的f值；既然如此，我们从小到大把所有的f(i)求出来不就好了？注意一下边界情况即可。代码如下：</p>\r\n<figure>\r\n<img src=\"/img/动态规划/解决方案.jpg\" alt=\"pic1\" />\r\n<figcaption aria-hidden=\"true\">pic1</figcaption>\r\n</figure>\r\n<p>我们以O(n)的复杂度解决了这个问题。现在回过头来，我们看看它的原理：</p>\r\n<ul>\r\n<li>f(n)只与f(n-1),f(n-5),f(n-11)的值有关。</li>\r\n<li>我们只关心f(w)的值，不关心是怎么凑出w的。</li>\r\n</ul>\r\n<p>这两个事实，保证了我们做法的正确性。它比起贪心策略，会分别算出取1、5、11的代价，从而做出一个正确决策，这样就避免掉了“鼠目寸光”！</p>\r\n<p>它与暴力的区别在哪里？我们的暴力枚举了“使用的硬币”，然而这属于冗余信息。我们要的是答案，根本不关心这个答案是怎么凑出来的。譬如，要求出f(15)，只需要知道f(14),f(10),f(4)的值。<strong>其他信息并不需要</strong>。我们舍弃了冗余信息。我们只记录了对解决问题有帮助的信息——f(n).</p>\r\n<p>我们能这样干，取决于问题的性质：求出f(n)，只需要知道几个更小的f(c)。<strong>我们将求解f(c)称作求解f(n)的“子问题”</strong>。</p>\r\n<p><strong>这就是DP（动态规划，dynamic programming）</strong>.</p>\r\n<p><strong>将一个问题拆成几个子问题，分别求解这些子问题，即可推断出大问题的解。</strong></p>\r\n<h2 id=\"几个简单的概念\">2. 几个简单的概念</h2>\r\n<ul>\r\n<li><strong>无后效性</strong><br />\r\n一旦f(n)确定，“我们如何凑出f(n)”就再也用不着了。</li>\r\n</ul>\r\n<p>要求出f(15)，只需要知道f(14),f(10),f(4)的值，而f(14),f(10),f(4)是如何算出来的，对之后的问题没有影响。</p>\r\n<p>“<strong>未来与过去无关</strong>”，这就是<strong>无后效性</strong>。</p>\r\n<p>（严格定义：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响。）</p>\r\n<ul>\r\n<li>最优子结构</li>\r\n</ul>\r\n<p>回顾我们对f(n)的定义：我们记“凑出n所需的最少钞票数量”为f(n).</p>\r\n<p>f(n)的定义就已经蕴含了“最优”。利用w=14,10,4的最优解，我们即可算出w=15的最优解。</p>\r\n<p>大问题的<strong>最优解</strong>可以由小问题的<strong>最优解</strong>推出，这个性质叫做“最优子结构性质”。</p>\r\n<p>引入这两个概念之后，我们如何判断一个问题能否使用DP解决呢？</p>\r\n<p><strong>能将大问题拆成几个小问题，且满足无后效性、最优子结构性质</strong>。</p>\r\n<h2 id=\"dp的典型应用dag最短路\">3. DP的典型应用：DAG最短路</h2>\r\n<p>问题很简单：给定一个城市的地图，所有的道路都是单行道，而且不会构成环。每条道路都有过路费，问您从S点到T点花费的最少费用。</p>\r\n<figure>\r\n<img src=\"/img/动态规划/最短路径.png\" alt=\"最短路径\" />\r\n<figcaption aria-hidden=\"true\">最短路径</figcaption>\r\n</figure>\r\n<p>这个问题能用DP解决吗？我们先试着记从S到P的最少费用为f(P).</p>\r\n<p>想要到T，要么经过C，要么经过D。从而<span\r\nclass=\"math inline\">\\(f(T)=min\\{f(C)+20,f(D)+10\\}\\)</span>.</p>\r\n<p>好像看起来可以DP。现在我们检验刚刚那两个性质：</p>\r\n<ul>\r\n<li>无后效性：对于点P，一旦f(P)确定，以后就只关心f(P)的值，不关心怎么去的。</li>\r\n<li>最优子结构：对于P，我们当然只关心到P的最小费用，即f(P)。如果我们从S走到T是<span\r\nclass=\"math inline\">\\(S \\rightarrow P\\rightarrow Q \\rightarrow\r\nT\\)</span>,那肯定S走到Q的最优路径是<span class=\"math inline\">\\(S\r\n\\rightarrow P\\rightarrow\r\nQ\\)</span>。对一条最优的路径而言，从S走到<strong>沿途上所有的点（子问题）</strong>的最优路径，都是这条大路的一部分。这个问题的最优子结构性质是显然的。</li>\r\n</ul>\r\n<p>既然这两个性质都满足，那么本题可以DP。式子明显为：</p>\r\n<blockquote>\r\n<p>f(P)=min{f(R)+W<sub><span class=\"math inline\">\\(R \\rightarrow\r\nP\\)</span></sub>}</p>\r\n</blockquote>\r\n<p>其中R为有路通到P的所有的点， [公式] 为R到P的过路费。</p>\r\n<p>代码实现也很简单，拓扑排序即可。</p>\r\n<h2 id=\"对dp原理的一点讨论\">4. 对DP原理的一点讨论</h2>\r\n<ul>\r\n<li>DP的核心思想</li>\r\n</ul>\r\n<p>DP为什么会快？</p>\r\n<p>无论是DP还是暴力，我们的算法都是在<strong>可能解空间</strong>内，寻找<strong>最优解</strong>。</p>\r\n<p>来看钞票问题。暴力做法是枚举所有的可能解，这是最大的可能解空间。</p>\r\n<p>DP是枚举<strong>有希望成为答案的解</strong>。这个空间比暴力的小得多。</p>\r\n<p>也就是说：<strong>DP自带剪枝</strong>。</p>\r\n<p>DP舍弃了一大堆不可能成为最优解的答案。譬如：<br />\r\n　　15 = 5+5+5 被考虑了。<br />\r\n　　15 = 5+5+1+1+1+1+1 从来没有考虑过，因为这不可能成为最优解。</p>\r\n<p>在暴力算法中，可能解空间往往是指数级的大小；如果我们采用DP，那么有可能把解空间的大小降到多项式级。</p>\r\n<p>一般来说，解空间越小，寻找解就越快。这样就完成了优化。</p>\r\n<ul>\r\n<li>DP的操作过程</li>\r\n</ul>\r\n<p>一言以蔽之：<strong>大事化小，小事化了</strong>。</p>\r\n<p>将一个大问题转化成几个小问题；<br />\r\n　　求解小问题；<br />\r\n　　推出大问题的解。</p>\r\n<ul>\r\n<li>如何设计DP算法</li>\r\n</ul>\r\n<p>下面介绍比较通用的设计DP算法的步骤。</p>\r\n<p>首先，把我们面对的局面表示为x。这一步称为设计状态。</p>\r\n<p>对于状态x，记我们要求出的答案(e.g.\r\n最小费用)为f(x).我们的目标是求出f(T).\r\n<strong>找出f(x)与哪些局面有关（记为p）</strong>，写出一个式子（称为状态转移方程），通过f(p)来推出f(x).</p>\r\n<ul>\r\n<li>DP三连</li>\r\n</ul>\r\n<p>设计DP算法，往往可以遵循DP三连：</p>\r\n<p>我是谁？ ——设计状态，表示局面</p>\r\n<p>我从哪里来？</p>\r\n<p>我要到哪里去？ ——设计转移</p>\r\n<p>设计状态是DP的基础。接下来的设计转移，有两种方式：一种是考虑我从哪里来（本文之前提到的两个例子，都是在考虑“我从哪里来”）；另一种是考虑我到哪里去，这常见于求出f(x)之后，<strong>更新能从x走到的一些解</strong>。这种DP也是不少的，我们以后会遇到。</p>\r\n<p>总而言之，“我从哪里来”和“我要到哪里去”只需要考虑清楚其中一个，就能设计出状态转移方程，从而写代码求解问题。前者又称pull型的转移，后者又称push型的转移。</p>\r\n<blockquote>\r\n<p>思考题：如何把钞票问题的代码改写成“我到哪里去”的形式？<br />\r\n提示：求出f(x)之后，更新f(x+1),f(x+5),f(x+11).</p>\r\n</blockquote>\r\n<h2 id=\"例题最长上升子序列\">5. 例题：最长上升子序列</h2>\r\n<p>扯了这么多形而上的内容，还是做一道例题吧。</p>\r\n<p>最长上升子序列（LIS）问题：给定长度为n的序列a，从a中抽取出一个子序列，这个子序列需要单调递增。问最长的上升子序列（LIS）的长度。<br />\r\n　　e.g. 1,5,3,4,6,9,7,8的LIS为1,3,4,6,7,8，长度为6。</p>\r\n<p>如何设计状态（我是谁）？</p>\r\n<p>我们记<span\r\nclass=\"math inline\">\\(f(x)\\)</span>为以a<sub>x</sub>结尾的LIS长度，那么答案就是\r\n<span class=\"math inline\">\\(max\\{f(x)\\}\\)</span></p>\r\n<p>状态x从哪里推过来（我从哪里来）？</p>\r\n<p>考虑比x小的每一个p：如果 a<sub>x</sub> &gt; a<sub>p</sub>，那么<span\r\nclass=\"math inline\">\\(f(x)\\)</span>可以取<span\r\nclass=\"math inline\">\\(f(p)+1\\)</span>.</p>\r\n<p>解释：我们把 a<sub>x</sub> 接在 a<sub>p</sub>\r\n的后面，肯定能构造一个以 a<sub>x</sub> 结尾的上升子序列，长度比以\r\na<sub>p</sub> 结尾的LIS大1.那么，我们可以写出状态转移方程了：</p>\r\n<figure>\r\n<img src=\"/img/动态规划/状态转移方程.svg\" alt=\"状态转移方程\" />\r\n<figcaption aria-hidden=\"true\">状态转移方程</figcaption>\r\n</figure>\r\n<p>至此解决问题。两层for循环，复杂度O(n<sup>2</sup>) 。</p>\r\n<figure>\r\n<img src=\"/img/动态规划/最长上升子序列代码.jpg\"\r\nalt=\"最长上升子序列代码\" />\r\n<figcaption aria-hidden=\"true\">最长上升子序列代码</figcaption>\r\n</figure>\r\n<p>从这三个例题中可以看出，DP是一种思想，一种“大事化小，小事化了”的思想。带着这种思想，DP将会成为我们解决问题的利器。</p>\r\n<h2 id=\"习题\">6. 习题</h2>\r\n<p>如果读者有兴趣，可以试着完成下面几个习题：</p>\r\n<ol type=\"1\">\r\n<li>请采取一些优化手段，以 O(n log<sub>2</sub> n)\r\n的复杂度解决LIS问题。</li>\r\n</ol>\r\n<p>提示：可以参考这篇博客 <a\r\nhref=\"https://www.luogu.com.cn/blog/pks-LOVING/junior-dynamic-programming-dong-tai-gui-hua-chu-bu-ge-zhong-zi-xu-lie\">Junior\r\nDynamic Programming--动态规划初步·各种子序列问题</a></p>\r\n<ol start=\"2\" type=\"1\">\r\n<li>“按顺序递推”和“记忆化搜索”是实现DP的两种方式。请查阅资料，简单描述“记忆化搜索”是什么。并采用记忆化搜索写出钞票问题的代码，然后完成<a\r\nhref=\"https://www.luogu.com.cn/problem/P1541\">P1541 乌龟棋 - 洛谷</a>\r\n。</li>\r\n<li>01背包问题是一种常见的DP模型。请完成<a\r\nhref=\"https://www.luogu.com.cn/problem/P1048\">P1048 采药 -\r\n洛谷</a>。</li>\r\n</ol>\r\n<h2 id=\"读后思考动态规划和分治法的区别与共同点\">7.\r\n读后思考：动态规划和分治法的区别与共同点？</h2>\r\n<h3 id=\"分治法\">1. 分治法</h3>\r\n<p>分治法(Divide-and-Conquer) :\r\n将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。</p>\r\n<p>分治模式在每一层递归上都有三个步骤：</p>\r\n<ul>\r\n<li>分解(Divide)：将原问题分解成一系列子问题；</li>\r\n<li>解决(Conquer)：递归地解决各个子问题。若子问题足够小，则直接求解。</li>\r\n<li>合并(Combine)：将子问题的结果合并成原问题的解。</li>\r\n</ul>\r\n<p>合并排序(Merge\r\nSort)是一个典型分治法的例子。其对应的直观的操作如下:</p>\r\n<p>分解： 将n个元素分成各含n/2个元素的子序列；</p>\r\n<p>解决：用合并排序法对两个子序列递归地排序；</p>\r\n<p>合并：合并两个已排序的子序列以得到排序结果。</p>\r\n<h3 id=\"动态规划法\">2. 动态规划法</h3>\r\n<p>动态规划算法的设计可以分为如下4个步骤：</p>\r\n<ul>\r\n<li>描述最优解的结构</li>\r\n<li>递归定义最优解的值</li>\r\n<li>按自底向上的方式计算最优解的值</li>\r\n<li>由计算出的结果构造一个最优解</li>\r\n</ul>\r\n<p><strong>分治法是指将问题划分成一些独立的子问题，递归的求解各子问题，然后合并子问题的解而得到原问题的解。与此不同，动态规划适用于子问题独立且重叠的情况，也就是各子问题包含公共的子子问题。在这种情况下，若用分治法则会做许多不必要的工作，即重复地求解公共的子问题。动态规划算法对每个子子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。</strong></p>\r\n<p>适合采用动态规划方法的最优化问题中的两个要素：<strong>最优子结构</strong>和<strong>重叠子问题</strong>。</p>\r\n<p>最优子结构：如果问题的一个最优解中包含了子问题的最优解，则该问题具有最优子结构。</p>\r\n<p>重叠子问题：适用于动态规划求解的最优化问题必须具有的第二个要素是子问题的空间要很小，也就是用来求解原问题的递归算法反复地解同样的子问题，而不是总是在产生新的子问题。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则它们是重叠的。</p>\r\n<p>In a word, <strong>分治法 —— 各子问题独立；动态规划 ——\r\n各子问题重叠</strong>。</p>\r\n<p>算法导论：\r\n<strong>动态规划要求其子问题既要独立又要重叠，这看上去似乎有些奇怪。虽然这两点要求听起来可能矛盾的，但它们描述了两种不同的概念，而不是同一个问题的两个方面。如果同一个问题的两个子问题不共享资源，则它们就是独立的。对两个子问题俩说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，是重叠的，则它们是重叠</strong>。</p>\r\n"},{"title":"多项式规约","math":true,"_content":"\n\n## NP、NPC、NPH问题\n**NP问题** ：能在多项式时间内验证某个猜想答案的正确性，但可能在无法再多项式时间内解决。比如：数独，很容易就确定一个答案是否正确，但确找不到一个公式来描述其规律。\n\n**NPC问题**: 需要满足两个条件\n    \n- 它是一个NP问题\n- 所有的NP问题都可以规约到NP-complete\n**如果**我们给NPC问题找到了一个多项式时间复杂度的算法，那么也就意味着我们给所有的NP问题找到了多项式时间复杂度的算法，从而NP=P，因为P=NP，所以“P对NP问题”就可以被解决。但给NPC问题找一个多项式时间复杂度的算法太难了，所以现在人们普遍相信P≠NP。\n\n\n**NPH问题** ：满足上面NPC问题的第二个条件，但不一定要满足第一个条件，所以NPH的范围比HPC更大。\n\n## 多项式规约\n定义：若问题X 的任意实例可以由下面两条之和解决\n\n- 问题X可以通过多项式时间的基本运算步骤转换为问题Y；\n- 问题X多项式次调用求解问题Y的算法，且问题Y可以在多项式时间内被求解。\n\n那么称问题X可以多项式规约到问题Y，记为 $ X \\le_{p} Y $。需要注意的是，问题X转换为问题Y之后，问题Y的运行时间是建立在问题Y的输入上。\n\n多项式规约的几个性质：\n\n- 若 $X \\le_{p} Y$，则若Y能在多项式时间内求解，那么X也能在多项式时间内求解。\n- 若 $X \\le_{p} Y$，则若X不能在多项式时间内求解，那么Y也不能在多项式时间内求解。\n- 若 $X \\le_{p} Y$ 且 $Y \\le_{p} X$，那么X和Y是等价的。\n\n\n\n基本的规约方法：\n    \n- 简单的恒等归约：比如最大独立集和最小点覆盖。\n- 从特殊情况到一般情况：比如 $点覆盖 \\le_{p} 集合覆盖$。  \n- 通过一些小技巧规约。比如 $3-SAT \\le_{p} 独立集$\n\n### 独立集问题\n定义：给定一个图 $G=(V,E)$和一个整数k(V为顶点集，E为边集)，是否有一个V的子集 $S \\subseteq V $使得 $|S| \\ge k$并且S中的每条边至多有一个顶点在S中？\n\n![独立集](/img/多项式规约/独立集.png)\n\n### 点覆盖问题\n定义:给定一个图 $G=(V,E)$和一个整数k,是否有一个V的子集 $S \\subseteq V $使得 $|S| \\le k$并且S中的每条边至少有一个顶点在S中？\n\n\n![点覆盖](/img/多项式规约/点覆盖.png)\n\n**定理： $点覆盖 \\equiv 独立集$**\n\n证明如下（简单的恒等规约）：\n\n$\\Rightarrow$\n- 令S为任意独立集\n- 对任意的边 $(u,v)$\n- S是独立集 $\\Rightarrow u \\notin S$ 或 $v \\notin S \\Rightarrow u \\in V - S $ 或 $v \\in V-S$\n- 所以 $V-S$ 是一个点覆盖\n\n$\\Leftarrow$\n- 令 $V-S$是一个点覆盖\n- 对两个顶点 $u \\in S$ 及 $v \\in S$\n- 若 $V-S$ 是一个点覆盖,那么 $(u, v) \\notin E$\n- 因此，没有相邻的顶点在 $S$ 中 $\\Rightarrow$ S是独立集 ","source":"_posts/多项式规约.md","raw":"---\ntitle: 多项式规约\ncategories: 算法\ntags: 高级算法设计与分析\nmath: true\n---\n\n\n## NP、NPC、NPH问题\n**NP问题** ：能在多项式时间内验证某个猜想答案的正确性，但可能在无法再多项式时间内解决。比如：数独，很容易就确定一个答案是否正确，但确找不到一个公式来描述其规律。\n\n**NPC问题**: 需要满足两个条件\n    \n- 它是一个NP问题\n- 所有的NP问题都可以规约到NP-complete\n**如果**我们给NPC问题找到了一个多项式时间复杂度的算法，那么也就意味着我们给所有的NP问题找到了多项式时间复杂度的算法，从而NP=P，因为P=NP，所以“P对NP问题”就可以被解决。但给NPC问题找一个多项式时间复杂度的算法太难了，所以现在人们普遍相信P≠NP。\n\n\n**NPH问题** ：满足上面NPC问题的第二个条件，但不一定要满足第一个条件，所以NPH的范围比HPC更大。\n\n## 多项式规约\n定义：若问题X 的任意实例可以由下面两条之和解决\n\n- 问题X可以通过多项式时间的基本运算步骤转换为问题Y；\n- 问题X多项式次调用求解问题Y的算法，且问题Y可以在多项式时间内被求解。\n\n那么称问题X可以多项式规约到问题Y，记为 $ X \\le_{p} Y $。需要注意的是，问题X转换为问题Y之后，问题Y的运行时间是建立在问题Y的输入上。\n\n多项式规约的几个性质：\n\n- 若 $X \\le_{p} Y$，则若Y能在多项式时间内求解，那么X也能在多项式时间内求解。\n- 若 $X \\le_{p} Y$，则若X不能在多项式时间内求解，那么Y也不能在多项式时间内求解。\n- 若 $X \\le_{p} Y$ 且 $Y \\le_{p} X$，那么X和Y是等价的。\n\n\n\n基本的规约方法：\n    \n- 简单的恒等归约：比如最大独立集和最小点覆盖。\n- 从特殊情况到一般情况：比如 $点覆盖 \\le_{p} 集合覆盖$。  \n- 通过一些小技巧规约。比如 $3-SAT \\le_{p} 独立集$\n\n### 独立集问题\n定义：给定一个图 $G=(V,E)$和一个整数k(V为顶点集，E为边集)，是否有一个V的子集 $S \\subseteq V $使得 $|S| \\ge k$并且S中的每条边至多有一个顶点在S中？\n\n![独立集](/img/多项式规约/独立集.png)\n\n### 点覆盖问题\n定义:给定一个图 $G=(V,E)$和一个整数k,是否有一个V的子集 $S \\subseteq V $使得 $|S| \\le k$并且S中的每条边至少有一个顶点在S中？\n\n\n![点覆盖](/img/多项式规约/点覆盖.png)\n\n**定理： $点覆盖 \\equiv 独立集$**\n\n证明如下（简单的恒等规约）：\n\n$\\Rightarrow$\n- 令S为任意独立集\n- 对任意的边 $(u,v)$\n- S是独立集 $\\Rightarrow u \\notin S$ 或 $v \\notin S \\Rightarrow u \\in V - S $ 或 $v \\in V-S$\n- 所以 $V-S$ 是一个点覆盖\n\n$\\Leftarrow$\n- 令 $V-S$是一个点覆盖\n- 对两个顶点 $u \\in S$ 及 $v \\in S$\n- 若 $V-S$ 是一个点覆盖,那么 $(u, v) \\notin E$\n- 因此，没有相邻的顶点在 $S$ 中 $\\Rightarrow$ S是独立集 ","slug":"多项式规约","published":1,"date":"2022-12-03T10:36:46.044Z","updated":"2022-12-03T16:00:52.653Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clb8pvosw0003zgsgagryegrv","content":"<h2 id=\"npnpcnph问题\">NP、NPC、NPH问题</h2>\r\n<p><strong>NP问题</strong>\r\n：能在多项式时间内验证某个猜想答案的正确性，但可能在无法再多项式时间内解决。比如：数独，很容易就确定一个答案是否正确，但确找不到一个公式来描述其规律。</p>\r\n<p><strong>NPC问题</strong>: 需要满足两个条件</p>\r\n<ul>\r\n<li>它是一个NP问题</li>\r\n<li>所有的NP问题都可以规约到NP-complete\r\n<strong>如果</strong>我们给NPC问题找到了一个多项式时间复杂度的算法，那么也就意味着我们给所有的NP问题找到了多项式时间复杂度的算法，从而NP=P，因为P=NP，所以“P对NP问题”就可以被解决。但给NPC问题找一个多项式时间复杂度的算法太难了，所以现在人们普遍相信P≠NP。</li>\r\n</ul>\r\n<p><strong>NPH问题</strong>\r\n：满足上面NPC问题的第二个条件，但不一定要满足第一个条件，所以NPH的范围比HPC更大。</p>\r\n<h2 id=\"多项式规约\">多项式规约</h2>\r\n<p>定义：若问题X 的任意实例可以由下面两条之和解决</p>\r\n<ul>\r\n<li>问题X可以通过多项式时间的基本运算步骤转换为问题Y；</li>\r\n<li>问题X多项式次调用求解问题Y的算法，且问题Y可以在多项式时间内被求解。</li>\r\n</ul>\r\n<p>那么称问题X可以多项式规约到问题Y，记为 $ X _{p} Y\r\n$。需要注意的是，问题X转换为问题Y之后，问题Y的运行时间是建立在问题Y的输入上。</p>\r\n<p>多项式规约的几个性质：</p>\r\n<ul>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p}\r\nY\\)</span>，则若Y能在多项式时间内求解，那么X也能在多项式时间内求解。</li>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p}\r\nY\\)</span>，则若X不能在多项式时间内求解，那么Y也不能在多项式时间内求解。</li>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p} Y\\)</span> 且 <span\r\nclass=\"math inline\">\\(Y \\le_{p} X\\)</span>，那么X和Y是等价的。</li>\r\n</ul>\r\n<p>基本的规约方法：</p>\r\n<ul>\r\n<li>简单的恒等归约：比如最大独立集和最小点覆盖。</li>\r\n<li>从特殊情况到一般情况：比如 <span class=\"math inline\">\\(点覆盖\r\n\\le_{p} 集合覆盖\\)</span>。<br />\r\n</li>\r\n<li>通过一些小技巧规约。比如 <span class=\"math inline\">\\(3-SAT \\le_{p}\r\n独立集\\)</span></li>\r\n</ul>\r\n<h3 id=\"独立集问题\">独立集问题</h3>\r\n<p>定义：给定一个图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>和一个整数k(V为顶点集，E为边集)，是否有一个V的子集\r\n$S V $使得 <span class=\"math inline\">\\(|S| \\ge\r\nk\\)</span>并且S中的每条边至多有一个顶点在S中？</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/独立集.png\" alt=\"独立集\" />\r\n<figcaption aria-hidden=\"true\">独立集</figcaption>\r\n</figure>\r\n<h3 id=\"点覆盖问题\">点覆盖问题</h3>\r\n<p>定义:给定一个图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>和一个整数k,是否有一个V的子集 $S V\r\n$使得 <span class=\"math inline\">\\(|S| \\le\r\nk\\)</span>并且S中的每条边至少有一个顶点在S中？</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/点覆盖.png\" alt=\"点覆盖\" />\r\n<figcaption aria-hidden=\"true\">点覆盖</figcaption>\r\n</figure>\r\n<p><strong>定理： <span class=\"math inline\">\\(点覆盖 \\equiv\r\n独立集\\)</span></strong></p>\r\n<p>证明如下（简单的恒等规约）：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span> - 令S为任意独立集 -\r\n对任意的边 <span class=\"math inline\">\\((u,v)\\)</span> - S是独立集 <span\r\nclass=\"math inline\">\\(\\Rightarrow u \\notin S\\)</span> 或 $v S u V - S $\r\n或 <span class=\"math inline\">\\(v \\in V-S\\)</span> - 所以 <span\r\nclass=\"math inline\">\\(V-S\\)</span> 是一个点覆盖</p>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span> - 令 <span\r\nclass=\"math inline\">\\(V-S\\)</span>是一个点覆盖 - 对两个顶点 <span\r\nclass=\"math inline\">\\(u \\in S\\)</span> 及 <span class=\"math inline\">\\(v\r\n\\in S\\)</span> - 若 <span class=\"math inline\">\\(V-S\\)</span>\r\n是一个点覆盖,那么 <span class=\"math inline\">\\((u, v) \\notin E\\)</span> -\r\n因此，没有相邻的顶点在 <span class=\"math inline\">\\(S\\)</span> 中 <span\r\nclass=\"math inline\">\\(\\Rightarrow\\)</span> S是独立集</p>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"npnpcnph问题\">NP、NPC、NPH问题</h2>\r\n<p><strong>NP问题</strong>\r\n：能在多项式时间内验证某个猜想答案的正确性，但可能在无法再多项式时间内解决。比如：数独，很容易就确定一个答案是否正确，但确找不到一个公式来描述其规律。</p>\r\n<p><strong>NPC问题</strong>: 需要满足两个条件</p>\r\n<ul>\r\n<li>它是一个NP问题</li>\r\n<li>所有的NP问题都可以规约到NP-complete\r\n<strong>如果</strong>我们给NPC问题找到了一个多项式时间复杂度的算法，那么也就意味着我们给所有的NP问题找到了多项式时间复杂度的算法，从而NP=P，因为P=NP，所以“P对NP问题”就可以被解决。但给NPC问题找一个多项式时间复杂度的算法太难了，所以现在人们普遍相信P≠NP。</li>\r\n</ul>\r\n<p><strong>NPH问题</strong>\r\n：满足上面NPC问题的第二个条件，但不一定要满足第一个条件，所以NPH的范围比HPC更大。</p>\r\n<h2 id=\"多项式规约\">多项式规约</h2>\r\n<p>定义：若问题X 的任意实例可以由下面两条之和解决</p>\r\n<ul>\r\n<li>问题X可以通过多项式时间的基本运算步骤转换为问题Y；</li>\r\n<li>问题X多项式次调用求解问题Y的算法，且问题Y可以在多项式时间内被求解。</li>\r\n</ul>\r\n<p>那么称问题X可以多项式规约到问题Y，记为 $ X _{p} Y\r\n$。需要注意的是，问题X转换为问题Y之后，问题Y的运行时间是建立在问题Y的输入上。</p>\r\n<p>多项式规约的几个性质：</p>\r\n<ul>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p}\r\nY\\)</span>，则若Y能在多项式时间内求解，那么X也能在多项式时间内求解。</li>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p}\r\nY\\)</span>，则若X不能在多项式时间内求解，那么Y也不能在多项式时间内求解。</li>\r\n<li>若 <span class=\"math inline\">\\(X \\le_{p} Y\\)</span> 且 <span\r\nclass=\"math inline\">\\(Y \\le_{p} X\\)</span>，那么X和Y是等价的。</li>\r\n</ul>\r\n<p>基本的规约方法：</p>\r\n<ul>\r\n<li>简单的恒等归约：比如最大独立集和最小点覆盖。</li>\r\n<li>从特殊情况到一般情况：比如 <span class=\"math inline\">\\(点覆盖\r\n\\le_{p} 集合覆盖\\)</span>。<br />\r\n</li>\r\n<li>通过一些小技巧规约。比如 <span class=\"math inline\">\\(3-SAT \\le_{p}\r\n独立集\\)</span></li>\r\n</ul>\r\n<h3 id=\"独立集问题\">独立集问题</h3>\r\n<p>定义：给定一个图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>和一个整数k(V为顶点集，E为边集)，是否有一个V的子集\r\n$S V $使得 <span class=\"math inline\">\\(|S| \\ge\r\nk\\)</span>并且S中的每条边至多有一个顶点在S中？</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/独立集.png\" alt=\"独立集\" />\r\n<figcaption aria-hidden=\"true\">独立集</figcaption>\r\n</figure>\r\n<h3 id=\"点覆盖问题\">点覆盖问题</h3>\r\n<p>定义:给定一个图 <span\r\nclass=\"math inline\">\\(G=(V,E)\\)</span>和一个整数k,是否有一个V的子集 $S V\r\n$使得 <span class=\"math inline\">\\(|S| \\le\r\nk\\)</span>并且S中的每条边至少有一个顶点在S中？</p>\r\n<figure>\r\n<img src=\"/img/多项式规约/点覆盖.png\" alt=\"点覆盖\" />\r\n<figcaption aria-hidden=\"true\">点覆盖</figcaption>\r\n</figure>\r\n<p><strong>定理： <span class=\"math inline\">\\(点覆盖 \\equiv\r\n独立集\\)</span></strong></p>\r\n<p>证明如下（简单的恒等规约）：</p>\r\n<p><span class=\"math inline\">\\(\\Rightarrow\\)</span> - 令S为任意独立集 -\r\n对任意的边 <span class=\"math inline\">\\((u,v)\\)</span> - S是独立集 <span\r\nclass=\"math inline\">\\(\\Rightarrow u \\notin S\\)</span> 或 $v S u V - S $\r\n或 <span class=\"math inline\">\\(v \\in V-S\\)</span> - 所以 <span\r\nclass=\"math inline\">\\(V-S\\)</span> 是一个点覆盖</p>\r\n<p><span class=\"math inline\">\\(\\Leftarrow\\)</span> - 令 <span\r\nclass=\"math inline\">\\(V-S\\)</span>是一个点覆盖 - 对两个顶点 <span\r\nclass=\"math inline\">\\(u \\in S\\)</span> 及 <span class=\"math inline\">\\(v\r\n\\in S\\)</span> - 若 <span class=\"math inline\">\\(V-S\\)</span>\r\n是一个点覆盖,那么 <span class=\"math inline\">\\((u, v) \\notin E\\)</span> -\r\n因此，没有相邻的顶点在 <span class=\"math inline\">\\(S\\)</span> 中 <span\r\nclass=\"math inline\">\\(\\Rightarrow\\)</span> S是独立集</p>\r\n"},{"title":"最大流最小割","math":true,"_content":"\n\n## 最小割\n在图论中，去掉其中所有边能使一张网络流图不再连通（即分成两个子图）的边集称为图的割。一个$ st-cut $即去掉的边把源点s和汇点t划分在两个不同的部分。\n\n![最小割定义](/img/最大流最小割/最小割定义.png)\n\n一般来说，一张图中有多个不同的$st-cut$，如下图便为其中一个 $st-cut$ 。\n\n\n![一个割例子](/img/最大流最小割/一个割例子.png)\n\n\n但是在实际应用中，我们去掉每条边往往都是有代价的，以边的容量作为权值，一个割中去掉的边的权值之和为这个割的值，那么最小割就是这张图上最小的割。\n\n\n\n## 最大流\n为了求解最小割，需要引入最大流的概念。用边的权值表示边的最大流量，一个 $st-flow$ 是从源点s到汇点t的流量。通俗的讲，最大流就是从源点s到汇点t的最大流量。\n\n![最大流](/img/最大流最小割/最大流.png)\n\n\n\n## 求解最大流\n### 贪心算法\n\n- 开始时对每条边e令$f(e)=0$\n- 找到一条从源点s到汇点t的路径 $s \\rightarrow t$ 使路径上的每条边e满足 $f(e)<c(e)$ ,其中 $c(e)$ 为边e的权值\n- $flow = flow + 路径上的流量$\n- 重复上述步骤直至找不到新的路径\n\n\n### Ford-Fulkerson算法\n#### 残留图(Residual Graph)\n在另一个图中，额外构造一个反向边，权值是实际流过该边的流量 $f(e)$ 。\n\n![残余图](/img/最大流最小割/残余图.png)\n\n剩余图有以下性质：\n- **增广路径(Augmenting Path)**:一个增广路径P是从残余图中的一条简单路径 $s \\rightarrow t$\n- 增广路径的容量是该条路径所有边中的最小权值\n\n#### 算法说明\n- 每次找到一条从s到t的增广路径，并调整flow和残留图，不断调整直到没有增广路径\n- 当残留图中不存在从s到t的增广路径时，该图已经达到最大流\n\n#### 例子\n\n初始时没有反向边,此时残留图等于原图\n\n![](/img/最大流最小割/Ford-Fulkerson例子1.png)\n\n从中选取一条增广路径,并更新残留图和原图\n\n![](/img/最大流最小割/Ford-Fulkerson例子2.png)\n\n重复上面的步骤,注意**增广路径一定要从残留图中找**,且可以使用残留图中的反向边.\n\n\n![](/img/最大流最小割/Ford-Fulkerson例子3.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子4.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子5.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子6.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子7.png)\n\n此时,没有新的增广路径,则最大流的值等于流出源点s的流量减去流进s的流量,即 $flow = s_{out} - s_{in}$\n\n## 最大流与最小割的关系\n**最大流最小割定理：最大流=最小割。** 最大流-最小割定理用来证明Ford-Fulkson方法的确达到了最大流.\n\n![最大流最小割定理](/img/最大流最小割/最大流最小割定理.png)\n\n\n证明:\n-  $(i) \\Rightarrow (ii)$ :弱对偶性法则的推论\n-  $(ii) \\Rightarrow (iii)$ :反证法  \n若f是一个最大流,且仍存在增广路径,那么可以让f加上增广路径的流量,与f是一个最大流相悖.故$(ii) \\Rightarrow (iii)$成立\n- $(iii) \\Rightarrow (i)$\n设f是一个流,且没有增广路径,令A等于s的可达顶点集,则\n\n![](/img/最大流最小割/iii到i.png)\n\n\n","source":"_posts/最大流最小割.md","raw":"---\ntitle: 最大流最小割\ntags: 高级算法设计与分析\ncategories: 算法\nmath: true\n---\n\n\n## 最小割\n在图论中，去掉其中所有边能使一张网络流图不再连通（即分成两个子图）的边集称为图的割。一个$ st-cut $即去掉的边把源点s和汇点t划分在两个不同的部分。\n\n![最小割定义](/img/最大流最小割/最小割定义.png)\n\n一般来说，一张图中有多个不同的$st-cut$，如下图便为其中一个 $st-cut$ 。\n\n\n![一个割例子](/img/最大流最小割/一个割例子.png)\n\n\n但是在实际应用中，我们去掉每条边往往都是有代价的，以边的容量作为权值，一个割中去掉的边的权值之和为这个割的值，那么最小割就是这张图上最小的割。\n\n\n\n## 最大流\n为了求解最小割，需要引入最大流的概念。用边的权值表示边的最大流量，一个 $st-flow$ 是从源点s到汇点t的流量。通俗的讲，最大流就是从源点s到汇点t的最大流量。\n\n![最大流](/img/最大流最小割/最大流.png)\n\n\n\n## 求解最大流\n### 贪心算法\n\n- 开始时对每条边e令$f(e)=0$\n- 找到一条从源点s到汇点t的路径 $s \\rightarrow t$ 使路径上的每条边e满足 $f(e)<c(e)$ ,其中 $c(e)$ 为边e的权值\n- $flow = flow + 路径上的流量$\n- 重复上述步骤直至找不到新的路径\n\n\n### Ford-Fulkerson算法\n#### 残留图(Residual Graph)\n在另一个图中，额外构造一个反向边，权值是实际流过该边的流量 $f(e)$ 。\n\n![残余图](/img/最大流最小割/残余图.png)\n\n剩余图有以下性质：\n- **增广路径(Augmenting Path)**:一个增广路径P是从残余图中的一条简单路径 $s \\rightarrow t$\n- 增广路径的容量是该条路径所有边中的最小权值\n\n#### 算法说明\n- 每次找到一条从s到t的增广路径，并调整flow和残留图，不断调整直到没有增广路径\n- 当残留图中不存在从s到t的增广路径时，该图已经达到最大流\n\n#### 例子\n\n初始时没有反向边,此时残留图等于原图\n\n![](/img/最大流最小割/Ford-Fulkerson例子1.png)\n\n从中选取一条增广路径,并更新残留图和原图\n\n![](/img/最大流最小割/Ford-Fulkerson例子2.png)\n\n重复上面的步骤,注意**增广路径一定要从残留图中找**,且可以使用残留图中的反向边.\n\n\n![](/img/最大流最小割/Ford-Fulkerson例子3.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子4.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子5.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子6.png)\n\n![](/img/最大流最小割/Ford-Fulkerson例子7.png)\n\n此时,没有新的增广路径,则最大流的值等于流出源点s的流量减去流进s的流量,即 $flow = s_{out} - s_{in}$\n\n## 最大流与最小割的关系\n**最大流最小割定理：最大流=最小割。** 最大流-最小割定理用来证明Ford-Fulkson方法的确达到了最大流.\n\n![最大流最小割定理](/img/最大流最小割/最大流最小割定理.png)\n\n\n证明:\n-  $(i) \\Rightarrow (ii)$ :弱对偶性法则的推论\n-  $(ii) \\Rightarrow (iii)$ :反证法  \n若f是一个最大流,且仍存在增广路径,那么可以让f加上增广路径的流量,与f是一个最大流相悖.故$(ii) \\Rightarrow (iii)$成立\n- $(iii) \\Rightarrow (i)$\n设f是一个流,且没有增广路径,令A等于s的可达顶点集,则\n\n![](/img/最大流最小割/iii到i.png)\n\n\n","slug":"最大流最小割","published":1,"date":"2022-12-03T04:40:24.747Z","updated":"2022-12-03T16:06:24.584Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clb8pvosy0006zgsg69na7ji0","content":"<h2 id=\"最小割\">最小割</h2>\r\n<p>在图论中，去掉其中所有边能使一张网络流图不再连通（即分成两个子图）的边集称为图的割。一个$\r\nst-cut $即去掉的边把源点s和汇点t划分在两个不同的部分。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最小割定义.png\" alt=\"最小割定义\" />\r\n<figcaption aria-hidden=\"true\">最小割定义</figcaption>\r\n</figure>\r\n<p>一般来说，一张图中有多个不同的<span\r\nclass=\"math inline\">\\(st-cut\\)</span>，如下图便为其中一个 <span\r\nclass=\"math inline\">\\(st-cut\\)</span> 。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/一个割例子.png\" alt=\"一个割例子\" />\r\n<figcaption aria-hidden=\"true\">一个割例子</figcaption>\r\n</figure>\r\n<p>但是在实际应用中，我们去掉每条边往往都是有代价的，以边的容量作为权值，一个割中去掉的边的权值之和为这个割的值，那么最小割就是这张图上最小的割。</p>\r\n<h2 id=\"最大流\">最大流</h2>\r\n<p>为了求解最小割，需要引入最大流的概念。用边的权值表示边的最大流量，一个\r\n<span class=\"math inline\">\\(st-flow\\)</span>\r\n是从源点s到汇点t的流量。通俗的讲，最大流就是从源点s到汇点t的最大流量。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最大流.png\" alt=\"最大流\" />\r\n<figcaption aria-hidden=\"true\">最大流</figcaption>\r\n</figure>\r\n<h2 id=\"求解最大流\">求解最大流</h2>\r\n<h3 id=\"贪心算法\">贪心算法</h3>\r\n<ul>\r\n<li>开始时对每条边e令<span class=\"math inline\">\\(f(e)=0\\)</span></li>\r\n<li>找到一条从源点s到汇点t的路径 <span class=\"math inline\">\\(s\r\n\\rightarrow t\\)</span> 使路径上的每条边e满足 <span\r\nclass=\"math inline\">\\(f(e)&lt;c(e)\\)</span> ,其中 <span\r\nclass=\"math inline\">\\(c(e)\\)</span> 为边e的权值</li>\r\n<li><span class=\"math inline\">\\(flow = flow + 路径上的流量\\)</span></li>\r\n<li>重复上述步骤直至找不到新的路径</li>\r\n</ul>\r\n<h3 id=\"ford-fulkerson算法\">Ford-Fulkerson算法</h3>\r\n<h4 id=\"残留图residual-graph\">残留图(Residual Graph)</h4>\r\n<p>在另一个图中，额外构造一个反向边，权值是实际流过该边的流量 <span\r\nclass=\"math inline\">\\(f(e)\\)</span> 。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/残余图.png\" alt=\"残余图\" />\r\n<figcaption aria-hidden=\"true\">残余图</figcaption>\r\n</figure>\r\n<p>剩余图有以下性质： - <strong>增广路径(Augmenting\r\nPath)</strong>:一个增广路径P是从残余图中的一条简单路径 <span\r\nclass=\"math inline\">\\(s \\rightarrow t\\)</span> -\r\n增广路径的容量是该条路径所有边中的最小权值</p>\r\n<h4 id=\"算法说明\">算法说明</h4>\r\n<ul>\r\n<li>每次找到一条从s到t的增广路径，并调整flow和残留图，不断调整直到没有增广路径</li>\r\n<li>当残留图中不存在从s到t的增广路径时，该图已经达到最大流</li>\r\n</ul>\r\n<h4 id=\"例子\">例子</h4>\r\n<p>初始时没有反向边,此时残留图等于原图</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子1.png\" /></p>\r\n<p>从中选取一条增广路径,并更新残留图和原图</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子2.png\" /></p>\r\n<p>重复上面的步骤,注意<strong>增广路径一定要从残留图中找</strong>,且可以使用残留图中的反向边.</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子3.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子4.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子5.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子6.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子7.png\" /></p>\r\n<p>此时,没有新的增广路径,则最大流的值等于流出源点s的流量减去流进s的流量,即\r\n<span class=\"math inline\">\\(flow = s_{out} - s_{in}\\)</span></p>\r\n<h2 id=\"最大流与最小割的关系\">最大流与最小割的关系</h2>\r\n<p><strong>最大流最小割定理：最大流=最小割。</strong>\r\n最大流-最小割定理用来证明Ford-Fulkson方法的确达到了最大流.</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最大流最小割定理.png\"\r\nalt=\"最大流最小割定理\" />\r\n<figcaption aria-hidden=\"true\">最大流最小割定理</figcaption>\r\n</figure>\r\n<p>证明: - <span class=\"math inline\">\\((i) \\Rightarrow (ii)\\)</span>\r\n:弱对偶性法则的推论 - <span class=\"math inline\">\\((ii) \\Rightarrow\r\n(iii)\\)</span> :反证法<br />\r\n若f是一个最大流,且仍存在增广路径,那么可以让f加上增广路径的流量,与f是一个最大流相悖.故<span\r\nclass=\"math inline\">\\((ii) \\Rightarrow (iii)\\)</span>成立 - <span\r\nclass=\"math inline\">\\((iii) \\Rightarrow (i)\\)</span>\r\n设f是一个流,且没有增广路径,令A等于s的可达顶点集,则</p>\r\n<p><img src=\"/img/最大流最小割/iii到i.png\" /></p>\r\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"最小割\">最小割</h2>\r\n<p>在图论中，去掉其中所有边能使一张网络流图不再连通（即分成两个子图）的边集称为图的割。一个$\r\nst-cut $即去掉的边把源点s和汇点t划分在两个不同的部分。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最小割定义.png\" alt=\"最小割定义\" />\r\n<figcaption aria-hidden=\"true\">最小割定义</figcaption>\r\n</figure>\r\n<p>一般来说，一张图中有多个不同的<span\r\nclass=\"math inline\">\\(st-cut\\)</span>，如下图便为其中一个 <span\r\nclass=\"math inline\">\\(st-cut\\)</span> 。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/一个割例子.png\" alt=\"一个割例子\" />\r\n<figcaption aria-hidden=\"true\">一个割例子</figcaption>\r\n</figure>\r\n<p>但是在实际应用中，我们去掉每条边往往都是有代价的，以边的容量作为权值，一个割中去掉的边的权值之和为这个割的值，那么最小割就是这张图上最小的割。</p>\r\n<h2 id=\"最大流\">最大流</h2>\r\n<p>为了求解最小割，需要引入最大流的概念。用边的权值表示边的最大流量，一个\r\n<span class=\"math inline\">\\(st-flow\\)</span>\r\n是从源点s到汇点t的流量。通俗的讲，最大流就是从源点s到汇点t的最大流量。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最大流.png\" alt=\"最大流\" />\r\n<figcaption aria-hidden=\"true\">最大流</figcaption>\r\n</figure>\r\n<h2 id=\"求解最大流\">求解最大流</h2>\r\n<h3 id=\"贪心算法\">贪心算法</h3>\r\n<ul>\r\n<li>开始时对每条边e令<span class=\"math inline\">\\(f(e)=0\\)</span></li>\r\n<li>找到一条从源点s到汇点t的路径 <span class=\"math inline\">\\(s\r\n\\rightarrow t\\)</span> 使路径上的每条边e满足 <span\r\nclass=\"math inline\">\\(f(e)&lt;c(e)\\)</span> ,其中 <span\r\nclass=\"math inline\">\\(c(e)\\)</span> 为边e的权值</li>\r\n<li><span class=\"math inline\">\\(flow = flow + 路径上的流量\\)</span></li>\r\n<li>重复上述步骤直至找不到新的路径</li>\r\n</ul>\r\n<h3 id=\"ford-fulkerson算法\">Ford-Fulkerson算法</h3>\r\n<h4 id=\"残留图residual-graph\">残留图(Residual Graph)</h4>\r\n<p>在另一个图中，额外构造一个反向边，权值是实际流过该边的流量 <span\r\nclass=\"math inline\">\\(f(e)\\)</span> 。</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/残余图.png\" alt=\"残余图\" />\r\n<figcaption aria-hidden=\"true\">残余图</figcaption>\r\n</figure>\r\n<p>剩余图有以下性质： - <strong>增广路径(Augmenting\r\nPath)</strong>:一个增广路径P是从残余图中的一条简单路径 <span\r\nclass=\"math inline\">\\(s \\rightarrow t\\)</span> -\r\n增广路径的容量是该条路径所有边中的最小权值</p>\r\n<h4 id=\"算法说明\">算法说明</h4>\r\n<ul>\r\n<li>每次找到一条从s到t的增广路径，并调整flow和残留图，不断调整直到没有增广路径</li>\r\n<li>当残留图中不存在从s到t的增广路径时，该图已经达到最大流</li>\r\n</ul>\r\n<h4 id=\"例子\">例子</h4>\r\n<p>初始时没有反向边,此时残留图等于原图</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子1.png\" /></p>\r\n<p>从中选取一条增广路径,并更新残留图和原图</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子2.png\" /></p>\r\n<p>重复上面的步骤,注意<strong>增广路径一定要从残留图中找</strong>,且可以使用残留图中的反向边.</p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子3.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子4.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子5.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子6.png\" /></p>\r\n<p><img src=\"/img/最大流最小割/Ford-Fulkerson例子7.png\" /></p>\r\n<p>此时,没有新的增广路径,则最大流的值等于流出源点s的流量减去流进s的流量,即\r\n<span class=\"math inline\">\\(flow = s_{out} - s_{in}\\)</span></p>\r\n<h2 id=\"最大流与最小割的关系\">最大流与最小割的关系</h2>\r\n<p><strong>最大流最小割定理：最大流=最小割。</strong>\r\n最大流-最小割定理用来证明Ford-Fulkson方法的确达到了最大流.</p>\r\n<figure>\r\n<img src=\"/img/最大流最小割/最大流最小割定理.png\"\r\nalt=\"最大流最小割定理\" />\r\n<figcaption aria-hidden=\"true\">最大流最小割定理</figcaption>\r\n</figure>\r\n<p>证明: - <span class=\"math inline\">\\((i) \\Rightarrow (ii)\\)</span>\r\n:弱对偶性法则的推论 - <span class=\"math inline\">\\((ii) \\Rightarrow\r\n(iii)\\)</span> :反证法<br />\r\n若f是一个最大流,且仍存在增广路径,那么可以让f加上增广路径的流量,与f是一个最大流相悖.故<span\r\nclass=\"math inline\">\\((ii) \\Rightarrow (iii)\\)</span>成立 - <span\r\nclass=\"math inline\">\\((iii) \\Rightarrow (i)\\)</span>\r\n设f是一个流,且没有增广路径,令A等于s的可达顶点集,则</p>\r\n<p><img src=\"/img/最大流最小割/iii到i.png\" /></p>\r\n"},{"title":"红黑树","categorires":"算法","math":true,"_content":"\n\n# 红黑树\n红黑树是一种特化的AVL树（平衡二叉树），都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。 \n\n它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的： 它可以在O(log n)时间内做查找，插入和删除，这里的n 是树中元素的数目。\n\n## 红黑树的性质\n1. 每个节点要么是黑色，要么是红色。\n2. 根节点是黑色。\n3. 每个叶子节点（NIL）是黑色。\n4. 每个红色结点的两个子结点一定都是黑色\n5. 任意一结点到每个叶子结点的路径都包含数量相同的黑结点。（保证这棵树尽量是平衡的。）\n\n由性质5我们可以推出：  \n    性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点。\n\n## 红黑树和AVL的区别\n1. 如果插入一个node引起了树的不平衡，AVL和RB-Tree都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度。\n\n2. 其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。\n\n3. map的实现只是折衷了两者在search、insert以及delete下的效率。总体来说，RB-tree的统计性能是高于AVL的。","source":"_posts/红黑树.md","raw":"---\ntitle: 红黑树\ncategorires: 算法\ntags: 算法\nmath: true\n---\n\n\n# 红黑树\n红黑树是一种特化的AVL树（平衡二叉树），都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。 \n\n它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的： 它可以在O(log n)时间内做查找，插入和删除，这里的n 是树中元素的数目。\n\n## 红黑树的性质\n1. 每个节点要么是黑色，要么是红色。\n2. 根节点是黑色。\n3. 每个叶子节点（NIL）是黑色。\n4. 每个红色结点的两个子结点一定都是黑色\n5. 任意一结点到每个叶子结点的路径都包含数量相同的黑结点。（保证这棵树尽量是平衡的。）\n\n由性质5我们可以推出：  \n    性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点。\n\n## 红黑树和AVL的区别\n1. 如果插入一个node引起了树的不平衡，AVL和RB-Tree都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度。\n\n2. 其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。\n\n3. map的实现只是折衷了两者在search、insert以及delete下的效率。总体来说，RB-tree的统计性能是高于AVL的。","slug":"红黑树","published":1,"date":"2022-12-02T04:29:47.325Z","updated":"2022-12-03T08:10:48.915Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clb8pvosy0007zgsgfdvncuyr","content":"<h1 id=\"红黑树\">红黑树</h1>\r\n<p>红黑树是一种特化的AVL树（平衡二叉树），都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。</p>\r\n<p>它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的：\r\n它可以在O(log n)时间内做查找，插入和删除，这里的n 是树中元素的数目。</p>\r\n<h2 id=\"红黑树的性质\">红黑树的性质</h2>\r\n<ol type=\"1\">\r\n<li>每个节点要么是黑色，要么是红色。</li>\r\n<li>根节点是黑色。</li>\r\n<li>每个叶子节点（NIL）是黑色。</li>\r\n<li>每个红色结点的两个子结点一定都是黑色</li>\r\n<li>任意一结点到每个叶子结点的路径都包含数量相同的黑结点。（保证这棵树尽量是平衡的。）</li>\r\n</ol>\r\n<p>由性质5我们可以推出：<br />\r\n性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点。</p>\r\n<h2 id=\"红黑树和avl的区别\">红黑树和AVL的区别</h2>\r\n<ol type=\"1\">\r\n<li><p>如果插入一个node引起了树的不平衡，AVL和RB-Tree都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度。</p></li>\r\n<li><p>其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。</p></li>\r\n<li><p>map的实现只是折衷了两者在search、insert以及delete下的效率。总体来说，RB-tree的统计性能是高于AVL的。</p></li>\r\n</ol>\r\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"红黑树\">红黑树</h1>\r\n<p>红黑树是一种特化的AVL树（平衡二叉树），都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。</p>\r\n<p>它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的：\r\n它可以在O(log n)时间内做查找，插入和删除，这里的n 是树中元素的数目。</p>\r\n<h2 id=\"红黑树的性质\">红黑树的性质</h2>\r\n<ol type=\"1\">\r\n<li>每个节点要么是黑色，要么是红色。</li>\r\n<li>根节点是黑色。</li>\r\n<li>每个叶子节点（NIL）是黑色。</li>\r\n<li>每个红色结点的两个子结点一定都是黑色</li>\r\n<li>任意一结点到每个叶子结点的路径都包含数量相同的黑结点。（保证这棵树尽量是平衡的。）</li>\r\n</ol>\r\n<p>由性质5我们可以推出：<br />\r\n性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点。</p>\r\n<h2 id=\"红黑树和avl的区别\">红黑树和AVL的区别</h2>\r\n<ol type=\"1\">\r\n<li><p>如果插入一个node引起了树的不平衡，AVL和RB-Tree都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度。</p></li>\r\n<li><p>其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。</p></li>\r\n<li><p>map的实现只是折衷了两者在search、insert以及delete下的效率。总体来说，RB-tree的统计性能是高于AVL的。</p></li>\r\n</ol>\r\n"},{"title":"矩阵分解","_content":"\n<!-- <link href=\"https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css\" rel=\"stylesheet\"> -->\n\n## 正交三角分解(QR分解)\n### 满秩矩阵的 QR 分解\n若 $n$ 阶实矩阵 $A\\in \\mathbb {C}^{n\\times n}$ 满秩，且 $$A = [\\alpha_1,...,\\alpha_n]$$\n\n其中 $\\alpha_1,...,\\alpha_n$ 是 $\\mathbb {C}^{n\\times n}$  中线性无关向量组\n\n**正交化**\n\n令\n\n$$ \\begin{aligned} \\beta_1&=\\alpha_1\\\\ \\beta_2&=\\alpha_2 - \\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1 \\\\ \\vdots \\\\ \\beta_n &= \\alpha_n - \\frac{\\left<\\beta_n,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1-\\cdots-\\frac{\\left<\\beta_{n-1},\\alpha_n\\right>}{\\left<\\beta_{n-1},\\alpha_{n-1}\\right>}\\beta_{n-1} \\end{aligned} $$\n\n变形得 \n\n$$ \\begin{aligned} \\alpha_1 &= \\beta_1\\\\ \\alpha_2 &= \\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1 + \\beta_2\\\\ \\vdots \\\\ \\alpha_n &= \\frac{\\left<\\beta_n,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1-\\cdots-\\frac{\\left<\\beta_{n-1},\\alpha_n\\right>}{\\left<\\beta_{n-1},\\alpha_{n-1}\\right>}\\beta_{n-1} + \\beta_n \\end{aligned} $$\n\n写成矩阵形式\n\n$$ \\begin{aligned} \\begin{bmatrix}\\alpha_1,\\alpha_2,...,\\alpha_n\\end{bmatrix} &= \\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix}\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &\\triangleq B\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix} \\end{aligned} $$\n\n**单位化**\n\n令 \n\n$$ q_1=\\frac{\\beta_1}{||\\beta_1||}\\\\ \\vdots \\\\ q_n = \\frac{\\beta_n}{||\\beta_n||} $$\n\n变形得 \n\n$$ \\beta_1 = q_1||\\beta_1||\\\\ \\vdots \\\\ \\beta_n = q_n ||\\beta_n|| $$\n\n写成矩阵形式 \n\n$$ \\begin{aligned} \\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix} &= \\begin{bmatrix}q_1,q_2,...,q_n\\end{bmatrix}\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\\\ &\\triangleq Q\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix} \\end{aligned} $$\n\n综上，结合正交化和单位化可得 \n\n$$ \\begin{aligned} A &= B\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &=Q\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &=Q\\begin{bmatrix}||\\beta_1||&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&||\\beta_2||&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\\\ &\\triangleq QR \\end{aligned} $$\n\n**QR 分解定理** : $A\\in \\mathbb {C}^{n\\times n}$ ,则存在酉矩阵 $Q$ 和正线上三角阵 $R$ ，使 $$A=QR$$\n\n且分解唯一\n\n### QR 分解的求法\n1. 取矩阵 $A=(A_1,A_2,...,A_n)$ 的列向量，进行 **Schmidt 标准正交化**,得 $v_1,v_2,...,v_n$ ，有 $$Q=(v_1,v_2,...,v_n)$$\n2. 再由 $R=Q^HA$ 得到 $R$ , 于是 $A=QR$\n\n\n## 矩阵的满秩分解\n设 $A\\in \\mathbb {C}_r^{m\\times n}$，则存在 $B\\in \\mathbb {C}_r^{m\\times r}, C\\in \\mathbb {C}_r^{r\\times n}$，满足\n$$ A = BC $$\n\n$\\mathbb {C}_r$ 表示矩阵的秩为 $r$\n\n实际上上述定理用文字描述就是，一个亏秩的矩阵可以分解成一个列满秩与行满秩矩阵的乘积\n\n证明：因为 $rank (A)=r$，所以一定可以找到与 $A$ 相似的一个矩阵\n\n$$ A \\simeq \\begin{bmatrix}E_r&0_{r\\times (n-r)}\\\\0_{(m-r)\\times r}&0_{(m-r)\\times (n-r)}\\end{bmatrix}=\\begin{bmatrix}E_r\\\\0_{(m-r)\\times r}\\end{bmatrix}\\begin{bmatrix}E_r&0_{r\\times (n-r)}\\end{bmatrix} $$\n\n因此存在两个可逆矩阵 $P,Q$，使 $PAQ=\\begin {bmatrix} E_r&0\\\\0&0\\end {bmatrix}$，则\n\n$$ \\begin{aligned} A &= P^{-1}\\begin{bmatrix}E_r\\\\0\\end{bmatrix}\\begin{bmatrix}E_r&0\\end{bmatrix}Q^{-1}\\\\ &\\triangleq BC \\end{aligned} $$\n\n因为 $P^{-1}$ 是可逆矩阵，$\\begin {bmatrix} E_r\\\\0\\end {bmatrix}$ 是一个列满秩矩阵，所以 $B=P^{-1}\\begin {bmatrix} E_r\\\\0\\end {bmatrix}$ 仍是一个列满秩矩阵；同理，$C=\\begin {bmatrix} E_r&0\\end {bmatrix} Q^{-1}$ 是一个行满秩矩阵\n\n### 矩阵满秩分解的计算\n如何在给定矩阵 $A$ 的情况下，求出矩阵 $B,C$ 呢？\n\n设\n\n$$ A = [\\alpha_1,\\alpha_2,...,\\alpha_n]\\\\ B = [\\beta_1,\\beta_2,...,\\beta_r]$$\n\n其中 \\beta_1,...,\\beta_r 线性无关 \n\n所以 \n$$ \\begin{aligned} &A=BC\\\\ &\\Rightarrow[\\alpha_1,\\alpha_2,...,\\alpha_n]=[\\beta_1,...,\\beta_r]\\begin{bmatrix}c_{11}&\\cdots &c_{1n}\\\\\\vdots &\\ddots&\\vdots\\\\c_{r1}&\\cdots &c_{rn}\\end{bmatrix} \\end{aligned} $$\n\n实际上我们可以取 $\\beta_1,...,\\beta_r$ 为 $\\alpha_1,...,\\alpha_n$ 的一个极大线性无关组，因此 $B$ 就是矩阵 $A$ 列向量组的一个极大线性无关组，$C$ 就是用该线性无关组去表示 $A$ 时的系数\n\n#### 例 1\n\n求矩阵 $A=\\begin {bmatrix} 1&4&-1&5&6\\\\2&0&0&0&-14\\\\-1&2&-4&0&1\\\\2&6&-5&5&-7\\end {bmatrix}$ 的满秩分解\n\n**解**：对矩阵 $A$ 只作初等行变换\n$$ A=\\begin{bmatrix}1&4&-1&5&6\\\\2&0&0&0&-14\\\\-1&2&-4&0&1\\\\2&6&-5&5&-7\\end{bmatrix}\\to ···\\to\\begin{bmatrix}1&0&0&0&-7\\\\0&1&0&\\frac{10}{7}&\\frac{29}{7}\\\\0&0&1&\\frac{5}{7}&\\frac{25}{7}\\\\0&0&0&0&0\\end{bmatrix} $$\n\n$A$ 的秩为 3，且前三个列向量线性无关，故\n$$ B = \\begin{bmatrix}1&4&-1\\\\2&0&0\\\\-1&2&-4\\\\2&6&-5\\end{bmatrix}，C=\\begin{bmatrix}1&0&0&0&-7\\\\0&1&0&\\frac{10}{7}&\\frac{29}{7}\\\\0&0&1&\\frac{5}{7}&\\frac{25}{7}\\end{bmatrix} $$\n\n#### 例 2\n求矩阵 $A=\\begin {bmatrix} 2&1&-2&3&1\\\\2&5&-1&4&1\\\\1&3&-1&2&1\\end {bmatrix}$ 的满秩分解\n\n**解**：对矩阵 $A$ 只作初等行变换\n\n$$ A=\\begin{bmatrix}2&1&-2&3&1\\\\2&5&-1&4&1\\\\1&3&-1&2&1\\end{bmatrix}\\to ···\\to \\begin{bmatrix}1&0&0&\\frac{8}{5}&-\\frac{2}{5}\\\\0&1&0&\\frac{1}{5}&\\frac{1}{5}\\\\0&0&1&\\frac{1}{5}&-\\frac{4}{5}\\end{bmatrix} $$\n\n$A$ 的秩为 3，且前三个列向量线性无关，故\n$$ B = \\begin{bmatrix}2&1&-2\\\\2&5&-1\\\\1&3&-1\\end{bmatrix},C = \\begin{bmatrix}1&0&0&\\frac{8}{5}&-\\frac{2}{5}\\\\0&1&0&\\frac{1}{5}&\\frac{1}{5}\\\\0&0&1&\\frac{1}{5}&-\\frac{4}{5}\\end{bmatrix} $$\n\n## 矩阵的LU分解\nLU 分解（LU Decomposition）是矩阵分解的一种，可以将一个矩阵分解为一个单位下三角矩阵和一个上三角矩阵的乘积，以四阶矩阵为例\n$$ L = \\begin{bmatrix}1&0&0&0\\\\*&1&0&0\\\\*&*&1&0\\\\*&*&*&1\\end{bmatrix}, U=\\begin{bmatrix}*&*&*&*\\\\0&*&*&*\\\\0&0&*&*\\\\0&0&0&*\\end{bmatrix} $$\n\nLU 矩阵是否一定存在？答案是否，具体看下面的例子\n\n设 $\\begin {bmatrix} 0&1\\\\1&0\\end {bmatrix}=\\begin {bmatrix} a&0\\\\b&c\\end {bmatrix}\\begin {bmatrix} l&m\\\\0&n\\end {bmatrix}$，则应该满足如下 4 个式子\n\n$$ \\begin{cases} al=0\\\\ am=1\\\\ bl=1\\\\ bm+cn=0 \\end{cases} $$\n\n由 $al=0$ 得 $a=0$ 或 $l=0$，但实际上这两种情况带入上面的式子都会推出矛盾，因此不是所有情况 LU 分解都存在\n\n**LU 分解定理** ：设 $A\\in \\mathbb {C}_n^{n\\times n}$，$A$ 有唯一的 LU 分解 $\\Leftrightarrow A$ 的各阶顺序主子式 $\\Delta k \\neq 0,\\ k=1,2...,n$\n\n$k$ 阶顺序主子式指的是矩阵左上角 $k\\times k$ 个元素组成的行列式\n\n将矩阵 $A$ 分解为 $L$ 和 $U$ 之后，解方程组 $Ax=b$ 就变得简单了，因为 $A=LU$，所以 $(LU) x=b\\Rightarrow L (Ux)=b\\Rightarrow \\begin {cases} Ly=b\\\\Ux=y\\end {cases}$\n\n所以 $x=U^{-1} y=U^{-1} L^{-1} b$\n\n### LU 矩阵的求法\n实际上 LU 矩阵有非常多的求法，这里列举一种比较简单的待定系数法\n\n设 $A = \\begin {bmatrix} 2&3&4\\\\1&1&9\\\\1&2&-6\\end {bmatrix}$，求矩阵 $A$ 的 LU 分解矩阵 $L$ 和 $U$\n\n**解**：令\n$$ L=\\begin{bmatrix}1&0&0\\\\l_1&1&0\\\\l_2&l_3&1\\end{bmatrix},U = \\begin{bmatrix}u_1&u_2&u_3\\\\0&u_4&u_5\\\\0&0&u_6\\end{bmatrix} $$\n\n由于 $A=LU$，所以有\n\n$$ \\begin{cases} u_1=2\\\\ u_2=3\\\\ u_3=4\\\\ l_1u_1=1\\\\ l_1u_2+u_4=1\\\\ l_1u_3+u_5=9\\\\ l_2u_1=1\\\\ l_2u_2+l_3u_4=2\\\\ l_2u_3+l_3u_5+u_6=-6 \\end{cases} $$\n\n上面的方程组非常容易解，最后求出\n\n$$ L = \\begin{bmatrix}1&0&0\\\\\\frac{1}{2}&1&0\\\\\\frac{1}{2}&-1&1\\end{bmatrix},U=\\begin{bmatrix}2&3&4\\\\0&-\\frac{1}{2}&7\\\\0&0&-1\\end{bmatrix} $$\n\n","source":"_posts/矩阵分解.md","raw":"---\ntitle: 矩阵分解\ncategories: [数学， 矩阵论]\ntags: 矩阵论\n---\n\n<!-- <link href=\"https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css\" rel=\"stylesheet\"> -->\n\n## 正交三角分解(QR分解)\n### 满秩矩阵的 QR 分解\n若 $n$ 阶实矩阵 $A\\in \\mathbb {C}^{n\\times n}$ 满秩，且 $$A = [\\alpha_1,...,\\alpha_n]$$\n\n其中 $\\alpha_1,...,\\alpha_n$ 是 $\\mathbb {C}^{n\\times n}$  中线性无关向量组\n\n**正交化**\n\n令\n\n$$ \\begin{aligned} \\beta_1&=\\alpha_1\\\\ \\beta_2&=\\alpha_2 - \\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1 \\\\ \\vdots \\\\ \\beta_n &= \\alpha_n - \\frac{\\left<\\beta_n,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1-\\cdots-\\frac{\\left<\\beta_{n-1},\\alpha_n\\right>}{\\left<\\beta_{n-1},\\alpha_{n-1}\\right>}\\beta_{n-1} \\end{aligned} $$\n\n变形得 \n\n$$ \\begin{aligned} \\alpha_1 &= \\beta_1\\\\ \\alpha_2 &= \\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1 + \\beta_2\\\\ \\vdots \\\\ \\alpha_n &= \\frac{\\left<\\beta_n,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\beta_1-\\cdots-\\frac{\\left<\\beta_{n-1},\\alpha_n\\right>}{\\left<\\beta_{n-1},\\alpha_{n-1}\\right>}\\beta_{n-1} + \\beta_n \\end{aligned} $$\n\n写成矩阵形式\n\n$$ \\begin{aligned} \\begin{bmatrix}\\alpha_1,\\alpha_2,...,\\alpha_n\\end{bmatrix} &= \\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix}\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &\\triangleq B\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix} \\end{aligned} $$\n\n**单位化**\n\n令 \n\n$$ q_1=\\frac{\\beta_1}{||\\beta_1||}\\\\ \\vdots \\\\ q_n = \\frac{\\beta_n}{||\\beta_n||} $$\n\n变形得 \n\n$$ \\beta_1 = q_1||\\beta_1||\\\\ \\vdots \\\\ \\beta_n = q_n ||\\beta_n|| $$\n\n写成矩阵形式 \n\n$$ \\begin{aligned} \\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix} &= \\begin{bmatrix}q_1,q_2,...,q_n\\end{bmatrix}\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\\\ &\\triangleq Q\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix} \\end{aligned} $$\n\n综上，结合正交化和单位化可得 \n\n$$ \\begin{aligned} A &= B\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &=Q\\begin{bmatrix}||\\beta_1||&0&\\cdots &0\\\\0&||\\beta_2||&\\cdots&0\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\begin{bmatrix}1&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&1&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& 1\\end{bmatrix}\\\\ &=Q\\begin{bmatrix}||\\beta_1||&\\frac{\\left<\\beta_1,\\alpha_1\\right>}{\\left<\\beta_1,\\beta_1\\right>}&\\cdots &\\frac{\\left<\\beta_1,\\alpha_n\\right>}{\\left<\\beta_1,\\beta_1\\right>}\\\\0&||\\beta_2||&\\cdots&\\frac{\\left<\\beta_2,\\alpha_n\\right>}{\\left<\\beta_2,\\beta_2\\right>}\\\\ &&\\ddots\\\\0&&\\cdots& ||\\beta_n||\\end{bmatrix}\\\\ &\\triangleq QR \\end{aligned} $$\n\n**QR 分解定理** : $A\\in \\mathbb {C}^{n\\times n}$ ,则存在酉矩阵 $Q$ 和正线上三角阵 $R$ ，使 $$A=QR$$\n\n且分解唯一\n\n### QR 分解的求法\n1. 取矩阵 $A=(A_1,A_2,...,A_n)$ 的列向量，进行 **Schmidt 标准正交化**,得 $v_1,v_2,...,v_n$ ，有 $$Q=(v_1,v_2,...,v_n)$$\n2. 再由 $R=Q^HA$ 得到 $R$ , 于是 $A=QR$\n\n\n## 矩阵的满秩分解\n设 $A\\in \\mathbb {C}_r^{m\\times n}$，则存在 $B\\in \\mathbb {C}_r^{m\\times r}, C\\in \\mathbb {C}_r^{r\\times n}$，满足\n$$ A = BC $$\n\n$\\mathbb {C}_r$ 表示矩阵的秩为 $r$\n\n实际上上述定理用文字描述就是，一个亏秩的矩阵可以分解成一个列满秩与行满秩矩阵的乘积\n\n证明：因为 $rank (A)=r$，所以一定可以找到与 $A$ 相似的一个矩阵\n\n$$ A \\simeq \\begin{bmatrix}E_r&0_{r\\times (n-r)}\\\\0_{(m-r)\\times r}&0_{(m-r)\\times (n-r)}\\end{bmatrix}=\\begin{bmatrix}E_r\\\\0_{(m-r)\\times r}\\end{bmatrix}\\begin{bmatrix}E_r&0_{r\\times (n-r)}\\end{bmatrix} $$\n\n因此存在两个可逆矩阵 $P,Q$，使 $PAQ=\\begin {bmatrix} E_r&0\\\\0&0\\end {bmatrix}$，则\n\n$$ \\begin{aligned} A &= P^{-1}\\begin{bmatrix}E_r\\\\0\\end{bmatrix}\\begin{bmatrix}E_r&0\\end{bmatrix}Q^{-1}\\\\ &\\triangleq BC \\end{aligned} $$\n\n因为 $P^{-1}$ 是可逆矩阵，$\\begin {bmatrix} E_r\\\\0\\end {bmatrix}$ 是一个列满秩矩阵，所以 $B=P^{-1}\\begin {bmatrix} E_r\\\\0\\end {bmatrix}$ 仍是一个列满秩矩阵；同理，$C=\\begin {bmatrix} E_r&0\\end {bmatrix} Q^{-1}$ 是一个行满秩矩阵\n\n### 矩阵满秩分解的计算\n如何在给定矩阵 $A$ 的情况下，求出矩阵 $B,C$ 呢？\n\n设\n\n$$ A = [\\alpha_1,\\alpha_2,...,\\alpha_n]\\\\ B = [\\beta_1,\\beta_2,...,\\beta_r]$$\n\n其中 \\beta_1,...,\\beta_r 线性无关 \n\n所以 \n$$ \\begin{aligned} &A=BC\\\\ &\\Rightarrow[\\alpha_1,\\alpha_2,...,\\alpha_n]=[\\beta_1,...,\\beta_r]\\begin{bmatrix}c_{11}&\\cdots &c_{1n}\\\\\\vdots &\\ddots&\\vdots\\\\c_{r1}&\\cdots &c_{rn}\\end{bmatrix} \\end{aligned} $$\n\n实际上我们可以取 $\\beta_1,...,\\beta_r$ 为 $\\alpha_1,...,\\alpha_n$ 的一个极大线性无关组，因此 $B$ 就是矩阵 $A$ 列向量组的一个极大线性无关组，$C$ 就是用该线性无关组去表示 $A$ 时的系数\n\n#### 例 1\n\n求矩阵 $A=\\begin {bmatrix} 1&4&-1&5&6\\\\2&0&0&0&-14\\\\-1&2&-4&0&1\\\\2&6&-5&5&-7\\end {bmatrix}$ 的满秩分解\n\n**解**：对矩阵 $A$ 只作初等行变换\n$$ A=\\begin{bmatrix}1&4&-1&5&6\\\\2&0&0&0&-14\\\\-1&2&-4&0&1\\\\2&6&-5&5&-7\\end{bmatrix}\\to ···\\to\\begin{bmatrix}1&0&0&0&-7\\\\0&1&0&\\frac{10}{7}&\\frac{29}{7}\\\\0&0&1&\\frac{5}{7}&\\frac{25}{7}\\\\0&0&0&0&0\\end{bmatrix} $$\n\n$A$ 的秩为 3，且前三个列向量线性无关，故\n$$ B = \\begin{bmatrix}1&4&-1\\\\2&0&0\\\\-1&2&-4\\\\2&6&-5\\end{bmatrix}，C=\\begin{bmatrix}1&0&0&0&-7\\\\0&1&0&\\frac{10}{7}&\\frac{29}{7}\\\\0&0&1&\\frac{5}{7}&\\frac{25}{7}\\end{bmatrix} $$\n\n#### 例 2\n求矩阵 $A=\\begin {bmatrix} 2&1&-2&3&1\\\\2&5&-1&4&1\\\\1&3&-1&2&1\\end {bmatrix}$ 的满秩分解\n\n**解**：对矩阵 $A$ 只作初等行变换\n\n$$ A=\\begin{bmatrix}2&1&-2&3&1\\\\2&5&-1&4&1\\\\1&3&-1&2&1\\end{bmatrix}\\to ···\\to \\begin{bmatrix}1&0&0&\\frac{8}{5}&-\\frac{2}{5}\\\\0&1&0&\\frac{1}{5}&\\frac{1}{5}\\\\0&0&1&\\frac{1}{5}&-\\frac{4}{5}\\end{bmatrix} $$\n\n$A$ 的秩为 3，且前三个列向量线性无关，故\n$$ B = \\begin{bmatrix}2&1&-2\\\\2&5&-1\\\\1&3&-1\\end{bmatrix},C = \\begin{bmatrix}1&0&0&\\frac{8}{5}&-\\frac{2}{5}\\\\0&1&0&\\frac{1}{5}&\\frac{1}{5}\\\\0&0&1&\\frac{1}{5}&-\\frac{4}{5}\\end{bmatrix} $$\n\n## 矩阵的LU分解\nLU 分解（LU Decomposition）是矩阵分解的一种，可以将一个矩阵分解为一个单位下三角矩阵和一个上三角矩阵的乘积，以四阶矩阵为例\n$$ L = \\begin{bmatrix}1&0&0&0\\\\*&1&0&0\\\\*&*&1&0\\\\*&*&*&1\\end{bmatrix}, U=\\begin{bmatrix}*&*&*&*\\\\0&*&*&*\\\\0&0&*&*\\\\0&0&0&*\\end{bmatrix} $$\n\nLU 矩阵是否一定存在？答案是否，具体看下面的例子\n\n设 $\\begin {bmatrix} 0&1\\\\1&0\\end {bmatrix}=\\begin {bmatrix} a&0\\\\b&c\\end {bmatrix}\\begin {bmatrix} l&m\\\\0&n\\end {bmatrix}$，则应该满足如下 4 个式子\n\n$$ \\begin{cases} al=0\\\\ am=1\\\\ bl=1\\\\ bm+cn=0 \\end{cases} $$\n\n由 $al=0$ 得 $a=0$ 或 $l=0$，但实际上这两种情况带入上面的式子都会推出矛盾，因此不是所有情况 LU 分解都存在\n\n**LU 分解定理** ：设 $A\\in \\mathbb {C}_n^{n\\times n}$，$A$ 有唯一的 LU 分解 $\\Leftrightarrow A$ 的各阶顺序主子式 $\\Delta k \\neq 0,\\ k=1,2...,n$\n\n$k$ 阶顺序主子式指的是矩阵左上角 $k\\times k$ 个元素组成的行列式\n\n将矩阵 $A$ 分解为 $L$ 和 $U$ 之后，解方程组 $Ax=b$ 就变得简单了，因为 $A=LU$，所以 $(LU) x=b\\Rightarrow L (Ux)=b\\Rightarrow \\begin {cases} Ly=b\\\\Ux=y\\end {cases}$\n\n所以 $x=U^{-1} y=U^{-1} L^{-1} b$\n\n### LU 矩阵的求法\n实际上 LU 矩阵有非常多的求法，这里列举一种比较简单的待定系数法\n\n设 $A = \\begin {bmatrix} 2&3&4\\\\1&1&9\\\\1&2&-6\\end {bmatrix}$，求矩阵 $A$ 的 LU 分解矩阵 $L$ 和 $U$\n\n**解**：令\n$$ L=\\begin{bmatrix}1&0&0\\\\l_1&1&0\\\\l_2&l_3&1\\end{bmatrix},U = \\begin{bmatrix}u_1&u_2&u_3\\\\0&u_4&u_5\\\\0&0&u_6\\end{bmatrix} $$\n\n由于 $A=LU$，所以有\n\n$$ \\begin{cases} u_1=2\\\\ u_2=3\\\\ u_3=4\\\\ l_1u_1=1\\\\ l_1u_2+u_4=1\\\\ l_1u_3+u_5=9\\\\ l_2u_1=1\\\\ l_2u_2+l_3u_4=2\\\\ l_2u_3+l_3u_5+u_6=-6 \\end{cases} $$\n\n上面的方程组非常容易解，最后求出\n\n$$ L = \\begin{bmatrix}1&0&0\\\\\\frac{1}{2}&1&0\\\\\\frac{1}{2}&-1&1\\end{bmatrix},U=\\begin{bmatrix}2&3&4\\\\0&-\\frac{1}{2}&7\\\\0&0&-1\\end{bmatrix} $$\n\n","slug":"矩阵分解","published":1,"date":"2022-12-03T13:15:58.658Z","updated":"2022-12-04T01:45:40.614Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clb8pvosz0008zgsg75dy67w4","content":"<!-- <link href=\"https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css\" rel=\"stylesheet\"> -->\r\n<h2 id=\"正交三角分解qr分解\">正交三角分解(QR分解)</h2>\r\n<h3 id=\"满秩矩阵的-qr-分解\">满秩矩阵的 QR 分解</h3>\r\n<p>若 <span class=\"math inline\">\\(n\\)</span> 阶实矩阵 <span\r\nclass=\"math inline\">\\(A\\in \\mathbb {C}^{n\\times n}\\)</span> 满秩，且\r\n<span class=\"math display\">\\[A = [\\alpha_1,...,\\alpha_n]\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(\\alpha_1,...,\\alpha_n\\)</span> 是\r\n<span class=\"math inline\">\\(\\mathbb {C}^{n\\times n}\\)</span>\r\n中线性无关向量组</p>\r\n<p><strong>正交化</strong></p>\r\n<p>令</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} \\beta_1&amp;=\\alpha_1\\\\\r\n\\beta_2&amp;=\\alpha_2 -\r\n\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1\r\n\\\\ \\vdots \\\\ \\beta_n &amp;= \\alpha_n -\r\n\\frac{\\left&lt;\\beta_n,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1-\\cdots-\\frac{\\left&lt;\\beta_{n-1},\\alpha_n\\right&gt;}{\\left&lt;\\beta_{n-1},\\alpha_{n-1}\\right&gt;}\\beta_{n-1}\r\n\\end{aligned} \\]</span></p>\r\n<p>变形得</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} \\alpha_1 &amp;=\r\n\\beta_1\\\\ \\alpha_2 &amp;=\r\n\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1\r\n+ \\beta_2\\\\ \\vdots \\\\ \\alpha_n &amp;=\r\n\\frac{\\left&lt;\\beta_n,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1-\\cdots-\\frac{\\left&lt;\\beta_{n-1},\\alpha_n\\right&gt;}{\\left&lt;\\beta_{n-1},\\alpha_{n-1}\\right&gt;}\\beta_{n-1}\r\n+ \\beta_n \\end{aligned} \\]</span></p>\r\n<p>写成矩阵形式</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned}\r\n\\begin{bmatrix}\\alpha_1,\\alpha_2,...,\\alpha_n\\end{bmatrix} &amp;=\r\n\\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix}\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;\\triangleq\r\nB\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix} \\end{aligned}\r\n\\]</span></p>\r\n<p><strong>单位化</strong></p>\r\n<p>令</p>\r\n<p><span class=\"math display\">\\[ q_1=\\frac{\\beta_1}{||\\beta_1||}\\\\\r\n\\vdots \\\\ q_n = \\frac{\\beta_n}{||\\beta_n||} \\]</span></p>\r\n<p>变形得</p>\r\n<p><span class=\"math display\">\\[ \\beta_1 = q_1||\\beta_1||\\\\ \\vdots \\\\\r\n\\beta_n = q_n ||\\beta_n|| \\]</span></p>\r\n<p>写成矩阵形式</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned}\r\n\\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix} &amp;=\r\n\\begin{bmatrix}q_1,q_2,...,q_n\\end{bmatrix}\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\\\\\r\n&amp;\\triangleq Q\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\r\n\\end{aligned} \\]</span></p>\r\n<p>综上，结合正交化和单位化可得</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} A &amp;=\r\nB\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;=Q\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp;\r\n||\\beta_n||\\end{bmatrix}\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;=Q\\begin{bmatrix}||\\beta_1||&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\\\\\r\n&amp;\\triangleq QR \\end{aligned} \\]</span></p>\r\n<p><strong>QR 分解定理</strong> : <span class=\"math inline\">\\(A\\in\r\n\\mathbb {C}^{n\\times n}\\)</span> ,则存在酉矩阵 <span\r\nclass=\"math inline\">\\(Q\\)</span> 和正线上三角阵 <span\r\nclass=\"math inline\">\\(R\\)</span> ，使 <span\r\nclass=\"math display\">\\[A=QR\\]</span></p>\r\n<p>且分解唯一</p>\r\n<h3 id=\"qr-分解的求法\">QR 分解的求法</h3>\r\n<ol type=\"1\">\r\n<li>取矩阵 <span class=\"math inline\">\\(A=(A_1,A_2,...,A_n)\\)</span>\r\n的列向量，进行 <strong>Schmidt 标准正交化</strong>,得 <span\r\nclass=\"math inline\">\\(v_1,v_2,...,v_n\\)</span> ，有 <span\r\nclass=\"math display\">\\[Q=(v_1,v_2,...,v_n)\\]</span></li>\r\n<li>再由 <span class=\"math inline\">\\(R=Q^HA\\)</span> 得到 <span\r\nclass=\"math inline\">\\(R\\)</span> , 于是 <span\r\nclass=\"math inline\">\\(A=QR\\)</span></li>\r\n</ol>\r\n<h2 id=\"矩阵的满秩分解\">矩阵的满秩分解</h2>\r\n<p>设 <span class=\"math inline\">\\(A\\in \\mathbb {C}_r^{m\\times\r\nn}\\)</span>，则存在 <span class=\"math inline\">\\(B\\in \\mathbb\r\n{C}_r^{m\\times r}, C\\in \\mathbb {C}_r^{r\\times n}\\)</span>，满足 <span\r\nclass=\"math display\">\\[ A = BC \\]</span></p>\r\n<p><span class=\"math inline\">\\(\\mathbb {C}_r\\)</span> 表示矩阵的秩为\r\n<span class=\"math inline\">\\(r\\)</span></p>\r\n<p>实际上上述定理用文字描述就是，一个亏秩的矩阵可以分解成一个列满秩与行满秩矩阵的乘积</p>\r\n<p>证明：因为 <span class=\"math inline\">\\(rank\r\n(A)=r\\)</span>，所以一定可以找到与 <span\r\nclass=\"math inline\">\\(A\\)</span> 相似的一个矩阵</p>\r\n<p><span class=\"math display\">\\[ A \\simeq\r\n\\begin{bmatrix}E_r&amp;0_{r\\times (n-r)}\\\\0_{(m-r)\\times\r\nr}&amp;0_{(m-r)\\times\r\n(n-r)}\\end{bmatrix}=\\begin{bmatrix}E_r\\\\0_{(m-r)\\times\r\nr}\\end{bmatrix}\\begin{bmatrix}E_r&amp;0_{r\\times (n-r)}\\end{bmatrix}\r\n\\]</span></p>\r\n<p>因此存在两个可逆矩阵 <span class=\"math inline\">\\(P,Q\\)</span>，使\r\n<span class=\"math inline\">\\(PAQ=\\begin {bmatrix} E_r&amp;0\\\\0&amp;0\\end\r\n{bmatrix}\\)</span>，则</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} A &amp;=\r\nP^{-1}\\begin{bmatrix}E_r\\\\0\\end{bmatrix}\\begin{bmatrix}E_r&amp;0\\end{bmatrix}Q^{-1}\\\\\r\n&amp;\\triangleq BC \\end{aligned} \\]</span></p>\r\n<p>因为 <span class=\"math inline\">\\(P^{-1}\\)</span> 是可逆矩阵，<span\r\nclass=\"math inline\">\\(\\begin {bmatrix} E_r\\\\0\\end {bmatrix}\\)</span>\r\n是一个列满秩矩阵，所以 <span class=\"math inline\">\\(B=P^{-1}\\begin\r\n{bmatrix} E_r\\\\0\\end {bmatrix}\\)</span> 仍是一个列满秩矩阵；同理，<span\r\nclass=\"math inline\">\\(C=\\begin {bmatrix} E_r&amp;0\\end {bmatrix}\r\nQ^{-1}\\)</span> 是一个行满秩矩阵</p>\r\n<h3 id=\"矩阵满秩分解的计算\">矩阵满秩分解的计算</h3>\r\n<p>如何在给定矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n的情况下，求出矩阵 <span class=\"math inline\">\\(B,C\\)</span> 呢？</p>\r\n<p>设</p>\r\n<p><span class=\"math display\">\\[ A = [\\alpha_1,\\alpha_2,...,\\alpha_n]\\\\\r\nB = [\\beta_1,\\beta_2,...,\\beta_r]\\]</span></p>\r\n<p>其中 _1,...,_r 线性无关</p>\r\n<p>所以 <span class=\"math display\">\\[ \\begin{aligned} &amp;A=BC\\\\\r\n&amp;\\Rightarrow[\\alpha_1,\\alpha_2,...,\\alpha_n]=[\\beta_1,...,\\beta_r]\\begin{bmatrix}c_{11}&amp;\\cdots\r\n&amp;c_{1n}\\\\\\vdots &amp;\\ddots&amp;\\vdots\\\\c_{r1}&amp;\\cdots\r\n&amp;c_{rn}\\end{bmatrix} \\end{aligned} \\]</span></p>\r\n<p>实际上我们可以取 <span\r\nclass=\"math inline\">\\(\\beta_1,...,\\beta_r\\)</span> 为 <span\r\nclass=\"math inline\">\\(\\alpha_1,...,\\alpha_n\\)</span>\r\n的一个极大线性无关组，因此 <span class=\"math inline\">\\(B\\)</span>\r\n就是矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n列向量组的一个极大线性无关组，<span class=\"math inline\">\\(C\\)</span>\r\n就是用该线性无关组去表示 <span class=\"math inline\">\\(A\\)</span>\r\n时的系数</p>\r\n<h4 id=\"例-1\">例 1</h4>\r\n<p>求矩阵 <span class=\"math inline\">\\(A=\\begin {bmatrix}\r\n1&amp;4&amp;-1&amp;5&amp;6\\\\2&amp;0&amp;0&amp;0&amp;-14\\\\-1&amp;2&amp;-4&amp;0&amp;1\\\\2&amp;6&amp;-5&amp;5&amp;-7\\end\r\n{bmatrix}\\)</span> 的满秩分解</p>\r\n<p><strong>解</strong>：对矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n只作初等行变换 <span class=\"math display\">\\[\r\nA=\\begin{bmatrix}1&amp;4&amp;-1&amp;5&amp;6\\\\2&amp;0&amp;0&amp;0&amp;-14\\\\-1&amp;2&amp;-4&amp;0&amp;1\\\\2&amp;6&amp;-5&amp;5&amp;-7\\end{bmatrix}\\to\r\n···\\to\\begin{bmatrix}1&amp;0&amp;0&amp;0&amp;-7\\\\0&amp;1&amp;0&amp;\\frac{10}{7}&amp;\\frac{29}{7}\\\\0&amp;0&amp;1&amp;\\frac{5}{7}&amp;\\frac{25}{7}\\\\0&amp;0&amp;0&amp;0&amp;0\\end{bmatrix}\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(A\\)</span> 的秩为\r\n3，且前三个列向量线性无关，故 <span class=\"math display\">\\[ B =\r\n\\begin{bmatrix}1&amp;4&amp;-1\\\\2&amp;0&amp;0\\\\-1&amp;2&amp;-4\\\\2&amp;6&amp;-5\\end{bmatrix}，C=\\begin{bmatrix}1&amp;0&amp;0&amp;0&amp;-7\\\\0&amp;1&amp;0&amp;\\frac{10}{7}&amp;\\frac{29}{7}\\\\0&amp;0&amp;1&amp;\\frac{5}{7}&amp;\\frac{25}{7}\\end{bmatrix}\r\n\\]</span></p>\r\n<h4 id=\"例-2\">例 2</h4>\r\n<p>求矩阵 <span class=\"math inline\">\\(A=\\begin {bmatrix}\r\n2&amp;1&amp;-2&amp;3&amp;1\\\\2&amp;5&amp;-1&amp;4&amp;1\\\\1&amp;3&amp;-1&amp;2&amp;1\\end\r\n{bmatrix}\\)</span> 的满秩分解</p>\r\n<p><strong>解</strong>：对矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n只作初等行变换</p>\r\n<p><span class=\"math display\">\\[\r\nA=\\begin{bmatrix}2&amp;1&amp;-2&amp;3&amp;1\\\\2&amp;5&amp;-1&amp;4&amp;1\\\\1&amp;3&amp;-1&amp;2&amp;1\\end{bmatrix}\\to\r\n···\\to\r\n\\begin{bmatrix}1&amp;0&amp;0&amp;\\frac{8}{5}&amp;-\\frac{2}{5}\\\\0&amp;1&amp;0&amp;\\frac{1}{5}&amp;\\frac{1}{5}\\\\0&amp;0&amp;1&amp;\\frac{1}{5}&amp;-\\frac{4}{5}\\end{bmatrix}\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(A\\)</span> 的秩为\r\n3，且前三个列向量线性无关，故 <span class=\"math display\">\\[ B =\r\n\\begin{bmatrix}2&amp;1&amp;-2\\\\2&amp;5&amp;-1\\\\1&amp;3&amp;-1\\end{bmatrix},C\r\n=\r\n\\begin{bmatrix}1&amp;0&amp;0&amp;\\frac{8}{5}&amp;-\\frac{2}{5}\\\\0&amp;1&amp;0&amp;\\frac{1}{5}&amp;\\frac{1}{5}\\\\0&amp;0&amp;1&amp;\\frac{1}{5}&amp;-\\frac{4}{5}\\end{bmatrix}\r\n\\]</span></p>\r\n<h2 id=\"矩阵的lu分解\">矩阵的LU分解</h2>\r\n<p>LU 分解（LU\r\nDecomposition）是矩阵分解的一种，可以将一个矩阵分解为一个单位下三角矩阵和一个上三角矩阵的乘积，以四阶矩阵为例\r\n<span class=\"math display\">\\[ L =\r\n\\begin{bmatrix}1&amp;0&amp;0&amp;0\\\\*&amp;1&amp;0&amp;0\\\\*&amp;*&amp;1&amp;0\\\\*&amp;*&amp;*&amp;1\\end{bmatrix},\r\nU=\\begin{bmatrix}*&amp;*&amp;*&amp;*\\\\0&amp;*&amp;*&amp;*\\\\0&amp;0&amp;*&amp;*\\\\0&amp;0&amp;0&amp;*\\end{bmatrix}\r\n\\]</span></p>\r\n<p>LU 矩阵是否一定存在？答案是否，具体看下面的例子</p>\r\n<p>设 <span class=\"math inline\">\\(\\begin {bmatrix} 0&amp;1\\\\1&amp;0\\end\r\n{bmatrix}=\\begin {bmatrix} a&amp;0\\\\b&amp;c\\end {bmatrix}\\begin\r\n{bmatrix} l&amp;m\\\\0&amp;n\\end {bmatrix}\\)</span>，则应该满足如下 4\r\n个式子</p>\r\n<p><span class=\"math display\">\\[ \\begin{cases} al=0\\\\ am=1\\\\ bl=1\\\\\r\nbm+cn=0 \\end{cases} \\]</span></p>\r\n<p>由 <span class=\"math inline\">\\(al=0\\)</span> 得 <span\r\nclass=\"math inline\">\\(a=0\\)</span> 或 <span\r\nclass=\"math inline\">\\(l=0\\)</span>，但实际上这两种情况带入上面的式子都会推出矛盾，因此不是所有情况\r\nLU 分解都存在</p>\r\n<p><strong>LU 分解定理</strong> ：设 <span class=\"math inline\">\\(A\\in\r\n\\mathbb {C}_n^{n\\times n}\\)</span>，<span\r\nclass=\"math inline\">\\(A\\)</span> 有唯一的 LU 分解 <span\r\nclass=\"math inline\">\\(\\Leftrightarrow A\\)</span> 的各阶顺序主子式 <span\r\nclass=\"math inline\">\\(\\Delta k \\neq 0,\\ k=1,2...,n\\)</span></p>\r\n<p><span class=\"math inline\">\\(k\\)</span> 阶顺序主子式指的是矩阵左上角\r\n<span class=\"math inline\">\\(k\\times k\\)</span> 个元素组成的行列式</p>\r\n<p>将矩阵 <span class=\"math inline\">\\(A\\)</span> 分解为 <span\r\nclass=\"math inline\">\\(L\\)</span> 和 <span\r\nclass=\"math inline\">\\(U\\)</span> 之后，解方程组 <span\r\nclass=\"math inline\">\\(Ax=b\\)</span> 就变得简单了，因为 <span\r\nclass=\"math inline\">\\(A=LU\\)</span>，所以 <span\r\nclass=\"math inline\">\\((LU) x=b\\Rightarrow L (Ux)=b\\Rightarrow \\begin\r\n{cases} Ly=b\\\\Ux=y\\end {cases}\\)</span></p>\r\n<p>所以 <span class=\"math inline\">\\(x=U^{-1} y=U^{-1} L^{-1}\r\nb\\)</span></p>\r\n<h3 id=\"lu-矩阵的求法\">LU 矩阵的求法</h3>\r\n<p>实际上 LU 矩阵有非常多的求法，这里列举一种比较简单的待定系数法</p>\r\n<p>设 <span class=\"math inline\">\\(A = \\begin {bmatrix}\r\n2&amp;3&amp;4\\\\1&amp;1&amp;9\\\\1&amp;2&amp;-6\\end\r\n{bmatrix}\\)</span>，求矩阵 <span class=\"math inline\">\\(A\\)</span> 的 LU\r\n分解矩阵 <span class=\"math inline\">\\(L\\)</span> 和 <span\r\nclass=\"math inline\">\\(U\\)</span></p>\r\n<p><strong>解</strong>：令 <span class=\"math display\">\\[\r\nL=\\begin{bmatrix}1&amp;0&amp;0\\\\l_1&amp;1&amp;0\\\\l_2&amp;l_3&amp;1\\end{bmatrix},U\r\n=\r\n\\begin{bmatrix}u_1&amp;u_2&amp;u_3\\\\0&amp;u_4&amp;u_5\\\\0&amp;0&amp;u_6\\end{bmatrix}\r\n\\]</span></p>\r\n<p>由于 <span class=\"math inline\">\\(A=LU\\)</span>，所以有</p>\r\n<p><span class=\"math display\">\\[ \\begin{cases} u_1=2\\\\ u_2=3\\\\ u_3=4\\\\\r\nl_1u_1=1\\\\ l_1u_2+u_4=1\\\\ l_1u_3+u_5=9\\\\ l_2u_1=1\\\\ l_2u_2+l_3u_4=2\\\\\r\nl_2u_3+l_3u_5+u_6=-6 \\end{cases} \\]</span></p>\r\n<p>上面的方程组非常容易解，最后求出</p>\r\n<p><span class=\"math display\">\\[ L =\r\n\\begin{bmatrix}1&amp;0&amp;0\\\\\\frac{1}{2}&amp;1&amp;0\\\\\\frac{1}{2}&amp;-1&amp;1\\end{bmatrix},U=\\begin{bmatrix}2&amp;3&amp;4\\\\0&amp;-\\frac{1}{2}&amp;7\\\\0&amp;0&amp;-1\\end{bmatrix}\r\n\\]</span></p>\r\n","site":{"data":{}},"excerpt":"","more":"<!-- <link href=\"https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/KaTeX/0.10.2/katex.min.css\" rel=\"stylesheet\"> -->\r\n<h2 id=\"正交三角分解qr分解\">正交三角分解(QR分解)</h2>\r\n<h3 id=\"满秩矩阵的-qr-分解\">满秩矩阵的 QR 分解</h3>\r\n<p>若 <span class=\"math inline\">\\(n\\)</span> 阶实矩阵 <span\r\nclass=\"math inline\">\\(A\\in \\mathbb {C}^{n\\times n}\\)</span> 满秩，且\r\n<span class=\"math display\">\\[A = [\\alpha_1,...,\\alpha_n]\\]</span></p>\r\n<p>其中 <span class=\"math inline\">\\(\\alpha_1,...,\\alpha_n\\)</span> 是\r\n<span class=\"math inline\">\\(\\mathbb {C}^{n\\times n}\\)</span>\r\n中线性无关向量组</p>\r\n<p><strong>正交化</strong></p>\r\n<p>令</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} \\beta_1&amp;=\\alpha_1\\\\\r\n\\beta_2&amp;=\\alpha_2 -\r\n\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1\r\n\\\\ \\vdots \\\\ \\beta_n &amp;= \\alpha_n -\r\n\\frac{\\left&lt;\\beta_n,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1-\\cdots-\\frac{\\left&lt;\\beta_{n-1},\\alpha_n\\right&gt;}{\\left&lt;\\beta_{n-1},\\alpha_{n-1}\\right&gt;}\\beta_{n-1}\r\n\\end{aligned} \\]</span></p>\r\n<p>变形得</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} \\alpha_1 &amp;=\r\n\\beta_1\\\\ \\alpha_2 &amp;=\r\n\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1\r\n+ \\beta_2\\\\ \\vdots \\\\ \\alpha_n &amp;=\r\n\\frac{\\left&lt;\\beta_n,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\beta_1-\\cdots-\\frac{\\left&lt;\\beta_{n-1},\\alpha_n\\right&gt;}{\\left&lt;\\beta_{n-1},\\alpha_{n-1}\\right&gt;}\\beta_{n-1}\r\n+ \\beta_n \\end{aligned} \\]</span></p>\r\n<p>写成矩阵形式</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned}\r\n\\begin{bmatrix}\\alpha_1,\\alpha_2,...,\\alpha_n\\end{bmatrix} &amp;=\r\n\\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix}\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;\\triangleq\r\nB\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix} \\end{aligned}\r\n\\]</span></p>\r\n<p><strong>单位化</strong></p>\r\n<p>令</p>\r\n<p><span class=\"math display\">\\[ q_1=\\frac{\\beta_1}{||\\beta_1||}\\\\\r\n\\vdots \\\\ q_n = \\frac{\\beta_n}{||\\beta_n||} \\]</span></p>\r\n<p>变形得</p>\r\n<p><span class=\"math display\">\\[ \\beta_1 = q_1||\\beta_1||\\\\ \\vdots \\\\\r\n\\beta_n = q_n ||\\beta_n|| \\]</span></p>\r\n<p>写成矩阵形式</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned}\r\n\\begin{bmatrix}\\beta_1,\\beta_2,...,\\beta_n\\end{bmatrix} &amp;=\r\n\\begin{bmatrix}q_1,q_2,...,q_n\\end{bmatrix}\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\\\\\r\n&amp;\\triangleq Q\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\r\n\\end{aligned} \\]</span></p>\r\n<p>综上，结合正交化和单位化可得</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} A &amp;=\r\nB\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;=Q\\begin{bmatrix}||\\beta_1||&amp;0&amp;\\cdots\r\n&amp;0\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;0\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp;\r\n||\\beta_n||\\end{bmatrix}\\begin{bmatrix}1&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;1&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; 1\\end{bmatrix}\\\\\r\n&amp;=Q\\begin{bmatrix}||\\beta_1||&amp;\\frac{\\left&lt;\\beta_1,\\alpha_1\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}&amp;\\cdots\r\n&amp;\\frac{\\left&lt;\\beta_1,\\alpha_n\\right&gt;}{\\left&lt;\\beta_1,\\beta_1\\right&gt;}\\\\0&amp;||\\beta_2||&amp;\\cdots&amp;\\frac{\\left&lt;\\beta_2,\\alpha_n\\right&gt;}{\\left&lt;\\beta_2,\\beta_2\\right&gt;}\\\\\r\n&amp;&amp;\\ddots\\\\0&amp;&amp;\\cdots&amp; ||\\beta_n||\\end{bmatrix}\\\\\r\n&amp;\\triangleq QR \\end{aligned} \\]</span></p>\r\n<p><strong>QR 分解定理</strong> : <span class=\"math inline\">\\(A\\in\r\n\\mathbb {C}^{n\\times n}\\)</span> ,则存在酉矩阵 <span\r\nclass=\"math inline\">\\(Q\\)</span> 和正线上三角阵 <span\r\nclass=\"math inline\">\\(R\\)</span> ，使 <span\r\nclass=\"math display\">\\[A=QR\\]</span></p>\r\n<p>且分解唯一</p>\r\n<h3 id=\"qr-分解的求法\">QR 分解的求法</h3>\r\n<ol type=\"1\">\r\n<li>取矩阵 <span class=\"math inline\">\\(A=(A_1,A_2,...,A_n)\\)</span>\r\n的列向量，进行 <strong>Schmidt 标准正交化</strong>,得 <span\r\nclass=\"math inline\">\\(v_1,v_2,...,v_n\\)</span> ，有 <span\r\nclass=\"math display\">\\[Q=(v_1,v_2,...,v_n)\\]</span></li>\r\n<li>再由 <span class=\"math inline\">\\(R=Q^HA\\)</span> 得到 <span\r\nclass=\"math inline\">\\(R\\)</span> , 于是 <span\r\nclass=\"math inline\">\\(A=QR\\)</span></li>\r\n</ol>\r\n<h2 id=\"矩阵的满秩分解\">矩阵的满秩分解</h2>\r\n<p>设 <span class=\"math inline\">\\(A\\in \\mathbb {C}_r^{m\\times\r\nn}\\)</span>，则存在 <span class=\"math inline\">\\(B\\in \\mathbb\r\n{C}_r^{m\\times r}, C\\in \\mathbb {C}_r^{r\\times n}\\)</span>，满足 <span\r\nclass=\"math display\">\\[ A = BC \\]</span></p>\r\n<p><span class=\"math inline\">\\(\\mathbb {C}_r\\)</span> 表示矩阵的秩为\r\n<span class=\"math inline\">\\(r\\)</span></p>\r\n<p>实际上上述定理用文字描述就是，一个亏秩的矩阵可以分解成一个列满秩与行满秩矩阵的乘积</p>\r\n<p>证明：因为 <span class=\"math inline\">\\(rank\r\n(A)=r\\)</span>，所以一定可以找到与 <span\r\nclass=\"math inline\">\\(A\\)</span> 相似的一个矩阵</p>\r\n<p><span class=\"math display\">\\[ A \\simeq\r\n\\begin{bmatrix}E_r&amp;0_{r\\times (n-r)}\\\\0_{(m-r)\\times\r\nr}&amp;0_{(m-r)\\times\r\n(n-r)}\\end{bmatrix}=\\begin{bmatrix}E_r\\\\0_{(m-r)\\times\r\nr}\\end{bmatrix}\\begin{bmatrix}E_r&amp;0_{r\\times (n-r)}\\end{bmatrix}\r\n\\]</span></p>\r\n<p>因此存在两个可逆矩阵 <span class=\"math inline\">\\(P,Q\\)</span>，使\r\n<span class=\"math inline\">\\(PAQ=\\begin {bmatrix} E_r&amp;0\\\\0&amp;0\\end\r\n{bmatrix}\\)</span>，则</p>\r\n<p><span class=\"math display\">\\[ \\begin{aligned} A &amp;=\r\nP^{-1}\\begin{bmatrix}E_r\\\\0\\end{bmatrix}\\begin{bmatrix}E_r&amp;0\\end{bmatrix}Q^{-1}\\\\\r\n&amp;\\triangleq BC \\end{aligned} \\]</span></p>\r\n<p>因为 <span class=\"math inline\">\\(P^{-1}\\)</span> 是可逆矩阵，<span\r\nclass=\"math inline\">\\(\\begin {bmatrix} E_r\\\\0\\end {bmatrix}\\)</span>\r\n是一个列满秩矩阵，所以 <span class=\"math inline\">\\(B=P^{-1}\\begin\r\n{bmatrix} E_r\\\\0\\end {bmatrix}\\)</span> 仍是一个列满秩矩阵；同理，<span\r\nclass=\"math inline\">\\(C=\\begin {bmatrix} E_r&amp;0\\end {bmatrix}\r\nQ^{-1}\\)</span> 是一个行满秩矩阵</p>\r\n<h3 id=\"矩阵满秩分解的计算\">矩阵满秩分解的计算</h3>\r\n<p>如何在给定矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n的情况下，求出矩阵 <span class=\"math inline\">\\(B,C\\)</span> 呢？</p>\r\n<p>设</p>\r\n<p><span class=\"math display\">\\[ A = [\\alpha_1,\\alpha_2,...,\\alpha_n]\\\\\r\nB = [\\beta_1,\\beta_2,...,\\beta_r]\\]</span></p>\r\n<p>其中 _1,...,_r 线性无关</p>\r\n<p>所以 <span class=\"math display\">\\[ \\begin{aligned} &amp;A=BC\\\\\r\n&amp;\\Rightarrow[\\alpha_1,\\alpha_2,...,\\alpha_n]=[\\beta_1,...,\\beta_r]\\begin{bmatrix}c_{11}&amp;\\cdots\r\n&amp;c_{1n}\\\\\\vdots &amp;\\ddots&amp;\\vdots\\\\c_{r1}&amp;\\cdots\r\n&amp;c_{rn}\\end{bmatrix} \\end{aligned} \\]</span></p>\r\n<p>实际上我们可以取 <span\r\nclass=\"math inline\">\\(\\beta_1,...,\\beta_r\\)</span> 为 <span\r\nclass=\"math inline\">\\(\\alpha_1,...,\\alpha_n\\)</span>\r\n的一个极大线性无关组，因此 <span class=\"math inline\">\\(B\\)</span>\r\n就是矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n列向量组的一个极大线性无关组，<span class=\"math inline\">\\(C\\)</span>\r\n就是用该线性无关组去表示 <span class=\"math inline\">\\(A\\)</span>\r\n时的系数</p>\r\n<h4 id=\"例-1\">例 1</h4>\r\n<p>求矩阵 <span class=\"math inline\">\\(A=\\begin {bmatrix}\r\n1&amp;4&amp;-1&amp;5&amp;6\\\\2&amp;0&amp;0&amp;0&amp;-14\\\\-1&amp;2&amp;-4&amp;0&amp;1\\\\2&amp;6&amp;-5&amp;5&amp;-7\\end\r\n{bmatrix}\\)</span> 的满秩分解</p>\r\n<p><strong>解</strong>：对矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n只作初等行变换 <span class=\"math display\">\\[\r\nA=\\begin{bmatrix}1&amp;4&amp;-1&amp;5&amp;6\\\\2&amp;0&amp;0&amp;0&amp;-14\\\\-1&amp;2&amp;-4&amp;0&amp;1\\\\2&amp;6&amp;-5&amp;5&amp;-7\\end{bmatrix}\\to\r\n···\\to\\begin{bmatrix}1&amp;0&amp;0&amp;0&amp;-7\\\\0&amp;1&amp;0&amp;\\frac{10}{7}&amp;\\frac{29}{7}\\\\0&amp;0&amp;1&amp;\\frac{5}{7}&amp;\\frac{25}{7}\\\\0&amp;0&amp;0&amp;0&amp;0\\end{bmatrix}\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(A\\)</span> 的秩为\r\n3，且前三个列向量线性无关，故 <span class=\"math display\">\\[ B =\r\n\\begin{bmatrix}1&amp;4&amp;-1\\\\2&amp;0&amp;0\\\\-1&amp;2&amp;-4\\\\2&amp;6&amp;-5\\end{bmatrix}，C=\\begin{bmatrix}1&amp;0&amp;0&amp;0&amp;-7\\\\0&amp;1&amp;0&amp;\\frac{10}{7}&amp;\\frac{29}{7}\\\\0&amp;0&amp;1&amp;\\frac{5}{7}&amp;\\frac{25}{7}\\end{bmatrix}\r\n\\]</span></p>\r\n<h4 id=\"例-2\">例 2</h4>\r\n<p>求矩阵 <span class=\"math inline\">\\(A=\\begin {bmatrix}\r\n2&amp;1&amp;-2&amp;3&amp;1\\\\2&amp;5&amp;-1&amp;4&amp;1\\\\1&amp;3&amp;-1&amp;2&amp;1\\end\r\n{bmatrix}\\)</span> 的满秩分解</p>\r\n<p><strong>解</strong>：对矩阵 <span class=\"math inline\">\\(A\\)</span>\r\n只作初等行变换</p>\r\n<p><span class=\"math display\">\\[\r\nA=\\begin{bmatrix}2&amp;1&amp;-2&amp;3&amp;1\\\\2&amp;5&amp;-1&amp;4&amp;1\\\\1&amp;3&amp;-1&amp;2&amp;1\\end{bmatrix}\\to\r\n···\\to\r\n\\begin{bmatrix}1&amp;0&amp;0&amp;\\frac{8}{5}&amp;-\\frac{2}{5}\\\\0&amp;1&amp;0&amp;\\frac{1}{5}&amp;\\frac{1}{5}\\\\0&amp;0&amp;1&amp;\\frac{1}{5}&amp;-\\frac{4}{5}\\end{bmatrix}\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(A\\)</span> 的秩为\r\n3，且前三个列向量线性无关，故 <span class=\"math display\">\\[ B =\r\n\\begin{bmatrix}2&amp;1&amp;-2\\\\2&amp;5&amp;-1\\\\1&amp;3&amp;-1\\end{bmatrix},C\r\n=\r\n\\begin{bmatrix}1&amp;0&amp;0&amp;\\frac{8}{5}&amp;-\\frac{2}{5}\\\\0&amp;1&amp;0&amp;\\frac{1}{5}&amp;\\frac{1}{5}\\\\0&amp;0&amp;1&amp;\\frac{1}{5}&amp;-\\frac{4}{5}\\end{bmatrix}\r\n\\]</span></p>\r\n<h2 id=\"矩阵的lu分解\">矩阵的LU分解</h2>\r\n<p>LU 分解（LU\r\nDecomposition）是矩阵分解的一种，可以将一个矩阵分解为一个单位下三角矩阵和一个上三角矩阵的乘积，以四阶矩阵为例\r\n<span class=\"math display\">\\[ L =\r\n\\begin{bmatrix}1&amp;0&amp;0&amp;0\\\\*&amp;1&amp;0&amp;0\\\\*&amp;*&amp;1&amp;0\\\\*&amp;*&amp;*&amp;1\\end{bmatrix},\r\nU=\\begin{bmatrix}*&amp;*&amp;*&amp;*\\\\0&amp;*&amp;*&amp;*\\\\0&amp;0&amp;*&amp;*\\\\0&amp;0&amp;0&amp;*\\end{bmatrix}\r\n\\]</span></p>\r\n<p>LU 矩阵是否一定存在？答案是否，具体看下面的例子</p>\r\n<p>设 <span class=\"math inline\">\\(\\begin {bmatrix} 0&amp;1\\\\1&amp;0\\end\r\n{bmatrix}=\\begin {bmatrix} a&amp;0\\\\b&amp;c\\end {bmatrix}\\begin\r\n{bmatrix} l&amp;m\\\\0&amp;n\\end {bmatrix}\\)</span>，则应该满足如下 4\r\n个式子</p>\r\n<p><span class=\"math display\">\\[ \\begin{cases} al=0\\\\ am=1\\\\ bl=1\\\\\r\nbm+cn=0 \\end{cases} \\]</span></p>\r\n<p>由 <span class=\"math inline\">\\(al=0\\)</span> 得 <span\r\nclass=\"math inline\">\\(a=0\\)</span> 或 <span\r\nclass=\"math inline\">\\(l=0\\)</span>，但实际上这两种情况带入上面的式子都会推出矛盾，因此不是所有情况\r\nLU 分解都存在</p>\r\n<p><strong>LU 分解定理</strong> ：设 <span class=\"math inline\">\\(A\\in\r\n\\mathbb {C}_n^{n\\times n}\\)</span>，<span\r\nclass=\"math inline\">\\(A\\)</span> 有唯一的 LU 分解 <span\r\nclass=\"math inline\">\\(\\Leftrightarrow A\\)</span> 的各阶顺序主子式 <span\r\nclass=\"math inline\">\\(\\Delta k \\neq 0,\\ k=1,2...,n\\)</span></p>\r\n<p><span class=\"math inline\">\\(k\\)</span> 阶顺序主子式指的是矩阵左上角\r\n<span class=\"math inline\">\\(k\\times k\\)</span> 个元素组成的行列式</p>\r\n<p>将矩阵 <span class=\"math inline\">\\(A\\)</span> 分解为 <span\r\nclass=\"math inline\">\\(L\\)</span> 和 <span\r\nclass=\"math inline\">\\(U\\)</span> 之后，解方程组 <span\r\nclass=\"math inline\">\\(Ax=b\\)</span> 就变得简单了，因为 <span\r\nclass=\"math inline\">\\(A=LU\\)</span>，所以 <span\r\nclass=\"math inline\">\\((LU) x=b\\Rightarrow L (Ux)=b\\Rightarrow \\begin\r\n{cases} Ly=b\\\\Ux=y\\end {cases}\\)</span></p>\r\n<p>所以 <span class=\"math inline\">\\(x=U^{-1} y=U^{-1} L^{-1}\r\nb\\)</span></p>\r\n<h3 id=\"lu-矩阵的求法\">LU 矩阵的求法</h3>\r\n<p>实际上 LU 矩阵有非常多的求法，这里列举一种比较简单的待定系数法</p>\r\n<p>设 <span class=\"math inline\">\\(A = \\begin {bmatrix}\r\n2&amp;3&amp;4\\\\1&amp;1&amp;9\\\\1&amp;2&amp;-6\\end\r\n{bmatrix}\\)</span>，求矩阵 <span class=\"math inline\">\\(A\\)</span> 的 LU\r\n分解矩阵 <span class=\"math inline\">\\(L\\)</span> 和 <span\r\nclass=\"math inline\">\\(U\\)</span></p>\r\n<p><strong>解</strong>：令 <span class=\"math display\">\\[\r\nL=\\begin{bmatrix}1&amp;0&amp;0\\\\l_1&amp;1&amp;0\\\\l_2&amp;l_3&amp;1\\end{bmatrix},U\r\n=\r\n\\begin{bmatrix}u_1&amp;u_2&amp;u_3\\\\0&amp;u_4&amp;u_5\\\\0&amp;0&amp;u_6\\end{bmatrix}\r\n\\]</span></p>\r\n<p>由于 <span class=\"math inline\">\\(A=LU\\)</span>，所以有</p>\r\n<p><span class=\"math display\">\\[ \\begin{cases} u_1=2\\\\ u_2=3\\\\ u_3=4\\\\\r\nl_1u_1=1\\\\ l_1u_2+u_4=1\\\\ l_1u_3+u_5=9\\\\ l_2u_1=1\\\\ l_2u_2+l_3u_4=2\\\\\r\nl_2u_3+l_3u_5+u_6=-6 \\end{cases} \\]</span></p>\r\n<p>上面的方程组非常容易解，最后求出</p>\r\n<p><span class=\"math display\">\\[ L =\r\n\\begin{bmatrix}1&amp;0&amp;0\\\\\\frac{1}{2}&amp;1&amp;0\\\\\\frac{1}{2}&amp;-1&amp;1\\end{bmatrix},U=\\begin{bmatrix}2&amp;3&amp;4\\\\0&amp;-\\frac{1}{2}&amp;7\\\\0&amp;0&amp;-1\\end{bmatrix}\r\n\\]</span></p>\r\n"},{"title":"胜者树与败者树","math":true,"_content":"\n胜者树与败者树是完全二叉树。就像是参加比赛一样，每个选手有不同的实力，两个选手PK,实力决定胜负，晋级下一轮，经过几轮之后，就能得到冠军。不同的是，胜者树的中间结点记录的是胜者的标号；而败者树的中间结点记录的败者的标号。 胜者树与败者树可以在log(n)的时间内找到最值。任何一个叶子结点的值改变后，利用中间结点的信息，还是能够快速地找到最值。在k路归并排序中经常用到。\n\n\n## 胜者树\n胜者树的一个优点是，如果一个选手的值改变了，可以很容易地修改这棵胜者树。只需要沿着从该结点到根结点的路径修改这棵二叉树，而不必改变其他比赛的结果。\n\n![fig1](/img/胜者树败者树/fig1.jpg)\n\n上图是一个胜者树的示例。规定数值小者胜。\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；\n2. b3 PK b0，b3胜b0负，内部结点ls[2]的值为3；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；\n4. b3 PK b1，b3胜b1负，内部结点ls[1]的值为3。\n\n取出胜者b3之后，叶子结点b3的值变为11时，重构的胜者树如下:\n\n![fig2](/img/胜者树败者树/fig2.jpg)\n\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；\n2. b3 PK b0，b0胜b3负，内部结点ls[2]的值为0；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；\n4. b0 PK b1，b1胜b0负，内部结点ls[1]的值为1。\n\n用胜者树对n个节点实现排序操作，构建胜者树和构建堆比较相似，区别在于胜者树只有叶子节点存放了数据，中间节点记录的是叶子节点间的关系。\n\n胜者树在每次重构时只需与其兄弟结点比较，一直到根节点选出胜者为止。\n\n## 败者树\n败者树是胜者树的一种变体。在败者树中，用父结点记录其左右子结点进行比赛的败者，而让胜者参加下一轮的比赛。败者树的根结点记录的是败者，需要加一个结点来记录整个比赛的胜利者。采用败者树可以简化重构的过程。\n\n![fig3](/img/胜者树败者树/fig3.jpg)\n\n上图是一棵败者树。规定数大者败。\n\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为4；\n2. b3 PK b0，b3胜b0负，内部结点ls[2]的值为0；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为2；\n4. b3 PK b1，b3胜b1负，内部结点ls[1]的值为1；\n\n败者树重构过程如下：\n- 将新进入选择树的结点与其父结点进行比赛：将败者存放在父结点中；而胜者再与上一级的父结点比较。\n- 比赛沿着到根结点的路径不断进行，直到ls[1]处。把败者存放在结点ls[1]中，胜者存放在ls[0]中。\n\n![fig4](/img/胜者树败者树/fig4.jpg)\n\n## 胜者树、败者树、堆比较\n### 相同点  \n这三者空间和时间复杂度都是一样的。调整一次的时间复杂度都是O(logN)的。\n\n### 不同点\n一开始就是只有堆来完成多路归并的，但是人们发现堆每次取出最小值之后，把最后一个数放到堆顶，**调整堆的时候，每次都要选出父结点的两个孩子节点的最小值，然后再用孩子结点的最小值和父节点进行比较，所以每调整一层需要比较两次**。\n\n这时人们想能否简化比较过程，这时就有了胜者树。这样**每次比较只用跟自己的兄弟结点进行比较就好**，所以用胜者树可以比堆少一半的比较次数。\n\n而**胜者树想要比较兄弟结点首先要获得其父结点，也就是说需要访存两次**，这时人们又想能否再次减少比较次数，于是就有了败者树。败者树每个新元素上升时，**只需要获得父节点并比较即可**。\n\n总的来说，败者树与胜者树相比减少了访存时间。**现在程序的主要瓶颈在于访存了，计算倒几乎可以忽略不计了**。\n\n## 参考\n1. [胜者树和败者树](https://www.cnblogs.com/qianye/archive/2012/11/25/2787923.html#:~:text=%E8%83%9C%E8%80%85%E6%A0%91%E5%92%8C%E8%B4%A5%E8%80%85%E6%A0%91%E9%83%BD%E6%98%AF%E5%AE%8C%E5%85%A8,%E6%97%B6%E9%97%B4%E5%86%85%E6%89%BE%E5%88%B0%E6%9C%80%E5%80%BC%E3%80%82)\n2. [堆，赢者树，败者树的区别与联系](https://blog.csdn.net/haolexiao/article/details/53488314)\n\n","source":"_posts/胜者树败者树.md","raw":"---\ntitle: 胜者树与败者树\ntags: 算法\nmath: true\n---\n\n胜者树与败者树是完全二叉树。就像是参加比赛一样，每个选手有不同的实力，两个选手PK,实力决定胜负，晋级下一轮，经过几轮之后，就能得到冠军。不同的是，胜者树的中间结点记录的是胜者的标号；而败者树的中间结点记录的败者的标号。 胜者树与败者树可以在log(n)的时间内找到最值。任何一个叶子结点的值改变后，利用中间结点的信息，还是能够快速地找到最值。在k路归并排序中经常用到。\n\n\n## 胜者树\n胜者树的一个优点是，如果一个选手的值改变了，可以很容易地修改这棵胜者树。只需要沿着从该结点到根结点的路径修改这棵二叉树，而不必改变其他比赛的结果。\n\n![fig1](/img/胜者树败者树/fig1.jpg)\n\n上图是一个胜者树的示例。规定数值小者胜。\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；\n2. b3 PK b0，b3胜b0负，内部结点ls[2]的值为3；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；\n4. b3 PK b1，b3胜b1负，内部结点ls[1]的值为3。\n\n取出胜者b3之后，叶子结点b3的值变为11时，重构的胜者树如下:\n\n![fig2](/img/胜者树败者树/fig2.jpg)\n\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；\n2. b3 PK b0，b0胜b3负，内部结点ls[2]的值为0；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；\n4. b0 PK b1，b1胜b0负，内部结点ls[1]的值为1。\n\n用胜者树对n个节点实现排序操作，构建胜者树和构建堆比较相似，区别在于胜者树只有叶子节点存放了数据，中间节点记录的是叶子节点间的关系。\n\n胜者树在每次重构时只需与其兄弟结点比较，一直到根节点选出胜者为止。\n\n## 败者树\n败者树是胜者树的一种变体。在败者树中，用父结点记录其左右子结点进行比赛的败者，而让胜者参加下一轮的比赛。败者树的根结点记录的是败者，需要加一个结点来记录整个比赛的胜利者。采用败者树可以简化重构的过程。\n\n![fig3](/img/胜者树败者树/fig3.jpg)\n\n上图是一棵败者树。规定数大者败。\n\n1. b3 PK b4，b3胜b4负，内部结点ls[4]的值为4；\n2. b3 PK b0，b3胜b0负，内部结点ls[2]的值为0；\n3. b1 PK b2，b1胜b2负，内部结点ls[3]的值为2；\n4. b3 PK b1，b3胜b1负，内部结点ls[1]的值为1；\n\n败者树重构过程如下：\n- 将新进入选择树的结点与其父结点进行比赛：将败者存放在父结点中；而胜者再与上一级的父结点比较。\n- 比赛沿着到根结点的路径不断进行，直到ls[1]处。把败者存放在结点ls[1]中，胜者存放在ls[0]中。\n\n![fig4](/img/胜者树败者树/fig4.jpg)\n\n## 胜者树、败者树、堆比较\n### 相同点  \n这三者空间和时间复杂度都是一样的。调整一次的时间复杂度都是O(logN)的。\n\n### 不同点\n一开始就是只有堆来完成多路归并的，但是人们发现堆每次取出最小值之后，把最后一个数放到堆顶，**调整堆的时候，每次都要选出父结点的两个孩子节点的最小值，然后再用孩子结点的最小值和父节点进行比较，所以每调整一层需要比较两次**。\n\n这时人们想能否简化比较过程，这时就有了胜者树。这样**每次比较只用跟自己的兄弟结点进行比较就好**，所以用胜者树可以比堆少一半的比较次数。\n\n而**胜者树想要比较兄弟结点首先要获得其父结点，也就是说需要访存两次**，这时人们又想能否再次减少比较次数，于是就有了败者树。败者树每个新元素上升时，**只需要获得父节点并比较即可**。\n\n总的来说，败者树与胜者树相比减少了访存时间。**现在程序的主要瓶颈在于访存了，计算倒几乎可以忽略不计了**。\n\n## 参考\n1. [胜者树和败者树](https://www.cnblogs.com/qianye/archive/2012/11/25/2787923.html#:~:text=%E8%83%9C%E8%80%85%E6%A0%91%E5%92%8C%E8%B4%A5%E8%80%85%E6%A0%91%E9%83%BD%E6%98%AF%E5%AE%8C%E5%85%A8,%E6%97%B6%E9%97%B4%E5%86%85%E6%89%BE%E5%88%B0%E6%9C%80%E5%80%BC%E3%80%82)\n2. [堆，赢者树，败者树的区别与联系](https://blog.csdn.net/haolexiao/article/details/53488314)\n\n","slug":"胜者树败者树","published":1,"date":"2022-12-02T04:31:08.731Z","updated":"2022-12-03T15:57:36.104Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clb8pvot2000ozgsg7y8139n2","content":"<p>胜者树与败者树是完全二叉树。就像是参加比赛一样，每个选手有不同的实力，两个选手PK,实力决定胜负，晋级下一轮，经过几轮之后，就能得到冠军。不同的是，胜者树的中间结点记录的是胜者的标号；而败者树的中间结点记录的败者的标号。\r\n胜者树与败者树可以在log(n)的时间内找到最值。任何一个叶子结点的值改变后，利用中间结点的信息，还是能够快速地找到最值。在k路归并排序中经常用到。</p>\r\n<h2 id=\"胜者树\">胜者树</h2>\r\n<p>胜者树的一个优点是，如果一个选手的值改变了，可以很容易地修改这棵胜者树。只需要沿着从该结点到根结点的路径修改这棵二叉树，而不必改变其他比赛的结果。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig1.jpg\" alt=\"fig1\" />\r\n<figcaption aria-hidden=\"true\">fig1</figcaption>\r\n</figure>\r\n<p>上图是一个胜者树的示例。规定数值小者胜。 1. b3 PK\r\nb4，b3胜b4负，内部结点ls[4]的值为3； 2. b3 PK\r\nb0，b3胜b0负，内部结点ls[2]的值为3； 3. b1 PK\r\nb2，b1胜b2负，内部结点ls[3]的值为1； 4. b3 PK\r\nb1，b3胜b1负，内部结点ls[1]的值为3。</p>\r\n<p>取出胜者b3之后，叶子结点b3的值变为11时，重构的胜者树如下:</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig2.jpg\" alt=\"fig2\" />\r\n<figcaption aria-hidden=\"true\">fig2</figcaption>\r\n</figure>\r\n<ol type=\"1\">\r\n<li>b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；</li>\r\n<li>b3 PK b0，b0胜b3负，内部结点ls[2]的值为0；</li>\r\n<li>b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；</li>\r\n<li>b0 PK b1，b1胜b0负，内部结点ls[1]的值为1。</li>\r\n</ol>\r\n<p>用胜者树对n个节点实现排序操作，构建胜者树和构建堆比较相似，区别在于胜者树只有叶子节点存放了数据，中间节点记录的是叶子节点间的关系。</p>\r\n<p>胜者树在每次重构时只需与其兄弟结点比较，一直到根节点选出胜者为止。</p>\r\n<h2 id=\"败者树\">败者树</h2>\r\n<p>败者树是胜者树的一种变体。在败者树中，用父结点记录其左右子结点进行比赛的败者，而让胜者参加下一轮的比赛。败者树的根结点记录的是败者，需要加一个结点来记录整个比赛的胜利者。采用败者树可以简化重构的过程。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig3.jpg\" alt=\"fig3\" />\r\n<figcaption aria-hidden=\"true\">fig3</figcaption>\r\n</figure>\r\n<p>上图是一棵败者树。规定数大者败。</p>\r\n<ol type=\"1\">\r\n<li>b3 PK b4，b3胜b4负，内部结点ls[4]的值为4；</li>\r\n<li>b3 PK b0，b3胜b0负，内部结点ls[2]的值为0；</li>\r\n<li>b1 PK b2，b1胜b2负，内部结点ls[3]的值为2；</li>\r\n<li>b3 PK b1，b3胜b1负，内部结点ls[1]的值为1；</li>\r\n</ol>\r\n<p>败者树重构过程如下： -\r\n将新进入选择树的结点与其父结点进行比赛：将败者存放在父结点中；而胜者再与上一级的父结点比较。\r\n-\r\n比赛沿着到根结点的路径不断进行，直到ls[1]处。把败者存放在结点ls[1]中，胜者存放在ls[0]中。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig4.jpg\" alt=\"fig4\" />\r\n<figcaption aria-hidden=\"true\">fig4</figcaption>\r\n</figure>\r\n<h2 id=\"胜者树败者树堆比较\">胜者树、败者树、堆比较</h2>\r\n<h3 id=\"相同点\">相同点</h3>\r\n<p>这三者空间和时间复杂度都是一样的。调整一次的时间复杂度都是O(logN)的。</p>\r\n<h3 id=\"不同点\">不同点</h3>\r\n<p>一开始就是只有堆来完成多路归并的，但是人们发现堆每次取出最小值之后，把最后一个数放到堆顶，<strong>调整堆的时候，每次都要选出父结点的两个孩子节点的最小值，然后再用孩子结点的最小值和父节点进行比较，所以每调整一层需要比较两次</strong>。</p>\r\n<p>这时人们想能否简化比较过程，这时就有了胜者树。这样<strong>每次比较只用跟自己的兄弟结点进行比较就好</strong>，所以用胜者树可以比堆少一半的比较次数。</p>\r\n<p>而<strong>胜者树想要比较兄弟结点首先要获得其父结点，也就是说需要访存两次</strong>，这时人们又想能否再次减少比较次数，于是就有了败者树。败者树每个新元素上升时，<strong>只需要获得父节点并比较即可</strong>。</p>\r\n<p>总的来说，败者树与胜者树相比减少了访存时间。<strong>现在程序的主要瓶颈在于访存了，计算倒几乎可以忽略不计了</strong>。</p>\r\n<h2 id=\"参考\">参考</h2>\r\n<ol type=\"1\">\r\n<li><a\r\nhref=\"https://www.cnblogs.com/qianye/archive/2012/11/25/2787923.html#:~:text=%E8%83%9C%E8%80%85%E6%A0%91%E5%92%8C%E8%B4%A5%E8%80%85%E6%A0%91%E9%83%BD%E6%98%AF%E5%AE%8C%E5%85%A8,%E6%97%B6%E9%97%B4%E5%86%85%E6%89%BE%E5%88%B0%E6%9C%80%E5%80%BC%E3%80%82\">胜者树和败者树</a></li>\r\n<li><a\r\nhref=\"https://blog.csdn.net/haolexiao/article/details/53488314\">堆，赢者树，败者树的区别与联系</a></li>\r\n</ol>\r\n","site":{"data":{}},"excerpt":"","more":"<p>胜者树与败者树是完全二叉树。就像是参加比赛一样，每个选手有不同的实力，两个选手PK,实力决定胜负，晋级下一轮，经过几轮之后，就能得到冠军。不同的是，胜者树的中间结点记录的是胜者的标号；而败者树的中间结点记录的败者的标号。\r\n胜者树与败者树可以在log(n)的时间内找到最值。任何一个叶子结点的值改变后，利用中间结点的信息，还是能够快速地找到最值。在k路归并排序中经常用到。</p>\r\n<h2 id=\"胜者树\">胜者树</h2>\r\n<p>胜者树的一个优点是，如果一个选手的值改变了，可以很容易地修改这棵胜者树。只需要沿着从该结点到根结点的路径修改这棵二叉树，而不必改变其他比赛的结果。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig1.jpg\" alt=\"fig1\" />\r\n<figcaption aria-hidden=\"true\">fig1</figcaption>\r\n</figure>\r\n<p>上图是一个胜者树的示例。规定数值小者胜。 1. b3 PK\r\nb4，b3胜b4负，内部结点ls[4]的值为3； 2. b3 PK\r\nb0，b3胜b0负，内部结点ls[2]的值为3； 3. b1 PK\r\nb2，b1胜b2负，内部结点ls[3]的值为1； 4. b3 PK\r\nb1，b3胜b1负，内部结点ls[1]的值为3。</p>\r\n<p>取出胜者b3之后，叶子结点b3的值变为11时，重构的胜者树如下:</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig2.jpg\" alt=\"fig2\" />\r\n<figcaption aria-hidden=\"true\">fig2</figcaption>\r\n</figure>\r\n<ol type=\"1\">\r\n<li>b3 PK b4，b3胜b4负，内部结点ls[4]的值为3；</li>\r\n<li>b3 PK b0，b0胜b3负，内部结点ls[2]的值为0；</li>\r\n<li>b1 PK b2，b1胜b2负，内部结点ls[3]的值为1；</li>\r\n<li>b0 PK b1，b1胜b0负，内部结点ls[1]的值为1。</li>\r\n</ol>\r\n<p>用胜者树对n个节点实现排序操作，构建胜者树和构建堆比较相似，区别在于胜者树只有叶子节点存放了数据，中间节点记录的是叶子节点间的关系。</p>\r\n<p>胜者树在每次重构时只需与其兄弟结点比较，一直到根节点选出胜者为止。</p>\r\n<h2 id=\"败者树\">败者树</h2>\r\n<p>败者树是胜者树的一种变体。在败者树中，用父结点记录其左右子结点进行比赛的败者，而让胜者参加下一轮的比赛。败者树的根结点记录的是败者，需要加一个结点来记录整个比赛的胜利者。采用败者树可以简化重构的过程。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig3.jpg\" alt=\"fig3\" />\r\n<figcaption aria-hidden=\"true\">fig3</figcaption>\r\n</figure>\r\n<p>上图是一棵败者树。规定数大者败。</p>\r\n<ol type=\"1\">\r\n<li>b3 PK b4，b3胜b4负，内部结点ls[4]的值为4；</li>\r\n<li>b3 PK b0，b3胜b0负，内部结点ls[2]的值为0；</li>\r\n<li>b1 PK b2，b1胜b2负，内部结点ls[3]的值为2；</li>\r\n<li>b3 PK b1，b3胜b1负，内部结点ls[1]的值为1；</li>\r\n</ol>\r\n<p>败者树重构过程如下： -\r\n将新进入选择树的结点与其父结点进行比赛：将败者存放在父结点中；而胜者再与上一级的父结点比较。\r\n-\r\n比赛沿着到根结点的路径不断进行，直到ls[1]处。把败者存放在结点ls[1]中，胜者存放在ls[0]中。</p>\r\n<figure>\r\n<img src=\"/img/胜者树败者树/fig4.jpg\" alt=\"fig4\" />\r\n<figcaption aria-hidden=\"true\">fig4</figcaption>\r\n</figure>\r\n<h2 id=\"胜者树败者树堆比较\">胜者树、败者树、堆比较</h2>\r\n<h3 id=\"相同点\">相同点</h3>\r\n<p>这三者空间和时间复杂度都是一样的。调整一次的时间复杂度都是O(logN)的。</p>\r\n<h3 id=\"不同点\">不同点</h3>\r\n<p>一开始就是只有堆来完成多路归并的，但是人们发现堆每次取出最小值之后，把最后一个数放到堆顶，<strong>调整堆的时候，每次都要选出父结点的两个孩子节点的最小值，然后再用孩子结点的最小值和父节点进行比较，所以每调整一层需要比较两次</strong>。</p>\r\n<p>这时人们想能否简化比较过程，这时就有了胜者树。这样<strong>每次比较只用跟自己的兄弟结点进行比较就好</strong>，所以用胜者树可以比堆少一半的比较次数。</p>\r\n<p>而<strong>胜者树想要比较兄弟结点首先要获得其父结点，也就是说需要访存两次</strong>，这时人们又想能否再次减少比较次数，于是就有了败者树。败者树每个新元素上升时，<strong>只需要获得父节点并比较即可</strong>。</p>\r\n<p>总的来说，败者树与胜者树相比减少了访存时间。<strong>现在程序的主要瓶颈在于访存了，计算倒几乎可以忽略不计了</strong>。</p>\r\n<h2 id=\"参考\">参考</h2>\r\n<ol type=\"1\">\r\n<li><a\r\nhref=\"https://www.cnblogs.com/qianye/archive/2012/11/25/2787923.html#:~:text=%E8%83%9C%E8%80%85%E6%A0%91%E5%92%8C%E8%B4%A5%E8%80%85%E6%A0%91%E9%83%BD%E6%98%AF%E5%AE%8C%E5%85%A8,%E6%97%B6%E9%97%B4%E5%86%85%E6%89%BE%E5%88%B0%E6%9C%80%E5%80%BC%E3%80%82\">胜者树和败者树</a></li>\r\n<li><a\r\nhref=\"https://blog.csdn.net/haolexiao/article/details/53488314\">堆，赢者树，败者树的区别与联系</a></li>\r\n</ol>\r\n"}],"PostAsset":[],"PostCategory":[{"post_id":"clb8pvosu0002zgsgbj5p58hw","category_id":"clb8pvosx0004zgsgfrip20v4","_id":"clb8pvot1000ezgsg2nt217n1"},{"post_id":"clb8pvosw0003zgsgagryegrv","category_id":"clb8pvosx0004zgsgfrip20v4","_id":"clb8pvot1000izgsg4qdsb40m"},{"post_id":"clb8pvosy0006zgsg69na7ji0","category_id":"clb8pvosx0004zgsgfrip20v4","_id":"clb8pvot2000lzgsggscy6797"},{"post_id":"clb8pvosz0008zgsg75dy67w4","category_id":"clb8pvot1000hzgsg76poawec","_id":"clb8pvot2000nzgsgfyakc7p7"}],"PostTag":[{"post_id":"clb8pvosy0007zgsgfdvncuyr","tag_id":"clb8pvosy0005zgsggm0igbv6","_id":"clb8pvot0000bzgsg4zeu84oh"},{"post_id":"clb8pvosu0002zgsgbj5p58hw","tag_id":"clb8pvosy0005zgsggm0igbv6","_id":"clb8pvot1000czgsg9m9k65bk"},{"post_id":"clb8pvosw0003zgsgagryegrv","tag_id":"clb8pvosz000azgsg6woc2z5l","_id":"clb8pvot1000gzgsg92e61wts"},{"post_id":"clb8pvosy0006zgsg69na7ji0","tag_id":"clb8pvosz000azgsg6woc2z5l","_id":"clb8pvot2000kzgsge6o9fbsw"},{"post_id":"clb8pvosz0008zgsg75dy67w4","tag_id":"clb8pvot1000jzgsg2k5keese","_id":"clb8pvot2000mzgsgc6j8dnts"},{"post_id":"clb8pvot2000ozgsg7y8139n2","tag_id":"clb8pvosy0005zgsggm0igbv6","_id":"clb8pvot3000pzgsg9jodexv8"}],"Tag":[{"name":"算法","_id":"clb8pvosy0005zgsggm0igbv6"},{"name":"高级算法设计与分析","_id":"clb8pvosz000azgsg6woc2z5l"},{"name":"矩阵论","_id":"clb8pvot1000jzgsg2k5keese"}]}}